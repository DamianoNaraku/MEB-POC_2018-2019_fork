[2019-01-25 10:23:08,449] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-01-25 10:23:08,449] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-25 10:23:08,449] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-25 10:23:08,449] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-25 10:23:08,449] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-01-25 10:23:08,480] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-01-25 10:23:08,480] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-01-25 10:23:13,136] INFO Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 10:23:13,136] INFO Server environment:host.name=ITdif (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 10:23:13,136] INFO Server environment:java.version=1.8.0_181 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 10:23:13,136] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 10:23:13,136] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_181 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 10:23:13,136] INFO Server environment:java.class.path=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-connect-jdbc-5.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\mysql-connector-java-8.0.13.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 10:23:13,136] INFO Server environment:java.library.path=C:\Program Files\Java\jre1.8.0_181\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Docker\Docker\Resources\bin;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\Scripts\;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\dotnet\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\NoteBook FanControl\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\extras\CUPTI\libx64;C:\tools\cuda\bin;C:\Program Files\PuTTY\;C:\Program Files\Calibre2\;C:\apache-maven-3.6.\bin;C:\Users\Stefano\Downloads\platform-tools_r28.0.1-windows\platform-tools;C:\Program Files\Java\jre1.8.0_181\bin;C:\Users\Stefano\AppData\Local\Programs\Python\Launcher\;C:\Users\Stefano\AppData\Local\Microsoft\WindowsApps;C:\Users\Stefano\AppData\Local\GitHubDesktop\bin;C:\apache-maven-3.6.0\bin;;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 10:23:13,136] INFO Server environment:java.io.tmpdir=C:\Users\Stefano\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 10:23:13,136] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 10:23:13,136] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 10:23:13,136] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 10:23:13,136] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 10:23:13,136] INFO Server environment:user.name=Stefano (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 10:23:13,136] INFO Server environment:user.home=C:\Users\Stefano (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 10:23:13,136] INFO Server environment:user.dir=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 10:23:13,151] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 10:23:13,151] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 10:23:13,151] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 10:23:13,198] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-01-25 10:23:13,213] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-25 10:23:19,803] INFO Expiring session 0x100004a06e80002, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 10:23:19,803] INFO Expiring session 0x100004a06e80000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 10:23:19,803] INFO Expiring session 0x100004a06e80001, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 10:23:19,803] INFO Processed session termination for sessionid: 0x100004a06e80002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:23:19,803] INFO Processed session termination for sessionid: 0x100004a06e80000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:23:19,803] INFO Creating new log file: log.9b2 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-01-25 10:23:19,803] INFO Processed session termination for sessionid: 0x100004a06e80001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:23:27,303] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-25 10:23:27,881] INFO starting (kafka.server.KafkaServer)
[2019-01-25 10:23:27,881] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-25 10:23:27,912] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-25 10:23:32,552] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:23:32,552] INFO Client environment:host.name=ITdif (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:23:32,552] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:23:32,552] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:23:32,552] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:23:32,552] INFO Client environment:java.class.path=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-connect-jdbc-5.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\mysql-connector-java-8.0.13.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:23:32,552] INFO Client environment:java.library.path=C:\Program Files\Java\jre1.8.0_181\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Docker\Docker\Resources\bin;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\Scripts\;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\dotnet\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\NoteBook FanControl\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\extras\CUPTI\libx64;C:\tools\cuda\bin;C:\Program Files\PuTTY\;C:\Program Files\Calibre2\;C:\apache-maven-3.6.\bin;C:\Users\Stefano\Downloads\platform-tools_r28.0.1-windows\platform-tools;C:\Program Files\Java\jre1.8.0_181\bin;C:\Users\Stefano\AppData\Local\Programs\Python\Launcher\;C:\Users\Stefano\AppData\Local\Microsoft\WindowsApps;C:\Users\Stefano\AppData\Local\GitHubDesktop\bin;C:\apache-maven-3.6.0\bin;;. (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:23:32,552] INFO Client environment:java.io.tmpdir=C:\Users\Stefano\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:23:32,552] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:23:32,552] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:23:32,552] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:23:32,552] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:23:32,552] INFO Client environment:user.name=Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:23:32,552] INFO Client environment:user.home=C:\Users\Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:23:32,552] INFO Client environment:user.dir=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:23:32,552] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@1622f1b (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:23:32,583] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-25 10:23:32,583] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-25 10:23:32,583] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-25 10:23:32,583] INFO Accepted socket connection from /127.0.0.1:52840 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-25 10:23:32,599] INFO Client attempting to establish new session at /127.0.0.1:52840 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 10:23:32,599] INFO Established session 0x1000380b4ed0000 with negotiated timeout 6000 for client /127.0.0.1:52840 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 10:23:32,599] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000380b4ed0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-25 10:23:32,599] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-25 10:23:32,677] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0000 type:create cxid:0x1 zxid:0x9b6 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:23:32,708] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0000 type:create cxid:0x2 zxid:0x9b7 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:23:32,708] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0000 type:create cxid:0x3 zxid:0x9b8 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:23:32,708] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0000 type:create cxid:0x4 zxid:0x9b9 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:23:32,708] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0000 type:create cxid:0x5 zxid:0x9ba txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:23:32,723] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0000 type:create cxid:0x6 zxid:0x9bb txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:23:32,723] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0000 type:create cxid:0x7 zxid:0x9bc txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:23:32,723] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0000 type:create cxid:0x8 zxid:0x9bd txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:23:32,723] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0000 type:create cxid:0x9 zxid:0x9be txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:23:32,723] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0000 type:create cxid:0xa zxid:0x9bf txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:23:32,739] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0000 type:create cxid:0xb zxid:0x9c0 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:23:32,739] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0000 type:create cxid:0xc zxid:0x9c1 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:23:32,739] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0000 type:create cxid:0xd zxid:0x9c2 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:23:33,005] INFO Cluster ID = RvEiz9fYQgKWcHR6fHb3dg (kafka.server.KafkaServer)
[2019-01-25 10:23:33,098] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-25 10:23:33,114] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-25 10:23:33,145] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-25 10:23:33,145] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-25 10:23:33,145] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-25 10:23:33,208] INFO Loading logs. (kafka.log.LogManager)
[2019-01-25 10:23:33,286] WARN [Log partition=alltools-0, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\alltools-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\alltools-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547977751460}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:33,286] INFO [Log partition=alltools-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,333] INFO [ProducerStateManager partition=alltools-0] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:33,348] INFO [Log partition=alltools-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:33,348] INFO [Log partition=alltools-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,348] INFO [ProducerStateManager partition=alltools-0] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:33,380] INFO [Log partition=alltools-0, dir=C:\tmp\logs1] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,380] INFO [ProducerStateManager partition=alltools-0] Loading producer state from snapshot file 'C:\tmp\logs1\alltools-0\00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:33,395] INFO [Log partition=alltools-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 140 ms (kafka.log.Log)
[2019-01-25 10:23:33,411] WARN [Log partition=alltools-2, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\alltools-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\alltools-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547977368170}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:33,411] INFO [Log partition=alltools-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,426] INFO [ProducerStateManager partition=alltools-2] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:33,426] INFO [Log partition=alltools-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:33,426] INFO [Log partition=alltools-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,442] INFO [ProducerStateManager partition=alltools-2] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:33,458] INFO [Log partition=alltools-2, dir=C:\tmp\logs1] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,458] INFO [ProducerStateManager partition=alltools-2] Loading producer state from snapshot file 'C:\tmp\logs1\alltools-2\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:33,458] INFO [Log partition=alltools-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 47 ms (kafka.log.Log)
[2019-01-25 10:23:33,473] WARN [Log partition=edited-0, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\edited-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\edited-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996878625}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:33,473] INFO [Log partition=edited-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,473] INFO [ProducerStateManager partition=edited-0] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:33,473] INFO [Log partition=edited-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:33,473] INFO [Log partition=edited-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,489] INFO [ProducerStateManager partition=edited-0] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:33,505] INFO [Log partition=edited-0, dir=C:\tmp\logs1] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,505] INFO [ProducerStateManager partition=edited-0] Loading producer state from snapshot file 'C:\tmp\logs1\edited-0\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:33,505] INFO [Log partition=edited-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 47 ms (kafka.log.Log)
[2019-01-25 10:23:33,520] WARN [Log partition=edited-1, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\edited-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\edited-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996876577}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:33,520] INFO [Log partition=edited-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,520] INFO [ProducerStateManager partition=edited-1] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:33,520] INFO [Log partition=edited-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:33,520] INFO [Log partition=edited-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,536] INFO [ProducerStateManager partition=edited-1] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:33,536] INFO [Log partition=edited-1, dir=C:\tmp\logs1] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,551] INFO [ProducerStateManager partition=edited-1] Loading producer state from snapshot file 'C:\tmp\logs1\edited-1\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:33,551] INFO [Log partition=edited-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 9 in 46 ms (kafka.log.Log)
[2019-01-25 10:23:33,551] WARN [Log partition=edited6-0, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\edited6-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\edited6-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548158302054}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:33,551] INFO [Log partition=edited6-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,567] INFO [ProducerStateManager partition=edited6-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:33,567] INFO [Log partition=edited6-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:33,567] INFO [Log partition=edited6-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,567] INFO [ProducerStateManager partition=edited6-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:33,583] INFO [Log partition=edited6-0, dir=C:\tmp\logs1] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,583] INFO [ProducerStateManager partition=edited6-0] Loading producer state from snapshot file 'C:\tmp\logs1\edited6-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:33,583] INFO [Log partition=edited6-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 32 ms (kafka.log.Log)
[2019-01-25 10:23:33,598] WARN [Log partition=edited6-1, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\edited6-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\edited6-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548321919981}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:33,598] INFO [Log partition=edited6-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,614] INFO [ProducerStateManager partition=edited6-1] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:33,614] INFO [Log partition=edited6-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:33,614] INFO [Log partition=edited6-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,614] INFO [ProducerStateManager partition=edited6-1] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:33,629] INFO [Log partition=edited6-1, dir=C:\tmp\logs1] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,629] INFO [ProducerStateManager partition=edited6-1] Loading producer state from snapshot file 'C:\tmp\logs1\edited6-1\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:33,629] INFO [Log partition=edited6-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 31 ms (kafka.log.Log)
[2019-01-25 10:23:33,645] INFO [Log partition=edited8-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:33,645] INFO [Log partition=edited8-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,661] INFO [Log partition=edited8-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,661] INFO [Log partition=edited8-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:23:33,676] INFO [Log partition=edited8-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:33,676] INFO [Log partition=edited8-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,692] INFO [Log partition=edited8-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,692] INFO [Log partition=edited8-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:23:33,708] WARN [Log partition=mytools-0, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\mytools-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\mytools-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547991919170}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:33,708] INFO [Log partition=mytools-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,708] INFO [ProducerStateManager partition=mytools-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:33,708] INFO [Log partition=mytools-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:33,708] INFO [Log partition=mytools-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,723] INFO [ProducerStateManager partition=mytools-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:33,723] INFO [Log partition=mytools-0, dir=C:\tmp\logs1] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,739] INFO [ProducerStateManager partition=mytools-0] Loading producer state from snapshot file 'C:\tmp\logs1\mytools-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:33,739] INFO [Log partition=mytools-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 47 ms (kafka.log.Log)
[2019-01-25 10:23:33,739] INFO [Log partition=mytools-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:33,739] INFO [Log partition=mytools-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,754] INFO [Log partition=mytools-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,754] INFO [Log partition=mytools-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-25 10:23:33,770] INFO [Log partition=test-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:33,770] INFO [Log partition=test-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,786] INFO [Log partition=test-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,786] INFO [Log partition=test-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:23:33,801] WARN [Log partition=tools-0, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\tools-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\tools-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547991352625}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:33,801] INFO [Log partition=tools-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,801] INFO [ProducerStateManager partition=tools-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:33,801] INFO [Log partition=tools-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:33,801] INFO [Log partition=tools-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,817] INFO [ProducerStateManager partition=tools-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:33,833] INFO [Log partition=tools-0, dir=C:\tmp\logs1] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,833] INFO [ProducerStateManager partition=tools-0] Loading producer state from snapshot file 'C:\tmp\logs1\tools-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:33,833] INFO [Log partition=tools-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 32 ms (kafka.log.Log)
[2019-01-25 10:23:33,833] INFO [Log partition=tools-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:33,848] INFO [Log partition=tools-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,848] INFO [Log partition=tools-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,864] INFO [Log partition=tools-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-25 10:23:33,864] INFO [Log partition=tools1-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:33,864] INFO [Log partition=tools1-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,879] INFO [Log partition=tools1-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,879] INFO [Log partition=tools1-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-25 10:23:33,879] INFO [Log partition=tools1-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:33,879] INFO [Log partition=tools1-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,895] INFO [Log partition=tools1-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,895] INFO [Log partition=tools1-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:23:33,911] INFO [Log partition=tools2-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:33,911] INFO [Log partition=tools2-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,911] INFO [Log partition=tools2-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,926] INFO [Log partition=tools2-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-25 10:23:33,926] INFO [Log partition=tools2-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:33,926] INFO [Log partition=tools2-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,942] INFO [Log partition=tools2-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,942] INFO [Log partition=tools2-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:23:33,942] INFO [Log partition=tools3-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:33,942] INFO [Log partition=tools3-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,958] INFO [Log partition=tools3-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,958] INFO [Log partition=tools3-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:23:33,973] INFO [Log partition=tools3-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:33,973] INFO [Log partition=tools3-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,973] INFO [Log partition=tools3-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:33,973] INFO [Log partition=tools3-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 10:23:33,989] INFO [Log partition=tools4-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:33,989] INFO [Log partition=tools4-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,004] INFO [Log partition=tools4-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,004] INFO [Log partition=tools4-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-25 10:23:34,004] INFO [Log partition=tools4-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:34,020] INFO [Log partition=tools4-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,020] INFO [Log partition=tools4-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,020] INFO [Log partition=tools4-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:23:34,036] WARN [Log partition=tools5-1, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\tools5-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\tools5-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996876577}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:34,036] INFO [Log partition=tools5-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,036] INFO [ProducerStateManager partition=tools5-1] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,036] INFO [Log partition=tools5-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:34,036] INFO [Log partition=tools5-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,051] INFO [ProducerStateManager partition=tools5-1] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,051] INFO [Log partition=tools5-1, dir=C:\tmp\logs1] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,067] INFO [ProducerStateManager partition=tools5-1] Loading producer state from snapshot file 'C:\tmp\logs1\tools5-1\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,067] INFO [Log partition=tools5-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 31 ms (kafka.log.Log)
[2019-01-25 10:23:34,067] WARN [Log partition=tools5-2, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\tools5-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\tools5-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996835000}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:34,067] INFO [Log partition=tools5-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,083] INFO [ProducerStateManager partition=tools5-2] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,083] INFO [Log partition=tools5-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:34,083] INFO [Log partition=tools5-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,098] INFO [ProducerStateManager partition=tools5-2] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,098] INFO [Log partition=tools5-2, dir=C:\tmp\logs1] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,114] INFO [ProducerStateManager partition=tools5-2] Loading producer state from snapshot file 'C:\tmp\logs1\tools5-2\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,114] INFO [Log partition=tools5-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 47 ms (kafka.log.Log)
[2019-01-25 10:23:34,114] WARN [Log partition=tools6-0, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\tools6-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\tools6-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548176773646}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:34,114] INFO [Log partition=tools6-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,129] INFO [ProducerStateManager partition=tools6-0] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,129] INFO [Log partition=tools6-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:34,129] INFO [Log partition=tools6-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,129] INFO [ProducerStateManager partition=tools6-0] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,145] INFO [Log partition=tools6-0, dir=C:\tmp\logs1] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,145] INFO [ProducerStateManager partition=tools6-0] Loading producer state from snapshot file 'C:\tmp\logs1\tools6-0\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,161] INFO [Log partition=tools6-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 47 ms (kafka.log.Log)
[2019-01-25 10:23:34,161] WARN [Log partition=tools6-2, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\tools6-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\tools6-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548158302054}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:34,176] INFO [Log partition=tools6-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,176] INFO [ProducerStateManager partition=tools6-2] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,176] INFO [Log partition=tools6-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:34,176] INFO [Log partition=tools6-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,192] INFO [ProducerStateManager partition=tools6-2] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,192] INFO [Log partition=tools6-2, dir=C:\tmp\logs1] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,207] INFO [ProducerStateManager partition=tools6-2] Loading producer state from snapshot file 'C:\tmp\logs1\tools6-2\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,207] INFO [Log partition=tools6-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 46 ms (kafka.log.Log)
[2019-01-25 10:23:34,207] WARN [Log partition=tools7-0, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\tools7-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\tools7-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548173477306}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:34,207] INFO [Log partition=tools7-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,223] INFO [ProducerStateManager partition=tools7-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,223] INFO [Log partition=tools7-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:34,223] INFO [Log partition=tools7-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,223] INFO [ProducerStateManager partition=tools7-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,239] INFO [Log partition=tools7-0, dir=C:\tmp\logs1] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,239] INFO [ProducerStateManager partition=tools7-0] Loading producer state from snapshot file 'C:\tmp\logs1\tools7-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,239] INFO [Log partition=tools7-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 32 ms (kafka.log.Log)
[2019-01-25 10:23:34,254] WARN [Log partition=tools7-2, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\tools7-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\tools7-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548156023437}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:34,254] INFO [Log partition=tools7-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,254] INFO [ProducerStateManager partition=tools7-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,254] INFO [Log partition=tools7-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:34,254] INFO [Log partition=tools7-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,270] INFO [ProducerStateManager partition=tools7-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,286] INFO [Log partition=tools7-2, dir=C:\tmp\logs1] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,286] INFO [ProducerStateManager partition=tools7-2] Loading producer state from snapshot file 'C:\tmp\logs1\tools7-2\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,286] INFO [Log partition=tools7-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 32 ms (kafka.log.Log)
[2019-01-25 10:23:34,301] INFO [Log partition=tools8-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:34,301] INFO [Log partition=tools8-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,301] INFO [Log partition=tools8-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,317] INFO [Log partition=tools8-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-25 10:23:34,317] WARN [Log partition=tools8-1, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\tools8-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\tools8-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548341369651}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:34,317] INFO [Log partition=tools8-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,332] INFO [ProducerStateManager partition=tools8-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,332] INFO [Log partition=tools8-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:34,332] INFO [Log partition=tools8-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,332] INFO [ProducerStateManager partition=tools8-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,348] INFO [Log partition=tools8-1, dir=C:\tmp\logs1] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,348] INFO [ProducerStateManager partition=tools8-1] Loading producer state from snapshot file 'C:\tmp\logs1\tools8-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,348] INFO [Log partition=tools8-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 31 ms (kafka.log.Log)
[2019-01-25 10:23:34,364] WARN [Log partition=__consumer_offsets-0, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\__consumer_offsets-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\__consumer_offsets-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547994284686}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:34,364] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,364] INFO [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,364] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:34,364] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,379] INFO [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,395] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\logs1] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,395] INFO [ProducerStateManager partition=__consumer_offsets-0] Loading producer state from snapshot file 'C:\tmp\logs1\__consumer_offsets-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,395] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 31 ms (kafka.log.Log)
[2019-01-25 10:23:34,395] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:34,411] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,411] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,411] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:23:34,426] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:34,426] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,442] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,442] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:23:34,442] WARN [Log partition=__consumer_offsets-18, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\__consumer_offsets-18\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\__consumer_offsets-18\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548177188378}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:34,457] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,457] INFO [ProducerStateManager partition=__consumer_offsets-18] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,457] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:34,457] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,457] INFO [ProducerStateManager partition=__consumer_offsets-18] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,473] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\logs1] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,473] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file 'C:\tmp\logs1\__consumer_offsets-18\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,473] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 31 ms (kafka.log.Log)
[2019-01-25 10:23:34,489] WARN [Log partition=__consumer_offsets-21, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\__consumer_offsets-21\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\__consumer_offsets-21\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547985284682}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:34,489] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,489] INFO [ProducerStateManager partition=__consumer_offsets-21] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,504] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:34,504] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,504] INFO [ProducerStateManager partition=__consumer_offsets-21] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,520] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\logs1] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,520] INFO [ProducerStateManager partition=__consumer_offsets-21] Loading producer state from snapshot file 'C:\tmp\logs1\__consumer_offsets-21\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,520] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 31 ms (kafka.log.Log)
[2019-01-25 10:23:34,536] WARN [Log partition=__consumer_offsets-24, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\__consumer_offsets-24\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\__consumer_offsets-24\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547991284687}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:34,536] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,536] INFO [ProducerStateManager partition=__consumer_offsets-24] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,536] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:34,536] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,551] INFO [ProducerStateManager partition=__consumer_offsets-24] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,567] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\logs1] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,567] INFO [ProducerStateManager partition=__consumer_offsets-24] Loading producer state from snapshot file 'C:\tmp\logs1\__consumer_offsets-24\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,567] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 31 ms (kafka.log.Log)
[2019-01-25 10:23:34,567] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:34,567] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,582] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,582] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-25 10:23:34,598] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:34,598] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,598] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,598] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 10:23:34,614] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:34,614] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,629] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,629] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-25 10:23:34,629] WARN [Log partition=__consumer_offsets-33, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\__consumer_offsets-33\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\__consumer_offsets-33\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548156193182}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:34,629] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,645] INFO [ProducerStateManager partition=__consumer_offsets-33] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,645] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:34,645] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,645] INFO [ProducerStateManager partition=__consumer_offsets-33] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,660] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\logs1] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,660] INFO [ProducerStateManager partition=__consumer_offsets-33] Loading producer state from snapshot file 'C:\tmp\logs1\__consumer_offsets-33\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,660] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 31 ms (kafka.log.Log)
[2019-01-25 10:23:34,676] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:34,676] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,692] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,692] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:23:34,692] WARN [Log partition=__consumer_offsets-39, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\__consumer_offsets-39\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\__consumer_offsets-39\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548010498324}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:34,707] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,707] INFO [ProducerStateManager partition=__consumer_offsets-39] Writing producer snapshot at offset 31 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,707] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:34,707] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,723] INFO [ProducerStateManager partition=__consumer_offsets-39] Writing producer snapshot at offset 31 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,723] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\logs1] Loading producer state till offset 31 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,739] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file 'C:\tmp\logs1\__consumer_offsets-39\00000000000000000031.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,739] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 31 in 47 ms (kafka.log.Log)
[2019-01-25 10:23:34,739] WARN [Log partition=__consumer_offsets-42, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\__consumer_offsets-42\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\__consumer_offsets-42\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548156193185}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:34,739] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,754] INFO [ProducerStateManager partition=__consumer_offsets-42] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,754] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:34,754] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,754] INFO [ProducerStateManager partition=__consumer_offsets-42] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,770] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\logs1] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,770] INFO [ProducerStateManager partition=__consumer_offsets-42] Loading producer state from snapshot file 'C:\tmp\logs1\__consumer_offsets-42\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:34,770] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 31 ms (kafka.log.Log)
[2019-01-25 10:23:34,785] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:34,785] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,801] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,801] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:23:34,801] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:34,801] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,817] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,817] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:23:34,832] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:34,832] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,832] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,848] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-25 10:23:34,848] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:34,848] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,864] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:34,864] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:23:34,864] INFO Logs loading complete in 1656 ms. (kafka.log.LogManager)
[2019-01-25 10:23:34,879] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-25 10:23:34,879] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-25 10:23:35,207] INFO Awaiting socket connections on localhost:9093. (kafka.network.Acceptor)
[2019-01-25 10:23:35,238] INFO [SocketServer brokerId=1] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-25 10:23:35,254] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-25 10:23:35,270] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-25 10:23:35,270] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-25 10:23:35,285] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-25 10:23:35,332] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-25 10:23:35,348] INFO Result of znode creation at /brokers/ids/1 is: OK (kafka.zk.KafkaZkClient)
[2019-01-25 10:23:35,348] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(localhost,9093,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-25 10:23:35,395] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-25 10:23:35,410] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-25 10:23:35,410] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-25 10:23:35,442] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:23:35,442] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:23:35,457] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:35,473] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:27000,blockEndProducerId:27999) by writing to Zk with path version 28 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-25 10:23:35,520] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-25 10:23:35,535] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-25 10:23:35,535] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-25 10:23:35,598] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-25 10:23:35,645] INFO [SocketServer brokerId=1] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-25 10:23:35,645] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-25 10:23:35,645] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-25 10:23:35,660] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2019-01-25 10:23:35,754] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(edited8-2, __consumer_offsets-30, __consumer_offsets-21, tools7-0, __consumer_offsets-27, tools8-1, __consumer_offsets-9, tools3-0, tools4-1, tools5-2, __consumer_offsets-33, tools1-2, tools8-0, edited-1, test-0, mytools-0, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, tools6-2, alltools-0, __consumer_offsets-48, tools-0, __consumer_offsets-6, edited6-1, __consumer_offsets-0, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, tools6-0, tools2-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 10:23:35,785] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-25 10:23:35,785] INFO [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 3 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:35,801] INFO Replica loaded for partition edited6-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:35,816] INFO Replica loaded for partition edited6-1 with initial high watermark 7 (kafka.cluster.Replica)
[2019-01-25 10:23:35,816] INFO [Partition edited6-1 broker=1] edited6-1 starts at Leader Epoch 3 from offset 7. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:35,832] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0000 type:multi cxid:0x138 zxid:0x9d2 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:23:35,832] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:35,832] INFO [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:35,832] INFO Replica loaded for partition mytools-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:35,832] INFO Replica loaded for partition mytools-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 10:23:35,832] INFO [Partition mytools-0 broker=1] mytools-0 starts at Leader Epoch 6 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:35,848] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0000 type:multi cxid:0x13b zxid:0x9d3 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:23:35,848] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:35,848] INFO [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:35,863] INFO Replica loaded for partition tools4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:35,863] INFO Replica loaded for partition tools4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:35,863] INFO [Partition tools4-1 broker=1] tools4-1 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:35,879] INFO Replica loaded for partition tools5-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:35,879] INFO Replica loaded for partition tools5-2 with initial high watermark 8 (kafka.cluster.Replica)
[2019-01-25 10:23:35,879] INFO [Partition tools5-2 broker=1] tools5-2 starts at Leader Epoch 6 from offset 8. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:35,879] INFO Replica loaded for partition tools3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:35,895] INFO Replica loaded for partition tools3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:35,895] INFO [Partition tools3-0 broker=1] tools3-0 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:35,895] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-25 10:23:35,895] INFO [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 3 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:35,910] INFO Replica loaded for partition tools-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:35,910] INFO Replica loaded for partition tools-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 10:23:35,910] INFO [Partition tools-0 broker=1] tools-0 starts at Leader Epoch 6 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:35,926] INFO Replica loaded for partition tools6-0 with initial high watermark 5 (kafka.cluster.Replica)
[2019-01-25 10:23:35,926] INFO Replica loaded for partition tools6-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:35,926] INFO [Partition tools6-0 broker=1] tools6-0 starts at Leader Epoch 7 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:35,941] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 31 (kafka.cluster.Replica)
[2019-01-25 10:23:35,941] INFO [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 3 from offset 31. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:35,941] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:35,941] INFO [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:35,957] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-25 10:23:35,957] INFO [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 3 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:35,973] INFO Replica loaded for partition tools8-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:35,973] INFO Replica loaded for partition tools8-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:35,973] INFO [Partition tools8-0 broker=1] tools8-0 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:35,973] INFO Replica loaded for partition tools1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:35,973] INFO Replica loaded for partition tools1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:35,973] INFO [Partition tools1-2 broker=1] tools1-2 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:35,988] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:35,988] INFO [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:36,004] INFO Replica loaded for partition test-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:36,004] INFO [Partition test-0 broker=1] test-0 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:36,004] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:36,004] INFO [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:36,020] INFO Replica loaded for partition tools2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:36,020] INFO Replica loaded for partition tools2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:36,020] INFO [Partition tools2-0 broker=1] tools2-0 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:36,020] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-25 10:23:36,020] INFO [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 3 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:36,035] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-25 10:23:36,035] INFO [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 3 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:36,051] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-25 10:23:36,051] INFO [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 3 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:36,051] INFO Replica loaded for partition edited8-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:36,051] INFO Replica loaded for partition edited8-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:36,051] INFO [Partition edited8-2 broker=1] edited8-2 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:36,066] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:36,066] INFO [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:36,066] INFO Replica loaded for partition tools6-2 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-25 10:23:36,066] INFO Replica loaded for partition tools6-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:36,082] INFO [Partition tools6-2 broker=1] tools6-2 starts at Leader Epoch 6 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:36,082] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:36,082] INFO [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:36,082] INFO Replica loaded for partition edited-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:36,098] INFO Replica loaded for partition edited-1 with initial high watermark 9 (kafka.cluster.Replica)
[2019-01-25 10:23:36,098] INFO [Partition edited-1 broker=1] edited-1 starts at Leader Epoch 6 from offset 9. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:36,113] INFO Replica loaded for partition tools8-1 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 10:23:36,113] INFO Replica loaded for partition tools8-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:36,113] INFO [Partition tools8-1 broker=1] tools8-1 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:36,129] INFO Replica loaded for partition tools7-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:36,129] INFO Replica loaded for partition tools7-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 10:23:36,129] INFO [Partition tools7-0 broker=1] tools7-0 starts at Leader Epoch 3 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:36,145] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:36,145] INFO [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:36,145] INFO Replica loaded for partition alltools-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:36,145] INFO Replica loaded for partition alltools-0 with initial high watermark 4 (kafka.cluster.Replica)
[2019-01-25 10:23:36,145] INFO [Partition alltools-0 broker=1] alltools-0 starts at Leader Epoch 7 from offset 4. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:36,160] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:36,160] INFO [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:36,160] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:36,160] INFO [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:36,176] INFO Replica loaded for partition tools2-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:36,176] INFO Replica loaded for partition tools1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:36,191] INFO Replica loaded for partition tools7-2 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 10:23:36,191] INFO Replica loaded for partition edited-0 with initial high watermark 8 (kafka.cluster.Replica)
[2019-01-25 10:23:36,191] INFO Replica loaded for partition alltools-2 with initial high watermark 5 (kafka.cluster.Replica)
[2019-01-25 10:23:36,191] INFO Replica loaded for partition edited8-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:36,207] INFO Replica loaded for partition mytools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:36,207] INFO Replica loaded for partition tools3-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:36,207] INFO Replica loaded for partition tools5-1 with initial high watermark 5 (kafka.cluster.Replica)
[2019-01-25 10:23:36,207] INFO Replica loaded for partition tools4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:36,223] INFO Replica loaded for partition edited6-0 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-25 10:23:36,223] INFO Replica loaded for partition tools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:36,223] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-25 10:23:36,238] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:36,238] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:36,238] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:36,238] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:36,238] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:36,254] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:36,254] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:36,254] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:36,254] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:36,254] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:36,254] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:36,254] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:36,269] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:36,269] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:36,285] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:36,285] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:36,285] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:36,316] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools4-0, tools1-1, tools2-2, tools-2, edited6-0, alltools-2, edited8-1, tools5-1, tools7-2, edited-0, tools3-2, mytools-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 10:23:36,332] INFO Replica loaded for partition tools1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:36,332] INFO [Partition tools1-1 broker=1] tools1-1 starts at Leader Epoch 23 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:36,332] INFO Replica loaded for partition tools2-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:36,332] INFO [Partition tools2-2 broker=1] tools2-2 starts at Leader Epoch 23 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:36,332] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 94 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:36,332] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:36,332] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:36,332] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:36,332] INFO Replica loaded for partition tools7-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:36,348] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:36,348] INFO [Partition tools7-2 broker=1] tools7-2 starts at Leader Epoch 13 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:36,348] INFO Replica loaded for partition edited-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:36,348] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:36,348] INFO [Partition edited-0 broker=1] edited-0 starts at Leader Epoch 23 from offset 8. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:36,363] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 15 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:36,363] INFO Replica loaded for partition edited8-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:36,363] INFO [Partition edited8-1 broker=1] edited8-1 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:36,363] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:36,379] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:36,379] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:36,379] INFO Replica loaded for partition alltools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:36,379] INFO [Partition alltools-2 broker=1] alltools-2 starts at Leader Epoch 24 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:36,379] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:36,379] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:36,394] INFO Replica loaded for partition mytools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:36,394] INFO [Partition mytools-2 broker=1] mytools-2 starts at Leader Epoch 23 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:36,394] INFO [GroupCoordinator 1]: Loading group metadata for group2 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:23:36,394] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 15 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:36,410] INFO Replica loaded for partition tools3-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:36,410] INFO [Partition tools3-2 broker=1] tools3-2 starts at Leader Epoch 23 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:36,410] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:36,410] INFO Replica loaded for partition tools5-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:36,410] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:36,410] INFO [Partition tools5-1 broker=1] tools5-1 starts at Leader Epoch 23 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:36,410] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:36,410] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:36,426] INFO Replica loaded for partition tools4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:36,426] INFO [Partition tools4-0 broker=1] tools4-0 starts at Leader Epoch 23 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:36,426] INFO Replica loaded for partition edited6-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:36,426] INFO [Partition edited6-0 broker=1] edited6-0 starts at Leader Epoch 19 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:36,441] INFO Replica loaded for partition tools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:36,441] INFO [Partition tools-2 broker=1] tools-2 starts at Leader Epoch 23 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:50,287] INFO [Partition edited-1 broker=1] Shrinking ISR from 2,1 to 1 (kafka.cluster.Partition)
[2019-01-25 10:23:50,287] INFO [Partition tools-0 broker=1] Shrinking ISR from 2,1 to 1 (kafka.cluster.Partition)
[2019-01-25 10:23:50,287] INFO [Partition alltools-0 broker=1] Shrinking ISR from 2,1 to 1 (kafka.cluster.Partition)
[2019-01-25 10:23:50,287] INFO [Partition edited8-2 broker=1] Shrinking ISR from 2,1 to 1 (kafka.cluster.Partition)
[2019-01-25 10:23:50,303] INFO [Partition tools4-1 broker=1] Shrinking ISR from 2,1 to 1 (kafka.cluster.Partition)
[2019-01-25 10:23:50,303] INFO [Partition tools8-1 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-25 10:23:50,303] INFO [Partition mytools-0 broker=1] Shrinking ISR from 2,1 to 1 (kafka.cluster.Partition)
[2019-01-25 10:23:50,303] INFO [Partition tools1-2 broker=1] Shrinking ISR from 2,1 to 1 (kafka.cluster.Partition)
[2019-01-25 10:23:50,303] INFO [Partition tools6-2 broker=1] Shrinking ISR from 1,3 to 1 (kafka.cluster.Partition)
[2019-01-25 10:23:50,303] INFO [Partition tools2-0 broker=1] Shrinking ISR from 2,1 to 1 (kafka.cluster.Partition)
[2019-01-25 10:23:50,318] INFO [Partition edited6-1 broker=1] Shrinking ISR from 2,1 to 1 (kafka.cluster.Partition)
[2019-01-25 10:23:50,318] INFO [Partition tools3-0 broker=1] Shrinking ISR from 2,1 to 1 (kafka.cluster.Partition)
[2019-01-25 10:23:50,318] INFO [Partition tools5-2 broker=1] Shrinking ISR from 2,1 to 1 (kafka.cluster.Partition)
[2019-01-25 10:23:50,318] INFO [Partition tools8-0 broker=1] Shrinking ISR from 1,3 to 1 (kafka.cluster.Partition)
[2019-01-25 10:23:50,318] INFO [Partition tools6-0 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-25 10:23:50,334] INFO [Partition tools7-0 broker=1] Shrinking ISR from 2,1 to 1 (kafka.cluster.Partition)
[2019-01-25 10:23:50,912] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-25 10:23:51,428] INFO starting (kafka.server.KafkaServer)
[2019-01-25 10:23:51,428] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-25 10:23:51,443] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-25 10:23:56,068] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:23:56,068] INFO Client environment:host.name=ITdif (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:23:56,068] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:23:56,068] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:23:56,068] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:23:56,068] INFO Client environment:java.class.path=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-connect-jdbc-5.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\mysql-connector-java-8.0.13.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:23:56,068] INFO Client environment:java.library.path=C:\Program Files\Java\jre1.8.0_181\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Docker\Docker\Resources\bin;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\Scripts\;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\dotnet\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\NoteBook FanControl\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\extras\CUPTI\libx64;C:\tools\cuda\bin;C:\Program Files\PuTTY\;C:\Program Files\Calibre2\;C:\apache-maven-3.6.\bin;C:\Users\Stefano\Downloads\platform-tools_r28.0.1-windows\platform-tools;C:\Program Files\Java\jre1.8.0_181\bin;C:\Users\Stefano\AppData\Local\Programs\Python\Launcher\;C:\Users\Stefano\AppData\Local\Microsoft\WindowsApps;C:\Users\Stefano\AppData\Local\GitHubDesktop\bin;C:\apache-maven-3.6.0\bin;;. (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:23:56,068] INFO Client environment:java.io.tmpdir=C:\Users\Stefano\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:23:56,068] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:23:56,068] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:23:56,068] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:23:56,068] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:23:56,068] INFO Client environment:user.name=Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:23:56,068] INFO Client environment:user.home=C:\Users\Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:23:56,068] INFO Client environment:user.dir=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:23:56,068] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@1622f1b (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:23:56,098] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-25 10:23:56,098] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-25 10:23:56,098] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:52857 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-25 10:23:56,098] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-25 10:23:56,098] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:52857 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 10:23:56,098] INFO Established session 0x1000380b4ed0001 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:52857 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 10:23:56,098] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1000380b4ed0001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-25 10:23:56,114] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-25 10:23:56,161] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0001 type:create cxid:0x1 zxid:0x9e5 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:23:56,176] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0001 type:create cxid:0x2 zxid:0x9e6 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:23:56,176] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0001 type:create cxid:0x3 zxid:0x9e7 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:23:56,176] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0001 type:create cxid:0x4 zxid:0x9e8 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:23:56,176] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0001 type:create cxid:0x5 zxid:0x9e9 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:23:56,192] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0001 type:create cxid:0x6 zxid:0x9ea txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:23:56,192] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0001 type:create cxid:0x7 zxid:0x9eb txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:23:56,192] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0001 type:create cxid:0x8 zxid:0x9ec txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:23:56,192] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0001 type:create cxid:0x9 zxid:0x9ed txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:23:56,192] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0001 type:create cxid:0xa zxid:0x9ee txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:23:56,192] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0001 type:create cxid:0xb zxid:0x9ef txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:23:56,208] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0001 type:create cxid:0xc zxid:0x9f0 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:23:56,208] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0001 type:create cxid:0xd zxid:0x9f1 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:23:56,333] INFO Cluster ID = RvEiz9fYQgKWcHR6fHb3dg (kafka.server.KafkaServer)
[2019-01-25 10:23:56,426] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-25 10:23:56,426] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-25 10:23:56,473] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-25 10:23:56,473] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-25 10:23:56,473] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-25 10:23:56,520] INFO Loading logs. (kafka.log.LogManager)
[2019-01-25 10:23:56,583] WARN [Log partition=alltools-0, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\alltools-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\alltools-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547977751460}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:56,583] INFO [Log partition=alltools-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:56,629] INFO [ProducerStateManager partition=alltools-0] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:56,629] INFO [Log partition=alltools-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:56,645] INFO [Log partition=alltools-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:56,645] INFO [ProducerStateManager partition=alltools-0] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:56,661] INFO [Log partition=alltools-0, dir=C:\tmp\logs2] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:56,676] INFO [ProducerStateManager partition=alltools-0] Loading producer state from snapshot file 'C:\tmp\logs2\alltools-0\00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:56,692] INFO [Log partition=alltools-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 141 ms (kafka.log.Log)
[2019-01-25 10:23:56,708] WARN [Log partition=alltools-1, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\alltools-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\alltools-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547979859855}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:56,708] INFO [Log partition=alltools-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:56,708] INFO [ProducerStateManager partition=alltools-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:56,723] INFO [Log partition=alltools-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:56,723] INFO [Log partition=alltools-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:56,723] INFO [ProducerStateManager partition=alltools-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:56,739] INFO [Log partition=alltools-1, dir=C:\tmp\logs2] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:56,739] INFO [ProducerStateManager partition=alltools-1] Loading producer state from snapshot file 'C:\tmp\logs2\alltools-1\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:56,739] INFO [Log partition=alltools-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 31 ms (kafka.log.Log)
[2019-01-25 10:23:56,754] WARN [Log partition=edited-1, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\edited-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\edited-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996876577}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:56,754] INFO [Log partition=edited-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:56,754] INFO [ProducerStateManager partition=edited-1] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:56,754] INFO [Log partition=edited-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:56,754] INFO [Log partition=edited-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:56,770] INFO [ProducerStateManager partition=edited-1] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:56,770] INFO [Log partition=edited-1, dir=C:\tmp\logs2] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:56,770] INFO [ProducerStateManager partition=edited-1] Loading producer state from snapshot file 'C:\tmp\logs2\edited-1\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:56,770] INFO [Log partition=edited-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 9 in 16 ms (kafka.log.Log)
[2019-01-25 10:23:56,786] WARN [Log partition=edited-2, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\edited-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\edited-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996875547}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:56,786] INFO [Log partition=edited-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:56,801] INFO [ProducerStateManager partition=edited-2] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:56,801] INFO [Log partition=edited-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:56,801] INFO [Log partition=edited-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:56,801] INFO [ProducerStateManager partition=edited-2] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:56,817] INFO [Log partition=edited-2, dir=C:\tmp\logs2] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:56,817] INFO [ProducerStateManager partition=edited-2] Loading producer state from snapshot file 'C:\tmp\logs2\edited-2\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:56,817] INFO [Log partition=edited-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 31 ms (kafka.log.Log)
[2019-01-25 10:23:56,833] WARN [Log partition=edited6-1, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\edited6-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\edited6-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548321919981}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:56,833] INFO [Log partition=edited6-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:56,833] INFO [ProducerStateManager partition=edited6-1] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:56,848] INFO [Log partition=edited6-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:56,848] INFO [Log partition=edited6-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:56,848] INFO [ProducerStateManager partition=edited6-1] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:56,864] INFO [Log partition=edited6-1, dir=C:\tmp\logs2] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:56,864] INFO [ProducerStateManager partition=edited6-1] Loading producer state from snapshot file 'C:\tmp\logs2\edited6-1\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:56,864] INFO [Log partition=edited6-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 31 ms (kafka.log.Log)
[2019-01-25 10:23:56,879] WARN [Log partition=edited6-2, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\edited6-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\edited6-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548176773646}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:56,879] INFO [Log partition=edited6-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:56,879] INFO [ProducerStateManager partition=edited6-2] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:56,879] INFO [Log partition=edited6-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:56,879] INFO [Log partition=edited6-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:56,895] INFO [ProducerStateManager partition=edited6-2] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:56,911] INFO [Log partition=edited6-2, dir=C:\tmp\logs2] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:56,911] INFO [ProducerStateManager partition=edited6-2] Loading producer state from snapshot file 'C:\tmp\logs2\edited6-2\00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:56,911] INFO [Log partition=edited6-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 47 ms (kafka.log.Log)
[2019-01-25 10:23:56,926] WARN [Log partition=edited8-0, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\edited8-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\edited8-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548341369651}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:56,926] INFO [Log partition=edited8-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:56,926] INFO [ProducerStateManager partition=edited8-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:56,926] INFO [Log partition=edited8-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:56,926] INFO [Log partition=edited8-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:56,926] INFO [ProducerStateManager partition=edited8-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:56,942] INFO [Log partition=edited8-0, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:56,942] INFO [ProducerStateManager partition=edited8-0] Loading producer state from snapshot file 'C:\tmp\logs2\edited8-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:56,958] INFO [Log partition=edited8-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 47 ms (kafka.log.Log)
[2019-01-25 10:23:56,958] INFO [Log partition=edited8-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:56,958] INFO [Log partition=edited8-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:56,973] INFO [Log partition=edited8-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:56,973] INFO [Log partition=edited8-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-25 10:23:56,973] INFO [Log partition=my-example-topic-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:56,973] INFO [Log partition=my-example-topic-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:56,989] INFO [Log partition=my-example-topic-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:56,989] INFO [Log partition=my-example-topic-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:23:57,004] WARN [Log partition=mytools-0, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\mytools-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\mytools-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547991919170}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:57,004] INFO [Log partition=mytools-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,004] INFO [ProducerStateManager partition=mytools-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,004] INFO [Log partition=mytools-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:57,004] INFO [Log partition=mytools-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,020] INFO [ProducerStateManager partition=mytools-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,020] INFO [Log partition=mytools-0, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,020] INFO [ProducerStateManager partition=mytools-0] Loading producer state from snapshot file 'C:\tmp\logs2\mytools-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,020] INFO [Log partition=mytools-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 16 ms (kafka.log.Log)
[2019-01-25 10:23:57,036] INFO [Log partition=mytools-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:57,036] INFO [Log partition=mytools-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,051] INFO [Log partition=mytools-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,051] INFO [Log partition=mytools-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-25 10:23:57,067] WARN [Log partition=tools-0, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547991352625}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:57,067] INFO [Log partition=tools-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,067] INFO [ProducerStateManager partition=tools-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,067] INFO [Log partition=tools-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:57,067] INFO [Log partition=tools-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,082] INFO [ProducerStateManager partition=tools-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,082] INFO [Log partition=tools-0, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,098] INFO [ProducerStateManager partition=tools-0] Loading producer state from snapshot file 'C:\tmp\logs2\tools-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,098] INFO [Log partition=tools-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 47 ms (kafka.log.Log)
[2019-01-25 10:23:57,098] INFO [Log partition=tools-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:57,098] INFO [Log partition=tools-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,114] INFO [Log partition=tools-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,114] INFO [Log partition=tools-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:23:57,129] INFO [Log partition=tools1-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:57,129] INFO [Log partition=tools1-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,129] INFO [Log partition=tools1-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,145] INFO [Log partition=tools1-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:23:57,145] INFO [Log partition=tools1-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:57,145] INFO [Log partition=tools1-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,161] INFO [Log partition=tools1-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,161] INFO [Log partition=tools1-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:23:57,161] INFO [Log partition=tools2-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:57,161] INFO [Log partition=tools2-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,176] INFO [Log partition=tools2-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,176] INFO [Log partition=tools2-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-25 10:23:57,176] WARN [Log partition=tools2-1, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools2-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools2-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547992951029}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:57,176] INFO [Log partition=tools2-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,192] INFO [ProducerStateManager partition=tools2-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,192] INFO [Log partition=tools2-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:57,192] INFO [Log partition=tools2-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,192] INFO [ProducerStateManager partition=tools2-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,208] INFO [Log partition=tools2-1, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,208] INFO [ProducerStateManager partition=tools2-1] Loading producer state from snapshot file 'C:\tmp\logs2\tools2-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,208] INFO [Log partition=tools2-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 32 ms (kafka.log.Log)
[2019-01-25 10:23:57,223] INFO [Log partition=tools3-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:57,223] INFO [Log partition=tools3-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,223] INFO [Log partition=tools3-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,223] INFO [Log partition=tools3-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 10:23:57,239] WARN [Log partition=tools3-1, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools3-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools3-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547993388462}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:57,239] INFO [Log partition=tools3-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,239] INFO [ProducerStateManager partition=tools3-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,239] INFO [Log partition=tools3-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:57,239] INFO [Log partition=tools3-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,254] INFO [ProducerStateManager partition=tools3-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,254] INFO [Log partition=tools3-1, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,270] INFO [ProducerStateManager partition=tools3-1] Loading producer state from snapshot file 'C:\tmp\logs2\tools3-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,270] INFO [Log partition=tools3-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 31 ms (kafka.log.Log)
[2019-01-25 10:23:57,270] INFO [Log partition=tools4-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:57,270] INFO [Log partition=tools4-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,286] INFO [Log partition=tools4-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,286] INFO [Log partition=tools4-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:23:57,286] WARN [Log partition=tools4-2, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools4-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools4-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547993897061}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:57,286] INFO [Log partition=tools4-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,301] INFO [ProducerStateManager partition=tools4-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,301] INFO [Log partition=tools4-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:57,301] INFO [Log partition=tools4-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,301] INFO [ProducerStateManager partition=tools4-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,317] INFO [Log partition=tools4-2, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,317] INFO [ProducerStateManager partition=tools4-2] Loading producer state from snapshot file 'C:\tmp\logs2\tools4-2\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,317] INFO [Log partition=tools4-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 31 ms (kafka.log.Log)
[2019-01-25 10:23:57,332] WARN [Log partition=tools5-0, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools5-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools5-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996871342}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:57,332] INFO [Log partition=tools5-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,348] INFO [ProducerStateManager partition=tools5-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,348] INFO [Log partition=tools5-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:57,348] INFO [Log partition=tools5-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,348] INFO [ProducerStateManager partition=tools5-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,364] INFO [Log partition=tools5-0, dir=C:\tmp\logs2] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,364] INFO [ProducerStateManager partition=tools5-0] Loading producer state from snapshot file 'C:\tmp\logs2\tools5-0\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,379] INFO [Log partition=tools5-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 47 ms (kafka.log.Log)
[2019-01-25 10:23:57,379] WARN [Log partition=tools5-2, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools5-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools5-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996835000}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:57,379] INFO [Log partition=tools5-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,379] INFO [ProducerStateManager partition=tools5-2] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,395] INFO [Log partition=tools5-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:57,395] INFO [Log partition=tools5-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,395] INFO [ProducerStateManager partition=tools5-2] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,411] INFO [Log partition=tools5-2, dir=C:\tmp\logs2] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,411] INFO [ProducerStateManager partition=tools5-2] Loading producer state from snapshot file 'C:\tmp\logs2\tools5-2\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,411] INFO [Log partition=tools5-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 32 ms (kafka.log.Log)
[2019-01-25 10:23:57,426] WARN [Log partition=tools6-0, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools6-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools6-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548176773646}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:57,426] INFO [Log partition=tools6-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,426] INFO [ProducerStateManager partition=tools6-0] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,426] INFO [Log partition=tools6-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:57,426] INFO [Log partition=tools6-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,442] INFO [ProducerStateManager partition=tools6-0] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,442] INFO [Log partition=tools6-0, dir=C:\tmp\logs2] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,442] INFO [ProducerStateManager partition=tools6-0] Loading producer state from snapshot file 'C:\tmp\logs2\tools6-0\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,442] INFO [Log partition=tools6-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 31 ms (kafka.log.Log)
[2019-01-25 10:23:57,457] WARN [Log partition=tools6-1, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools6-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools6-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548321919981}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:57,457] INFO [Log partition=tools6-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,457] INFO [ProducerStateManager partition=tools6-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,457] INFO [Log partition=tools6-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:57,457] INFO [Log partition=tools6-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,473] INFO [ProducerStateManager partition=tools6-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,489] INFO [Log partition=tools6-1, dir=C:\tmp\logs2] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,489] INFO [ProducerStateManager partition=tools6-1] Loading producer state from snapshot file 'C:\tmp\logs2\tools6-1\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,489] INFO [Log partition=tools6-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 32 ms (kafka.log.Log)
[2019-01-25 10:23:57,504] WARN [Log partition=tools7-0, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools7-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools7-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548173477306}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:57,504] INFO [Log partition=tools7-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,504] INFO [ProducerStateManager partition=tools7-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,504] INFO [Log partition=tools7-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:57,504] INFO [Log partition=tools7-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,504] INFO [ProducerStateManager partition=tools7-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,520] INFO [Log partition=tools7-0, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,520] INFO [ProducerStateManager partition=tools7-0] Loading producer state from snapshot file 'C:\tmp\logs2\tools7-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,520] INFO [Log partition=tools7-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 31 ms (kafka.log.Log)
[2019-01-25 10:23:57,536] INFO [Log partition=tools7-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:57,536] INFO [Log partition=tools7-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,551] INFO [Log partition=tools7-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,551] INFO [Log partition=tools7-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-25 10:23:57,567] WARN [Log partition=tools8-1, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools8-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools8-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548341369651}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:57,567] INFO [Log partition=tools8-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,567] INFO [ProducerStateManager partition=tools8-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,567] INFO [Log partition=tools8-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:57,567] INFO [Log partition=tools8-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,582] INFO [ProducerStateManager partition=tools8-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,582] INFO [Log partition=tools8-1, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,582] INFO [ProducerStateManager partition=tools8-1] Loading producer state from snapshot file 'C:\tmp\logs2\tools8-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,598] INFO [Log partition=tools8-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 47 ms (kafka.log.Log)
[2019-01-25 10:23:57,598] INFO [Log partition=tools8-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:57,598] INFO [Log partition=tools8-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,614] INFO [Log partition=tools8-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,614] INFO [Log partition=tools8-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:23:57,629] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:57,629] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,629] INFO [ProducerStateManager partition=__consumer_offsets-1] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,645] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\logs2] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,645] INFO [ProducerStateManager partition=__consumer_offsets-1] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-1\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,645] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 31 ms (kafka.log.Log)
[2019-01-25 10:23:57,645] WARN [Log partition=__consumer_offsets-10, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\__consumer_offsets-10\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\__consumer_offsets-10\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547979865822}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:57,645] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,660] INFO [ProducerStateManager partition=__consumer_offsets-10] Writing producer snapshot at offset 40 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,660] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:57,660] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,676] INFO [ProducerStateManager partition=__consumer_offsets-10] Writing producer snapshot at offset 40 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,676] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\logs2] Loading producer state till offset 40 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,676] INFO [ProducerStateManager partition=__consumer_offsets-10] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-10\00000000000000000040.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,676] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 40 in 31 ms (kafka.log.Log)
[2019-01-25 10:23:57,692] WARN [Log partition=__consumer_offsets-13, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\__consumer_offsets-13\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\__consumer_offsets-13\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548333787424}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:57,692] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,692] INFO [ProducerStateManager partition=__consumer_offsets-13] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,707] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:57,707] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,707] INFO [ProducerStateManager partition=__consumer_offsets-13] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,723] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\logs2] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,723] INFO [ProducerStateManager partition=__consumer_offsets-13] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-13\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,723] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 31 ms (kafka.log.Log)
[2019-01-25 10:23:57,739] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:57,739] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,739] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,739] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:23:57,754] WARN [Log partition=__consumer_offsets-19, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\__consumer_offsets-19\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\__consumer_offsets-19\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548155030377}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:57,754] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,754] INFO [ProducerStateManager partition=__consumer_offsets-19] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,770] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:57,770] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,785] INFO [ProducerStateManager partition=__consumer_offsets-19] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,785] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\logs2] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,801] INFO [ProducerStateManager partition=__consumer_offsets-19] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-19\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,801] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 47 ms (kafka.log.Log)
[2019-01-25 10:23:57,817] WARN [Log partition=__consumer_offsets-22, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\__consumer_offsets-22\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\__consumer_offsets-22\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548322401427}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:57,817] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,817] INFO [ProducerStateManager partition=__consumer_offsets-22] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,832] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:57,832] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,832] INFO [ProducerStateManager partition=__consumer_offsets-22] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,848] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\logs2] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,848] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-22\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,848] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 47 ms (kafka.log.Log)
[2019-01-25 10:23:57,864] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:57,864] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,864] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,864] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:23:57,879] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:57,879] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,879] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,895] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:23:57,895] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:57,895] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,910] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,910] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-25 10:23:57,910] WARN [Log partition=__consumer_offsets-34, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\__consumer_offsets-34\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\__consumer_offsets-34\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548082054556}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:57,910] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,926] INFO [ProducerStateManager partition=__consumer_offsets-34] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,926] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:57,926] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,926] INFO [ProducerStateManager partition=__consumer_offsets-34] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,942] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\logs2] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,942] INFO [ProducerStateManager partition=__consumer_offsets-34] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-34\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,942] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 32 ms (kafka.log.Log)
[2019-01-25 10:23:57,957] WARN [Log partition=__consumer_offsets-37, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\__consumer_offsets-37\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\__consumer_offsets-37\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548173625567}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:57,957] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,973] INFO [ProducerStateManager partition=__consumer_offsets-37] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,973] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:57,973] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,973] INFO [ProducerStateManager partition=__consumer_offsets-37] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,989] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\logs2] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:57,989] INFO [ProducerStateManager partition=__consumer_offsets-37] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-37\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:57,989] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 32 ms (kafka.log.Log)
[2019-01-25 10:23:58,004] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:58,004] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:58,020] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:58,020] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:23:58,020] WARN [Log partition=__consumer_offsets-40, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\__consumer_offsets-40\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\__consumer_offsets-40\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547994301596}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:58,020] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:58,035] INFO [ProducerStateManager partition=__consumer_offsets-40] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:58,035] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:58,035] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:58,035] INFO [ProducerStateManager partition=__consumer_offsets-40] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:58,051] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\logs2] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:58,051] INFO [ProducerStateManager partition=__consumer_offsets-40] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-40\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:58,051] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 31 ms (kafka.log.Log)
[2019-01-25 10:23:58,067] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:58,067] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:58,082] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:58,082] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-25 10:23:58,098] WARN [Log partition=__consumer_offsets-46, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\__consumer_offsets-46\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\__consumer_offsets-46\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547993701594}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:58,098] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:58,098] INFO [ProducerStateManager partition=__consumer_offsets-46] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:58,098] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:58,098] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:58,114] INFO [ProducerStateManager partition=__consumer_offsets-46] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:58,114] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\logs2] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:58,129] INFO [ProducerStateManager partition=__consumer_offsets-46] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-46\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:58,129] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 47 ms (kafka.log.Log)
[2019-01-25 10:23:58,129] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:58,129] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:58,145] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:58,145] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:23:58,160] WARN [Log partition=__consumer_offsets-7, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\__consumer_offsets-7\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\__consumer_offsets-7\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548333787424}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:23:58,160] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:58,160] INFO [ProducerStateManager partition=__consumer_offsets-7] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:58,160] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:23:58,160] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:58,176] INFO [ProducerStateManager partition=__consumer_offsets-7] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-25 10:23:58,192] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\logs2] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-25 10:23:58,192] INFO [ProducerStateManager partition=__consumer_offsets-7] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-7\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:23:58,192] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 47 ms (kafka.log.Log)
[2019-01-25 10:23:58,192] INFO Logs loading complete in 1672 ms. (kafka.log.LogManager)
[2019-01-25 10:23:58,207] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-25 10:23:58,207] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-25 10:23:58,457] INFO Awaiting socket connections on localhost:9094. (kafka.network.Acceptor)
[2019-01-25 10:23:58,488] INFO [SocketServer brokerId=2] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-25 10:23:58,520] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-25 10:23:58,520] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-25 10:23:58,520] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-25 10:23:58,535] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-25 10:23:58,598] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-25 10:23:58,598] INFO Result of znode creation at /brokers/ids/2 is: OK (kafka.zk.KafkaZkClient)
[2019-01-25 10:23:58,598] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(localhost,9094,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-25 10:23:58,691] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-25 10:23:58,691] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-25 10:23:58,691] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-25 10:23:58,707] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:23:58,723] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:23:58,723] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:58,738] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:28000,blockEndProducerId:28999) by writing to Zk with path version 29 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-25 10:23:58,754] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-25 10:23:58,770] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-25 10:23:58,770] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-25 10:23:58,816] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-25 10:23:58,863] INFO [SocketServer brokerId=2] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-25 10:23:58,863] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-25 10:23:58,863] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-25 10:23:58,863] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2019-01-25 10:23:58,941] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-25, tools1-0, __consumer_offsets-49, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-37, mytools-1, edited8-0, my-example-topic-0, edited-2, tools4-2, tools3-1, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, tools5-0, edited6-2, tools-1, tools2-1, alltools-1, tools7-1, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-01-25 10:23:58,973] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 40 (kafka.cluster.Replica)
[2019-01-25 10:23:58,973] INFO [Partition __consumer_offsets-10 broker=2] __consumer_offsets-10 starts at Leader Epoch 16 from offset 40. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:58,988] INFO Replica loaded for partition edited8-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 10:23:58,988] INFO Replica loaded for partition edited8-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:58,988] INFO [Partition edited8-0 broker=2] edited8-0 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:59,004] INFO Replica loaded for partition alltools-1 with initial high watermark 6 (kafka.cluster.Replica)
[2019-01-25 10:23:59,004] INFO Replica loaded for partition alltools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,004] INFO [Partition alltools-1 broker=2] alltools-1 starts at Leader Epoch 24 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:59,020] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 6 (kafka.cluster.Replica)
[2019-01-25 10:23:59,020] INFO [Partition __consumer_offsets-7 broker=2] __consumer_offsets-7 starts at Leader Epoch 16 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:59,035] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,035] INFO [Partition __consumer_offsets-4 broker=2] __consumer_offsets-4 starts at Leader Epoch 16 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:59,035] INFO Replica loaded for partition edited-2 with initial high watermark 8 (kafka.cluster.Replica)
[2019-01-25 10:23:59,035] INFO Replica loaded for partition edited-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,035] INFO [Partition edited-2 broker=2] edited-2 starts at Leader Epoch 21 from offset 8. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:59,051] INFO Replica loaded for partition mytools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,051] INFO Replica loaded for partition mytools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,051] INFO [Partition mytools-1 broker=2] mytools-1 starts at Leader Epoch 21 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:59,066] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-25 10:23:59,066] INFO [Partition __consumer_offsets-1 broker=2] __consumer_offsets-1 starts at Leader Epoch 16 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:59,066] INFO Replica loaded for partition tools5-0 with initial high watermark 10 (kafka.cluster.Replica)
[2019-01-25 10:23:59,066] INFO Replica loaded for partition tools5-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,066] INFO [Partition tools5-0 broker=2] tools5-0 starts at Leader Epoch 21 from offset 10. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:59,082] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,082] INFO [Partition __consumer_offsets-49 broker=2] __consumer_offsets-49 starts at Leader Epoch 16 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:59,098] INFO Replica loaded for partition edited6-2 with initial high watermark 4 (kafka.cluster.Replica)
[2019-01-25 10:23:59,098] INFO Replica loaded for partition edited6-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,098] INFO [Partition edited6-2 broker=2] edited6-2 starts at Leader Epoch 14 from offset 4. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:59,098] INFO Replica loaded for partition tools3-1 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 10:23:59,098] INFO Replica loaded for partition tools3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,113] INFO [Partition tools3-1 broker=2] tools3-1 starts at Leader Epoch 21 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:59,113] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-25 10:23:59,113] INFO [Partition __consumer_offsets-46 broker=2] __consumer_offsets-46 starts at Leader Epoch 16 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:59,129] INFO Replica loaded for partition tools4-2 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 10:23:59,129] INFO Replica loaded for partition tools4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,129] INFO [Partition tools4-2 broker=2] tools4-2 starts at Leader Epoch 21 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:59,129] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,145] INFO [Partition __consumer_offsets-43 broker=2] __consumer_offsets-43 starts at Leader Epoch 16 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:59,145] INFO Replica loaded for partition my-example-topic-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,145] INFO [Partition my-example-topic-0 broker=2] my-example-topic-0 starts at Leader Epoch 14 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:59,160] INFO Replica loaded for partition tools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,160] INFO Replica loaded for partition tools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,160] INFO [Partition tools-1 broker=2] tools-1 starts at Leader Epoch 21 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:59,160] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-25 10:23:59,176] INFO [Partition __consumer_offsets-40 broker=2] __consumer_offsets-40 starts at Leader Epoch 16 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:59,176] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 5 (kafka.cluster.Replica)
[2019-01-25 10:23:59,176] INFO [Partition __consumer_offsets-37 broker=2] __consumer_offsets-37 starts at Leader Epoch 16 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:59,191] INFO Replica loaded for partition tools2-1 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 10:23:59,191] INFO Replica loaded for partition tools2-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,191] INFO [Partition tools2-1 broker=2] tools2-1 starts at Leader Epoch 21 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:59,207] INFO Replica loaded for partition tools1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,207] INFO Replica loaded for partition tools1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,207] INFO [Partition tools1-0 broker=2] tools1-0 starts at Leader Epoch 21 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:59,223] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 6 (kafka.cluster.Replica)
[2019-01-25 10:23:59,223] INFO [Partition __consumer_offsets-34 broker=2] __consumer_offsets-34 starts at Leader Epoch 16 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:59,223] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,223] INFO [Partition __consumer_offsets-31 broker=2] __consumer_offsets-31 starts at Leader Epoch 16 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:59,238] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 7 (kafka.cluster.Replica)
[2019-01-25 10:23:59,238] INFO [Partition __consumer_offsets-19 broker=2] __consumer_offsets-19 starts at Leader Epoch 16 from offset 7. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:59,238] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,254] INFO [Partition __consumer_offsets-28 broker=2] __consumer_offsets-28 starts at Leader Epoch 16 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:59,254] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,254] INFO [Partition __consumer_offsets-16 broker=2] __consumer_offsets-16 starts at Leader Epoch 16 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:59,254] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,254] INFO [Partition __consumer_offsets-25 broker=2] __consumer_offsets-25 starts at Leader Epoch 16 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:59,269] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 5 (kafka.cluster.Replica)
[2019-01-25 10:23:59,269] INFO [Partition __consumer_offsets-22 broker=2] __consumer_offsets-22 starts at Leader Epoch 16 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:59,285] INFO Replica loaded for partition tools7-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,285] INFO Replica loaded for partition tools7-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,285] INFO [Partition tools7-1 broker=2] tools7-1 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:59,301] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 6 (kafka.cluster.Replica)
[2019-01-25 10:23:59,301] INFO [Partition __consumer_offsets-13 broker=2] __consumer_offsets-13 starts at Leader Epoch 16 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:59,316] INFO Replica loaded for partition edited6-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,316] INFO Replica loaded for partition edited6-1 with initial high watermark 7 (kafka.cluster.Replica)
[2019-01-25 10:23:59,316] INFO Replica loaded for partition mytools-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,316] INFO Replica loaded for partition mytools-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 10:23:59,316] INFO Replica loaded for partition tools4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,332] INFO Replica loaded for partition tools4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,332] INFO Replica loaded for partition tools5-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,332] INFO Replica loaded for partition tools5-2 with initial high watermark 8 (kafka.cluster.Replica)
[2019-01-25 10:23:59,332] INFO Replica loaded for partition tools3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,332] INFO Replica loaded for partition tools3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,348] INFO Replica loaded for partition tools-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,348] INFO Replica loaded for partition tools-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 10:23:59,348] INFO Replica loaded for partition tools6-0 with initial high watermark 5 (kafka.cluster.Replica)
[2019-01-25 10:23:59,348] INFO Replica loaded for partition tools6-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,363] INFO Replica loaded for partition tools6-1 with initial high watermark 6 (kafka.cluster.Replica)
[2019-01-25 10:23:59,363] INFO Replica loaded for partition tools1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,363] INFO Replica loaded for partition tools1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,363] INFO Replica loaded for partition tools2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,363] INFO Replica loaded for partition tools2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,363] INFO Replica loaded for partition edited8-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,379] INFO Replica loaded for partition edited8-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,379] INFO Replica loaded for partition edited-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,379] INFO Replica loaded for partition edited-1 with initial high watermark 9 (kafka.cluster.Replica)
[2019-01-25 10:23:59,379] INFO Replica loaded for partition tools8-1 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 10:23:59,379] INFO Replica loaded for partition tools8-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,379] INFO Replica loaded for partition tools7-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,394] INFO Replica loaded for partition tools7-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 10:23:59,394] INFO Replica loaded for partition alltools-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,394] INFO Replica loaded for partition alltools-0 with initial high watermark 4 (kafka.cluster.Replica)
[2019-01-25 10:23:59,394] INFO Replica loaded for partition tools8-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,394] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(alltools-0, tools7-0, edited8-2, mytools-0, tools5-2, tools2-0, tools8-1, tools3-0, edited6-1, tools1-2, tools4-1, tools-0, edited-1, tools6-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 10:23:59,441] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-25 10:23:59,457] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(edited8-2 -> (offset=0, leaderEpoch=2), tools7-0 -> (offset=1, leaderEpoch=3), tools8-1 -> (offset=1, leaderEpoch=1), tools3-0 -> (offset=0, leaderEpoch=6), tools4-1 -> (offset=0, leaderEpoch=6), tools5-2 -> (offset=8, leaderEpoch=6), tools1-2 -> (offset=0, leaderEpoch=6), edited-1 -> (offset=9, leaderEpoch=6), mytools-0 -> (offset=1, leaderEpoch=6), alltools-0 -> (offset=4, leaderEpoch=7), tools-0 -> (offset=1, leaderEpoch=6), edited6-1 -> (offset=7, leaderEpoch=3), tools6-0 -> (offset=5, leaderEpoch=7), tools2-0 -> (offset=0, leaderEpoch=6)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 10:23:59,457] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:59,457] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:59,457] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:59,457] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:59,457] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:59,473] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:59,473] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:59,473] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:59,473] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:59,488] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:59,488] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:59,488] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:59,488] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:59,488] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:59,488] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:59,488] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:59,504] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:59,504] INFO [Log partition=edited-1, dir=C:\tmp\logs2] Truncating to 9 has no effect as the largest offset in the log is 8 (kafka.log.Log)
[2019-01-25 10:23:59,504] INFO [Log partition=mytools-0, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 10:23:59,504] INFO [Log partition=tools-0, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 10:23:59,519] INFO [Log partition=alltools-0, dir=C:\tmp\logs2] Truncating to 4 has no effect as the largest offset in the log is 3 (kafka.log.Log)
[2019-01-25 10:23:59,519] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools1-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 10:23:59,519] INFO [Log partition=tools1-2, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 10:23:59,519] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in edited8-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 10:23:59,519] INFO [Log partition=edited8-2, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 10:23:59,535] INFO [Log partition=edited6-1, dir=C:\tmp\logs2] Truncating to 7 has no effect as the largest offset in the log is 6 (kafka.log.Log)
[2019-01-25 10:23:59,535] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools2-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 10:23:59,535] INFO [Log partition=tools2-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 10:23:59,535] INFO [Log partition=tools5-2, dir=C:\tmp\logs2] Truncating to 8 has no effect as the largest offset in the log is 7 (kafka.log.Log)
[2019-01-25 10:23:59,535] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools3-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 10:23:59,535] INFO [Log partition=tools3-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 10:23:59,535] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools4-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 10:23:59,535] INFO [Log partition=tools4-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 10:23:59,535] INFO [Log partition=tools6-0, dir=C:\tmp\logs2] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.Log)
[2019-01-25 10:23:59,535] INFO [Log partition=tools7-0, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 10:23:59,551] INFO [Log partition=tools8-1, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 10:23:59,551] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-25, tools1-0, __consumer_offsets-49, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-37, mytools-1, edited8-0, my-example-topic-0, edited-2, tools4-2, tools3-1, __consumer_offsets-19, tools6-1, __consumer_offsets-13, __consumer_offsets-43, tools5-0, edited6-2, tools-1, tools2-1, alltools-1, tools8-2, tools7-1, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-01-25 10:23:59,551] INFO [Partition __consumer_offsets-10 broker=2] __consumer_offsets-10 starts at Leader Epoch 17 from offset 40. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-25 10:23:59,551] WARN [LeaderEpochCache __consumer_offsets-10] New epoch entry EpochEntry(epoch=17, startOffset=40) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=16, startOffset=40)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:23:59,551] INFO [Partition alltools-1 broker=2] alltools-1 starts at Leader Epoch 25 from offset 6. Previous Leader Epoch was: 24 (kafka.cluster.Partition)
[2019-01-25 10:23:59,551] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-22 in 94 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:59,551] WARN [LeaderEpochCache alltools-1] New epoch entry EpochEntry(epoch=25, startOffset=6) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=24, startOffset=6)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:23:59,566] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:59,566] INFO [Partition edited8-0 broker=2] edited8-0 starts at Leader Epoch 2 from offset 1. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-25 10:23:59,566] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:59,566] WARN [LeaderEpochCache edited8-0] New epoch entry EpochEntry(epoch=2, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:23:59,566] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:59,582] INFO [Partition __consumer_offsets-7 broker=2] __consumer_offsets-7 starts at Leader Epoch 17 from offset 6. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-25 10:23:59,582] WARN [LeaderEpochCache __consumer_offsets-7] New epoch entry EpochEntry(epoch=17, startOffset=6) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=16, startOffset=6)). Cache now contains 4 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:23:59,582] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-34 in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:59,582] INFO [Partition __consumer_offsets-4 broker=2] __consumer_offsets-4 starts at Leader Epoch 17 from offset 0. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-25 10:23:59,582] WARN [LeaderEpochCache __consumer_offsets-4] New epoch entry EpochEntry(epoch=17, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=16, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:23:59,582] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:59,598] INFO [Partition edited-2 broker=2] edited-2 starts at Leader Epoch 22 from offset 8. Previous Leader Epoch was: 21 (kafka.cluster.Partition)
[2019-01-25 10:23:59,598] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-40 in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:59,598] WARN [LeaderEpochCache edited-2] New epoch entry EpochEntry(epoch=22, startOffset=8) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=21, startOffset=8)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:23:59,598] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:59,613] INFO [Partition mytools-1 broker=2] mytools-1 starts at Leader Epoch 22 from offset 0. Previous Leader Epoch was: 21 (kafka.cluster.Partition)
[2019-01-25 10:23:59,613] WARN [LeaderEpochCache mytools-1] New epoch entry EpochEntry(epoch=22, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=21, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:23:59,613] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-46 in 15 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:59,613] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:59,613] INFO [Partition __consumer_offsets-1 broker=2] __consumer_offsets-1 starts at Leader Epoch 17 from offset 3. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-25 10:23:59,613] INFO [Partition edited8-2 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-25 10:23:59,613] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:59,613] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:59,629] INFO [Partition tools7-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-25 10:23:59,629] INFO [Partition tools8-1 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-25 10:23:59,613] INFO Replica loaded for partition tools6-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,629] INFO [Partition tools3-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-25 10:23:59,629] INFO [Partition tools6-1 broker=2] tools6-1 starts at Leader Epoch 18 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:23:59,629] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:59,644] INFO [Partition tools4-1 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-25 10:23:59,644] INFO [Partition tools5-0 broker=2] tools5-0 starts at Leader Epoch 22 from offset 10. Previous Leader Epoch was: 21 (kafka.cluster.Partition)
[2019-01-25 10:23:59,644] WARN [LeaderEpochCache tools5-0] New epoch entry EpochEntry(epoch=22, startOffset=10) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=21, startOffset=10)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:23:59,644] INFO [Partition tools5-2 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-25 10:23:59,644] INFO [Partition tools1-2 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-25 10:23:59,644] INFO [Partition __consumer_offsets-49 broker=2] __consumer_offsets-49 starts at Leader Epoch 17 from offset 0. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-25 10:23:59,644] WARN [LeaderEpochCache __consumer_offsets-49] New epoch entry EpochEntry(epoch=17, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=16, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:23:59,644] INFO [Partition edited-1 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-25 10:23:59,660] INFO [Partition mytools-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-25 10:23:59,660] INFO [Partition edited6-2 broker=2] edited6-2 starts at Leader Epoch 15 from offset 4. Previous Leader Epoch was: 14 (kafka.cluster.Partition)
[2019-01-25 10:23:59,660] INFO [Partition alltools-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-25 10:23:59,660] INFO [GroupCoordinator 2]: Loading group metadata for KafkaExampleConsumer with generation 4 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:23:59,660] WARN [LeaderEpochCache edited6-2] New epoch entry EpochEntry(epoch=15, startOffset=4) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=14, startOffset=4)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:23:59,660] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-10 in 31 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:59,660] INFO [Partition tools-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-25 10:23:59,676] INFO [Partition edited6-1 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-25 10:23:59,676] INFO [Partition tools3-1 broker=2] tools3-1 starts at Leader Epoch 22 from offset 1. Previous Leader Epoch was: 21 (kafka.cluster.Partition)
[2019-01-25 10:23:59,676] WARN [LeaderEpochCache tools3-1] New epoch entry EpochEntry(epoch=22, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=21, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:23:59,676] INFO [Partition tools6-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-25 10:23:59,676] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:59,676] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:59,691] INFO [Partition tools2-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-25 10:23:59,691] INFO [Partition __consumer_offsets-46 broker=2] __consumer_offsets-46 starts at Leader Epoch 17 from offset 3. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-25 10:23:59,691] WARN [LeaderEpochCache __consumer_offsets-46] New epoch entry EpochEntry(epoch=17, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=16, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:23:59,691] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 15 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:23:59,691] INFO [Partition tools4-2 broker=2] tools4-2 starts at Leader Epoch 22 from offset 1. Previous Leader Epoch was: 21 (kafka.cluster.Partition)
[2019-01-25 10:23:59,707] WARN [LeaderEpochCache tools4-2] New epoch entry EpochEntry(epoch=22, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=21, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:23:59,707] INFO [Partition __consumer_offsets-43 broker=2] __consumer_offsets-43 starts at Leader Epoch 17 from offset 0. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-25 10:23:59,707] WARN [LeaderEpochCache __consumer_offsets-43] New epoch entry EpochEntry(epoch=17, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=16, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:23:59,723] INFO [Partition my-example-topic-0 broker=2] my-example-topic-0 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: 14 (kafka.cluster.Partition)
[2019-01-25 10:23:59,723] WARN [LeaderEpochCache my-example-topic-0] New epoch entry EpochEntry(epoch=15, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=14, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:23:59,723] INFO [Partition tools-1 broker=2] tools-1 starts at Leader Epoch 22 from offset 0. Previous Leader Epoch was: 21 (kafka.cluster.Partition)
[2019-01-25 10:23:59,723] WARN [LeaderEpochCache tools-1] New epoch entry EpochEntry(epoch=22, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=21, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:23:59,738] INFO [Partition __consumer_offsets-40 broker=2] __consumer_offsets-40 starts at Leader Epoch 17 from offset 3. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-25 10:23:59,738] WARN [LeaderEpochCache __consumer_offsets-40] New epoch entry EpochEntry(epoch=17, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=16, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:23:59,738] INFO [Partition __consumer_offsets-37 broker=2] __consumer_offsets-37 starts at Leader Epoch 17 from offset 5. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-25 10:23:59,738] WARN [LeaderEpochCache __consumer_offsets-37] New epoch entry EpochEntry(epoch=17, startOffset=5) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=16, startOffset=5)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:23:59,754] INFO [Partition tools2-1 broker=2] tools2-1 starts at Leader Epoch 22 from offset 1. Previous Leader Epoch was: 21 (kafka.cluster.Partition)
[2019-01-25 10:23:59,754] WARN [LeaderEpochCache tools2-1] New epoch entry EpochEntry(epoch=22, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=21, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:23:59,754] INFO [Partition tools1-0 broker=2] tools1-0 starts at Leader Epoch 22 from offset 0. Previous Leader Epoch was: 21 (kafka.cluster.Partition)
[2019-01-25 10:23:59,754] WARN [LeaderEpochCache tools1-0] New epoch entry EpochEntry(epoch=22, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=21, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:23:59,769] INFO [Partition __consumer_offsets-34 broker=2] __consumer_offsets-34 starts at Leader Epoch 17 from offset 6. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-25 10:23:59,769] WARN [LeaderEpochCache __consumer_offsets-34] New epoch entry EpochEntry(epoch=17, startOffset=6) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=16, startOffset=6)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:23:59,769] INFO [Partition __consumer_offsets-31 broker=2] __consumer_offsets-31 starts at Leader Epoch 17 from offset 0. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-25 10:23:59,769] WARN [LeaderEpochCache __consumer_offsets-31] New epoch entry EpochEntry(epoch=17, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=16, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:23:59,785] INFO [Partition __consumer_offsets-19 broker=2] __consumer_offsets-19 starts at Leader Epoch 17 from offset 7. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-25 10:23:59,785] WARN [LeaderEpochCache __consumer_offsets-19] New epoch entry EpochEntry(epoch=17, startOffset=7) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=16, startOffset=7)). Cache now contains 5 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:23:59,801] INFO [Partition __consumer_offsets-28 broker=2] __consumer_offsets-28 starts at Leader Epoch 17 from offset 0. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-25 10:23:59,801] WARN [LeaderEpochCache __consumer_offsets-28] New epoch entry EpochEntry(epoch=17, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=16, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:23:59,801] INFO [Partition __consumer_offsets-16 broker=2] __consumer_offsets-16 starts at Leader Epoch 17 from offset 0. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-25 10:23:59,801] WARN [LeaderEpochCache __consumer_offsets-16] New epoch entry EpochEntry(epoch=17, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=16, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:23:59,816] INFO [Partition __consumer_offsets-25 broker=2] __consumer_offsets-25 starts at Leader Epoch 17 from offset 0. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-25 10:23:59,816] WARN [LeaderEpochCache __consumer_offsets-25] New epoch entry EpochEntry(epoch=17, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=16, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:23:59,816] INFO [Partition __consumer_offsets-22 broker=2] __consumer_offsets-22 starts at Leader Epoch 17 from offset 5. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-25 10:23:59,816] WARN [LeaderEpochCache __consumer_offsets-22] New epoch entry EpochEntry(epoch=17, startOffset=5) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=16, startOffset=5)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:23:59,832] INFO [Partition tools7-1 broker=2] tools7-1 starts at Leader Epoch 10 from offset 0. Previous Leader Epoch was: 9 (kafka.cluster.Partition)
[2019-01-25 10:23:59,832] WARN [LeaderEpochCache tools7-1] New epoch entry EpochEntry(epoch=10, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=9, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:23:59,832] INFO [Partition __consumer_offsets-13 broker=2] __consumer_offsets-13 starts at Leader Epoch 17 from offset 6. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-25 10:23:59,832] WARN [LeaderEpochCache __consumer_offsets-13] New epoch entry EpochEntry(epoch=17, startOffset=6) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=16, startOffset=6)). Cache now contains 5 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:23:59,847] INFO Replica loaded for partition tools8-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:23:59,847] INFO [Partition tools8-2 broker=2] tools8-2 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:24:41,888] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-25 10:24:42,450] INFO starting (kafka.server.KafkaServer)
[2019-01-25 10:24:42,450] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-25 10:24:42,482] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-25 10:24:48,121] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:24:48,121] INFO Client environment:host.name=ITdif (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:24:48,121] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:24:48,121] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:24:48,121] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:24:48,121] INFO Client environment:java.class.path=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-connect-jdbc-5.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\mysql-connector-java-8.0.13.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:24:48,121] INFO Client environment:java.library.path=C:\Program Files\Java\jre1.8.0_181\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Docker\Docker\Resources\bin;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\Scripts\;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\dotnet\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\NoteBook FanControl\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\extras\CUPTI\libx64;C:\tools\cuda\bin;C:\Program Files\PuTTY\;C:\Program Files\Calibre2\;C:\apache-maven-3.6.\bin;C:\Users\Stefano\Downloads\platform-tools_r28.0.1-windows\platform-tools;C:\Program Files\Java\jre1.8.0_181\bin;C:\Users\Stefano\AppData\Local\Programs\Python\Launcher\;C:\Users\Stefano\AppData\Local\Microsoft\WindowsApps;C:\Users\Stefano\AppData\Local\GitHubDesktop\bin;C:\apache-maven-3.6.0\bin;;. (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:24:48,121] INFO Client environment:java.io.tmpdir=C:\Users\Stefano\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:24:48,121] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:24:48,121] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:24:48,121] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:24:48,121] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:24:48,121] INFO Client environment:user.name=Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:24:48,121] INFO Client environment:user.home=C:\Users\Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:24:48,121] INFO Client environment:user.dir=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:24:48,121] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@1622f1b (org.apache.zookeeper.ZooKeeper)
[2019-01-25 10:24:48,152] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-25 10:24:48,152] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-25 10:24:48,152] INFO Accepted socket connection from /127.0.0.1:52883 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-25 10:24:48,152] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-25 10:24:48,152] INFO Client attempting to establish new session at /127.0.0.1:52883 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 10:24:48,152] INFO Established session 0x1000380b4ed0002 with negotiated timeout 6000 for client /127.0.0.1:52883 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 10:24:48,152] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000380b4ed0002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-25 10:24:48,168] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-25 10:24:48,215] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0002 type:create cxid:0x1 zxid:0xa27 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:24:48,230] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0002 type:create cxid:0x2 zxid:0xa28 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:24:48,230] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0002 type:create cxid:0x3 zxid:0xa29 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:24:48,230] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0002 type:create cxid:0x4 zxid:0xa2a txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:24:48,230] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0002 type:create cxid:0x5 zxid:0xa2b txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:24:48,246] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0002 type:create cxid:0x6 zxid:0xa2c txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:24:48,246] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0002 type:create cxid:0x7 zxid:0xa2d txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:24:48,246] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0002 type:create cxid:0x8 zxid:0xa2e txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:24:48,246] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0002 type:create cxid:0x9 zxid:0xa2f txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:24:48,246] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0002 type:create cxid:0xa zxid:0xa30 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:24:48,246] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0002 type:create cxid:0xb zxid:0xa31 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:24:48,262] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0002 type:create cxid:0xc zxid:0xa32 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:24:48,262] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0002 type:create cxid:0xd zxid:0xa33 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:24:48,387] INFO Cluster ID = RvEiz9fYQgKWcHR6fHb3dg (kafka.server.KafkaServer)
[2019-01-25 10:24:48,480] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-25 10:24:48,496] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-25 10:24:48,527] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-25 10:24:48,527] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-25 10:24:48,527] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-25 10:24:48,574] INFO Loading logs. (kafka.log.LogManager)
[2019-01-25 10:24:48,636] WARN [Log partition=alltools-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\alltools-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\alltools-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547979859855}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:24:48,652] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:48,699] INFO [ProducerStateManager partition=alltools-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:48,699] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:48,699] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:48,715] INFO [ProducerStateManager partition=alltools-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:48,730] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:48,730] INFO [ProducerStateManager partition=alltools-1] Loading producer state from snapshot file 'C:\tmp\logs3\alltools-1\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:24:48,746] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 125 ms (kafka.log.Log)
[2019-01-25 10:24:48,777] WARN [Log partition=alltools-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\alltools-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\alltools-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547977368170}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:24:48,777] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:48,777] INFO [ProducerStateManager partition=alltools-2] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:48,777] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:48,777] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:48,793] INFO [ProducerStateManager partition=alltools-2] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:48,808] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:48,808] INFO [ProducerStateManager partition=alltools-2] Loading producer state from snapshot file 'C:\tmp\logs3\alltools-2\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:24:48,808] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 47 ms (kafka.log.Log)
[2019-01-25 10:24:48,824] WARN [Log partition=edited-0, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\edited-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\edited-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996878625}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:24:48,824] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:48,824] INFO [ProducerStateManager partition=edited-0] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:48,824] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:48,824] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:48,824] INFO [ProducerStateManager partition=edited-0] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:48,840] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:48,855] INFO [ProducerStateManager partition=edited-0] Loading producer state from snapshot file 'C:\tmp\logs3\edited-0\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:24:48,855] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 47 ms (kafka.log.Log)
[2019-01-25 10:24:48,855] WARN [Log partition=edited-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\edited-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\edited-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996875547}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:24:48,855] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:48,871] INFO [ProducerStateManager partition=edited-2] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:48,871] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:48,871] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:48,871] INFO [ProducerStateManager partition=edited-2] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:48,886] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:48,886] INFO [ProducerStateManager partition=edited-2] Loading producer state from snapshot file 'C:\tmp\logs3\edited-2\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:24:48,886] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 31 ms (kafka.log.Log)
[2019-01-25 10:24:48,902] WARN [Log partition=edited6-0, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\edited6-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\edited6-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548158302054}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:24:48,902] INFO [Log partition=edited6-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:48,902] INFO [ProducerStateManager partition=edited6-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:48,902] INFO [Log partition=edited6-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:48,902] INFO [Log partition=edited6-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:48,918] INFO [ProducerStateManager partition=edited6-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:48,933] INFO [Log partition=edited6-0, dir=C:\tmp\logs3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:48,933] INFO [ProducerStateManager partition=edited6-0] Loading producer state from snapshot file 'C:\tmp\logs3\edited6-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:24:48,933] INFO [Log partition=edited6-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 31 ms (kafka.log.Log)
[2019-01-25 10:24:48,949] WARN [Log partition=edited6-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\edited6-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\edited6-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548176773646}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:24:48,949] INFO [Log partition=edited6-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:48,949] INFO [ProducerStateManager partition=edited6-2] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:48,964] INFO [Log partition=edited6-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:48,964] INFO [Log partition=edited6-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:48,964] INFO [ProducerStateManager partition=edited6-2] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:48,980] INFO [Log partition=edited6-2, dir=C:\tmp\logs3] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:48,980] INFO [ProducerStateManager partition=edited6-2] Loading producer state from snapshot file 'C:\tmp\logs3\edited6-2\00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:24:48,980] INFO [Log partition=edited6-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 47 ms (kafka.log.Log)
[2019-01-25 10:24:48,996] WARN [Log partition=edited8-0, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\edited8-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\edited8-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548341369651}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:24:48,996] INFO [Log partition=edited8-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:48,996] INFO [ProducerStateManager partition=edited8-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:48,996] INFO [Log partition=edited8-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:48,996] INFO [Log partition=edited8-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,011] INFO [ProducerStateManager partition=edited8-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:49,011] INFO [Log partition=edited8-0, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,011] INFO [ProducerStateManager partition=edited8-0] Loading producer state from snapshot file 'C:\tmp\logs3\edited8-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:24:49,011] INFO [Log partition=edited8-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 31 ms (kafka.log.Log)
[2019-01-25 10:24:49,027] INFO [Log partition=edited8-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:49,027] INFO [Log partition=edited8-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,043] INFO [Log partition=edited8-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,043] INFO [Log partition=edited8-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:24:49,043] INFO [Log partition=mytools-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:49,058] INFO [Log partition=mytools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,058] INFO [Log partition=mytools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,058] INFO [Log partition=mytools-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-25 10:24:49,074] INFO [Log partition=mytools-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:49,074] INFO [Log partition=mytools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,074] INFO [Log partition=mytools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,074] INFO [Log partition=mytools-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:24:49,089] INFO [Log partition=tools-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:49,089] INFO [Log partition=tools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,105] INFO [Log partition=tools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,105] INFO [Log partition=tools-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:24:49,105] INFO [Log partition=tools-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:49,105] INFO [Log partition=tools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,121] INFO [Log partition=tools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,121] INFO [Log partition=tools-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:24:49,136] INFO [Log partition=tools1-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:49,136] INFO [Log partition=tools1-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,136] INFO [Log partition=tools1-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,136] INFO [Log partition=tools1-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-25 10:24:49,152] INFO [Log partition=tools1-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:49,152] INFO [Log partition=tools1-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,152] INFO [Log partition=tools1-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,152] INFO [Log partition=tools1-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:24:49,168] WARN [Log partition=tools2-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools2-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools2-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547992951029}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:24:49,168] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,183] INFO [ProducerStateManager partition=tools2-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:49,183] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:49,183] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,183] INFO [ProducerStateManager partition=tools2-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:49,199] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,199] INFO [ProducerStateManager partition=tools2-1] Loading producer state from snapshot file 'C:\tmp\logs3\tools2-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:24:49,199] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 31 ms (kafka.log.Log)
[2019-01-25 10:24:49,214] INFO [Log partition=tools2-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:49,214] INFO [Log partition=tools2-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,214] INFO [Log partition=tools2-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,230] INFO [Log partition=tools2-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:24:49,230] WARN [Log partition=tools3-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools3-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools3-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547993388462}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:24:49,230] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,246] INFO [ProducerStateManager partition=tools3-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:49,246] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:49,246] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,246] INFO [ProducerStateManager partition=tools3-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:49,261] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,261] INFO [ProducerStateManager partition=tools3-1] Loading producer state from snapshot file 'C:\tmp\logs3\tools3-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:24:49,261] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 31 ms (kafka.log.Log)
[2019-01-25 10:24:49,277] INFO [Log partition=tools3-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:49,277] INFO [Log partition=tools3-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,293] INFO [Log partition=tools3-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,293] INFO [Log partition=tools3-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:24:49,293] INFO [Log partition=tools4-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:49,293] INFO [Log partition=tools4-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,308] INFO [Log partition=tools4-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,308] INFO [Log partition=tools4-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-25 10:24:49,324] WARN [Log partition=tools4-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools4-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools4-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547993897061}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:24:49,324] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,324] INFO [ProducerStateManager partition=tools4-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:49,324] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:49,324] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,339] INFO [ProducerStateManager partition=tools4-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:49,339] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,339] INFO [ProducerStateManager partition=tools4-2] Loading producer state from snapshot file 'C:\tmp\logs3\tools4-2\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:24:49,355] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 31 ms (kafka.log.Log)
[2019-01-25 10:24:49,355] WARN [Log partition=tools5-0, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools5-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools5-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996871342}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:24:49,355] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,371] INFO [ProducerStateManager partition=tools5-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:49,371] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:49,371] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,371] INFO [ProducerStateManager partition=tools5-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:49,386] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,386] INFO [ProducerStateManager partition=tools5-0] Loading producer state from snapshot file 'C:\tmp\logs3\tools5-0\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:24:49,386] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 31 ms (kafka.log.Log)
[2019-01-25 10:24:49,402] WARN [Log partition=tools5-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools5-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools5-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996876577}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:24:49,402] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,418] INFO [ProducerStateManager partition=tools5-1] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:49,418] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:49,418] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,433] INFO [ProducerStateManager partition=tools5-1] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:49,433] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,449] INFO [ProducerStateManager partition=tools5-1] Loading producer state from snapshot file 'C:\tmp\logs3\tools5-1\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:24:49,449] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 47 ms (kafka.log.Log)
[2019-01-25 10:24:49,449] WARN [Log partition=tools6-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools6-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools6-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548321919981}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:24:49,449] INFO [Log partition=tools6-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,464] INFO [ProducerStateManager partition=tools6-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:49,464] INFO [Log partition=tools6-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:49,464] INFO [Log partition=tools6-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,464] INFO [ProducerStateManager partition=tools6-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:49,480] INFO [Log partition=tools6-1, dir=C:\tmp\logs3] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,480] INFO [ProducerStateManager partition=tools6-1] Loading producer state from snapshot file 'C:\tmp\logs3\tools6-1\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:24:49,480] INFO [Log partition=tools6-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 31 ms (kafka.log.Log)
[2019-01-25 10:24:49,496] WARN [Log partition=tools6-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools6-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools6-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548158302054}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:24:49,496] INFO [Log partition=tools6-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,511] INFO [ProducerStateManager partition=tools6-2] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:49,511] INFO [Log partition=tools6-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:49,511] INFO [Log partition=tools6-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,511] INFO [ProducerStateManager partition=tools6-2] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:49,527] INFO [Log partition=tools6-2, dir=C:\tmp\logs3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,527] INFO [ProducerStateManager partition=tools6-2] Loading producer state from snapshot file 'C:\tmp\logs3\tools6-2\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:24:49,527] INFO [Log partition=tools6-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 31 ms (kafka.log.Log)
[2019-01-25 10:24:49,542] INFO [Log partition=tools7-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:49,542] INFO [Log partition=tools7-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,542] INFO [Log partition=tools7-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,542] INFO [Log partition=tools7-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 10:24:49,558] WARN [Log partition=tools7-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools7-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools7-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548156023437}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:24:49,558] INFO [Log partition=tools7-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,558] INFO [ProducerStateManager partition=tools7-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:49,558] INFO [Log partition=tools7-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:49,558] INFO [Log partition=tools7-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,574] INFO [ProducerStateManager partition=tools7-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:49,574] INFO [Log partition=tools7-2, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,589] INFO [ProducerStateManager partition=tools7-2] Loading producer state from snapshot file 'C:\tmp\logs3\tools7-2\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:24:49,589] INFO [Log partition=tools7-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 31 ms (kafka.log.Log)
[2019-01-25 10:24:49,589] INFO [Log partition=tools8-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:49,589] INFO [Log partition=tools8-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,605] INFO [Log partition=tools8-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,605] INFO [Log partition=tools8-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:24:49,605] INFO [Log partition=tools8-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:49,605] INFO [Log partition=tools8-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,621] INFO [Log partition=tools8-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,621] INFO [Log partition=tools8-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:24:49,636] WARN [Log partition=__consumer_offsets-11, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\__consumer_offsets-11\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\__consumer_offsets-11\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548341547032}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:24:49,636] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,636] INFO [ProducerStateManager partition=__consumer_offsets-11] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:49,636] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:49,636] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,652] INFO [ProducerStateManager partition=__consumer_offsets-11] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:49,652] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs3] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,652] INFO [ProducerStateManager partition=__consumer_offsets-11] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-11\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:24:49,667] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 46 ms (kafka.log.Log)
[2019-01-25 10:24:49,667] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:49,667] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,683] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,683] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:24:49,699] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:49,699] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,699] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,714] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-25 10:24:49,714] WARN [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547989834290}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:24:49,714] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,730] INFO [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 142 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:49,730] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:49,730] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,746] INFO [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 142 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:49,761] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Loading producer state till offset 142 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,761] INFO [ProducerStateManager partition=__consumer_offsets-2] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-2\00000000000000000142.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:24:49,761] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 142 in 47 ms (kafka.log.Log)
[2019-01-25 10:24:49,777] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:49,777] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,777] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,792] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-25 10:24:49,792] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:49,792] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,808] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,808] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:24:49,808] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:49,808] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,824] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,824] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:24:49,839] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:49,839] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,839] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,855] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-25 10:24:49,855] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:49,855] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,871] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,871] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:24:49,871] WARN [Log partition=__consumer_offsets-35, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\__consumer_offsets-35\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\__consumer_offsets-35\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548327517176}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:24:49,871] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,886] INFO [ProducerStateManager partition=__consumer_offsets-35] Writing producer snapshot at offset 52 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:49,886] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:49,886] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,902] INFO [ProducerStateManager partition=__consumer_offsets-35] Writing producer snapshot at offset 52 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:49,902] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs3] Loading producer state till offset 52 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,902] INFO [ProducerStateManager partition=__consumer_offsets-35] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-35\00000000000000000052.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:24:49,902] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 52 in 31 ms (kafka.log.Log)
[2019-01-25 10:24:49,917] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:49,917] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,933] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,933] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:24:49,933] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:49,933] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,949] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,949] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:24:49,964] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:49,964] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,980] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,980] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-25 10:24:49,980] WARN [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\__consumer_offsets-47\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\__consumer_offsets-47\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547992512270}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 10:24:49,980] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,996] INFO [ProducerStateManager partition=__consumer_offsets-47] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:49,996] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:49,996] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:49,996] INFO [ProducerStateManager partition=__consumer_offsets-47] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 10:24:50,011] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:50,011] INFO [ProducerStateManager partition=__consumer_offsets-47] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-47\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 10:24:50,011] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 31 ms (kafka.log.Log)
[2019-01-25 10:24:50,027] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:50,027] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:50,042] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:50,042] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-25 10:24:50,042] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 10:24:50,042] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:50,058] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:24:50,058] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:24:50,074] INFO Logs loading complete in 1500 ms. (kafka.log.LogManager)
[2019-01-25 10:24:50,089] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-25 10:24:50,089] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-25 10:24:50,355] INFO Awaiting socket connections on localhost:9095. (kafka.network.Acceptor)
[2019-01-25 10:24:50,386] INFO [SocketServer brokerId=3] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-25 10:24:50,402] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-25 10:24:50,402] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-25 10:24:50,402] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-25 10:24:50,417] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-25 10:24:50,480] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-25 10:24:50,480] INFO Result of znode creation at /brokers/ids/3 is: OK (kafka.zk.KafkaZkClient)
[2019-01-25 10:24:50,495] INFO Registered broker 3 at path /brokers/ids/3 with addresses: ArrayBuffer(EndPoint(localhost,9095,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-25 10:24:50,558] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-25 10:24:50,574] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-25 10:24:50,574] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-25 10:24:50,589] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:24:50,589] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:24:50,589] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:24:50,605] INFO [ProducerId Manager 3]: Acquired new producerId block (brokerId:3,blockStartProducerId:29000,blockEndProducerId:29999) by writing to Zk with path version 30 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-25 10:24:50,636] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-25 10:24:50,636] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-25 10:24:50,652] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-25 10:24:50,698] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-25 10:24:50,730] INFO [SocketServer brokerId=3] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-25 10:24:50,745] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-25 10:24:50,745] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-25 10:24:50,745] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2019-01-25 10:24:50,823] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(__consumer_offsets-8, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-47, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-32) (kafka.server.ReplicaFetcherManager)
[2019-01-25 10:24:50,839] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:50,855] INFO [Partition __consumer_offsets-29 broker=3] __consumer_offsets-29 starts at Leader Epoch 16 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:24:50,870] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:50,870] INFO [Partition __consumer_offsets-26 broker=3] __consumer_offsets-26 starts at Leader Epoch 16 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:24:50,886] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:50,886] INFO [Partition __consumer_offsets-23 broker=3] __consumer_offsets-23 starts at Leader Epoch 16 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:24:50,886] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:50,886] INFO [Partition __consumer_offsets-20 broker=3] __consumer_offsets-20 starts at Leader Epoch 16 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:24:50,902] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:50,902] INFO [Partition __consumer_offsets-17 broker=3] __consumer_offsets-17 starts at Leader Epoch 16 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:24:50,917] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:50,917] INFO [Partition __consumer_offsets-14 broker=3] __consumer_offsets-14 starts at Leader Epoch 16 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:24:50,917] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 5 (kafka.cluster.Replica)
[2019-01-25 10:24:50,917] INFO [Partition __consumer_offsets-11 broker=3] __consumer_offsets-11 starts at Leader Epoch 16 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:24:50,933] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:50,933] INFO [Partition __consumer_offsets-8 broker=3] __consumer_offsets-8 starts at Leader Epoch 16 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:24:50,948] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:50,948] INFO [Partition __consumer_offsets-5 broker=3] __consumer_offsets-5 starts at Leader Epoch 16 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:24:50,948] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 142 (kafka.cluster.Replica)
[2019-01-25 10:24:50,948] INFO [Partition __consumer_offsets-2 broker=3] __consumer_offsets-2 starts at Leader Epoch 16 from offset 142. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:24:50,948] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-25 10:24:50,948] INFO [Partition __consumer_offsets-47 broker=3] __consumer_offsets-47 starts at Leader Epoch 16 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:24:50,964] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:50,964] INFO [Partition __consumer_offsets-38 broker=3] __consumer_offsets-38 starts at Leader Epoch 16 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:24:50,980] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 52 (kafka.cluster.Replica)
[2019-01-25 10:24:50,980] INFO [Partition __consumer_offsets-35 broker=3] __consumer_offsets-35 starts at Leader Epoch 16 from offset 52. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:24:50,980] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:50,980] INFO [Partition __consumer_offsets-44 broker=3] __consumer_offsets-44 starts at Leader Epoch 16 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:24:50,995] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:50,995] INFO [Partition __consumer_offsets-41 broker=3] __consumer_offsets-41 starts at Leader Epoch 16 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:24:51,011] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,011] INFO [Partition __consumer_offsets-32 broker=3] __consumer_offsets-32 starts at Leader Epoch 16 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:24:51,027] INFO Replica loaded for partition tools2-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,027] INFO Replica loaded for partition tools2-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,027] INFO Replica loaded for partition tools1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,027] INFO Replica loaded for partition tools1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,027] INFO Replica loaded for partition edited8-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,042] INFO Replica loaded for partition edited8-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 10:24:51,042] INFO Replica loaded for partition alltools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,042] INFO Replica loaded for partition alltools-1 with initial high watermark 6 (kafka.cluster.Replica)
[2019-01-25 10:24:51,042] INFO Replica loaded for partition edited-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,042] INFO Replica loaded for partition edited-2 with initial high watermark 8 (kafka.cluster.Replica)
[2019-01-25 10:24:51,042] INFO Replica loaded for partition mytools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,058] INFO Replica loaded for partition mytools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,058] INFO Replica loaded for partition tools7-2 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 10:24:51,058] INFO Replica loaded for partition tools7-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,058] INFO Replica loaded for partition tools6-1 with initial high watermark 6 (kafka.cluster.Replica)
[2019-01-25 10:24:51,058] INFO Replica loaded for partition tools6-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,058] INFO Replica loaded for partition tools5-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,073] INFO Replica loaded for partition tools5-0 with initial high watermark 10 (kafka.cluster.Replica)
[2019-01-25 10:24:51,073] INFO Replica loaded for partition tools8-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,073] INFO Replica loaded for partition tools8-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,073] INFO Replica loaded for partition edited6-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,089] INFO Replica loaded for partition edited6-2 with initial high watermark 4 (kafka.cluster.Replica)
[2019-01-25 10:24:51,089] INFO Replica loaded for partition edited-0 with initial high watermark 8 (kafka.cluster.Replica)
[2019-01-25 10:24:51,089] INFO Replica loaded for partition edited-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,089] INFO Replica loaded for partition alltools-2 with initial high watermark 5 (kafka.cluster.Replica)
[2019-01-25 10:24:51,089] INFO Replica loaded for partition alltools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,089] INFO Replica loaded for partition tools3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,105] INFO Replica loaded for partition tools3-1 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 10:24:51,105] INFO Replica loaded for partition tools4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,105] INFO Replica loaded for partition tools4-2 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 10:24:51,105] INFO Replica loaded for partition edited8-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,105] INFO Replica loaded for partition edited8-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,105] INFO Replica loaded for partition tools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,120] INFO Replica loaded for partition tools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,120] INFO Replica loaded for partition mytools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,120] INFO Replica loaded for partition mytools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,120] INFO Replica loaded for partition tools2-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,120] INFO Replica loaded for partition tools2-1 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 10:24:51,120] INFO Replica loaded for partition tools3-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,120] INFO Replica loaded for partition tools3-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,136] INFO Replica loaded for partition tools1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,136] INFO Replica loaded for partition tools1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,136] INFO Replica loaded for partition tools5-1 with initial high watermark 5 (kafka.cluster.Replica)
[2019-01-25 10:24:51,136] INFO Replica loaded for partition tools5-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,136] INFO Replica loaded for partition tools4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,136] INFO Replica loaded for partition tools4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,136] INFO Replica loaded for partition tools6-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,151] INFO Replica loaded for partition tools6-2 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-25 10:24:51,151] INFO Replica loaded for partition edited6-0 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-25 10:24:51,151] INFO Replica loaded for partition edited6-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,151] INFO Replica loaded for partition tools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,151] INFO Replica loaded for partition tools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,151] INFO Replica loaded for partition tools7-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,167] INFO Replica loaded for partition tools7-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,167] INFO Replica loaded for partition tools8-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,167] INFO Replica loaded for partition tools8-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:24:51,167] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools2-2, edited-2, tools3-2, tools5-1, tools4-2, tools6-1, alltools-1, tools-2, tools7-1, tools6-2, edited-0, tools1-1, edited8-0, tools2-1, tools4-0, tools3-1, edited8-1, tools5-0, mytools-2, tools-1, tools8-0, edited6-0, tools1-0, mytools-1, alltools-2, tools7-2, tools8-2, edited6-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 10:24:51,214] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-25 10:24:51,214] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(tools4-0 -> (offset=0, leaderEpoch=23), tools1-1 -> (offset=0, leaderEpoch=23), tools2-2 -> (offset=0, leaderEpoch=23), tools-2 -> (offset=0, leaderEpoch=23), edited6-0 -> (offset=3, leaderEpoch=19), alltools-2 -> (offset=5, leaderEpoch=24), tools8-0 -> (offset=0, leaderEpoch=2), edited8-1 -> (offset=0, leaderEpoch=3), tools5-1 -> (offset=5, leaderEpoch=23), tools6-2 -> (offset=3, leaderEpoch=6), tools7-2 -> (offset=1, leaderEpoch=13), edited-0 -> (offset=8, leaderEpoch=23), tools3-2 -> (offset=0, leaderEpoch=23), mytools-2 -> (offset=0, leaderEpoch=23)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 10:24:51,214] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(tools1-0 -> (offset=0, leaderEpoch=22), mytools-1 -> (offset=0, leaderEpoch=22), edited8-0 -> (offset=1, leaderEpoch=2), edited-2 -> (offset=8, leaderEpoch=22), tools4-2 -> (offset=1, leaderEpoch=22), tools3-1 -> (offset=1, leaderEpoch=22), tools6-1 -> (offset=6, leaderEpoch=18), tools5-0 -> (offset=10, leaderEpoch=22), edited6-2 -> (offset=4, leaderEpoch=15), tools-1 -> (offset=0, leaderEpoch=22), tools2-1 -> (offset=1, leaderEpoch=22), alltools-1 -> (offset=6, leaderEpoch=25), tools8-2 -> (offset=0, leaderEpoch=3), tools7-1 -> (offset=0, leaderEpoch=10)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 10:24:51,214] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-25 10:24:51,245] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:24:51,245] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:24:51,261] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:24:51,261] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:24:51,261] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:24:51,261] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:24:51,276] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:24:51,276] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Truncating to 8 has no effect as the largest offset in the log is 7 (kafka.log.Log)
[2019-01-25 10:24:51,276] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Truncating to 8 has no effect as the largest offset in the log is 7 (kafka.log.Log)
[2019-01-25 10:24:51,276] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:24:51,276] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.Log)
[2019-01-25 10:24:51,276] INFO [Log partition=edited8-0, dir=C:\tmp\logs3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 10:24:51,276] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:24:51,292] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 10:24:51,292] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 10:24:51,292] INFO [Log partition=tools-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 10:24:51,292] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:24:51,292] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools1-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 10:24:51,292] INFO [Log partition=tools-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 10:24:51,292] INFO [Log partition=tools1-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 10:24:51,292] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:24:51,308] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools2-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 10:24:51,308] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Truncating to 6 has no effect as the largest offset in the log is 5 (kafka.log.Log)
[2019-01-25 10:24:51,308] INFO [Log partition=tools2-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 10:24:51,308] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:24:51,308] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools3-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 10:24:51,308] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 10:24:51,308] INFO [Log partition=tools3-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 10:24:51,308] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:24:51,323] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in mytools-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 10:24:51,323] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools1-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 10:24:51,323] INFO [Log partition=mytools-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 10:24:51,323] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:24:51,323] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.Log)
[2019-01-25 10:24:51,323] INFO [Log partition=tools1-0, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 10:24:51,339] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in mytools-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 10:24:51,323] INFO [Log partition=tools6-2, dir=C:\tmp\logs3] Truncating to 3 has no effect as the largest offset in the log is 2 (kafka.log.Log)
[2019-01-25 10:24:51,323] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:24:51,339] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools4-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 10:24:51,339] INFO [Log partition=mytools-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 10:24:51,339] INFO [Log partition=tools4-0, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 10:24:51,339] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:24:51,339] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in edited8-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 10:24:51,339] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Truncating to 10 has no effect as the largest offset in the log is 9 (kafka.log.Log)
[2019-01-25 10:24:51,355] INFO [Log partition=tools6-1, dir=C:\tmp\logs3] Truncating to 6 has no effect as the largest offset in the log is 5 (kafka.log.Log)
[2019-01-25 10:24:51,355] INFO [Log partition=edited8-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 10:24:51,355] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 10:24:51,355] INFO [Log partition=edited6-0, dir=C:\tmp\logs3] Truncating to 3 has no effect as the largest offset in the log is 2 (kafka.log.Log)
[2019-01-25 10:24:51,355] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 10:24:51,355] INFO [Log partition=tools7-2, dir=C:\tmp\logs3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 10:24:51,370] INFO [Log partition=edited6-2, dir=C:\tmp\logs3] Truncating to 4 has no effect as the largest offset in the log is 3 (kafka.log.Log)
[2019-01-25 10:24:51,370] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools8-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 10:24:51,370] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools8-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 10:24:51,370] INFO [Log partition=tools8-0, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 10:24:51,370] INFO [Log partition=tools8-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 10:24:51,370] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools7-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 10:24:51,370] INFO [Log partition=tools7-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 10:24:51,386] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(__consumer_offsets-8, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-47, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-32) (kafka.server.ReplicaFetcherManager)
[2019-01-25 10:24:51,386] INFO [GroupCoordinator 3]: Loading group metadata for alltoolsStream with generation 66 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:24:51,386] INFO [Partition tools4-0 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-25 10:24:51,386] INFO [Partition __consumer_offsets-29 broker=3] __consumer_offsets-29 starts at Leader Epoch 17 from offset 0. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-25 10:24:51,386] WARN [LeaderEpochCache __consumer_offsets-29] New epoch entry EpochEntry(epoch=17, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=16, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:24:51,386] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-2 in 141 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:24:51,401] INFO [Partition tools1-1 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-25 10:24:51,401] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:24:51,401] INFO [Partition tools2-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-25 10:24:51,401] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:24:51,401] INFO [Partition __consumer_offsets-26 broker=3] __consumer_offsets-26 starts at Leader Epoch 17 from offset 0. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-25 10:24:51,401] WARN [LeaderEpochCache __consumer_offsets-26] New epoch entry EpochEntry(epoch=17, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=16, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:24:51,401] INFO [Partition tools-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-25 10:24:51,417] INFO [Partition edited6-0 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-25 10:24:51,417] INFO [Partition __consumer_offsets-23 broker=3] __consumer_offsets-23 starts at Leader Epoch 17 from offset 0. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-25 10:24:51,417] INFO [Partition alltools-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-25 10:24:51,417] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-11 in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:24:51,417] WARN [LeaderEpochCache __consumer_offsets-23] New epoch entry EpochEntry(epoch=17, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=16, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:24:51,433] INFO [Partition tools8-0 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-25 10:24:51,433] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-14 in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:24:51,433] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:24:51,433] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:24:51,433] INFO [Partition edited8-1 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-25 10:24:51,433] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:24:51,433] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:24:51,433] INFO [Partition __consumer_offsets-20 broker=3] __consumer_offsets-20 starts at Leader Epoch 17 from offset 0. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-25 10:24:51,433] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:24:51,433] INFO [Partition tools5-1 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-25 10:24:51,433] WARN [LeaderEpochCache __consumer_offsets-20] New epoch entry EpochEntry(epoch=17, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=16, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:24:51,433] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:24:51,433] INFO [Partition tools6-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-25 10:24:51,433] INFO [Partition __consumer_offsets-17 broker=3] __consumer_offsets-17 starts at Leader Epoch 17 from offset 0. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-25 10:24:51,448] INFO [Partition tools7-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-25 10:24:51,448] INFO [Partition edited-0 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-25 10:24:51,448] WARN [LeaderEpochCache __consumer_offsets-17] New epoch entry EpochEntry(epoch=17, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=16, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:24:51,448] INFO [Partition tools3-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-25 10:24:51,464] INFO [Partition __consumer_offsets-14 broker=3] __consumer_offsets-14 starts at Leader Epoch 17 from offset 0. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-25 10:24:51,464] WARN [LeaderEpochCache __consumer_offsets-14] New epoch entry EpochEntry(epoch=17, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=16, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:24:51,464] INFO [Partition tools1-0 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-25 10:24:51,464] INFO [Partition mytools-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-25 10:24:51,464] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-35 in 31 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:24:51,464] INFO [Partition __consumer_offsets-11 broker=3] __consumer_offsets-11 starts at Leader Epoch 17 from offset 5. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-25 10:24:51,464] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:24:51,464] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:24:51,464] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:24:51,480] INFO [Partition __consumer_offsets-8 broker=3] __consumer_offsets-8 starts at Leader Epoch 17 from offset 0. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-25 10:24:51,480] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-47 in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:24:51,480] WARN [LeaderEpochCache __consumer_offsets-8] New epoch entry EpochEntry(epoch=17, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=16, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:24:51,495] INFO [Partition __consumer_offsets-5 broker=3] __consumer_offsets-5 starts at Leader Epoch 17 from offset 0. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-25 10:24:51,495] WARN [LeaderEpochCache __consumer_offsets-5] New epoch entry EpochEntry(epoch=17, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=16, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:24:51,495] INFO [Partition mytools-1 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-25 10:24:51,495] INFO [Partition edited8-0 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-25 10:24:51,495] INFO [Partition __consumer_offsets-2 broker=3] __consumer_offsets-2 starts at Leader Epoch 17 from offset 142. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-25 10:24:51,495] WARN [LeaderEpochCache __consumer_offsets-2] New epoch entry EpochEntry(epoch=17, startOffset=142) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=16, startOffset=142)). Cache now contains 11 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:24:51,495] INFO [Partition edited-2 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-25 10:24:51,511] INFO [Partition tools4-2 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-25 10:24:51,495] INFO [Partition __consumer_offsets-47 broker=3] __consumer_offsets-47 starts at Leader Epoch 17 from offset 3. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-25 10:24:51,511] INFO [Partition tools3-1 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-25 10:24:51,511] WARN [LeaderEpochCache __consumer_offsets-47] New epoch entry EpochEntry(epoch=17, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=16, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:24:51,511] INFO [Partition tools6-1 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-25 10:24:51,526] INFO [Partition tools5-0 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-25 10:24:51,526] INFO [Partition __consumer_offsets-38 broker=3] __consumer_offsets-38 starts at Leader Epoch 17 from offset 0. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-25 10:24:51,526] WARN [LeaderEpochCache __consumer_offsets-38] New epoch entry EpochEntry(epoch=17, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=16, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:24:51,526] INFO [Partition edited6-2 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-25 10:24:51,526] INFO [Partition __consumer_offsets-35 broker=3] __consumer_offsets-35 starts at Leader Epoch 17 from offset 52. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-25 10:24:51,526] INFO [Partition tools-1 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-25 10:24:51,542] INFO [Partition tools2-1 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-25 10:24:51,542] INFO [Partition __consumer_offsets-44 broker=3] __consumer_offsets-44 starts at Leader Epoch 17 from offset 0. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-25 10:24:51,542] INFO [Partition alltools-1 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-25 10:24:51,542] WARN [LeaderEpochCache __consumer_offsets-44] New epoch entry EpochEntry(epoch=17, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=16, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:24:51,542] INFO [Partition tools8-2 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-25 10:24:51,558] INFO [Partition tools7-1 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-25 10:24:51,558] INFO [Partition __consumer_offsets-32 broker=3] __consumer_offsets-32 starts at Leader Epoch 17 from offset 0. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-25 10:24:51,558] WARN [LeaderEpochCache __consumer_offsets-32] New epoch entry EpochEntry(epoch=17, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=16, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:24:51,558] INFO [Partition __consumer_offsets-41 broker=3] __consumer_offsets-41 starts at Leader Epoch 17 from offset 0. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-25 10:24:51,558] WARN [LeaderEpochCache __consumer_offsets-41] New epoch entry EpochEntry(epoch=17, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=16, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 10:25:00,586] INFO [GroupCoordinator 3]: Preparing to rebalance group console-consumer-66603 in state PreparingRebalance with old generation 0 (__consumer_offsets-32) (reason: Adding new member consumer-1-7ad790e5-3584-44f8-a6e1-dcac7fde2c86) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:25:00,586] INFO [GroupCoordinator 3]: Stabilized group console-consumer-66603 generation 1 (__consumer_offsets-32) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:25:00,601] INFO [GroupCoordinator 3]: Assignment received from leader for group console-consumer-66603 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:25:49,798] INFO [GroupCoordinator 3]: Member consumer-1-7ad790e5-3584-44f8-a6e1-dcac7fde2c86 in group console-consumer-66603 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:25:49,798] INFO [GroupCoordinator 3]: Preparing to rebalance group console-consumer-66603 in state PreparingRebalance with old generation 1 (__consumer_offsets-32) (reason: removing member consumer-1-7ad790e5-3584-44f8-a6e1-dcac7fde2c86 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:25:49,798] INFO [GroupCoordinator 3]: Group console-consumer-66603 with generation 2 is now empty (__consumer_offsets-32) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:25:52,126] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0000 type:setData cxid:0x271 zxid:0xa66 txntype:-1 reqpath:n/a Error Path:/config/topics/edited9 Error:KeeperErrorCode = NoNode for /config/topics/edited9 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:25:52,142] INFO Topic creation Map(edited9-0 -> ArrayBuffer(3)) (kafka.zk.AdminZkClient)
[2019-01-25 10:25:52,142] INFO [KafkaApi-1] Auto creation of topic edited9 with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2019-01-25 10:25:52,173] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(edited9-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 10:25:52,173] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-76935 in state PreparingRebalance with old generation 0 (__consumer_offsets-31) (reason: Adding new member consumer-1-f05c950f-96c5-42f8-933d-55b3da7488ee) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:25:52,173] INFO [Log partition=edited9-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:25:52,173] INFO [Log partition=edited9-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 10:25:52,173] INFO Created log for partition edited9-0 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 10:25:52,173] INFO [Partition edited9-0 broker=3] No checkpointed highwatermark is found for partition edited9-0 (kafka.cluster.Partition)
[2019-01-25 10:25:52,173] INFO Replica loaded for partition edited9-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:25:52,173] INFO [Partition edited9-0 broker=3] edited9-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:25:52,173] INFO [GroupCoordinator 2]: Stabilized group console-consumer-76935 generation 1 (__consumer_offsets-31) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:25:52,267] INFO [GroupCoordinator 2]: Assignment received from leader for group console-consumer-76935 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:26:11,348] INFO [GroupCoordinator 2]: Member consumer-1-f05c950f-96c5-42f8-933d-55b3da7488ee in group console-consumer-76935 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:26:11,348] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-76935 in state PreparingRebalance with old generation 1 (__consumer_offsets-31) (reason: removing member consumer-1-f05c950f-96c5-42f8-933d-55b3da7488ee on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:26:11,348] INFO [GroupCoordinator 2]: Group console-consumer-76935 with generation 2 is now empty (__consumer_offsets-31) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:26:39,178] INFO [GroupCoordinator 3]: Preparing to rebalance group connect-test-sink in state PreparingRebalance with old generation 0 (__consumer_offsets-35) (reason: Adding new member consumer-1-1087d5db-b12f-4427-bb43-1501a2809b24) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:26:39,178] INFO [GroupCoordinator 3]: Stabilized group connect-test-sink generation 1 (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:26:39,194] INFO [GroupCoordinator 3]: Assignment received from leader for group connect-test-sink for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:26:39,256] INFO [GroupCoordinator 3]: Preparing to rebalance group connect-test-sink in state PreparingRebalance with old generation 1 (__consumer_offsets-35) (reason: removing member consumer-1-1087d5db-b12f-4427-bb43-1501a2809b24 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:26:39,256] INFO [GroupCoordinator 3]: Group connect-test-sink with generation 2 is now empty (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:28:40,910] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(tools6-1, tools8-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 10:28:40,910] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools4-0, tools1-1, tools2-2, tools-2, edited6-0, alltools-2, edited8-1, tools5-1, tools6-1, tools7-2, edited-0, tools3-2, tools8-2, mytools-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 10:28:40,910] INFO [Partition tools1-1 broker=3] tools1-1 starts at Leader Epoch 24 from offset 0. Previous Leader Epoch was: 23 (kafka.cluster.Partition)
[2019-01-25 10:28:40,910] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools2-2, edited-0, tools1-1, tools3-2, alltools-2, tools5-1, tools7-2, tools4-0, edited6-0, edited8-1, tools-2, mytools-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 10:28:40,910] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(tools8-2 -> (offset=0, leaderEpoch=4), tools6-1 -> (offset=6, leaderEpoch=19)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 10:28:40,910] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-25 10:28:40,910] INFO [Partition tools2-2 broker=3] tools2-2 starts at Leader Epoch 24 from offset 0. Previous Leader Epoch was: 23 (kafka.cluster.Partition)
[2019-01-25 10:28:40,926] INFO [Partition tools7-2 broker=3] tools7-2 starts at Leader Epoch 14 from offset 1. Previous Leader Epoch was: 13 (kafka.cluster.Partition)
[2019-01-25 10:28:40,926] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition tools6-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 10:28:40,926] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition tools8-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 10:28:40,926] INFO [Partition tools6-1 broker=3] tools6-1 starts at Leader Epoch 19 from offset 6. Previous Leader Epoch was: 18 (kafka.cluster.Partition)
[2019-01-25 10:28:40,926] INFO [Partition edited-0 broker=3] edited-0 starts at Leader Epoch 24 from offset 8. Previous Leader Epoch was: 23 (kafka.cluster.Partition)
[2019-01-25 10:28:40,942] INFO [Partition alltools-2 broker=3] alltools-2 starts at Leader Epoch 25 from offset 5. Previous Leader Epoch was: 24 (kafka.cluster.Partition)
[2019-01-25 10:28:40,942] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-25 10:28:40,942] INFO [Partition edited8-1 broker=3] edited8-1 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-25 10:28:40,942] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(tools4-0 -> (offset=0, leaderEpoch=24), tools1-1 -> (offset=0, leaderEpoch=24), tools2-2 -> (offset=0, leaderEpoch=24), tools-2 -> (offset=0, leaderEpoch=24), edited6-0 -> (offset=3, leaderEpoch=20), alltools-2 -> (offset=5, leaderEpoch=25), edited8-1 -> (offset=0, leaderEpoch=4), tools5-1 -> (offset=5, leaderEpoch=24), tools7-2 -> (offset=1, leaderEpoch=14), edited-0 -> (offset=8, leaderEpoch=24), tools3-2 -> (offset=0, leaderEpoch=24), mytools-2 -> (offset=0, leaderEpoch=24)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 10:28:40,942] INFO [Partition mytools-2 broker=3] mytools-2 starts at Leader Epoch 24 from offset 0. Previous Leader Epoch was: 23 (kafka.cluster.Partition)
[2019-01-25 10:28:40,957] INFO [Partition tools3-2 broker=3] tools3-2 starts at Leader Epoch 24 from offset 0. Previous Leader Epoch was: 23 (kafka.cluster.Partition)
[2019-01-25 10:28:40,957] INFO [Partition tools5-1 broker=3] tools5-1 starts at Leader Epoch 24 from offset 5. Previous Leader Epoch was: 23 (kafka.cluster.Partition)
[2019-01-25 10:28:40,957] INFO [Partition tools4-0 broker=3] tools4-0 starts at Leader Epoch 24 from offset 0. Previous Leader Epoch was: 23 (kafka.cluster.Partition)
[2019-01-25 10:28:40,957] INFO [Partition edited6-0 broker=3] edited6-0 starts at Leader Epoch 20 from offset 3. Previous Leader Epoch was: 19 (kafka.cluster.Partition)
[2019-01-25 10:28:40,973] INFO [Partition tools-2 broker=3] tools-2 starts at Leader Epoch 24 from offset 0. Previous Leader Epoch was: 23 (kafka.cluster.Partition)
[2019-01-25 10:28:40,973] INFO [Partition tools8-2 broker=3] tools8-2 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-25 10:28:40,973] INFO [Log partition=tools1-1, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 10:28:40,973] INFO [Log partition=tools2-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 10:28:40,973] INFO [Log partition=tools3-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 10:28:40,973] INFO [Log partition=edited-0, dir=C:\tmp\logs1] Truncating to 8 has no effect as the largest offset in the log is 7 (kafka.log.Log)
[2019-01-25 10:28:40,973] INFO [Log partition=mytools-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 10:28:40,973] INFO [Log partition=tools5-1, dir=C:\tmp\logs1] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.Log)
[2019-01-25 10:28:40,973] INFO [Log partition=edited8-1, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 10:28:40,973] INFO [Log partition=tools4-0, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 10:28:40,973] INFO [Log partition=edited6-0, dir=C:\tmp\logs1] Truncating to 3 has no effect as the largest offset in the log is 2 (kafka.log.Log)
[2019-01-25 10:28:40,989] INFO [Log partition=tools7-2, dir=C:\tmp\logs1] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 10:28:40,989] INFO [Log partition=tools-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 10:28:40,989] INFO [Log partition=alltools-2, dir=C:\tmp\logs1] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.Log)
[2019-01-25 10:28:41,937] INFO [Log partition=tools6-1, dir=C:\tmp\logs2] Truncating to 6 has no effect as the largest offset in the log is 5 (kafka.log.Log)
[2019-01-25 10:28:41,938] INFO [Log partition=tools8-2, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 10:33:35,463] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:33:58,731] INFO [GroupMetadataManager brokerId=2] Group console-consumer-76935 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:33:58,731] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:34:50,599] INFO [GroupMetadataManager brokerId=3] Group connect-test-sink transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:34:50,599] INFO [GroupMetadataManager brokerId=3] Group console-consumer-66603 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:34:50,599] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:39:19,367] INFO [GroupCoordinator 3]: Preparing to rebalance group connect-test-sink in state PreparingRebalance with old generation 0 (__consumer_offsets-35) (reason: Adding new member consumer-1-0b75d52a-3499-4f44-a902-2d29733a8c5d) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:39:19,367] INFO [GroupCoordinator 3]: Stabilized group connect-test-sink generation 1 (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:39:19,367] INFO [GroupCoordinator 3]: Assignment received from leader for group connect-test-sink for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:39:19,429] INFO [GroupCoordinator 3]: Preparing to rebalance group connect-test-sink in state PreparingRebalance with old generation 1 (__consumer_offsets-35) (reason: removing member consumer-1-0b75d52a-3499-4f44-a902-2d29733a8c5d on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:39:19,429] INFO [GroupCoordinator 3]: Group connect-test-sink with generation 2 is now empty (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:39:56,640] INFO [GroupCoordinator 3]: Preparing to rebalance group connect-test-sink in state PreparingRebalance with old generation 2 (__consumer_offsets-35) (reason: Adding new member consumer-1-ef460228-2dda-413b-927b-a4d5147465f3) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:39:56,640] INFO [GroupCoordinator 3]: Stabilized group connect-test-sink generation 3 (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:39:56,640] INFO [GroupCoordinator 3]: Assignment received from leader for group connect-test-sink for generation 3 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:39:56,718] INFO [GroupCoordinator 3]: Preparing to rebalance group connect-test-sink in state PreparingRebalance with old generation 3 (__consumer_offsets-35) (reason: removing member consumer-1-ef460228-2dda-413b-927b-a4d5147465f3 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:39:56,718] INFO [GroupCoordinator 3]: Group connect-test-sink with generation 4 is now empty (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:43:35,466] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:43:58,725] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:44:50,605] INFO [GroupMetadataManager brokerId=3] Group connect-test-sink transitioned to Dead in generation 4 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:44:50,605] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:50:54,259] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:53271 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-25 10:50:54,259] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:53271 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 10:50:54,274] INFO Established session 0x1000380b4ed0003 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:53271 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 10:50:54,524] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0003 type:setData cxid:0x6 zxid:0xa7b txntype:-1 reqpath:n/a Error Path:/config/topics/tools10 Error:KeeperErrorCode = NoNode for /config/topics/tools10 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:50:54,571] INFO Processed session termination for sessionid: 0x1000380b4ed0003 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:50:54,571] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:53271 which had sessionid 0x1000380b4ed0003 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-25 10:50:54,587] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(tools10-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 10:50:54,587] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools10-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 10:50:54,587] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools10-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 10:50:54,587] INFO [Log partition=tools10-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:50:54,587] INFO [Log partition=tools10-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:50:54,587] INFO [Log partition=tools10-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:50:54,587] INFO [Log partition=tools10-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 10:50:54,587] INFO [Log partition=tools10-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 10:50:54,587] INFO [Log partition=tools10-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 10:50:54,587] INFO Created log for partition tools10-1 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 10:50:54,587] INFO Created log for partition tools10-2 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 10:50:54,587] INFO Created log for partition tools10-0 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 10:50:54,587] INFO [Partition tools10-1 broker=3] No checkpointed highwatermark is found for partition tools10-1 (kafka.cluster.Partition)
[2019-01-25 10:50:54,587] INFO Replica loaded for partition tools10-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:50:54,603] INFO [Partition tools10-2 broker=1] No checkpointed highwatermark is found for partition tools10-2 (kafka.cluster.Partition)
[2019-01-25 10:50:54,603] INFO Replica loaded for partition tools10-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:50:54,603] INFO [Partition tools10-0 broker=2] No checkpointed highwatermark is found for partition tools10-0 (kafka.cluster.Partition)
[2019-01-25 10:50:54,603] INFO Replica loaded for partition tools10-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:50:54,603] INFO [Partition tools10-1 broker=3] tools10-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:50:54,603] INFO Replica loaded for partition tools10-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:50:54,603] INFO Replica loaded for partition tools10-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:50:54,603] INFO Replica loaded for partition tools10-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:50:54,603] INFO [Partition tools10-2 broker=1] tools10-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:50:54,603] INFO [Partition tools10-0 broker=2] tools10-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:50:54,603] INFO Replica loaded for partition tools10-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:50:54,603] INFO Replica loaded for partition tools10-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:50:54,603] INFO Replica loaded for partition tools10-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:50:54,618] INFO [Log partition=tools10-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:50:54,618] INFO [Log partition=tools10-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-25 10:50:54,618] INFO Created log for partition tools10-2 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 10:50:54,618] INFO [Partition tools10-2 broker=3] No checkpointed highwatermark is found for partition tools10-2 (kafka.cluster.Partition)
[2019-01-25 10:50:54,618] INFO [Log partition=tools10-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:50:54,618] INFO Replica loaded for partition tools10-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:50:54,618] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools10-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 10:50:54,618] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(tools10-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 10:50:54,618] INFO [Log partition=tools10-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:50:54,618] INFO [Log partition=tools10-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 10:50:54,618] INFO [Log partition=tools10-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 10:50:54,618] INFO Created log for partition tools10-0 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 10:50:54,618] INFO Created log for partition tools10-1 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 10:50:54,618] INFO [Partition tools10-0 broker=1] No checkpointed highwatermark is found for partition tools10-0 (kafka.cluster.Partition)
[2019-01-25 10:50:54,618] INFO Replica loaded for partition tools10-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:50:54,618] INFO [Partition tools10-1 broker=2] No checkpointed highwatermark is found for partition tools10-1 (kafka.cluster.Partition)
[2019-01-25 10:50:54,618] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools10-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 10:50:54,618] INFO Replica loaded for partition tools10-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:50:54,618] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(tools10-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 10:50:54,618] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(tools10-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 10:50:54,634] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(tools10-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 10:50:54,634] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-25 10:50:54,634] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools10-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 10:50:54,634] INFO [Log partition=tools10-0, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 10:50:54,980] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools10-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 10:50:54,980] INFO [Log partition=tools10-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 10:50:55,058] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools10-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 10:50:55,058] INFO [Log partition=tools10-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 10:51:12,179] INFO Accepted socket connection from /127.0.0.1:53281 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-25 10:51:12,179] INFO Client attempting to establish new session at /127.0.0.1:53281 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 10:51:12,179] INFO Established session 0x1000380b4ed0004 with negotiated timeout 30000 for client /127.0.0.1:53281 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 10:51:12,445] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0004 type:setData cxid:0x6 zxid:0xa87 txntype:-1 reqpath:n/a Error Path:/config/topics/edited10 Error:KeeperErrorCode = NoNode for /config/topics/edited10 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:51:12,507] INFO Processed session termination for sessionid: 0x1000380b4ed0004 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 10:51:12,507] INFO Closed socket connection for client /127.0.0.1:53281 which had sessionid 0x1000380b4ed0004 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-25 10:51:12,507] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(edited10-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 10:51:12,507] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(edited10-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 10:51:12,507] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(edited10-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 10:51:12,523] INFO [Log partition=edited10-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:51:12,523] INFO [Log partition=edited10-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:51:12,523] INFO [Log partition=edited10-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:51:12,523] INFO [Log partition=edited10-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:51:12,523] INFO [Log partition=edited10-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 10:51:12,523] INFO Created log for partition edited10-2 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 10:51:12,523] INFO Created log for partition edited10-1 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 10:51:12,523] INFO [Partition edited10-2 broker=1] No checkpointed highwatermark is found for partition edited10-2 (kafka.cluster.Partition)
[2019-01-25 10:51:12,523] INFO Replica loaded for partition edited10-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:51:12,523] INFO [Partition edited10-1 broker=3] No checkpointed highwatermark is found for partition edited10-1 (kafka.cluster.Partition)
[2019-01-25 10:51:12,523] INFO [Log partition=edited10-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 10:51:12,523] INFO Replica loaded for partition edited10-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:51:12,523] INFO Replica loaded for partition edited10-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:51:12,523] INFO Created log for partition edited10-0 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 10:51:12,523] INFO [Partition edited10-2 broker=1] edited10-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:51:12,523] INFO Replica loaded for partition edited10-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:51:12,523] INFO [Partition edited10-0 broker=2] No checkpointed highwatermark is found for partition edited10-0 (kafka.cluster.Partition)
[2019-01-25 10:51:12,538] INFO Replica loaded for partition edited10-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:51:12,538] INFO [Partition edited10-1 broker=3] edited10-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:51:12,538] INFO Replica loaded for partition edited10-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:51:12,538] INFO [Partition edited10-0 broker=2] edited10-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 10:51:12,538] INFO Replica loaded for partition edited10-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:51:12,538] INFO Replica loaded for partition edited10-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:51:12,538] INFO Replica loaded for partition edited10-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:51:12,538] INFO [Log partition=edited10-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:51:12,538] INFO [Log partition=edited10-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:51:12,538] INFO [Log partition=edited10-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 10:51:12,554] INFO Created log for partition edited10-0 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 10:51:12,554] INFO [Log partition=edited10-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 10:51:12,554] INFO [Partition edited10-0 broker=3] No checkpointed highwatermark is found for partition edited10-0 (kafka.cluster.Partition)
[2019-01-25 10:51:12,554] INFO Replica loaded for partition edited10-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:51:12,554] INFO Created log for partition edited10-2 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 10:51:12,554] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(edited10-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 10:51:12,554] INFO [Partition edited10-2 broker=2] No checkpointed highwatermark is found for partition edited10-2 (kafka.cluster.Partition)
[2019-01-25 10:51:12,554] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(edited10-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 10:51:12,554] INFO Replica loaded for partition edited10-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:51:12,554] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(edited10-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 10:51:12,554] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(edited10-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 10:51:12,554] INFO [Log partition=edited10-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 10:51:12,554] INFO [Log partition=edited10-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 10:51:12,554] INFO Created log for partition edited10-1 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 10:51:12,554] INFO [Partition edited10-1 broker=1] No checkpointed highwatermark is found for partition edited10-1 (kafka.cluster.Partition)
[2019-01-25 10:51:12,554] INFO Replica loaded for partition edited10-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 10:51:12,554] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(edited10-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 10:51:12,554] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(edited10-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 10:51:12,741] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in edited10-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 10:51:12,741] INFO [Log partition=edited10-0, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 10:51:12,991] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in edited10-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 10:51:12,991] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in edited10-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 10:51:12,991] INFO [Log partition=edited10-2, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 10:51:12,991] INFO [Log partition=edited10-1, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 10:51:32,899] INFO [GroupCoordinator 3]: Preparing to rebalance group connect-test-sink in state PreparingRebalance with old generation 0 (__consumer_offsets-35) (reason: Adding new member consumer-1-8015daba-99ff-4304-9b0a-a8570e60f57b) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:51:32,899] INFO [GroupCoordinator 3]: Stabilized group connect-test-sink generation 1 (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:51:32,899] INFO [GroupCoordinator 3]: Assignment received from leader for group connect-test-sink for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:53:21,374] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-20494 in state PreparingRebalance with old generation 0 (__consumer_offsets-10) (reason: Adding new member consumer-1-ca8d639a-37ed-4023-abae-e64565c8f35c) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:53:21,375] INFO [GroupCoordinator 2]: Stabilized group console-consumer-20494 generation 1 (__consumer_offsets-10) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:53:21,379] INFO [GroupCoordinator 2]: Assignment received from leader for group console-consumer-20494 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:53:35,457] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:53:45,087] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 66 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-194ac9ed-9d27-4b3c-a93c-41a6fabd134d-StreamThread-1-consumer-0387ff6a-40b4-4bc3-bb4b-7b4150dc5728) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:53:45,088] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 67 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:53:45,096] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 67 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:53:56,382] INFO [GroupCoordinator 3]: Preparing to rebalance group connect-test-sink in state PreparingRebalance with old generation 1 (__consumer_offsets-35) (reason: removing member consumer-1-8015daba-99ff-4304-9b0a-a8570e60f57b on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:53:56,383] INFO [GroupCoordinator 3]: Group connect-test-sink with generation 2 is now empty (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:53:58,724] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:54:50,597] INFO [GroupMetadataManager brokerId=3] Group connect-test-sink transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:54:50,598] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 10:56:52,129] INFO [GroupCoordinator 3]: Member alltoolsStream-194ac9ed-9d27-4b3c-a93c-41a6fabd134d-StreamThread-1-consumer-0387ff6a-40b4-4bc3-bb4b-7b4150dc5728 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:56:52,129] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 67 (__consumer_offsets-2) (reason: removing member alltoolsStream-194ac9ed-9d27-4b3c-a93c-41a6fabd134d-StreamThread-1-consumer-0387ff6a-40b4-4bc3-bb4b-7b4150dc5728 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:56:52,130] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 68 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:59:28,444] INFO [GroupCoordinator 2]: Member consumer-1-ca8d639a-37ed-4023-abae-e64565c8f35c in group console-consumer-20494 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:59:28,444] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-20494 in state PreparingRebalance with old generation 1 (__consumer_offsets-10) (reason: removing member consumer-1-ca8d639a-37ed-4023-abae-e64565c8f35c on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 10:59:28,444] INFO [GroupCoordinator 2]: Group console-consumer-20494 with generation 2 is now empty (__consumer_offsets-10) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:00:45,895] INFO Accepted socket connection from /127.0.0.1:53424 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-25 11:00:45,899] INFO Client attempting to establish new session at /127.0.0.1:53424 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:00:45,901] INFO Established session 0x1000380b4ed0005 with negotiated timeout 30000 for client /127.0.0.1:53424 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:00:46,213] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0005 type:setData cxid:0x7 zxid:0xa93 txntype:-1 reqpath:n/a Error Path:/config/topics/aggregated_data Error:KeeperErrorCode = NoNode for /config/topics/aggregated_data (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:00:46,261] INFO Processed session termination for sessionid: 0x1000380b4ed0005 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:00:46,263] INFO Closed socket connection for client /127.0.0.1:53424 which had sessionid 0x1000380b4ed0005 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-25 11:00:46,274] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(aggregated_data-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:00:46,275] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(aggregated_data-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:00:46,275] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(aggregated_data-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:00:46,281] INFO [Log partition=aggregated_data-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:00:46,282] INFO [Log partition=aggregated_data-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:00:46,283] INFO [Log partition=aggregated_data-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:00:46,284] INFO [Log partition=aggregated_data-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-01-25 11:00:46,284] INFO Created log for partition aggregated_data-0 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:00:46,284] INFO [Log partition=aggregated_data-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-01-25 11:00:46,285] INFO [Log partition=aggregated_data-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-01-25 11:00:46,286] INFO Created log for partition aggregated_data-1 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:00:46,285] INFO [Partition aggregated_data-0 broker=1] No checkpointed highwatermark is found for partition aggregated_data-0 (kafka.cluster.Partition)
[2019-01-25 11:00:46,286] INFO Created log for partition aggregated_data-2 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:00:46,287] INFO [Partition aggregated_data-1 broker=2] No checkpointed highwatermark is found for partition aggregated_data-1 (kafka.cluster.Partition)
[2019-01-25 11:00:46,288] INFO Replica loaded for partition aggregated_data-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:00:46,289] INFO [Partition aggregated_data-2 broker=3] No checkpointed highwatermark is found for partition aggregated_data-2 (kafka.cluster.Partition)
[2019-01-25 11:00:46,289] INFO Replica loaded for partition aggregated_data-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:00:46,292] INFO Replica loaded for partition aggregated_data-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:00:46,290] INFO Replica loaded for partition aggregated_data-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:00:46,290] INFO Replica loaded for partition aggregated_data-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:00:46,293] INFO Replica loaded for partition aggregated_data-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:00:46,292] INFO [Partition aggregated_data-1 broker=2] aggregated_data-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:00:46,293] INFO [Partition aggregated_data-0 broker=1] aggregated_data-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:00:46,293] INFO [Partition aggregated_data-2 broker=3] aggregated_data-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:00:46,302] INFO Replica loaded for partition aggregated_data-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:00:46,303] INFO Replica loaded for partition aggregated_data-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:00:46,304] INFO Replica loaded for partition aggregated_data-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:00:46,307] INFO [Log partition=aggregated_data-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:00:46,308] INFO [Log partition=aggregated_data-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:00:46,309] INFO [Log partition=aggregated_data-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:00:46,310] INFO [Log partition=aggregated_data-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-01-25 11:00:46,310] INFO [Log partition=aggregated_data-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-01-25 11:00:46,311] INFO Created log for partition aggregated_data-2 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:00:46,312] INFO Created log for partition aggregated_data-0 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:00:46,312] INFO [Log partition=aggregated_data-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-01-25 11:00:46,313] INFO [Partition aggregated_data-0 broker=2] No checkpointed highwatermark is found for partition aggregated_data-0 (kafka.cluster.Partition)
[2019-01-25 11:00:46,313] INFO [Partition aggregated_data-2 broker=1] No checkpointed highwatermark is found for partition aggregated_data-2 (kafka.cluster.Partition)
[2019-01-25 11:00:46,313] INFO Created log for partition aggregated_data-1 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:00:46,314] INFO Replica loaded for partition aggregated_data-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:00:46,314] INFO Replica loaded for partition aggregated_data-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:00:46,316] INFO [Partition aggregated_data-1 broker=3] No checkpointed highwatermark is found for partition aggregated_data-1 (kafka.cluster.Partition)
[2019-01-25 11:00:46,316] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(aggregated_data-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:00:46,317] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(aggregated_data-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:00:46,317] INFO Replica loaded for partition aggregated_data-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:00:46,318] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(aggregated_data-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:00:46,319] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(aggregated_data-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:00:46,319] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(aggregated_data-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:00:46,321] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(aggregated_data-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:00:46,343] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in aggregated_data-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:00:46,344] INFO [Log partition=aggregated_data-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:00:46,469] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in aggregated_data-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:00:46,470] INFO [Log partition=aggregated_data-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:00:46,634] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in aggregated_data-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:00:46,635] INFO [Log partition=aggregated_data-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:01:26,480] INFO Accepted socket connection from /127.0.0.1:53428 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-25 11:01:26,483] INFO Client attempting to establish new session at /127.0.0.1:53428 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:01:26,487] INFO Established session 0x1000380b4ed0006 with negotiated timeout 30000 for client /127.0.0.1:53428 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:01:26,740] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0006 type:setData cxid:0x6 zxid:0xa9f txntype:-1 reqpath:n/a Error Path:/config/topics/tools11 Error:KeeperErrorCode = NoNode for /config/topics/tools11 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:01:26,794] INFO Processed session termination for sessionid: 0x1000380b4ed0006 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:01:26,797] INFO Closed socket connection for client /127.0.0.1:53428 which had sessionid 0x1000380b4ed0006 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-25 11:01:26,803] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools11-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:01:26,803] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(tools11-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:01:26,804] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools11-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:01:26,809] INFO [Log partition=tools11-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:01:26,810] INFO [Log partition=tools11-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:01:26,810] INFO [Log partition=tools11-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:01:26,812] INFO [Log partition=tools11-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-01-25 11:01:26,813] INFO [Log partition=tools11-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-01-25 11:01:26,813] INFO [Log partition=tools11-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-01-25 11:01:26,813] INFO Created log for partition tools11-1 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:01:26,814] INFO Created log for partition tools11-2 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:01:26,814] INFO Created log for partition tools11-0 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:01:26,815] INFO [Partition tools11-1 broker=1] No checkpointed highwatermark is found for partition tools11-1 (kafka.cluster.Partition)
[2019-01-25 11:01:26,815] INFO [Partition tools11-2 broker=2] No checkpointed highwatermark is found for partition tools11-2 (kafka.cluster.Partition)
[2019-01-25 11:01:26,815] INFO [Partition tools11-0 broker=3] No checkpointed highwatermark is found for partition tools11-0 (kafka.cluster.Partition)
[2019-01-25 11:01:26,815] INFO Replica loaded for partition tools11-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:01:26,815] INFO Replica loaded for partition tools11-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:01:26,815] INFO Replica loaded for partition tools11-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:01:26,816] INFO Replica loaded for partition tools11-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:01:26,817] INFO Replica loaded for partition tools11-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:01:26,818] INFO Replica loaded for partition tools11-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:01:26,818] INFO [Partition tools11-1 broker=1] tools11-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:01:26,819] INFO [Partition tools11-2 broker=2] tools11-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:01:26,820] INFO [Partition tools11-0 broker=3] tools11-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:01:26,825] INFO Replica loaded for partition tools11-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:01:26,828] INFO Replica loaded for partition tools11-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:01:26,829] INFO Replica loaded for partition tools11-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:01:26,832] INFO [Log partition=tools11-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:01:26,834] INFO [Log partition=tools11-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:01:26,834] INFO [Log partition=tools11-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-01-25 11:01:26,835] INFO [Log partition=tools11-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:01:26,835] INFO Created log for partition tools11-2 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:01:26,836] INFO [Partition tools11-2 broker=1] No checkpointed highwatermark is found for partition tools11-2 (kafka.cluster.Partition)
[2019-01-25 11:01:26,836] INFO [Log partition=tools11-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-01-25 11:01:26,836] INFO Replica loaded for partition tools11-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:01:26,837] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools11-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:01:26,837] INFO Created log for partition tools11-0 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:01:26,838] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(tools11-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:01:26,838] INFO [Log partition=tools11-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-01-25 11:01:26,838] INFO [Partition tools11-0 broker=2] No checkpointed highwatermark is found for partition tools11-0 (kafka.cluster.Partition)
[2019-01-25 11:01:26,839] INFO Created log for partition tools11-1 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:01:26,839] INFO Replica loaded for partition tools11-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:01:26,840] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(tools11-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:01:26,841] INFO [Partition tools11-1 broker=3] No checkpointed highwatermark is found for partition tools11-1 (kafka.cluster.Partition)
[2019-01-25 11:01:26,841] INFO Replica loaded for partition tools11-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:01:26,841] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(tools11-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:01:26,842] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools11-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:01:26,843] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(tools11-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:01:26,888] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools11-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:01:26,890] INFO [Log partition=tools11-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:01:26,955] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools11-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:01:26,956] INFO [Log partition=tools11-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:01:27,046] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools11-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:01:27,047] INFO [Log partition=tools11-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:01:36,194] INFO [GroupCoordinator 3]: Preparing to rebalance group connect-test-sink in state PreparingRebalance with old generation 0 (__consumer_offsets-35) (reason: Adding new member consumer-1-9973f8d8-b993-43c0-aeb2-6036040cb960) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:01:36,196] INFO [GroupCoordinator 3]: Stabilized group connect-test-sink generation 1 (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:01:36,199] INFO [GroupCoordinator 3]: Assignment received from leader for group connect-test-sink for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:01:50,311] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0000 type:setData cxid:0x2c6 zxid:0xaaa txntype:-1 reqpath:n/a Error Path:/config/topics/edited11 Error:KeeperErrorCode = NoNode for /config/topics/edited11 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:01:50,316] INFO Topic creation Map(edited11-0 -> ArrayBuffer(3)) (kafka.zk.AdminZkClient)
[2019-01-25 11:01:50,319] INFO [KafkaApi-1] Auto creation of topic edited11 with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2019-01-25 11:01:50,330] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(edited11-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:01:50,336] INFO [Log partition=edited11-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:01:50,339] INFO [Log partition=edited11-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-01-25 11:01:50,340] INFO Created log for partition edited11-0 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:01:50,341] INFO [Partition edited11-0 broker=3] No checkpointed highwatermark is found for partition edited11-0 (kafka.cluster.Partition)
[2019-01-25 11:01:50,341] INFO Replica loaded for partition edited11-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:01:50,342] INFO [Partition edited11-0 broker=3] edited11-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:01:50,343] INFO [GroupCoordinator 3]: Preparing to rebalance group console-consumer-69200 in state PreparingRebalance with old generation 0 (__consumer_offsets-8) (reason: Adding new member consumer-1-9ff9758d-fd96-4317-a303-f34a054f0c16) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:01:50,345] INFO [GroupCoordinator 3]: Stabilized group console-consumer-69200 generation 1 (__consumer_offsets-8) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:01:50,434] INFO [GroupCoordinator 3]: Assignment received from leader for group console-consumer-69200 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:02:13,065] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 68 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-82071d59-2063-4f8e-b8cf-0897bef0539e-StreamThread-1-consumer-58b55966-091e-44bc-9bb6-a13ecd3f48f6) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:02:13,066] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 69 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:02:13,073] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 69 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:02:51,280] INFO [GroupCoordinator 3]: Preparing to rebalance group connect-test-sink in state PreparingRebalance with old generation 1 (__consumer_offsets-35) (reason: removing member consumer-1-9973f8d8-b993-43c0-aeb2-6036040cb960 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:02:51,281] INFO [GroupCoordinator 3]: Group connect-test-sink with generation 2 is now empty (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:03:35,456] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:03:58,723] INFO [GroupMetadataManager brokerId=2] Group console-consumer-20494 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:03:58,724] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:04:50,596] INFO [GroupMetadataManager brokerId=3] Group connect-test-sink transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:04:50,596] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:06:57,496] INFO [GroupCoordinator 3]: Member consumer-1-9ff9758d-fd96-4317-a303-f34a054f0c16 in group console-consumer-69200 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:06:57,497] INFO [GroupCoordinator 3]: Preparing to rebalance group console-consumer-69200 in state PreparingRebalance with old generation 1 (__consumer_offsets-8) (reason: removing member consumer-1-9ff9758d-fd96-4317-a303-f34a054f0c16 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:06:57,500] INFO [GroupCoordinator 3]: Group console-consumer-69200 with generation 2 is now empty (__consumer_offsets-8) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:07:11,915] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:53538 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-25 11:07:11,917] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:53538 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:07:11,920] INFO Established session 0x1000380b4ed0007 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:53538 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:07:12,183] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0007 type:setData cxid:0x6 zxid:0xab1 txntype:-1 reqpath:n/a Error Path:/config/topics/tools12 Error:KeeperErrorCode = NoNode for /config/topics/tools12 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:07:12,234] INFO Processed session termination for sessionid: 0x1000380b4ed0007 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:07:12,239] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:53538 which had sessionid 0x1000380b4ed0007 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-25 11:07:12,240] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools12-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:07:12,240] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(tools12-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:07:12,240] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools12-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:07:12,246] INFO [Log partition=tools12-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:07:12,247] INFO [Log partition=tools12-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:07:12,247] INFO [Log partition=tools12-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:07:12,248] INFO [Log partition=tools12-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-01-25 11:07:12,249] INFO [Log partition=tools12-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-01-25 11:07:12,249] INFO Created log for partition tools12-0 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:07:12,249] INFO [Log partition=tools12-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-01-25 11:07:12,250] INFO [Partition tools12-0 broker=1] No checkpointed highwatermark is found for partition tools12-0 (kafka.cluster.Partition)
[2019-01-25 11:07:12,250] INFO Created log for partition tools12-2 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:07:12,251] INFO Created log for partition tools12-1 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:07:12,252] INFO [Partition tools12-2 broker=3] No checkpointed highwatermark is found for partition tools12-2 (kafka.cluster.Partition)
[2019-01-25 11:07:12,252] INFO Replica loaded for partition tools12-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:07:12,253] INFO [Partition tools12-1 broker=2] No checkpointed highwatermark is found for partition tools12-1 (kafka.cluster.Partition)
[2019-01-25 11:07:12,254] INFO Replica loaded for partition tools12-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:07:12,254] INFO Replica loaded for partition tools12-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:07:12,255] INFO Replica loaded for partition tools12-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:07:12,255] INFO Replica loaded for partition tools12-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:07:12,256] INFO [Partition tools12-0 broker=1] tools12-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:07:12,256] INFO Replica loaded for partition tools12-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:07:12,257] INFO [Partition tools12-2 broker=3] tools12-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:07:12,258] INFO [Partition tools12-1 broker=2] tools12-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:07:12,262] INFO Replica loaded for partition tools12-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:07:12,264] INFO Replica loaded for partition tools12-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:07:12,265] INFO Replica loaded for partition tools12-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:07:12,268] INFO [Log partition=tools12-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:07:12,270] INFO [Log partition=tools12-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-01-25 11:07:12,270] INFO [Log partition=tools12-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:07:12,270] INFO [Log partition=tools12-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:07:12,270] INFO Created log for partition tools12-2 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:07:12,272] INFO [Partition tools12-2 broker=1] No checkpointed highwatermark is found for partition tools12-2 (kafka.cluster.Partition)
[2019-01-25 11:07:12,272] INFO [Log partition=tools12-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-01-25 11:07:12,273] INFO [Log partition=tools12-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-01-25 11:07:12,272] INFO Replica loaded for partition tools12-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:07:12,274] INFO Created log for partition tools12-1 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:07:12,274] INFO Created log for partition tools12-0 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:07:12,274] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools12-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:07:12,276] INFO [Partition tools12-1 broker=3] No checkpointed highwatermark is found for partition tools12-1 (kafka.cluster.Partition)
[2019-01-25 11:07:12,276] INFO [Partition tools12-0 broker=2] No checkpointed highwatermark is found for partition tools12-0 (kafka.cluster.Partition)
[2019-01-25 11:07:12,277] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(tools12-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:07:12,278] INFO Replica loaded for partition tools12-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:07:12,278] INFO Replica loaded for partition tools12-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:07:12,279] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(tools12-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:07:12,280] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools12-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:07:12,281] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(tools12-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:07:12,281] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(tools12-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:07:12,588] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools12-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:07:12,589] INFO [Log partition=tools12-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:07:12,661] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools12-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:07:12,662] INFO [Log partition=tools12-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:07:12,758] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools12-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:07:12,759] INFO [Log partition=tools12-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:07:26,476] INFO Accepted socket connection from /127.0.0.1:53544 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-25 11:07:26,479] INFO Client attempting to establish new session at /127.0.0.1:53544 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:07:26,481] INFO Established session 0x1000380b4ed0008 with negotiated timeout 30000 for client /127.0.0.1:53544 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:07:26,742] INFO Got user-level KeeperException when processing sessionid:0x1000380b4ed0008 type:setData cxid:0x6 zxid:0xabd txntype:-1 reqpath:n/a Error Path:/config/topics/edited12 Error:KeeperErrorCode = NoNode for /config/topics/edited12 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:07:26,788] INFO Processed session termination for sessionid: 0x1000380b4ed0008 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:07:26,790] INFO Closed socket connection for client /127.0.0.1:53544 which had sessionid 0x1000380b4ed0008 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-25 11:07:26,794] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(edited12-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:07:26,794] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(edited12-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:07:26,795] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(edited12-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:07:26,801] INFO [Log partition=edited12-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:07:26,801] INFO [Log partition=edited12-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:07:26,802] INFO [Log partition=edited12-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:07:26,803] INFO [Log partition=edited12-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-01-25 11:07:26,804] INFO [Log partition=edited12-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-01-25 11:07:26,804] INFO [Log partition=edited12-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-01-25 11:07:26,805] INFO Created log for partition edited12-0 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:07:26,805] INFO Created log for partition edited12-2 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:07:26,807] INFO [Partition edited12-0 broker=2] No checkpointed highwatermark is found for partition edited12-0 (kafka.cluster.Partition)
[2019-01-25 11:07:26,807] INFO Created log for partition edited12-1 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:07:26,807] INFO [Partition edited12-2 broker=1] No checkpointed highwatermark is found for partition edited12-2 (kafka.cluster.Partition)
[2019-01-25 11:07:26,807] INFO Replica loaded for partition edited12-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:07:26,808] INFO [Partition edited12-1 broker=3] No checkpointed highwatermark is found for partition edited12-1 (kafka.cluster.Partition)
[2019-01-25 11:07:26,808] INFO Replica loaded for partition edited12-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:07:26,809] INFO Replica loaded for partition edited12-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:07:26,809] INFO Replica loaded for partition edited12-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:07:26,810] INFO Replica loaded for partition edited12-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:07:26,810] INFO [Partition edited12-0 broker=2] edited12-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:07:26,810] INFO Replica loaded for partition edited12-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:07:26,811] INFO [Partition edited12-2 broker=1] edited12-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:07:26,812] INFO [Partition edited12-1 broker=3] edited12-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:07:26,817] INFO Replica loaded for partition edited12-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:07:26,817] INFO Replica loaded for partition edited12-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:07:26,819] INFO Replica loaded for partition edited12-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:07:26,823] INFO [Log partition=edited12-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:07:26,824] INFO [Log partition=edited12-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:07:26,824] INFO [Log partition=edited12-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:07:26,825] INFO [Log partition=edited12-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-01-25 11:07:26,826] INFO [Log partition=edited12-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-01-25 11:07:26,826] INFO Created log for partition edited12-2 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:07:26,827] INFO Created log for partition edited12-1 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:07:26,827] INFO [Log partition=edited12-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-01-25 11:07:26,827] INFO [Partition edited12-2 broker=2] No checkpointed highwatermark is found for partition edited12-2 (kafka.cluster.Partition)
[2019-01-25 11:07:26,828] INFO [Partition edited12-1 broker=1] No checkpointed highwatermark is found for partition edited12-1 (kafka.cluster.Partition)
[2019-01-25 11:07:26,828] INFO Created log for partition edited12-0 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:07:26,828] INFO Replica loaded for partition edited12-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:07:26,828] INFO Replica loaded for partition edited12-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:07:26,829] INFO [Partition edited12-0 broker=3] No checkpointed highwatermark is found for partition edited12-0 (kafka.cluster.Partition)
[2019-01-25 11:07:26,829] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(edited12-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:07:26,830] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(edited12-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:07:26,830] INFO Replica loaded for partition edited12-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:07:26,831] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(edited12-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:07:26,833] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(edited12-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:07:26,833] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(edited12-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:07:26,835] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(edited12-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:07:27,132] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in edited12-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:07:27,133] INFO [Log partition=edited12-1, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:07:27,211] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in edited12-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:07:27,212] INFO [Log partition=edited12-2, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:07:27,305] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in edited12-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:07:27,306] INFO [Log partition=edited12-0, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:07:51,860] INFO [GroupCoordinator 3]: Preparing to rebalance group connect-test-sink in state PreparingRebalance with old generation 0 (__consumer_offsets-35) (reason: Adding new member consumer-1-4cf04908-8fe5-4437-b852-f624828bde50) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:07:51,861] INFO [GroupCoordinator 3]: Stabilized group connect-test-sink generation 1 (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:07:51,864] INFO [GroupCoordinator 3]: Assignment received from leader for group connect-test-sink for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:08:07,965] INFO [GroupCoordinator 3]: Preparing to rebalance group console-consumer-8229 in state PreparingRebalance with old generation 0 (__consumer_offsets-20) (reason: Adding new member consumer-1-be6338b8-ce07-4f97-a924-37d44b902eea) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:08:07,967] INFO [GroupCoordinator 3]: Stabilized group console-consumer-8229 generation 1 (__consumer_offsets-20) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:08:07,972] INFO [GroupCoordinator 3]: Assignment received from leader for group console-consumer-8229 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:08:38,140] INFO [GroupCoordinator 3]: Member alltoolsStream-82071d59-2063-4f8e-b8cf-0897bef0539e-StreamThread-1-consumer-58b55966-091e-44bc-9bb6-a13ecd3f48f6 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:08:38,140] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 69 (__consumer_offsets-2) (reason: removing member alltoolsStream-82071d59-2063-4f8e-b8cf-0897bef0539e-StreamThread-1-consumer-58b55966-091e-44bc-9bb6-a13ecd3f48f6 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:08:38,141] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 70 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:08:53,816] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 70 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-b947e032-2a39-4235-9f29-850f6cb0e977-StreamThread-1-consumer-7655dec7-1b7f-44d7-86b5-6a53710dc020) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:08:53,817] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 71 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:08:53,825] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 71 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:09:32,186] INFO [GroupCoordinator 3]: Preparing to rebalance group connect-test-sink in state PreparingRebalance with old generation 1 (__consumer_offsets-35) (reason: removing member consumer-1-4cf04908-8fe5-4437-b852-f624828bde50 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:09:32,187] INFO [GroupCoordinator 3]: Group connect-test-sink with generation 2 is now empty (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:13:35,457] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:13:58,723] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:14:50,597] INFO [GroupMetadataManager brokerId=3] Group connect-test-sink transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:14:50,598] INFO [GroupMetadataManager brokerId=3] Group console-consumer-69200 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:14:50,599] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:21:19,631] INFO [GroupCoordinator 3]: Member alltoolsStream-b947e032-2a39-4235-9f29-850f6cb0e977-StreamThread-1-consumer-7655dec7-1b7f-44d7-86b5-6a53710dc020 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:21:19,631] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 71 (__consumer_offsets-2) (reason: removing member alltoolsStream-b947e032-2a39-4235-9f29-850f6cb0e977-StreamThread-1-consumer-7655dec7-1b7f-44d7-86b5-6a53710dc020 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:21:19,632] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 72 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:21:27,377] WARN Exception causing close of session 0x1000380b4ed0002: Connessione in corso interrotta forzatamente dall'host remoto (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-25 11:21:27,377] INFO Closed socket connection for client /127.0.0.1:52883 which had sessionid 0x1000380b4ed0002 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-25 11:21:27,377] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=720762709, epoch=6255) to node 3: java.io.IOException: Connection to 3 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-25 11:21:27,377] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=1537572875, epoch=6255) to node 3: java.io.IOException: Connection to 3 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-25 11:21:27,377] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=720762709, epoch=6255)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 3 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:97)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:97)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-25 11:21:27,377] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1537572875, epoch=6255)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 3 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:97)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:97)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-25 11:21:30,458] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Connection to node 3 (localhost/127.0.0.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-25 11:21:30,458] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Connection to node 3 (localhost/127.0.0.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-25 11:21:30,458] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=720762709, epoch=INITIAL) to node 3: java.io.IOException: Connection to localhost:9095 (id: 3 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-25 11:21:30,458] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=1537572875, epoch=INITIAL) to node 3: java.io.IOException: Connection to localhost:9095 (id: 3 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-25 11:21:30,458] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={tools2-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[24]), aggregated_data-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0]), tools12-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0]), tools3-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[24]), tools5-1=(offset=5, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[24]), edited6-0=(offset=3, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[20]), edited12-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0]), tools-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[24]), edited-0=(offset=8, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[24]), tools1-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[24]), alltools-2=(offset=5, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[25]), tools7-2=(offset=1, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[14]), tools4-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[24]), edited8-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[4]), mytools-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[24]), edited10-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=720762709, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9095 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-25 11:21:30,458] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={tools6-1=(offset=6, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[19]), tools8-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[4]), tools11-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0]), tools10-1=(offset=1, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1537572875, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9095 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-25 11:21:30,880] WARN Exception causing close of session 0x1000380b4ed0001: Connessione in corso interrotta forzatamente dall'host remoto (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-25 11:21:30,880] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:52857 which had sessionid 0x1000380b4ed0001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-25 11:21:30,880] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=1672005185, epoch=3650) to node 2: java.io.IOException: Connection to 2 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-25 11:21:30,880] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1672005185, epoch=3650)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 2 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:97)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:97)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-25 11:21:33,507] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Connection to node 3 (localhost/127.0.0.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-25 11:21:33,507] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=720762709, epoch=INITIAL) to node 3: java.io.IOException: Connection to localhost:9095 (id: 3 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-25 11:21:33,507] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={tools2-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[24]), aggregated_data-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0]), tools12-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0]), tools3-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[24]), tools5-1=(offset=5, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[24]), edited6-0=(offset=3, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[20]), edited12-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0]), tools-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[24]), edited-0=(offset=8, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[24]), tools1-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[24]), alltools-2=(offset=5, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[25]), tools7-2=(offset=1, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[14]), tools4-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[24]), edited8-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[4]), mytools-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[24]), edited10-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=720762709, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9095 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-25 11:21:33,928] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-25 11:21:33,928] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=1672005185, epoch=INITIAL) to node 2: java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-25 11:21:33,928] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={tools10-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0]), tools11-2=(offset=1, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1672005185, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9094 (id: 2 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-25 11:21:34,804] INFO Expiring session 0x1000380b4ed0002, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:21:34,804] INFO Processed session termination for sessionid: 0x1000380b4ed0002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:21:34,834] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools4-0, tools1-1, tools2-2, tools-2, edited6-0, alltools-2, edited8-1, edited10-1, tools5-1, tools12-2, edited12-1, tools7-2, edited-0, tools3-2, aggregated_data-2, mytools-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:21:34,850] INFO [Partition tools1-1 broker=1] tools1-1 starts at Leader Epoch 25 from offset 0. Previous Leader Epoch was: 24 (kafka.cluster.Partition)
[2019-01-25 11:21:34,850] WARN [LeaderEpochCache tools1-1] New epoch entry EpochEntry(epoch=25, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=23, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:21:34,850] INFO [Partition tools2-2 broker=1] tools2-2 starts at Leader Epoch 25 from offset 0. Previous Leader Epoch was: 24 (kafka.cluster.Partition)
[2019-01-25 11:21:34,850] WARN [LeaderEpochCache tools2-2] New epoch entry EpochEntry(epoch=25, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=23, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:21:34,866] INFO [Partition edited12-1 broker=1] edited12-1 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-25 11:21:34,866] INFO [Partition tools7-2 broker=1] tools7-2 starts at Leader Epoch 15 from offset 1. Previous Leader Epoch was: 14 (kafka.cluster.Partition)
[2019-01-25 11:21:34,866] WARN [LeaderEpochCache tools7-2] New epoch entry EpochEntry(epoch=15, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=13, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:21:34,881] INFO [Partition edited-0 broker=1] edited-0 starts at Leader Epoch 25 from offset 8. Previous Leader Epoch was: 24 (kafka.cluster.Partition)
[2019-01-25 11:21:34,881] WARN [LeaderEpochCache edited-0] New epoch entry EpochEntry(epoch=25, startOffset=8) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=23, startOffset=8)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:21:34,881] INFO [Partition alltools-2 broker=1] alltools-2 starts at Leader Epoch 26 from offset 5. Previous Leader Epoch was: 25 (kafka.cluster.Partition)
[2019-01-25 11:21:34,881] WARN [LeaderEpochCache alltools-2] New epoch entry EpochEntry(epoch=26, startOffset=5) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=24, startOffset=5)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:21:34,881] INFO [Partition edited8-1 broker=1] edited8-1 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-25 11:21:34,897] WARN [LeaderEpochCache edited8-1] New epoch entry EpochEntry(epoch=5, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:21:34,897] INFO [Partition mytools-2 broker=1] mytools-2 starts at Leader Epoch 25 from offset 0. Previous Leader Epoch was: 24 (kafka.cluster.Partition)
[2019-01-25 11:21:34,912] WARN [LeaderEpochCache mytools-2] New epoch entry EpochEntry(epoch=25, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=23, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:21:34,912] INFO [Partition tools3-2 broker=1] tools3-2 starts at Leader Epoch 25 from offset 0. Previous Leader Epoch was: 24 (kafka.cluster.Partition)
[2019-01-25 11:21:34,912] WARN [LeaderEpochCache tools3-2] New epoch entry EpochEntry(epoch=25, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=23, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:21:34,912] INFO [Partition tools4-0 broker=1] tools4-0 starts at Leader Epoch 25 from offset 0. Previous Leader Epoch was: 24 (kafka.cluster.Partition)
[2019-01-25 11:21:34,912] WARN [LeaderEpochCache tools4-0] New epoch entry EpochEntry(epoch=25, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=23, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:21:34,928] INFO [Partition tools5-1 broker=1] tools5-1 starts at Leader Epoch 25 from offset 5. Previous Leader Epoch was: 24 (kafka.cluster.Partition)
[2019-01-25 11:21:34,928] WARN [LeaderEpochCache tools5-1] New epoch entry EpochEntry(epoch=25, startOffset=5) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=23, startOffset=5)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:21:34,928] INFO [Partition edited6-0 broker=1] edited6-0 starts at Leader Epoch 21 from offset 3. Previous Leader Epoch was: 20 (kafka.cluster.Partition)
[2019-01-25 11:21:34,928] WARN [LeaderEpochCache edited6-0] New epoch entry EpochEntry(epoch=21, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=19, startOffset=3)). Cache now contains 4 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:21:34,944] INFO [Partition tools12-2 broker=1] tools12-2 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-25 11:21:34,944] INFO [Partition aggregated_data-2 broker=1] aggregated_data-2 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-25 11:21:34,959] INFO [Partition tools-2 broker=1] tools-2 starts at Leader Epoch 25 from offset 0. Previous Leader Epoch was: 24 (kafka.cluster.Partition)
[2019-01-25 11:21:34,959] WARN [LeaderEpochCache tools-2] New epoch entry EpochEntry(epoch=25, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=23, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:21:34,959] INFO [Partition edited10-1 broker=1] edited10-1 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-25 11:21:34,959] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:21:34,959] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:21:34,959] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:21:34,975] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools8-0, tools10-2, tools6-2, tools11-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:21:34,975] INFO [Partition tools8-0 broker=1] tools8-0 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-25 11:21:34,975] WARN [LeaderEpochCache tools8-0] New epoch entry EpochEntry(epoch=3, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:21:34,991] INFO [Partition tools10-2 broker=1] tools10-2 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-25 11:21:34,991] WARN [LeaderEpochCache tools10-2] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:21:34,991] INFO [Partition tools6-2 broker=1] tools6-2 starts at Leader Epoch 7 from offset 3. Previous Leader Epoch was: 6 (kafka.cluster.Partition)
[2019-01-25 11:21:34,991] WARN [LeaderEpochCache tools6-2] New epoch entry EpochEntry(epoch=7, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=6, startOffset=3)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:21:34,991] INFO [Partition tools11-1 broker=1] tools11-1 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-25 11:21:34,991] WARN [LeaderEpochCache tools11-1] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:21:35,850] WARN [Controller id=1, targetBrokerId=2] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-25 11:21:35,866] WARN Exception causing close of session 0x1000380b4ed0000: Connessione in corso interrotta forzatamente dall'host remoto (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-25 11:21:35,866] INFO Closed socket connection for client /127.0.0.1:52840 which had sessionid 0x1000380b4ed0000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-25 11:21:37,801] INFO Expiring session 0x1000380b4ed0001, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:21:37,801] INFO Processed session termination for sessionid: 0x1000380b4ed0001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:25:39,082] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-01-25 11:25:39,085] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-25 11:25:39,085] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-25 11:25:39,085] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-25 11:25:39,086] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-01-25 11:25:39,099] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-01-25 11:25:39,100] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-01-25 11:25:45,674] INFO Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:25:45,674] INFO Server environment:host.name=ITdif (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:25:45,675] INFO Server environment:java.version=1.8.0_181 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:25:45,675] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:25:45,675] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_181 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:25:45,676] INFO Server environment:java.class.path=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-connect-jdbc-5.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\mysql-connector-java-5.1.42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:25:45,678] INFO Server environment:java.library.path=C:\Program Files\Java\jre1.8.0_181\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Docker\Docker\Resources\bin;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\Scripts\;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\dotnet\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\NoteBook FanControl\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\extras\CUPTI\libx64;C:\tools\cuda\bin;C:\Program Files\PuTTY\;C:\Program Files\Calibre2\;C:\apache-maven-3.6.\bin;C:\Users\Stefano\Downloads\platform-tools_r28.0.1-windows\platform-tools;C:\Program Files\Java\jre1.8.0_181\bin;C:\Users\Stefano\AppData\Local\Programs\Python\Launcher\;C:\Users\Stefano\AppData\Local\Microsoft\WindowsApps;C:\Users\Stefano\AppData\Local\GitHubDesktop\bin;C:\apache-maven-3.6.0\bin;;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:25:45,678] INFO Server environment:java.io.tmpdir=C:\Users\Stefano\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:25:45,678] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:25:45,679] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:25:45,679] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:25:45,679] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:25:45,679] INFO Server environment:user.name=Stefano (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:25:45,679] INFO Server environment:user.home=C:\Users\Stefano (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:25:45,679] INFO Server environment:user.dir=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:25:45,691] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:25:45,694] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:25:45,700] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:25:45,716] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-01-25 11:25:45,722] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-25 11:25:52,798] INFO Expiring session 0x1000380b4ed0000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:25:52,800] INFO Processed session termination for sessionid: 0x1000380b4ed0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:25:52,800] INFO Creating new log file: log.b04 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-01-25 11:26:01,138] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-25 11:26:01,661] INFO starting (kafka.server.KafkaServer)
[2019-01-25 11:26:01,663] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-25 11:26:01,683] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-25 11:26:06,281] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:06,282] INFO Client environment:host.name=ITdif (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:06,282] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:06,283] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:06,283] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:06,284] INFO Client environment:java.class.path=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-connect-jdbc-5.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\mysql-connector-java-5.1.42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:06,286] INFO Client environment:java.library.path=C:\Program Files\Java\jre1.8.0_181\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Docker\Docker\Resources\bin;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\Scripts\;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\dotnet\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\NoteBook FanControl\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\extras\CUPTI\libx64;C:\tools\cuda\bin;C:\Program Files\PuTTY\;C:\Program Files\Calibre2\;C:\apache-maven-3.6.\bin;C:\Users\Stefano\Downloads\platform-tools_r28.0.1-windows\platform-tools;C:\Program Files\Java\jre1.8.0_181\bin;C:\Users\Stefano\AppData\Local\Programs\Python\Launcher\;C:\Users\Stefano\AppData\Local\Microsoft\WindowsApps;C:\Users\Stefano\AppData\Local\GitHubDesktop\bin;C:\apache-maven-3.6.0\bin;;. (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:06,287] INFO Client environment:java.io.tmpdir=C:\Users\Stefano\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:06,287] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:06,287] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:06,288] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:06,288] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:06,288] INFO Client environment:user.name=Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:06,289] INFO Client environment:user.home=C:\Users\Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:06,289] INFO Client environment:user.dir=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:06,292] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@1622f1b (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:06,316] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-25 11:26:06,317] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-25 11:26:06,321] INFO Accepted socket connection from /127.0.0.1:53839 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-25 11:26:06,321] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-25 11:26:06,335] INFO Client attempting to establish new session at /127.0.0.1:53839 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:26:06,340] INFO Established session 0x10003b9f7140000 with negotiated timeout 6000 for client /127.0.0.1:53839 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:26:06,342] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10003b9f7140000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-25 11:26:06,350] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-25 11:26:06,403] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140000 type:create cxid:0x1 zxid:0xb06 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:06,417] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140000 type:create cxid:0x2 zxid:0xb07 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:06,420] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140000 type:create cxid:0x3 zxid:0xb08 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:06,424] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140000 type:create cxid:0x4 zxid:0xb09 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:06,427] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140000 type:create cxid:0x5 zxid:0xb0a txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:06,430] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140000 type:create cxid:0x6 zxid:0xb0b txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:06,433] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140000 type:create cxid:0x7 zxid:0xb0c txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:06,436] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140000 type:create cxid:0x8 zxid:0xb0d txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:06,439] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140000 type:create cxid:0x9 zxid:0xb0e txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:06,442] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140000 type:create cxid:0xa zxid:0xb0f txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:06,445] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140000 type:create cxid:0xb zxid:0xb10 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:06,447] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140000 type:create cxid:0xc zxid:0xb11 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:06,450] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140000 type:create cxid:0xd zxid:0xb12 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:06,587] INFO Cluster ID = RvEiz9fYQgKWcHR6fHb3dg (kafka.server.KafkaServer)
[2019-01-25 11:26:06,671] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-25 11:26:06,683] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-25 11:26:06,717] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-25 11:26:06,718] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-25 11:26:06,721] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-25 11:26:06,782] INFO Loading logs. (kafka.log.LogManager)
[2019-01-25 11:26:06,850] INFO [Log partition=aggregated_data-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:06,854] INFO [Log partition=aggregated_data-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:06,892] INFO [ProducerStateManager partition=aggregated_data-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:06,923] INFO [Log partition=aggregated_data-0, dir=C:\tmp\logs1] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:06,929] INFO [ProducerStateManager partition=aggregated_data-0] Loading producer state from snapshot file 'C:\tmp\logs1\aggregated_data-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:06,942] INFO [Log partition=aggregated_data-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 119 ms (kafka.log.Log)
[2019-01-25 11:26:06,960] INFO [Log partition=aggregated_data-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:06,961] INFO [Log partition=aggregated_data-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:06,982] INFO [Log partition=aggregated_data-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:06,985] INFO [Log partition=aggregated_data-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2019-01-25 11:26:06,994] WARN [Log partition=alltools-0, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\alltools-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\alltools-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547977751460}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:06,995] INFO [Log partition=alltools-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,007] INFO [ProducerStateManager partition=alltools-0] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,010] INFO [Log partition=alltools-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,010] INFO [Log partition=alltools-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,018] INFO [ProducerStateManager partition=alltools-0] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,029] INFO [Log partition=alltools-0, dir=C:\tmp\logs1] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,031] INFO [ProducerStateManager partition=alltools-0] Loading producer state from snapshot file 'C:\tmp\logs1\alltools-0\00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,033] INFO [Log partition=alltools-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 43 ms (kafka.log.Log)
[2019-01-25 11:26:07,041] WARN [Log partition=alltools-2, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\alltools-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\alltools-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547977368170}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:07,041] INFO [Log partition=alltools-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,048] INFO [ProducerStateManager partition=alltools-2] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,052] INFO [Log partition=alltools-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,053] INFO [Log partition=alltools-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,064] INFO [ProducerStateManager partition=alltools-2] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,075] INFO [Log partition=alltools-2, dir=C:\tmp\logs1] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,077] INFO [ProducerStateManager partition=alltools-2] Loading producer state from snapshot file 'C:\tmp\logs1\alltools-2\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,079] INFO [Log partition=alltools-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 40 ms (kafka.log.Log)
[2019-01-25 11:26:07,089] WARN [Log partition=edited-0, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\edited-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\edited-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996878625}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:07,090] INFO [Log partition=edited-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,097] INFO [ProducerStateManager partition=edited-0] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,101] INFO [Log partition=edited-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,102] INFO [Log partition=edited-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,111] INFO [ProducerStateManager partition=edited-0] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,124] INFO [Log partition=edited-0, dir=C:\tmp\logs1] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,126] INFO [ProducerStateManager partition=edited-0] Loading producer state from snapshot file 'C:\tmp\logs1\edited-0\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,128] INFO [Log partition=edited-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 41 ms (kafka.log.Log)
[2019-01-25 11:26:07,142] WARN [Log partition=edited-1, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\edited-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\edited-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996876577}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:07,142] INFO [Log partition=edited-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,150] INFO [ProducerStateManager partition=edited-1] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,151] INFO [Log partition=edited-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,151] INFO [Log partition=edited-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,160] INFO [ProducerStateManager partition=edited-1] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,174] INFO [Log partition=edited-1, dir=C:\tmp\logs1] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,175] INFO [ProducerStateManager partition=edited-1] Loading producer state from snapshot file 'C:\tmp\logs1\edited-1\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,176] INFO [Log partition=edited-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 9 in 37 ms (kafka.log.Log)
[2019-01-25 11:26:07,191] INFO [Log partition=edited10-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,191] INFO [Log partition=edited10-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,204] INFO [Log partition=edited10-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,207] INFO [Log partition=edited10-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-01-25 11:26:07,218] INFO [Log partition=edited10-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,218] INFO [Log partition=edited10-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,223] INFO [ProducerStateManager partition=edited10-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,232] INFO [Log partition=edited10-2, dir=C:\tmp\logs1] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,234] INFO [ProducerStateManager partition=edited10-2] Loading producer state from snapshot file 'C:\tmp\logs1\edited10-2\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,235] INFO [Log partition=edited10-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 21 ms (kafka.log.Log)
[2019-01-25 11:26:07,242] INFO [Log partition=edited12-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,242] INFO [Log partition=edited12-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,252] INFO [Log partition=edited12-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,254] INFO [Log partition=edited12-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-25 11:26:07,264] INFO [Log partition=edited12-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,264] INFO [Log partition=edited12-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,273] INFO [Log partition=edited12-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,275] INFO [Log partition=edited12-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 11:26:07,286] WARN [Log partition=edited6-0, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\edited6-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\edited6-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548158302054}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:07,286] INFO [Log partition=edited6-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,291] INFO [ProducerStateManager partition=edited6-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,294] INFO [Log partition=edited6-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,297] INFO [Log partition=edited6-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,303] INFO [ProducerStateManager partition=edited6-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,316] INFO [Log partition=edited6-0, dir=C:\tmp\logs1] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,318] INFO [ProducerStateManager partition=edited6-0] Loading producer state from snapshot file 'C:\tmp\logs1\edited6-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,320] INFO [Log partition=edited6-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 36 ms (kafka.log.Log)
[2019-01-25 11:26:07,334] WARN [Log partition=edited6-1, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\edited6-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\edited6-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548321919981}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:07,335] INFO [Log partition=edited6-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,341] INFO [ProducerStateManager partition=edited6-1] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,345] INFO [Log partition=edited6-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,349] INFO [Log partition=edited6-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,356] INFO [ProducerStateManager partition=edited6-1] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,370] INFO [Log partition=edited6-1, dir=C:\tmp\logs1] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,371] INFO [ProducerStateManager partition=edited6-1] Loading producer state from snapshot file 'C:\tmp\logs1\edited6-1\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,373] INFO [Log partition=edited6-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 42 ms (kafka.log.Log)
[2019-01-25 11:26:07,385] INFO [Log partition=edited8-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,386] INFO [Log partition=edited8-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,396] INFO [Log partition=edited8-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,401] INFO [Log partition=edited8-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-01-25 11:26:07,409] INFO [Log partition=edited8-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,409] INFO [Log partition=edited8-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,418] INFO [Log partition=edited8-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,420] INFO [Log partition=edited8-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-01-25 11:26:07,431] WARN [Log partition=mytools-0, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\mytools-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\mytools-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547991919170}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:07,432] INFO [Log partition=mytools-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,437] INFO [ProducerStateManager partition=mytools-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,440] INFO [Log partition=mytools-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,441] INFO [Log partition=mytools-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,449] INFO [ProducerStateManager partition=mytools-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,458] INFO [Log partition=mytools-0, dir=C:\tmp\logs1] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,460] INFO [ProducerStateManager partition=mytools-0] Loading producer state from snapshot file 'C:\tmp\logs1\mytools-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,462] INFO [Log partition=mytools-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 36 ms (kafka.log.Log)
[2019-01-25 11:26:07,476] INFO [Log partition=mytools-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,476] INFO [Log partition=mytools-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,489] INFO [Log partition=mytools-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,492] INFO [Log partition=mytools-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-01-25 11:26:07,502] INFO [Log partition=test-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,502] INFO [Log partition=test-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,512] INFO [Log partition=test-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,515] INFO [Log partition=test-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 11:26:07,523] WARN [Log partition=tools-0, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\tools-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\tools-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547991352625}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:07,523] INFO [Log partition=tools-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,529] INFO [ProducerStateManager partition=tools-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,533] INFO [Log partition=tools-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,535] INFO [Log partition=tools-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,541] INFO [ProducerStateManager partition=tools-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,555] INFO [Log partition=tools-0, dir=C:\tmp\logs1] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,557] INFO [ProducerStateManager partition=tools-0] Loading producer state from snapshot file 'C:\tmp\logs1\tools-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,557] INFO [Log partition=tools-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 36 ms (kafka.log.Log)
[2019-01-25 11:26:07,563] INFO [Log partition=tools-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,563] INFO [Log partition=tools-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,575] INFO [Log partition=tools-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,576] INFO [Log partition=tools-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 11:26:07,584] INFO [Log partition=tools1-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,584] INFO [Log partition=tools1-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,592] INFO [Log partition=tools1-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,598] INFO [Log partition=tools1-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 11:26:07,613] INFO [Log partition=tools1-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,615] INFO [Log partition=tools1-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,625] INFO [Log partition=tools1-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,628] INFO [Log partition=tools1-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-01-25 11:26:07,633] INFO [Log partition=tools10-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,633] INFO [Log partition=tools10-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,636] INFO [Log partition=tools10-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,639] INFO [Log partition=tools10-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-01-25 11:26:07,651] INFO [Log partition=tools10-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,652] INFO [Log partition=tools10-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,665] INFO [Log partition=tools10-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,667] INFO [Log partition=tools10-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-01-25 11:26:07,673] INFO [Log partition=tools11-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,673] INFO [Log partition=tools11-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,684] INFO [Log partition=tools11-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,687] INFO [Log partition=tools11-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-01-25 11:26:07,693] INFO [Log partition=tools11-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,693] INFO [Log partition=tools11-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,699] INFO [ProducerStateManager partition=tools11-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,705] INFO [Log partition=tools11-2, dir=C:\tmp\logs1] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,706] INFO [ProducerStateManager partition=tools11-2] Loading producer state from snapshot file 'C:\tmp\logs1\tools11-2\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,707] INFO [Log partition=tools11-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 17 ms (kafka.log.Log)
[2019-01-25 11:26:07,714] INFO [Log partition=tools12-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,715] INFO [Log partition=tools12-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,718] INFO [ProducerStateManager partition=tools12-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,722] INFO [Log partition=tools12-0, dir=C:\tmp\logs1] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,724] INFO [ProducerStateManager partition=tools12-0] Loading producer state from snapshot file 'C:\tmp\logs1\tools12-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,725] INFO [Log partition=tools12-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 15 ms (kafka.log.Log)
[2019-01-25 11:26:07,734] INFO [Log partition=tools12-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,735] INFO [Log partition=tools12-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,741] INFO [Log partition=tools12-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,743] INFO [Log partition=tools12-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-01-25 11:26:07,751] INFO [Log partition=tools2-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,751] INFO [Log partition=tools2-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,758] INFO [Log partition=tools2-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,760] INFO [Log partition=tools2-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2019-01-25 11:26:07,767] INFO [Log partition=tools2-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,767] INFO [Log partition=tools2-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,777] INFO [Log partition=tools2-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,780] INFO [Log partition=tools2-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-25 11:26:07,787] INFO [Log partition=tools3-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,788] INFO [Log partition=tools3-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,796] INFO [Log partition=tools3-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,799] INFO [Log partition=tools3-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-01-25 11:26:07,803] INFO [Log partition=tools3-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,804] INFO [Log partition=tools3-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,809] INFO [Log partition=tools3-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,812] INFO [Log partition=tools3-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-01-25 11:26:07,818] INFO [Log partition=tools4-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,819] INFO [Log partition=tools4-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,825] INFO [Log partition=tools4-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,827] INFO [Log partition=tools4-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-01-25 11:26:07,834] INFO [Log partition=tools4-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,834] INFO [Log partition=tools4-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,840] INFO [Log partition=tools4-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,842] INFO [Log partition=tools4-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-01-25 11:26:07,847] WARN [Log partition=tools5-1, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\tools5-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\tools5-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996876577}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:07,848] INFO [Log partition=tools5-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,851] INFO [ProducerStateManager partition=tools5-1] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,852] INFO [Log partition=tools5-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,852] INFO [Log partition=tools5-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,856] INFO [ProducerStateManager partition=tools5-1] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,863] INFO [Log partition=tools5-1, dir=C:\tmp\logs1] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,865] INFO [ProducerStateManager partition=tools5-1] Loading producer state from snapshot file 'C:\tmp\logs1\tools5-1\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,865] INFO [Log partition=tools5-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 20 ms (kafka.log.Log)
[2019-01-25 11:26:07,870] WARN [Log partition=tools5-2, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\tools5-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\tools5-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996835000}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:07,870] INFO [Log partition=tools5-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,877] INFO [ProducerStateManager partition=tools5-2] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,878] INFO [Log partition=tools5-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,878] INFO [Log partition=tools5-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,882] INFO [ProducerStateManager partition=tools5-2] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,891] INFO [Log partition=tools5-2, dir=C:\tmp\logs1] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,893] INFO [ProducerStateManager partition=tools5-2] Loading producer state from snapshot file 'C:\tmp\logs1\tools5-2\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,894] INFO [Log partition=tools5-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 26 ms (kafka.log.Log)
[2019-01-25 11:26:07,899] WARN [Log partition=tools6-0, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\tools6-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\tools6-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548176773646}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:07,899] INFO [Log partition=tools6-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,903] INFO [ProducerStateManager partition=tools6-0] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,905] INFO [Log partition=tools6-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,906] INFO [Log partition=tools6-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,910] INFO [ProducerStateManager partition=tools6-0] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,921] INFO [Log partition=tools6-0, dir=C:\tmp\logs1] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,923] INFO [ProducerStateManager partition=tools6-0] Loading producer state from snapshot file 'C:\tmp\logs1\tools6-0\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,924] INFO [Log partition=tools6-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 27 ms (kafka.log.Log)
[2019-01-25 11:26:07,931] WARN [Log partition=tools6-2, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\tools6-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\tools6-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548158302054}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:07,933] INFO [Log partition=tools6-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,937] INFO [ProducerStateManager partition=tools6-2] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,937] INFO [Log partition=tools6-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,938] INFO [Log partition=tools6-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,942] INFO [ProducerStateManager partition=tools6-2] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,950] INFO [Log partition=tools6-2, dir=C:\tmp\logs1] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,952] INFO [ProducerStateManager partition=tools6-2] Loading producer state from snapshot file 'C:\tmp\logs1\tools6-2\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,952] INFO [Log partition=tools6-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 24 ms (kafka.log.Log)
[2019-01-25 11:26:07,957] WARN [Log partition=tools7-0, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\tools7-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\tools7-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548173477306}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:07,957] INFO [Log partition=tools7-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,960] INFO [ProducerStateManager partition=tools7-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,962] INFO [Log partition=tools7-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,962] INFO [Log partition=tools7-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,966] INFO [ProducerStateManager partition=tools7-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,974] INFO [Log partition=tools7-0, dir=C:\tmp\logs1] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,976] INFO [ProducerStateManager partition=tools7-0] Loading producer state from snapshot file 'C:\tmp\logs1\tools7-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,976] INFO [Log partition=tools7-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 22 ms (kafka.log.Log)
[2019-01-25 11:26:07,982] WARN [Log partition=tools7-2, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\tools7-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\tools7-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548156023437}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:07,982] INFO [Log partition=tools7-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,986] INFO [ProducerStateManager partition=tools7-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,986] INFO [Log partition=tools7-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:07,987] INFO [Log partition=tools7-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,990] INFO [ProducerStateManager partition=tools7-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,997] INFO [Log partition=tools7-2, dir=C:\tmp\logs1] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:07,999] INFO [ProducerStateManager partition=tools7-2] Loading producer state from snapshot file 'C:\tmp\logs1\tools7-2\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:07,999] INFO [Log partition=tools7-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 20 ms (kafka.log.Log)
[2019-01-25 11:26:08,004] INFO [Log partition=tools8-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:08,004] INFO [Log partition=tools8-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,014] INFO [Log partition=tools8-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,016] INFO [Log partition=tools8-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-25 11:26:08,020] WARN [Log partition=tools8-1, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\tools8-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\tools8-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548341369651}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:08,020] INFO [Log partition=tools8-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,024] INFO [ProducerStateManager partition=tools8-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:08,025] INFO [Log partition=tools8-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:08,025] INFO [Log partition=tools8-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,030] INFO [ProducerStateManager partition=tools8-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:08,038] INFO [Log partition=tools8-1, dir=C:\tmp\logs1] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,040] INFO [ProducerStateManager partition=tools8-1] Loading producer state from snapshot file 'C:\tmp\logs1\tools8-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:08,040] INFO [Log partition=tools8-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 22 ms (kafka.log.Log)
[2019-01-25 11:26:08,045] WARN [Log partition=__consumer_offsets-0, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\__consumer_offsets-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\__consumer_offsets-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547994284686}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:08,046] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,050] INFO [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:08,051] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:08,052] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,058] INFO [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:08,067] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\logs1] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,068] INFO [ProducerStateManager partition=__consumer_offsets-0] Loading producer state from snapshot file 'C:\tmp\logs1\__consumer_offsets-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:08,069] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 27 ms (kafka.log.Log)
[2019-01-25 11:26:08,073] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:08,074] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,082] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,084] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-01-25 11:26:08,088] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:08,088] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,097] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,099] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-01-25 11:26:08,103] WARN [Log partition=__consumer_offsets-18, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\__consumer_offsets-18\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\__consumer_offsets-18\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548177188378}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:08,103] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,106] INFO [ProducerStateManager partition=__consumer_offsets-18] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:08,108] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:08,108] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,114] INFO [ProducerStateManager partition=__consumer_offsets-18] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:08,123] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\logs1] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,125] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file 'C:\tmp\logs1\__consumer_offsets-18\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:08,126] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 25 ms (kafka.log.Log)
[2019-01-25 11:26:08,131] WARN [Log partition=__consumer_offsets-21, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\__consumer_offsets-21\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\__consumer_offsets-21\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547985284682}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:08,131] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,135] INFO [ProducerStateManager partition=__consumer_offsets-21] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:08,136] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:08,136] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,140] INFO [ProducerStateManager partition=__consumer_offsets-21] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:08,149] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\logs1] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,150] INFO [ProducerStateManager partition=__consumer_offsets-21] Loading producer state from snapshot file 'C:\tmp\logs1\__consumer_offsets-21\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:08,151] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 23 ms (kafka.log.Log)
[2019-01-25 11:26:08,155] WARN [Log partition=__consumer_offsets-24, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\__consumer_offsets-24\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\__consumer_offsets-24\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547991284687}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:08,156] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,159] INFO [ProducerStateManager partition=__consumer_offsets-24] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:08,160] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:08,160] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,164] INFO [ProducerStateManager partition=__consumer_offsets-24] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:08,173] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\logs1] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,175] INFO [ProducerStateManager partition=__consumer_offsets-24] Loading producer state from snapshot file 'C:\tmp\logs1\__consumer_offsets-24\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:08,175] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 22 ms (kafka.log.Log)
[2019-01-25 11:26:08,180] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:08,180] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,190] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,192] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-25 11:26:08,197] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:08,197] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,203] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,205] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-01-25 11:26:08,209] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:08,210] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,217] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,219] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2019-01-25 11:26:08,223] WARN [Log partition=__consumer_offsets-33, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\__consumer_offsets-33\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\__consumer_offsets-33\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548156193182}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:08,224] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,227] INFO [ProducerStateManager partition=__consumer_offsets-33] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:08,228] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:08,228] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,233] INFO [ProducerStateManager partition=__consumer_offsets-33] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:08,241] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\logs1] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,243] INFO [ProducerStateManager partition=__consumer_offsets-33] Loading producer state from snapshot file 'C:\tmp\logs1\__consumer_offsets-33\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:08,243] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 22 ms (kafka.log.Log)
[2019-01-25 11:26:08,247] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:08,248] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,254] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,256] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-01-25 11:26:08,260] WARN [Log partition=__consumer_offsets-39, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\__consumer_offsets-39\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\__consumer_offsets-39\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548010498324}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:08,261] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,264] INFO [ProducerStateManager partition=__consumer_offsets-39] Writing producer snapshot at offset 31 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:08,265] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:08,266] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,269] INFO [ProducerStateManager partition=__consumer_offsets-39] Writing producer snapshot at offset 31 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:08,278] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\logs1] Loading producer state till offset 31 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,280] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file 'C:\tmp\logs1\__consumer_offsets-39\00000000000000000031.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:08,281] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 31 in 23 ms (kafka.log.Log)
[2019-01-25 11:26:08,285] WARN [Log partition=__consumer_offsets-42, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\__consumer_offsets-42\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\__consumer_offsets-42\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548156193185}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:08,285] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,289] INFO [ProducerStateManager partition=__consumer_offsets-42] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:08,290] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:08,290] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,294] INFO [ProducerStateManager partition=__consumer_offsets-42] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:08,302] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\logs1] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,304] INFO [ProducerStateManager partition=__consumer_offsets-42] Loading producer state from snapshot file 'C:\tmp\logs1\__consumer_offsets-42\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:08,304] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 21 ms (kafka.log.Log)
[2019-01-25 11:26:08,308] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:08,308] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,318] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,320] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-01-25 11:26:08,324] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:08,324] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,331] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,333] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-01-25 11:26:08,337] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:08,337] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,345] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,347] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2019-01-25 11:26:08,351] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:08,351] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,358] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:08,359] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-01-25 11:26:08,363] INFO Logs loading complete in 1580 ms. (kafka.log.LogManager)
[2019-01-25 11:26:08,372] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-25 11:26:08,373] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-25 11:26:08,600] INFO Awaiting socket connections on localhost:9093. (kafka.network.Acceptor)
[2019-01-25 11:26:08,627] INFO [SocketServer brokerId=1] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-25 11:26:08,652] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-25 11:26:08,652] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-25 11:26:08,654] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-25 11:26:08,664] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-25 11:26:08,707] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-25 11:26:08,711] INFO Result of znode creation at /brokers/ids/1 is: OK (kafka.zk.KafkaZkClient)
[2019-01-25 11:26:08,712] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(localhost,9093,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-25 11:26:08,753] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-25 11:26:08,756] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-25 11:26:08,757] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-25 11:26:08,787] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:26:08,788] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:26:08,793] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:08,806] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:30000,blockEndProducerId:30999) by writing to Zk with path version 31 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-25 11:26:08,838] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-25 11:26:08,843] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-25 11:26:08,843] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-25 11:26:08,896] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-25 11:26:08,937] INFO [SocketServer brokerId=1] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-25 11:26:08,944] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-25 11:26:08,944] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-25 11:26:08,946] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2019-01-25 11:26:09,054] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools4-0, edited8-2, tools10-2, tools1-1, __consumer_offsets-30, tools2-2, tools-2, __consumer_offsets-21, tools7-0, edited6-0, __consumer_offsets-27, tools8-1, __consumer_offsets-9, tools3-0, tools4-1, alltools-2, tools5-2, __consumer_offsets-33, tools1-2, tools8-0, edited-1, test-0, edited8-1, mytools-0, __consumer_offsets-36, edited12-2, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, edited10-1, tools5-1, __consumer_offsets-15, __consumer_offsets-24, tools6-2, tools11-1, alltools-0, aggregated_data-0, __consumer_offsets-48, tools-0, tools12-2, edited10-2, edited12-1, tools7-2, __consumer_offsets-6, edited-0, tools3-2, edited6-1, __consumer_offsets-0, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, aggregated_data-2, mytools-2, tools6-0, tools12-0, tools2-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:26:09,069] INFO Replica loaded for partition tools2-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,073] INFO Replica loaded for partition tools2-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,076] INFO [Partition tools2-2 broker=1] tools2-2 starts at Leader Epoch 25 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,104] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-25 11:26:09,104] INFO [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 3 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,106] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140000 type:multi cxid:0x15f zxid:0xb18 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:09,112] INFO Replica loaded for partition edited6-1 with initial high watermark 7 (kafka.cluster.Replica)
[2019-01-25 11:26:09,112] INFO Replica loaded for partition edited6-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,113] INFO [Partition edited6-1 broker=1] edited6-1 starts at Leader Epoch 3 from offset 7. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,117] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140000 type:multi cxid:0x163 zxid:0xb19 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:09,119] INFO Replica loaded for partition tools1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,119] INFO Replica loaded for partition tools1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,119] INFO [Partition tools1-1 broker=1] tools1-1 starts at Leader Epoch 25 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,125] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,125] INFO [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,131] INFO Replica loaded for partition mytools-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 11:26:09,131] INFO Replica loaded for partition mytools-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,131] INFO [Partition mytools-0 broker=1] mytools-0 starts at Leader Epoch 6 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,136] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,137] INFO [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,142] INFO Replica loaded for partition tools5-2 with initial high watermark 8 (kafka.cluster.Replica)
[2019-01-25 11:26:09,142] INFO Replica loaded for partition tools5-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,143] INFO [Partition tools5-2 broker=1] tools5-2 starts at Leader Epoch 6 from offset 8. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,148] INFO Replica loaded for partition edited10-2 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 11:26:09,148] INFO Replica loaded for partition edited10-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,148] INFO [Partition edited10-2 broker=1] edited10-2 starts at Leader Epoch 0 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,150] INFO Replica loaded for partition tools4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,150] INFO Replica loaded for partition tools4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,151] INFO [Partition tools4-1 broker=1] tools4-1 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,156] INFO Replica loaded for partition tools3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,156] INFO Replica loaded for partition tools3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,156] INFO [Partition tools3-0 broker=1] tools3-0 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,161] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-25 11:26:09,162] INFO [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 3 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,167] INFO Replica loaded for partition tools-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 11:26:09,167] INFO Replica loaded for partition tools-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,168] INFO [Partition tools-0 broker=1] tools-0 starts at Leader Epoch 6 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,173] INFO Replica loaded for partition tools6-0 with initial high watermark 5 (kafka.cluster.Replica)
[2019-01-25 11:26:09,173] INFO Replica loaded for partition tools6-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,174] INFO [Partition tools6-0 broker=1] tools6-0 starts at Leader Epoch 7 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,179] INFO Replica loaded for partition edited12-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,179] INFO Replica loaded for partition edited12-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,180] INFO [Partition edited12-1 broker=1] edited12-1 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,186] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 31 (kafka.cluster.Replica)
[2019-01-25 11:26:09,187] INFO [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 3 from offset 31. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,191] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,191] INFO [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,197] INFO Replica loaded for partition tools12-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 11:26:09,197] INFO Replica loaded for partition tools12-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,197] INFO [Partition tools12-0 broker=1] tools12-0 starts at Leader Epoch 0 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,199] INFO Replica loaded for partition tools7-2 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 11:26:09,200] INFO Replica loaded for partition tools7-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,200] INFO [Partition tools7-2 broker=1] tools7-2 starts at Leader Epoch 15 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,205] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-25 11:26:09,205] INFO [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 3 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,210] INFO Replica loaded for partition aggregated_data-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 11:26:09,211] INFO Replica loaded for partition aggregated_data-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,212] INFO [Partition aggregated_data-0 broker=1] aggregated_data-0 starts at Leader Epoch 0 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,214] INFO Replica loaded for partition tools8-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,214] INFO Replica loaded for partition tools8-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,214] INFO [Partition tools8-0 broker=1] tools8-0 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,220] INFO Replica loaded for partition edited-0 with initial high watermark 8 (kafka.cluster.Replica)
[2019-01-25 11:26:09,220] INFO Replica loaded for partition edited-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,220] INFO [Partition edited-0 broker=1] edited-0 starts at Leader Epoch 25 from offset 8. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,229] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,230] INFO [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,235] INFO Replica loaded for partition tools1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,235] INFO Replica loaded for partition tools1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,236] INFO [Partition tools1-2 broker=1] tools1-2 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,241] INFO Replica loaded for partition test-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,241] INFO [Partition test-0 broker=1] test-0 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,246] INFO Replica loaded for partition alltools-2 with initial high watermark 5 (kafka.cluster.Replica)
[2019-01-25 11:26:09,247] INFO Replica loaded for partition alltools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,247] INFO [Partition alltools-2 broker=1] alltools-2 starts at Leader Epoch 26 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,252] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,253] INFO [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,258] INFO Replica loaded for partition edited8-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,258] INFO Replica loaded for partition edited8-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,258] INFO [Partition edited8-1 broker=1] edited8-1 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,265] INFO Replica loaded for partition tools2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,265] INFO Replica loaded for partition tools2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,266] INFO [Partition tools2-0 broker=1] tools2-0 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,271] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-25 11:26:09,271] INFO [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 3 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,276] INFO Replica loaded for partition edited12-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,276] INFO Replica loaded for partition edited12-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,277] INFO [Partition edited12-2 broker=1] edited12-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,282] INFO Replica loaded for partition mytools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,283] INFO Replica loaded for partition mytools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,283] INFO [Partition mytools-2 broker=1] mytools-2 starts at Leader Epoch 25 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,288] INFO Replica loaded for partition tools10-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,288] INFO Replica loaded for partition tools10-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,288] INFO [Partition tools10-2 broker=1] tools10-2 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,294] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-25 11:26:09,294] INFO [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 3 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,299] INFO Replica loaded for partition edited8-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,300] INFO Replica loaded for partition edited8-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,301] INFO [Partition edited8-2 broker=1] edited8-2 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,306] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-25 11:26:09,306] INFO [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 3 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,314] INFO Replica loaded for partition tools3-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,314] INFO Replica loaded for partition tools3-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,315] INFO [Partition tools3-2 broker=1] tools3-2 starts at Leader Epoch 25 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,320] INFO Replica loaded for partition tools4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,320] INFO Replica loaded for partition tools4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,321] INFO [Partition tools4-0 broker=1] tools4-0 starts at Leader Epoch 25 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,326] INFO Replica loaded for partition tools5-1 with initial high watermark 5 (kafka.cluster.Replica)
[2019-01-25 11:26:09,327] INFO Replica loaded for partition tools5-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,327] INFO [Partition tools5-1 broker=1] tools5-1 starts at Leader Epoch 25 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,332] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,333] INFO [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,338] INFO Replica loaded for partition tools6-2 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-25 11:26:09,338] INFO Replica loaded for partition tools6-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,339] INFO [Partition tools6-2 broker=1] tools6-2 starts at Leader Epoch 7 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,345] INFO Replica loaded for partition edited-1 with initial high watermark 9 (kafka.cluster.Replica)
[2019-01-25 11:26:09,346] INFO Replica loaded for partition edited-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,346] INFO [Partition edited-1 broker=1] edited-1 starts at Leader Epoch 6 from offset 9. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,351] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,352] INFO [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,357] INFO Replica loaded for partition tools8-1 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 11:26:09,358] INFO Replica loaded for partition tools8-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,358] INFO [Partition tools8-1 broker=1] tools8-1 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,364] INFO Replica loaded for partition tools7-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 11:26:09,365] INFO Replica loaded for partition tools7-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,365] INFO [Partition tools7-0 broker=1] tools7-0 starts at Leader Epoch 3 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,370] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,370] INFO [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,376] INFO Replica loaded for partition tools12-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,376] INFO Replica loaded for partition tools12-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,377] INFO [Partition tools12-2 broker=1] tools12-2 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,382] INFO Replica loaded for partition tools11-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,382] INFO Replica loaded for partition tools11-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,382] INFO [Partition tools11-1 broker=1] tools11-1 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,386] INFO Replica loaded for partition edited6-0 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-25 11:26:09,387] INFO Replica loaded for partition edited6-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,387] INFO [Partition edited6-0 broker=1] edited6-0 starts at Leader Epoch 21 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,394] INFO Replica loaded for partition aggregated_data-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,394] INFO Replica loaded for partition aggregated_data-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,395] INFO [Partition aggregated_data-2 broker=1] aggregated_data-2 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,400] INFO Replica loaded for partition edited10-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,400] INFO Replica loaded for partition edited10-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,401] INFO [Partition edited10-1 broker=1] edited10-1 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,406] INFO Replica loaded for partition alltools-0 with initial high watermark 4 (kafka.cluster.Replica)
[2019-01-25 11:26:09,407] INFO Replica loaded for partition alltools-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,407] INFO [Partition alltools-0 broker=1] alltools-0 starts at Leader Epoch 7 from offset 4. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,413] INFO Replica loaded for partition tools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,413] INFO Replica loaded for partition tools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,413] INFO [Partition tools-2 broker=1] tools-2 starts at Leader Epoch 25 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,419] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,420] INFO [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,427] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,427] INFO [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,437] INFO Replica loaded for partition tools11-2 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 11:26:09,439] INFO Replica loaded for partition tools10-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,440] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:26:09,459] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:09,460] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:09,460] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:09,461] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:09,461] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:09,461] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:09,461] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:09,462] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:09,462] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:09,462] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:09,463] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:09,463] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:09,463] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:09,463] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:09,464] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:09,464] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:09,464] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:09,488] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools11-2, tools10-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:26:09,489] INFO Replica loaded for partition tools11-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,489] INFO [Partition tools11-2 broker=1] tools11-2 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,493] INFO Replica loaded for partition tools10-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:09,494] INFO [Partition tools10-0 broker=1] tools10-0 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:09,513] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 53 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:09,515] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:09,516] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:09,516] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:09,520] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:09,524] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:09,528] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:09,529] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:09,529] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:09,537] INFO [GroupCoordinator 1]: Loading group metadata for group2 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:26:09,538] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 9 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:09,542] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:09,542] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:09,543] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:09,547] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:09,547] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:09,547] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:09,550] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:16,334] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-25 11:26:16,847] INFO starting (kafka.server.KafkaServer)
[2019-01-25 11:26:16,849] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-25 11:26:16,868] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-25 11:26:23,038] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:23,039] INFO Client environment:host.name=ITdif (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:23,039] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:23,040] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:23,040] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:23,040] INFO Client environment:java.class.path=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-connect-jdbc-5.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\mysql-connector-java-5.1.42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:23,042] INFO Client environment:java.library.path=C:\Program Files\Java\jre1.8.0_181\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Docker\Docker\Resources\bin;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\Scripts\;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\dotnet\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\NoteBook FanControl\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\extras\CUPTI\libx64;C:\tools\cuda\bin;C:\Program Files\PuTTY\;C:\Program Files\Calibre2\;C:\apache-maven-3.6.\bin;C:\Users\Stefano\Downloads\platform-tools_r28.0.1-windows\platform-tools;C:\Program Files\Java\jre1.8.0_181\bin;C:\Users\Stefano\AppData\Local\Programs\Python\Launcher\;C:\Users\Stefano\AppData\Local\Microsoft\WindowsApps;C:\Users\Stefano\AppData\Local\GitHubDesktop\bin;C:\apache-maven-3.6.0\bin;;. (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:23,042] INFO Client environment:java.io.tmpdir=C:\Users\Stefano\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:23,043] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:23,043] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:23,043] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:23,044] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:23,044] INFO Client environment:user.name=Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:23,044] INFO Client environment:user.home=C:\Users\Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:23,045] INFO Client environment:user.dir=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:23,046] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@1622f1b (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:23,065] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-25 11:26:23,066] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-25 11:26:23,071] INFO Accepted socket connection from /127.0.0.1:53856 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-25 11:26:23,072] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-25 11:26:23,080] INFO Client attempting to establish new session at /127.0.0.1:53856 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:26:23,084] INFO Established session 0x10003b9f7140001 with negotiated timeout 6000 for client /127.0.0.1:53856 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:26:23,086] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10003b9f7140001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-25 11:26:23,094] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-25 11:26:23,141] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140001 type:create cxid:0x1 zxid:0xb1b txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:23,154] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140001 type:create cxid:0x2 zxid:0xb1c txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:23,157] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140001 type:create cxid:0x3 zxid:0xb1d txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:23,161] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140001 type:create cxid:0x4 zxid:0xb1e txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:23,165] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140001 type:create cxid:0x5 zxid:0xb1f txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:23,167] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140001 type:create cxid:0x6 zxid:0xb20 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:23,170] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140001 type:create cxid:0x7 zxid:0xb21 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:23,173] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140001 type:create cxid:0x8 zxid:0xb22 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:23,176] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140001 type:create cxid:0x9 zxid:0xb23 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:23,178] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140001 type:create cxid:0xa zxid:0xb24 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:23,181] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140001 type:create cxid:0xb zxid:0xb25 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:23,184] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140001 type:create cxid:0xc zxid:0xb26 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:23,187] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140001 type:create cxid:0xd zxid:0xb27 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:23,334] INFO Cluster ID = RvEiz9fYQgKWcHR6fHb3dg (kafka.server.KafkaServer)
[2019-01-25 11:26:23,421] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-25 11:26:23,434] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-25 11:26:23,469] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-25 11:26:23,469] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-25 11:26:23,480] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-25 11:26:23,536] INFO Loading logs. (kafka.log.LogManager)
[2019-01-25 11:26:23,610] INFO [Log partition=aggregated_data-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:23,613] INFO [Log partition=aggregated_data-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:23,658] INFO [ProducerStateManager partition=aggregated_data-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:23,666] INFO [Partition edited10-2 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-25 11:26:23,674] INFO [Partition edited-1 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-25 11:26:23,678] INFO [Partition tools-0 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-25 11:26:23,681] INFO [Partition edited12-2 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-25 11:26:23,685] INFO [Partition aggregated_data-0 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-25 11:26:23,685] INFO [Log partition=aggregated_data-0, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:23,689] INFO [Partition tools2-0 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-25 11:26:23,696] INFO [Partition tools3-0 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-25 11:26:23,696] INFO [ProducerStateManager partition=aggregated_data-0] Loading producer state from snapshot file 'C:\tmp\logs2\aggregated_data-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:23,700] INFO [Partition tools6-0 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-25 11:26:23,703] INFO [Partition tools7-0 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-25 11:26:23,708] INFO [Partition alltools-0 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-25 11:26:23,714] INFO [Partition edited8-2 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-25 11:26:23,717] INFO [Partition tools4-1 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-25 11:26:23,719] INFO [Log partition=aggregated_data-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 139 ms (kafka.log.Log)
[2019-01-25 11:26:23,721] INFO [Partition tools8-1 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-25 11:26:23,727] INFO [Partition mytools-0 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-25 11:26:23,733] INFO [Partition tools12-0 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-25 11:26:23,735] INFO [Partition tools1-2 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-25 11:26:23,738] INFO [Partition edited6-1 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-25 11:26:23,743] INFO [Partition tools5-2 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-25 11:26:23,744] INFO [Log partition=aggregated_data-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:23,745] INFO [Log partition=aggregated_data-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:23,761] INFO [Log partition=aggregated_data-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:23,764] INFO [Log partition=aggregated_data-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2019-01-25 11:26:23,779] WARN [Log partition=alltools-0, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\alltools-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\alltools-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547977751460}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:23,780] INFO [Log partition=alltools-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:23,791] INFO [ProducerStateManager partition=alltools-0] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:23,794] INFO [Log partition=alltools-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:23,795] INFO [Log partition=alltools-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:23,808] INFO [ProducerStateManager partition=alltools-0] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:23,816] INFO [Log partition=alltools-0, dir=C:\tmp\logs2] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:23,818] INFO [ProducerStateManager partition=alltools-0] Loading producer state from snapshot file 'C:\tmp\logs2\alltools-0\00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:23,820] INFO [Log partition=alltools-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 47 ms (kafka.log.Log)
[2019-01-25 11:26:23,835] WARN [Log partition=alltools-1, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\alltools-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\alltools-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547979859855}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:23,836] INFO [Log partition=alltools-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:23,847] INFO [ProducerStateManager partition=alltools-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:23,848] INFO [Log partition=alltools-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:23,849] INFO [Log partition=alltools-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:23,858] INFO [ProducerStateManager partition=alltools-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:23,868] INFO [Log partition=alltools-1, dir=C:\tmp\logs2] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:23,872] INFO [ProducerStateManager partition=alltools-1] Loading producer state from snapshot file 'C:\tmp\logs2\alltools-1\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:23,876] INFO [Log partition=alltools-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 43 ms (kafka.log.Log)
[2019-01-25 11:26:23,890] WARN [Log partition=edited-1, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\edited-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\edited-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996876577}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:23,891] INFO [Log partition=edited-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:23,898] INFO [ProducerStateManager partition=edited-1] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:23,899] INFO [Log partition=edited-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:23,900] INFO [Log partition=edited-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:23,911] INFO [ProducerStateManager partition=edited-1] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:23,919] INFO [Log partition=edited-1, dir=C:\tmp\logs2] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:23,921] INFO [ProducerStateManager partition=edited-1] Loading producer state from snapshot file 'C:\tmp\logs2\edited-1\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:23,923] INFO [Log partition=edited-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 9 in 36 ms (kafka.log.Log)
[2019-01-25 11:26:23,937] WARN [Log partition=edited-2, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\edited-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\edited-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996875547}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:23,937] INFO [Log partition=edited-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:23,944] INFO [ProducerStateManager partition=edited-2] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:23,946] INFO [Log partition=edited-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:23,948] INFO [Log partition=edited-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:23,957] INFO [ProducerStateManager partition=edited-2] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:23,972] INFO [Log partition=edited-2, dir=C:\tmp\logs2] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:23,977] INFO [ProducerStateManager partition=edited-2] Loading producer state from snapshot file 'C:\tmp\logs2\edited-2\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:23,980] INFO [Log partition=edited-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 45 ms (kafka.log.Log)
[2019-01-25 11:26:23,996] INFO [Log partition=edited10-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:23,996] INFO [Log partition=edited10-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,006] INFO [Log partition=edited10-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,010] INFO [Log partition=edited10-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-01-25 11:26:24,019] INFO [Log partition=edited10-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:24,019] INFO [Log partition=edited10-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,025] INFO [ProducerStateManager partition=edited10-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,035] INFO [Log partition=edited10-2, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,038] INFO [ProducerStateManager partition=edited10-2] Loading producer state from snapshot file 'C:\tmp\logs2\edited10-2\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,045] INFO [Log partition=edited10-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 28 ms (kafka.log.Log)
[2019-01-25 11:26:24,054] INFO [Log partition=edited12-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:24,056] INFO [Log partition=edited12-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,065] INFO [ProducerStateManager partition=edited12-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,073] INFO [Log partition=edited12-0, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,076] INFO [ProducerStateManager partition=edited12-0] Loading producer state from snapshot file 'C:\tmp\logs2\edited12-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,077] INFO [Log partition=edited12-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 26 ms (kafka.log.Log)
[2019-01-25 11:26:24,084] INFO [Log partition=edited12-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:24,085] INFO [Log partition=edited12-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,093] INFO [Log partition=edited12-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,096] INFO [Log partition=edited12-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-01-25 11:26:24,107] WARN [Log partition=edited6-1, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\edited6-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\edited6-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548321919981}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:24,108] INFO [Log partition=edited6-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,114] INFO [ProducerStateManager partition=edited6-1] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,116] INFO [Log partition=edited6-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:24,116] INFO [Log partition=edited6-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,128] INFO [ProducerStateManager partition=edited6-1] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,136] INFO [Log partition=edited6-1, dir=C:\tmp\logs2] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,139] INFO [ProducerStateManager partition=edited6-1] Loading producer state from snapshot file 'C:\tmp\logs2\edited6-1\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,142] INFO [Log partition=edited6-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 40 ms (kafka.log.Log)
[2019-01-25 11:26:24,151] WARN [Log partition=edited6-2, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\edited6-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\edited6-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548176773646}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:24,152] INFO [Log partition=edited6-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,157] INFO [ProducerStateManager partition=edited6-2] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,163] INFO [Log partition=edited6-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:24,164] INFO [Log partition=edited6-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,176] INFO [ProducerStateManager partition=edited6-2] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,188] INFO [Log partition=edited6-2, dir=C:\tmp\logs2] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,192] INFO [ProducerStateManager partition=edited6-2] Loading producer state from snapshot file 'C:\tmp\logs2\edited6-2\00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,197] INFO [Log partition=edited6-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 49 ms (kafka.log.Log)
[2019-01-25 11:26:24,208] WARN [Log partition=edited8-0, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\edited8-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\edited8-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548341369651}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:24,209] INFO [Log partition=edited8-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,216] INFO [ProducerStateManager partition=edited8-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,218] INFO [Log partition=edited8-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:24,220] INFO [Log partition=edited8-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,230] INFO [ProducerStateManager partition=edited8-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,242] INFO [Log partition=edited8-0, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,244] INFO [ProducerStateManager partition=edited8-0] Loading producer state from snapshot file 'C:\tmp\logs2\edited8-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,245] INFO [Log partition=edited8-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 42 ms (kafka.log.Log)
[2019-01-25 11:26:24,257] INFO [Log partition=edited8-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:24,258] INFO [Log partition=edited8-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,265] INFO [Log partition=edited8-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,267] INFO [Log partition=edited8-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-01-25 11:26:24,278] INFO [Log partition=my-example-topic-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:24,278] INFO [Log partition=my-example-topic-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,292] INFO [Log partition=my-example-topic-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,295] INFO [Log partition=my-example-topic-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-01-25 11:26:24,303] WARN [Log partition=mytools-0, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\mytools-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\mytools-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547991919170}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:24,304] INFO [Log partition=mytools-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,311] INFO [ProducerStateManager partition=mytools-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,314] INFO [Log partition=mytools-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:24,315] INFO [Log partition=mytools-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,321] INFO [ProducerStateManager partition=mytools-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,331] INFO [Log partition=mytools-0, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,332] INFO [ProducerStateManager partition=mytools-0] Loading producer state from snapshot file 'C:\tmp\logs2\mytools-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,333] INFO [Log partition=mytools-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 33 ms (kafka.log.Log)
[2019-01-25 11:26:24,346] INFO [Log partition=mytools-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:24,346] INFO [Log partition=mytools-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,357] INFO [Log partition=mytools-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,360] INFO [Log partition=mytools-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-01-25 11:26:24,367] WARN [Log partition=tools-0, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547991352625}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:24,367] INFO [Log partition=tools-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,373] INFO [ProducerStateManager partition=tools-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,378] INFO [Log partition=tools-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:24,378] INFO [Log partition=tools-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,387] INFO [ProducerStateManager partition=tools-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,397] INFO [Log partition=tools-0, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,399] INFO [ProducerStateManager partition=tools-0] Loading producer state from snapshot file 'C:\tmp\logs2\tools-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,400] INFO [Log partition=tools-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 35 ms (kafka.log.Log)
[2019-01-25 11:26:24,412] INFO [Log partition=tools-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:24,413] INFO [Log partition=tools-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,423] INFO [Log partition=tools-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,426] INFO [Log partition=tools-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 11:26:24,434] INFO [Log partition=tools1-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:24,434] INFO [Log partition=tools1-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,445] INFO [Log partition=tools1-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,447] INFO [Log partition=tools1-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 11:26:24,460] INFO [Log partition=tools1-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:24,461] INFO [Log partition=tools1-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,467] INFO [Log partition=tools1-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,469] INFO [Log partition=tools1-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-25 11:26:24,478] INFO [Log partition=tools10-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:24,478] INFO [Log partition=tools10-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,489] INFO [Log partition=tools10-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,492] INFO [Log partition=tools10-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-01-25 11:26:24,500] INFO [Log partition=tools10-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:24,501] INFO [Log partition=tools10-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,506] INFO [ProducerStateManager partition=tools10-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,518] INFO [Log partition=tools10-1, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,521] INFO [ProducerStateManager partition=tools10-1] Loading producer state from snapshot file 'C:\tmp\logs2\tools10-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,523] INFO [Log partition=tools10-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 25 ms (kafka.log.Log)
[2019-01-25 11:26:24,534] INFO [Log partition=tools11-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:24,534] INFO [Log partition=tools11-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,540] INFO [Log partition=tools11-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,545] INFO [Log partition=tools11-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-01-25 11:26:24,552] INFO [Log partition=tools11-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:24,553] INFO [Log partition=tools11-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,559] INFO [ProducerStateManager partition=tools11-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,567] INFO [Log partition=tools11-2, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,570] INFO [ProducerStateManager partition=tools11-2] Loading producer state from snapshot file 'C:\tmp\logs2\tools11-2\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,571] INFO [Log partition=tools11-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 22 ms (kafka.log.Log)
[2019-01-25 11:26:24,579] INFO [Log partition=tools12-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:24,581] INFO [Log partition=tools12-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,585] INFO [ProducerStateManager partition=tools12-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,594] INFO [Log partition=tools12-0, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,596] INFO [ProducerStateManager partition=tools12-0] Loading producer state from snapshot file 'C:\tmp\logs2\tools12-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,596] INFO [Log partition=tools12-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 21 ms (kafka.log.Log)
[2019-01-25 11:26:24,608] INFO [Log partition=tools12-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:24,609] INFO [Log partition=tools12-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,619] INFO [Log partition=tools12-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,622] INFO [Log partition=tools12-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-01-25 11:26:24,631] INFO [Log partition=tools2-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:24,632] INFO [Log partition=tools2-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,637] INFO [Log partition=tools2-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,641] INFO [Log partition=tools2-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-01-25 11:26:24,647] WARN [Log partition=tools2-1, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools2-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools2-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547992951029}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:24,648] INFO [Log partition=tools2-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,653] INFO [ProducerStateManager partition=tools2-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,654] INFO [Log partition=tools2-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:24,655] INFO [Log partition=tools2-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,665] INFO [ProducerStateManager partition=tools2-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,678] INFO [Log partition=tools2-1, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,680] INFO [ProducerStateManager partition=tools2-1] Loading producer state from snapshot file 'C:\tmp\logs2\tools2-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,681] INFO [Log partition=tools2-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 37 ms (kafka.log.Log)
[2019-01-25 11:26:24,695] INFO [Log partition=tools3-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:24,696] INFO [Log partition=tools3-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,704] INFO [Log partition=tools3-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,707] INFO [Log partition=tools3-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-01-25 11:26:24,715] WARN [Log partition=tools3-1, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools3-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools3-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547993388462}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:24,715] INFO [Log partition=tools3-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,719] INFO [ProducerStateManager partition=tools3-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,721] INFO [Log partition=tools3-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:24,726] INFO [Log partition=tools3-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,734] INFO [ProducerStateManager partition=tools3-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,745] INFO [Log partition=tools3-1, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,748] INFO [ProducerStateManager partition=tools3-1] Loading producer state from snapshot file 'C:\tmp\logs2\tools3-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,750] INFO [Log partition=tools3-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 39 ms (kafka.log.Log)
[2019-01-25 11:26:24,765] INFO [Log partition=tools4-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:24,765] INFO [Log partition=tools4-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,769] INFO [Log partition=tools4-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,772] INFO [Log partition=tools4-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-01-25 11:26:24,781] WARN [Log partition=tools4-2, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools4-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools4-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547993897061}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:24,781] INFO [Log partition=tools4-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,787] INFO [ProducerStateManager partition=tools4-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,789] INFO [Log partition=tools4-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:24,792] INFO [Log partition=tools4-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,799] INFO [ProducerStateManager partition=tools4-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,812] INFO [Log partition=tools4-2, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,814] INFO [ProducerStateManager partition=tools4-2] Loading producer state from snapshot file 'C:\tmp\logs2\tools4-2\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,815] INFO [Log partition=tools4-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 39 ms (kafka.log.Log)
[2019-01-25 11:26:24,827] WARN [Log partition=tools5-0, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools5-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools5-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996871342}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:24,827] INFO [Log partition=tools5-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,838] INFO [ProducerStateManager partition=tools5-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,840] INFO [Log partition=tools5-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:24,843] INFO [Log partition=tools5-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,849] INFO [ProducerStateManager partition=tools5-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,863] INFO [Log partition=tools5-0, dir=C:\tmp\logs2] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,865] INFO [ProducerStateManager partition=tools5-0] Loading producer state from snapshot file 'C:\tmp\logs2\tools5-0\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,867] INFO [Log partition=tools5-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 42 ms (kafka.log.Log)
[2019-01-25 11:26:24,877] WARN [Log partition=tools5-2, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools5-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools5-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996835000}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:24,878] INFO [Log partition=tools5-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,884] INFO [ProducerStateManager partition=tools5-2] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,887] INFO [Log partition=tools5-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:24,888] INFO [Log partition=tools5-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,900] INFO [ProducerStateManager partition=tools5-2] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,911] INFO [Log partition=tools5-2, dir=C:\tmp\logs2] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,913] INFO [ProducerStateManager partition=tools5-2] Loading producer state from snapshot file 'C:\tmp\logs2\tools5-2\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,914] INFO [Log partition=tools5-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 39 ms (kafka.log.Log)
[2019-01-25 11:26:24,925] WARN [Log partition=tools6-0, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools6-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools6-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548176773646}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:24,928] INFO [Log partition=tools6-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,933] INFO [ProducerStateManager partition=tools6-0] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,935] INFO [Log partition=tools6-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:24,935] INFO [Log partition=tools6-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,946] INFO [ProducerStateManager partition=tools6-0] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,953] INFO [Log partition=tools6-0, dir=C:\tmp\logs2] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,957] INFO [ProducerStateManager partition=tools6-0] Loading producer state from snapshot file 'C:\tmp\logs2\tools6-0\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,962] INFO [Log partition=tools6-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 41 ms (kafka.log.Log)
[2019-01-25 11:26:24,968] WARN [Log partition=tools6-1, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools6-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools6-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548321919981}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:24,968] INFO [Log partition=tools6-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,973] INFO [ProducerStateManager partition=tools6-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,977] INFO [Log partition=tools6-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:24,979] INFO [Log partition=tools6-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,985] INFO [ProducerStateManager partition=tools6-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,995] INFO [Log partition=tools6-1, dir=C:\tmp\logs2] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:24,997] INFO [ProducerStateManager partition=tools6-1] Loading producer state from snapshot file 'C:\tmp\logs2\tools6-1\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:24,998] INFO [Log partition=tools6-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 32 ms (kafka.log.Log)
[2019-01-25 11:26:25,013] WARN [Log partition=tools7-0, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools7-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools7-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548173477306}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:25,014] INFO [Log partition=tools7-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,018] INFO [ProducerStateManager partition=tools7-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,020] INFO [Log partition=tools7-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:25,020] INFO [Log partition=tools7-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,032] INFO [ProducerStateManager partition=tools7-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,040] INFO [Log partition=tools7-0, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,045] INFO [ProducerStateManager partition=tools7-0] Loading producer state from snapshot file 'C:\tmp\logs2\tools7-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,046] INFO [Log partition=tools7-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 37 ms (kafka.log.Log)
[2019-01-25 11:26:25,056] INFO [Log partition=tools7-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:25,057] INFO [Log partition=tools7-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,070] INFO [Log partition=tools7-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,073] INFO [Log partition=tools7-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-01-25 11:26:25,083] WARN [Log partition=tools8-1, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools8-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools8-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548341369651}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:25,083] INFO [Log partition=tools8-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,089] INFO [ProducerStateManager partition=tools8-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,094] INFO [Log partition=tools8-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:25,094] INFO [Log partition=tools8-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,105] INFO [ProducerStateManager partition=tools8-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,113] INFO [Log partition=tools8-1, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,115] INFO [ProducerStateManager partition=tools8-1] Loading producer state from snapshot file 'C:\tmp\logs2\tools8-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,116] INFO [Log partition=tools8-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 36 ms (kafka.log.Log)
[2019-01-25 11:26:25,128] INFO [Log partition=tools8-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:25,128] INFO [Log partition=tools8-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,139] INFO [Log partition=tools8-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,142] INFO [Log partition=tools8-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-01-25 11:26:25,150] WARN [Log partition=__consumer_offsets-1, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\__consumer_offsets-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\__consumer_offsets-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548362705403}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:25,150] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,156] INFO [ProducerStateManager partition=__consumer_offsets-1] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,161] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:25,162] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,175] INFO [ProducerStateManager partition=__consumer_offsets-1] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,186] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\logs2] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,188] INFO [ProducerStateManager partition=__consumer_offsets-1] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-1\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,189] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 41 ms (kafka.log.Log)
[2019-01-25 11:26:25,201] WARN [Log partition=__consumer_offsets-10, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\__consumer_offsets-10\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\__consumer_offsets-10\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547979865822}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:25,202] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,210] INFO [ProducerStateManager partition=__consumer_offsets-10] Writing producer snapshot at offset 43 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,211] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:25,211] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,223] INFO [ProducerStateManager partition=__consumer_offsets-10] Writing producer snapshot at offset 43 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,233] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\logs2] Loading producer state till offset 43 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,235] INFO [ProducerStateManager partition=__consumer_offsets-10] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-10\00000000000000000043.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,236] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 43 in 39 ms (kafka.log.Log)
[2019-01-25 11:26:25,248] WARN [Log partition=__consumer_offsets-13, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\__consumer_offsets-13\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\__consumer_offsets-13\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548333787424}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:25,248] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,258] INFO [ProducerStateManager partition=__consumer_offsets-13] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,261] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:25,262] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,272] INFO [ProducerStateManager partition=__consumer_offsets-13] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,285] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\logs2] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,287] INFO [ProducerStateManager partition=__consumer_offsets-13] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-13\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,288] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 43 ms (kafka.log.Log)
[2019-01-25 11:26:25,299] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:25,300] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,311] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,313] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 11:26:25,321] WARN [Log partition=__consumer_offsets-19, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\__consumer_offsets-19\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\__consumer_offsets-19\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548155030377}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:25,322] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,331] INFO [ProducerStateManager partition=__consumer_offsets-19] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,332] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:25,333] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,344] INFO [ProducerStateManager partition=__consumer_offsets-19] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,354] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\logs2] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,356] INFO [ProducerStateManager partition=__consumer_offsets-19] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-19\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,361] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 43 ms (kafka.log.Log)
[2019-01-25 11:26:25,371] WARN [Log partition=__consumer_offsets-22, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\__consumer_offsets-22\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\__consumer_offsets-22\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548322401427}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:25,372] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,381] INFO [ProducerStateManager partition=__consumer_offsets-22] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,383] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:25,383] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,392] INFO [ProducerStateManager partition=__consumer_offsets-22] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,407] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\logs2] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,411] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-22\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,414] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 46 ms (kafka.log.Log)
[2019-01-25 11:26:25,426] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:25,427] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,437] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,439] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-01-25 11:26:25,450] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:25,451] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,463] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,465] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-01-25 11:26:25,478] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:25,479] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,482] INFO [ProducerStateManager partition=__consumer_offsets-31] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,489] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\logs2] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,492] INFO [ProducerStateManager partition=__consumer_offsets-31] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-31\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,495] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 25 ms (kafka.log.Log)
[2019-01-25 11:26:25,505] WARN [Log partition=__consumer_offsets-34, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\__consumer_offsets-34\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\__consumer_offsets-34\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548082054556}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:25,507] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,515] INFO [ProducerStateManager partition=__consumer_offsets-34] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,516] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:25,517] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,525] INFO [ProducerStateManager partition=__consumer_offsets-34] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,537] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\logs2] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,539] INFO [ProducerStateManager partition=__consumer_offsets-34] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-34\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,546] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 45 ms (kafka.log.Log)
[2019-01-25 11:26:25,553] WARN [Log partition=__consumer_offsets-37, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\__consumer_offsets-37\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\__consumer_offsets-37\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548173625567}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:25,553] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,558] INFO [ProducerStateManager partition=__consumer_offsets-37] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,560] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:25,564] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,568] INFO [ProducerStateManager partition=__consumer_offsets-37] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,582] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\logs2] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,583] INFO [ProducerStateManager partition=__consumer_offsets-37] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-37\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,584] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 34 ms (kafka.log.Log)
[2019-01-25 11:26:25,596] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:25,596] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,606] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,609] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-25 11:26:25,616] WARN [Log partition=__consumer_offsets-40, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\__consumer_offsets-40\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\__consumer_offsets-40\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547994301596}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:25,617] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,622] INFO [ProducerStateManager partition=__consumer_offsets-40] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,626] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:25,628] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,634] INFO [ProducerStateManager partition=__consumer_offsets-40] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,645] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\logs2] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,647] INFO [ProducerStateManager partition=__consumer_offsets-40] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-40\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,647] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 33 ms (kafka.log.Log)
[2019-01-25 11:26:25,652] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:25,653] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,662] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,664] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-01-25 11:26:25,671] WARN [Log partition=__consumer_offsets-46, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\__consumer_offsets-46\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\__consumer_offsets-46\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547993701594}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:25,675] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,679] INFO [ProducerStateManager partition=__consumer_offsets-46] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,682] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:25,682] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,690] INFO [ProducerStateManager partition=__consumer_offsets-46] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,701] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\logs2] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,703] INFO [ProducerStateManager partition=__consumer_offsets-46] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-46\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,704] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 36 ms (kafka.log.Log)
[2019-01-25 11:26:25,715] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:25,715] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,725] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,727] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-25 11:26:25,734] WARN [Log partition=__consumer_offsets-7, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\__consumer_offsets-7\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\__consumer_offsets-7\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548333787424}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:25,736] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,745] INFO [ProducerStateManager partition=__consumer_offsets-7] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,747] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:25,748] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,758] INFO [ProducerStateManager partition=__consumer_offsets-7] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,769] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\logs2] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:25,771] INFO [ProducerStateManager partition=__consumer_offsets-7] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-7\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:25,772] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 40 ms (kafka.log.Log)
[2019-01-25 11:26:25,782] INFO Logs loading complete in 2245 ms. (kafka.log.LogManager)
[2019-01-25 11:26:25,797] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-25 11:26:25,799] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-25 11:26:26,027] INFO Awaiting socket connections on localhost:9094. (kafka.network.Acceptor)
[2019-01-25 11:26:26,061] INFO [SocketServer brokerId=2] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-25 11:26:26,093] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-25 11:26:26,093] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-25 11:26:26,102] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-25 11:26:26,113] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-25 11:26:26,172] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-25 11:26:26,177] INFO Result of znode creation at /brokers/ids/2 is: OK (kafka.zk.KafkaZkClient)
[2019-01-25 11:26:26,181] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(localhost,9094,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-25 11:26:26,267] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-25 11:26:26,277] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-25 11:26:26,278] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-25 11:26:26,318] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:26:26,325] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:26:26,332] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:26,352] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:31000,blockEndProducerId:31999) by writing to Zk with path version 32 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-25 11:26:26,383] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-25 11:26:26,386] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-25 11:26:26,386] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-25 11:26:26,433] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-25 11:26:26,481] INFO [SocketServer brokerId=2] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-25 11:26:26,489] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-25 11:26:26,490] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-25 11:26:26,492] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2019-01-25 11:26:26,574] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-7, __consumer_offsets-46, aggregated_data-1, __consumer_offsets-25, tools1-0, tools11-0, __consumer_offsets-49, tools12-1, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-37, edited10-0, mytools-1, edited8-0, my-example-topic-0, edited-2, tools4-2, tools3-1, __consumer_offsets-19, tools6-1, __consumer_offsets-13, __consumer_offsets-43, tools5-0, edited6-2, tools-1, edited12-0, tools2-1, tools10-1, alltools-1, tools8-2, tools7-1, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:26:26,593] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 43 (kafka.cluster.Replica)
[2019-01-25 11:26:26,598] INFO [Partition __consumer_offsets-10 broker=2] __consumer_offsets-10 starts at Leader Epoch 17 from offset 43. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:26,617] INFO Replica loaded for partition edited8-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 11:26:26,618] INFO Replica loaded for partition edited8-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:26,622] INFO [Partition edited8-0 broker=2] edited8-0 starts at Leader Epoch 3 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:26,646] INFO Replica loaded for partition alltools-1 with initial high watermark 6 (kafka.cluster.Replica)
[2019-01-25 11:26:26,646] INFO Replica loaded for partition alltools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:26,647] INFO [Partition alltools-1 broker=2] alltools-1 starts at Leader Epoch 26 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:26,658] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 6 (kafka.cluster.Replica)
[2019-01-25 11:26:26,659] INFO [Partition __consumer_offsets-7 broker=2] __consumer_offsets-7 starts at Leader Epoch 17 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:26,668] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:26,669] INFO [Partition __consumer_offsets-4 broker=2] __consumer_offsets-4 starts at Leader Epoch 17 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:26,681] INFO Replica loaded for partition edited-2 with initial high watermark 8 (kafka.cluster.Replica)
[2019-01-25 11:26:26,682] INFO Replica loaded for partition edited-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:26,682] INFO [Partition edited-2 broker=2] edited-2 starts at Leader Epoch 23 from offset 8. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:26,697] INFO Replica loaded for partition mytools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:26,698] INFO Replica loaded for partition mytools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:26,698] INFO [Partition mytools-1 broker=2] mytools-1 starts at Leader Epoch 23 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:26,713] INFO Replica loaded for partition tools10-1 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 11:26:26,713] INFO Replica loaded for partition tools10-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:26,714] INFO [Partition tools10-1 broker=2] tools10-1 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:26,730] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-25 11:26:26,731] INFO [Partition __consumer_offsets-1 broker=2] __consumer_offsets-1 starts at Leader Epoch 17 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:26,741] INFO Replica loaded for partition tools6-1 with initial high watermark 6 (kafka.cluster.Replica)
[2019-01-25 11:26:26,742] INFO Replica loaded for partition tools6-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:26,744] INFO [Partition tools6-1 broker=2] tools6-1 starts at Leader Epoch 20 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:26,757] INFO Replica loaded for partition tools5-0 with initial high watermark 10 (kafka.cluster.Replica)
[2019-01-25 11:26:26,759] INFO Replica loaded for partition tools5-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:26,759] INFO [Partition tools5-0 broker=2] tools5-0 starts at Leader Epoch 23 from offset 10. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:26,770] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:26,771] INFO [Partition __consumer_offsets-49 broker=2] __consumer_offsets-49 starts at Leader Epoch 17 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:26,783] INFO Replica loaded for partition edited6-2 with initial high watermark 4 (kafka.cluster.Replica)
[2019-01-25 11:26:26,783] INFO Replica loaded for partition edited6-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:26,784] INFO [Partition edited6-2 broker=2] edited6-2 starts at Leader Epoch 16 from offset 4. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:26,799] INFO Replica loaded for partition tools11-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:26,799] INFO Replica loaded for partition tools11-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:26,800] INFO [Partition tools11-0 broker=2] tools11-0 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:26,809] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-25 11:26:26,811] INFO [Partition __consumer_offsets-46 broker=2] __consumer_offsets-46 starts at Leader Epoch 17 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:26,816] INFO Replica loaded for partition tools3-1 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 11:26:26,817] INFO Replica loaded for partition tools3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:26,817] INFO [Partition tools3-1 broker=2] tools3-1 starts at Leader Epoch 23 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:26,832] INFO Replica loaded for partition tools12-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:26,833] INFO Replica loaded for partition tools12-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:26,833] INFO [Partition tools12-1 broker=2] tools12-1 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:26,845] INFO Replica loaded for partition tools4-2 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 11:26:26,845] INFO Replica loaded for partition tools4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:26,846] INFO [Partition tools4-2 broker=2] tools4-2 starts at Leader Epoch 23 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:26,859] INFO Replica loaded for partition edited10-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:26,859] INFO Replica loaded for partition edited10-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:26,860] INFO [Partition edited10-0 broker=2] edited10-0 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:26,873] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:26,874] INFO [Partition __consumer_offsets-43 broker=2] __consumer_offsets-43 starts at Leader Epoch 17 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:26,883] INFO Replica loaded for partition my-example-topic-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:26,883] INFO [Partition my-example-topic-0 broker=2] my-example-topic-0 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:26,893] INFO Replica loaded for partition tools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:26,894] INFO Replica loaded for partition tools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:26,894] INFO [Partition tools-1 broker=2] tools-1 starts at Leader Epoch 23 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:26,907] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-25 11:26:26,908] INFO [Partition __consumer_offsets-40 broker=2] __consumer_offsets-40 starts at Leader Epoch 17 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:26,917] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 5 (kafka.cluster.Replica)
[2019-01-25 11:26:26,917] INFO [Partition __consumer_offsets-37 broker=2] __consumer_offsets-37 starts at Leader Epoch 17 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:26,927] INFO Replica loaded for partition tools2-1 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 11:26:26,928] INFO Replica loaded for partition tools2-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:26,928] INFO [Partition tools2-1 broker=2] tools2-1 starts at Leader Epoch 23 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:26,944] INFO Replica loaded for partition tools1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:26,945] INFO Replica loaded for partition tools1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:26,946] INFO [Partition tools1-0 broker=2] tools1-0 starts at Leader Epoch 23 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:26,952] INFO Replica loaded for partition aggregated_data-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:26,952] INFO Replica loaded for partition aggregated_data-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:26,953] INFO [Partition aggregated_data-1 broker=2] aggregated_data-1 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:26,966] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 6 (kafka.cluster.Replica)
[2019-01-25 11:26:26,979] INFO [Partition __consumer_offsets-34 broker=2] __consumer_offsets-34 starts at Leader Epoch 17 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:26,990] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-25 11:26:26,991] INFO [Partition __consumer_offsets-31 broker=2] __consumer_offsets-31 starts at Leader Epoch 17 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:26,997] INFO Replica loaded for partition edited12-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 11:26:26,998] INFO Replica loaded for partition edited12-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:27,001] INFO [Partition edited12-0 broker=2] edited12-0 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:27,011] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 7 (kafka.cluster.Replica)
[2019-01-25 11:26:27,012] INFO [Partition __consumer_offsets-19 broker=2] __consumer_offsets-19 starts at Leader Epoch 17 from offset 7. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:27,019] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:27,020] INFO [Partition __consumer_offsets-28 broker=2] __consumer_offsets-28 starts at Leader Epoch 17 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:27,029] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:27,029] INFO [Partition __consumer_offsets-16 broker=2] __consumer_offsets-16 starts at Leader Epoch 17 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:27,036] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:27,036] INFO [Partition __consumer_offsets-25 broker=2] __consumer_offsets-25 starts at Leader Epoch 17 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:27,045] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 5 (kafka.cluster.Replica)
[2019-01-25 11:26:27,046] INFO [Partition __consumer_offsets-22 broker=2] __consumer_offsets-22 starts at Leader Epoch 17 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:27,053] INFO Replica loaded for partition tools7-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:27,054] INFO Replica loaded for partition tools7-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:27,057] INFO [Partition tools7-1 broker=2] tools7-1 starts at Leader Epoch 11 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:27,065] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 6 (kafka.cluster.Replica)
[2019-01-25 11:26:27,065] INFO [Partition __consumer_offsets-13 broker=2] __consumer_offsets-13 starts at Leader Epoch 17 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:27,076] INFO Replica loaded for partition tools8-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:27,077] INFO Replica loaded for partition tools8-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:27,077] INFO [Partition tools8-2 broker=2] tools8-2 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:27,090] INFO Replica loaded for partition edited6-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:27,092] INFO Replica loaded for partition edited6-1 with initial high watermark 7 (kafka.cluster.Replica)
[2019-01-25 11:26:27,094] INFO Replica loaded for partition mytools-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:27,096] INFO Replica loaded for partition mytools-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 11:26:27,096] INFO Replica loaded for partition tools5-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:27,099] INFO Replica loaded for partition tools5-2 with initial high watermark 8 (kafka.cluster.Replica)
[2019-01-25 11:26:27,100] INFO Replica loaded for partition edited10-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:27,105] INFO Replica loaded for partition edited10-2 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 11:26:27,108] INFO Replica loaded for partition tools4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:27,112] INFO Replica loaded for partition tools4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:27,112] INFO Replica loaded for partition tools3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:27,119] INFO Replica loaded for partition tools3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:27,119] INFO Replica loaded for partition tools-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:27,125] INFO Replica loaded for partition tools-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 11:26:27,130] INFO Replica loaded for partition tools6-0 with initial high watermark 5 (kafka.cluster.Replica)
[2019-01-25 11:26:27,131] INFO Replica loaded for partition tools6-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:27,136] INFO Replica loaded for partition tools11-2 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 11:26:27,136] INFO Replica loaded for partition tools11-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:27,143] INFO Replica loaded for partition tools12-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:27,146] INFO Replica loaded for partition tools12-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 11:26:27,147] INFO Replica loaded for partition aggregated_data-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:27,151] INFO Replica loaded for partition aggregated_data-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 11:26:27,154] INFO Replica loaded for partition tools1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:27,158] INFO Replica loaded for partition tools1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:27,160] INFO Replica loaded for partition tools2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:27,164] INFO Replica loaded for partition tools2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:27,166] INFO Replica loaded for partition edited12-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:27,170] INFO Replica loaded for partition edited12-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:27,172] INFO Replica loaded for partition edited8-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:27,179] INFO Replica loaded for partition edited8-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:27,179] INFO Replica loaded for partition edited-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:27,184] INFO Replica loaded for partition edited-1 with initial high watermark 9 (kafka.cluster.Replica)
[2019-01-25 11:26:27,191] INFO Replica loaded for partition tools8-1 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 11:26:27,192] INFO Replica loaded for partition tools8-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:27,193] INFO Replica loaded for partition tools7-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:27,200] INFO Replica loaded for partition tools7-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 11:26:27,203] INFO Replica loaded for partition tools10-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:27,204] INFO Replica loaded for partition tools10-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:27,210] INFO Replica loaded for partition alltools-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:27,213] INFO Replica loaded for partition alltools-0 with initial high watermark 4 (kafka.cluster.Replica)
[2019-01-25 11:26:27,215] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(alltools-0, tools7-0, edited8-2, tools10-0, mytools-0, edited10-2, tools5-2, tools2-0, tools12-0, edited12-2, tools8-1, tools3-0, aggregated_data-0, edited6-1, tools1-2, tools11-2, tools4-1, tools-0, edited-1, tools6-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:26:27,250] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:26:27,257] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(edited8-2 -> (offset=0, leaderEpoch=2), tools7-0 -> (offset=1, leaderEpoch=3), tools8-1 -> (offset=1, leaderEpoch=1), tools3-0 -> (offset=0, leaderEpoch=6), tools4-1 -> (offset=0, leaderEpoch=6), tools5-2 -> (offset=8, leaderEpoch=6), tools1-2 -> (offset=0, leaderEpoch=6), edited-1 -> (offset=9, leaderEpoch=6), mytools-0 -> (offset=1, leaderEpoch=6), edited12-2 -> (offset=0, leaderEpoch=0), tools10-0 -> (offset=0, leaderEpoch=1), alltools-0 -> (offset=4, leaderEpoch=7), aggregated_data-0 -> (offset=1, leaderEpoch=0), tools-0 -> (offset=1, leaderEpoch=6), edited10-2 -> (offset=1, leaderEpoch=0), tools11-2 -> (offset=1, leaderEpoch=1), edited6-1 -> (offset=7, leaderEpoch=3), tools6-0 -> (offset=5, leaderEpoch=7), tools12-0 -> (offset=1, leaderEpoch=0), tools2-0 -> (offset=0, leaderEpoch=6)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:26:27,271] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:27,275] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:27,278] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:27,285] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:27,293] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:27,296] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:27,298] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:27,301] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:27,301] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:27,311] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:27,314] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:27,315] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:27,321] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:27,322] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:27,326] INFO [Log partition=edited10-2, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 11:26:27,328] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:27,332] INFO [Log partition=edited-1, dir=C:\tmp\logs2] Truncating to 9 has no effect as the largest offset in the log is 8 (kafka.log.Log)
[2019-01-25 11:26:27,335] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:27,335] INFO [Log partition=mytools-0, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 11:26:27,336] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:27,346] INFO [Log partition=tools-0, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 11:26:27,348] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in edited12-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:26:27,348] INFO [Log partition=edited12-2, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:26:27,349] INFO [Log partition=alltools-0, dir=C:\tmp\logs2] Truncating to 4 has no effect as the largest offset in the log is 3 (kafka.log.Log)
[2019-01-25 11:26:27,350] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools10-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:26:27,351] INFO [Log partition=tools10-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:26:27,352] INFO [Log partition=tools11-2, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 11:26:27,363] INFO [Log partition=tools12-0, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 11:26:27,363] INFO [Log partition=aggregated_data-0, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 11:26:27,364] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools1-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:26:27,365] INFO [Log partition=tools1-2, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:26:27,366] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in edited8-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:26:27,367] INFO [Log partition=edited8-2, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:26:27,368] INFO [Log partition=edited6-1, dir=C:\tmp\logs2] Truncating to 7 has no effect as the largest offset in the log is 6 (kafka.log.Log)
[2019-01-25 11:26:27,368] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools2-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:26:27,369] INFO [Log partition=tools2-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:26:27,370] INFO [Log partition=tools5-2, dir=C:\tmp\logs2] Truncating to 8 has no effect as the largest offset in the log is 7 (kafka.log.Log)
[2019-01-25 11:26:27,371] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools3-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:26:27,376] INFO [Log partition=tools3-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:26:27,380] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-22 in 104 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:27,381] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools4-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:26:27,382] INFO [Log partition=tools4-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:26:27,383] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:27,383] INFO [Log partition=tools6-0, dir=C:\tmp\logs2] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.Log)
[2019-01-25 11:26:27,384] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:27,384] INFO [Log partition=tools7-0, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 11:26:27,392] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:27,393] INFO [Log partition=tools8-1, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 11:26:27,398] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-7, __consumer_offsets-46, aggregated_data-1, __consumer_offsets-25, tools1-0, tools11-0, __consumer_offsets-49, tools12-1, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-37, edited10-0, mytools-1, edited8-0, my-example-topic-0, edited-2, tools4-2, tools3-1, __consumer_offsets-19, tools6-1, __consumer_offsets-13, __consumer_offsets-43, tools5-0, edited6-2, tools-1, edited12-0, tools2-1, tools10-1, alltools-1, tools8-2, tools7-1, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:26:27,398] INFO [Partition __consumer_offsets-10 broker=2] __consumer_offsets-10 starts at Leader Epoch 18 from offset 43. Previous Leader Epoch was: 17 (kafka.cluster.Partition)
[2019-01-25 11:26:27,399] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-34 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:27,408] INFO [Partition edited8-0 broker=2] edited8-0 starts at Leader Epoch 4 from offset 1. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-25 11:26:27,409] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 9 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:27,411] WARN [LeaderEpochCache edited8-0] New epoch entry EpochEntry(epoch=4, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:26:27,416] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-40 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:27,416] INFO [Partition alltools-1 broker=2] alltools-1 starts at Leader Epoch 27 from offset 6. Previous Leader Epoch was: 26 (kafka.cluster.Partition)
[2019-01-25 11:26:27,416] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:27,417] WARN [LeaderEpochCache alltools-1] New epoch entry EpochEntry(epoch=27, startOffset=6) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=26, startOffset=6)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:26:27,427] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-46 in 10 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:27,427] INFO [Partition __consumer_offsets-7 broker=2] __consumer_offsets-7 starts at Leader Epoch 18 from offset 6. Previous Leader Epoch was: 17 (kafka.cluster.Partition)
[2019-01-25 11:26:27,429] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:27,430] WARN [LeaderEpochCache __consumer_offsets-7] New epoch entry EpochEntry(epoch=18, startOffset=6) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=17, startOffset=6)). Cache now contains 4 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:26:27,435] INFO [Partition __consumer_offsets-4 broker=2] __consumer_offsets-4 starts at Leader Epoch 18 from offset 0. Previous Leader Epoch was: 17 (kafka.cluster.Partition)
[2019-01-25 11:26:27,435] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:27,435] WARN [LeaderEpochCache __consumer_offsets-4] New epoch entry EpochEntry(epoch=18, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=17, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:26:27,436] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:27,441] INFO [Partition edited-2 broker=2] edited-2 starts at Leader Epoch 24 from offset 8. Previous Leader Epoch was: 23 (kafka.cluster.Partition)
[2019-01-25 11:26:27,449] WARN [LeaderEpochCache edited-2] New epoch entry EpochEntry(epoch=24, startOffset=8) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=23, startOffset=8)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:26:27,452] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 9 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:27,459] INFO [Partition tools10-1 broker=2] tools10-1 starts at Leader Epoch 2 from offset 1. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-25 11:26:27,463] WARN [LeaderEpochCache tools10-1] New epoch entry EpochEntry(epoch=2, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:26:27,467] INFO [Partition mytools-1 broker=2] mytools-1 starts at Leader Epoch 24 from offset 0. Previous Leader Epoch was: 23 (kafka.cluster.Partition)
[2019-01-25 11:26:27,468] WARN [LeaderEpochCache mytools-1] New epoch entry EpochEntry(epoch=24, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=23, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:26:27,476] INFO [Partition __consumer_offsets-1 broker=2] __consumer_offsets-1 starts at Leader Epoch 18 from offset 3. Previous Leader Epoch was: 17 (kafka.cluster.Partition)
[2019-01-25 11:26:27,477] WARN [LeaderEpochCache __consumer_offsets-1] New epoch entry EpochEntry(epoch=18, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=17, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:26:27,484] INFO [Partition edited8-2 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-25 11:26:27,485] INFO [GroupCoordinator 2]: Loading group metadata for KafkaExampleConsumer with generation 4 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:26:27,491] INFO [Partition tools6-1 broker=2] tools6-1 starts at Leader Epoch 21 from offset 6. Previous Leader Epoch was: 20 (kafka.cluster.Partition)
[2019-01-25 11:26:27,495] INFO [Partition tools7-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-25 11:26:27,495] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-10 in 34 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:27,495] WARN [LeaderEpochCache tools6-1] New epoch entry EpochEntry(epoch=21, startOffset=6) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=20, startOffset=6)). Cache now contains 5 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:26:27,498] INFO [Partition tools8-1 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-25 11:26:27,502] INFO [Partition tools3-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-25 11:26:27,501] INFO [Partition tools5-0 broker=2] tools5-0 starts at Leader Epoch 24 from offset 10. Previous Leader Epoch was: 23 (kafka.cluster.Partition)
[2019-01-25 11:26:27,502] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:27,511] WARN [LeaderEpochCache tools5-0] New epoch entry EpochEntry(epoch=24, startOffset=10) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=23, startOffset=10)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:26:27,512] INFO [Partition tools4-1 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-25 11:26:27,512] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-16 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:27,516] INFO [Partition tools5-2 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-25 11:26:27,519] INFO [Partition tools1-2 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-25 11:26:27,518] INFO [Partition __consumer_offsets-49 broker=2] __consumer_offsets-49 starts at Leader Epoch 18 from offset 0. Previous Leader Epoch was: 17 (kafka.cluster.Partition)
[2019-01-25 11:26:27,521] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:27,528] INFO [Partition edited-1 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-25 11:26:27,527] WARN [LeaderEpochCache __consumer_offsets-49] New epoch entry EpochEntry(epoch=18, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=17, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:26:27,531] INFO [Partition mytools-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-25 11:26:27,533] INFO [Partition edited6-2 broker=2] edited6-2 starts at Leader Epoch 17 from offset 4. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-25 11:26:27,533] INFO [Partition edited12-2 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-25 11:26:27,533] WARN [LeaderEpochCache edited6-2] New epoch entry EpochEntry(epoch=17, startOffset=4) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=16, startOffset=4)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:26:27,538] INFO [Partition tools10-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-25 11:26:27,543] INFO [Partition tools11-0 broker=2] tools11-0 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-25 11:26:27,545] WARN [LeaderEpochCache tools11-0] New epoch entry EpochEntry(epoch=2, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:26:27,546] INFO [Partition alltools-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-25 11:26:27,549] INFO [Partition tools12-1 broker=2] tools12-1 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-25 11:26:27,550] INFO [Partition aggregated_data-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-25 11:26:27,550] WARN [LeaderEpochCache tools12-1] New epoch entry EpochEntry(epoch=2, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:26:27,552] INFO [Partition tools-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-25 11:26:27,557] INFO [Partition edited10-2 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-25 11:26:27,558] INFO [Partition __consumer_offsets-46 broker=2] __consumer_offsets-46 starts at Leader Epoch 18 from offset 3. Previous Leader Epoch was: 17 (kafka.cluster.Partition)
[2019-01-25 11:26:27,561] INFO [Partition tools11-2 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-25 11:26:27,559] WARN [LeaderEpochCache __consumer_offsets-46] New epoch entry EpochEntry(epoch=18, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=17, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:26:27,566] INFO [Partition edited6-1 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-25 11:26:27,569] INFO [Partition tools6-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-25 11:26:27,569] INFO [Partition tools3-1 broker=2] tools3-1 starts at Leader Epoch 24 from offset 1. Previous Leader Epoch was: 23 (kafka.cluster.Partition)
[2019-01-25 11:26:27,574] INFO [Partition tools12-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-25 11:26:27,571] WARN [LeaderEpochCache tools3-1] New epoch entry EpochEntry(epoch=24, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=23, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:26:27,579] INFO [Partition tools2-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-25 11:26:27,582] INFO [Partition tools4-2 broker=2] tools4-2 starts at Leader Epoch 24 from offset 1. Previous Leader Epoch was: 23 (kafka.cluster.Partition)
[2019-01-25 11:26:27,582] WARN [LeaderEpochCache tools4-2] New epoch entry EpochEntry(epoch=24, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=23, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:26:27,590] INFO [Partition edited10-0 broker=2] edited10-0 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-25 11:26:27,594] WARN [LeaderEpochCache edited10-0] New epoch entry EpochEntry(epoch=2, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:26:27,600] INFO [Partition __consumer_offsets-43 broker=2] __consumer_offsets-43 starts at Leader Epoch 18 from offset 0. Previous Leader Epoch was: 17 (kafka.cluster.Partition)
[2019-01-25 11:26:27,601] WARN [LeaderEpochCache __consumer_offsets-43] New epoch entry EpochEntry(epoch=18, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=17, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:26:27,608] INFO [Partition my-example-topic-0 broker=2] my-example-topic-0 starts at Leader Epoch 16 from offset 0. Previous Leader Epoch was: 15 (kafka.cluster.Partition)
[2019-01-25 11:26:27,609] WARN [LeaderEpochCache my-example-topic-0] New epoch entry EpochEntry(epoch=16, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=15, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:26:27,618] INFO [Partition tools-1 broker=2] tools-1 starts at Leader Epoch 24 from offset 0. Previous Leader Epoch was: 23 (kafka.cluster.Partition)
[2019-01-25 11:26:27,619] WARN [LeaderEpochCache tools-1] New epoch entry EpochEntry(epoch=24, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=23, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:26:27,627] INFO [Partition __consumer_offsets-40 broker=2] __consumer_offsets-40 starts at Leader Epoch 18 from offset 3. Previous Leader Epoch was: 17 (kafka.cluster.Partition)
[2019-01-25 11:26:27,627] WARN [LeaderEpochCache __consumer_offsets-40] New epoch entry EpochEntry(epoch=18, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=17, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:26:27,635] INFO [Partition __consumer_offsets-37 broker=2] __consumer_offsets-37 starts at Leader Epoch 18 from offset 5. Previous Leader Epoch was: 17 (kafka.cluster.Partition)
[2019-01-25 11:26:27,636] WARN [LeaderEpochCache __consumer_offsets-37] New epoch entry EpochEntry(epoch=18, startOffset=5) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=17, startOffset=5)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:26:27,643] INFO [Partition tools2-1 broker=2] tools2-1 starts at Leader Epoch 24 from offset 1. Previous Leader Epoch was: 23 (kafka.cluster.Partition)
[2019-01-25 11:26:27,644] WARN [LeaderEpochCache tools2-1] New epoch entry EpochEntry(epoch=24, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=23, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:26:27,651] INFO [Partition tools1-0 broker=2] tools1-0 starts at Leader Epoch 24 from offset 0. Previous Leader Epoch was: 23 (kafka.cluster.Partition)
[2019-01-25 11:26:27,654] WARN [LeaderEpochCache tools1-0] New epoch entry EpochEntry(epoch=24, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=23, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:26:27,665] INFO [Partition aggregated_data-1 broker=2] aggregated_data-1 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-25 11:26:27,665] WARN [LeaderEpochCache aggregated_data-1] New epoch entry EpochEntry(epoch=2, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:26:27,673] INFO [Partition __consumer_offsets-34 broker=2] __consumer_offsets-34 starts at Leader Epoch 18 from offset 6. Previous Leader Epoch was: 17 (kafka.cluster.Partition)
[2019-01-25 11:26:27,676] WARN [LeaderEpochCache __consumer_offsets-34] New epoch entry EpochEntry(epoch=18, startOffset=6) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=17, startOffset=6)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:26:27,683] INFO [Partition __consumer_offsets-31 broker=2] __consumer_offsets-31 starts at Leader Epoch 18 from offset 3. Previous Leader Epoch was: 17 (kafka.cluster.Partition)
[2019-01-25 11:26:27,688] INFO [Partition edited12-0 broker=2] edited12-0 starts at Leader Epoch 2 from offset 1. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-25 11:26:27,693] WARN [LeaderEpochCache edited12-0] New epoch entry EpochEntry(epoch=2, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:26:27,698] INFO [Partition __consumer_offsets-19 broker=2] __consumer_offsets-19 starts at Leader Epoch 18 from offset 7. Previous Leader Epoch was: 17 (kafka.cluster.Partition)
[2019-01-25 11:26:27,698] WARN [LeaderEpochCache __consumer_offsets-19] New epoch entry EpochEntry(epoch=18, startOffset=7) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=17, startOffset=7)). Cache now contains 5 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:26:27,704] INFO [Partition __consumer_offsets-28 broker=2] __consumer_offsets-28 starts at Leader Epoch 18 from offset 0. Previous Leader Epoch was: 17 (kafka.cluster.Partition)
[2019-01-25 11:26:27,710] WARN [LeaderEpochCache __consumer_offsets-28] New epoch entry EpochEntry(epoch=18, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=17, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:26:27,715] INFO [Partition __consumer_offsets-16 broker=2] __consumer_offsets-16 starts at Leader Epoch 18 from offset 0. Previous Leader Epoch was: 17 (kafka.cluster.Partition)
[2019-01-25 11:26:27,715] WARN [LeaderEpochCache __consumer_offsets-16] New epoch entry EpochEntry(epoch=18, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=17, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:26:27,720] INFO [Partition __consumer_offsets-25 broker=2] __consumer_offsets-25 starts at Leader Epoch 18 from offset 0. Previous Leader Epoch was: 17 (kafka.cluster.Partition)
[2019-01-25 11:26:27,722] WARN [LeaderEpochCache __consumer_offsets-25] New epoch entry EpochEntry(epoch=18, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=17, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:26:27,731] INFO [Partition __consumer_offsets-22 broker=2] __consumer_offsets-22 starts at Leader Epoch 18 from offset 5. Previous Leader Epoch was: 17 (kafka.cluster.Partition)
[2019-01-25 11:26:27,731] WARN [LeaderEpochCache __consumer_offsets-22] New epoch entry EpochEntry(epoch=18, startOffset=5) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=17, startOffset=5)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:26:27,737] INFO [Partition tools7-1 broker=2] tools7-1 starts at Leader Epoch 12 from offset 0. Previous Leader Epoch was: 11 (kafka.cluster.Partition)
[2019-01-25 11:26:27,738] WARN [LeaderEpochCache tools7-1] New epoch entry EpochEntry(epoch=12, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=11, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:26:27,745] INFO [Partition __consumer_offsets-13 broker=2] __consumer_offsets-13 starts at Leader Epoch 18 from offset 6. Previous Leader Epoch was: 17 (kafka.cluster.Partition)
[2019-01-25 11:26:27,745] WARN [LeaderEpochCache __consumer_offsets-13] New epoch entry EpochEntry(epoch=18, startOffset=6) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=17, startOffset=6)). Cache now contains 5 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:26:27,755] INFO [Partition tools8-2 broker=2] tools8-2 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-01-25 11:26:27,756] WARN [LeaderEpochCache tools8-2] New epoch entry EpochEntry(epoch=6, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 11:26:38,996] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-25 11:26:39,523] INFO starting (kafka.server.KafkaServer)
[2019-01-25 11:26:39,524] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-25 11:26:39,542] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-25 11:26:44,797] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:44,798] INFO Client environment:host.name=ITdif (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:44,798] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:44,798] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:44,799] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:44,799] INFO Client environment:java.class.path=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-connect-jdbc-5.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\mysql-connector-java-5.1.42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:44,800] INFO Client environment:java.library.path=C:\Program Files\Java\jre1.8.0_181\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Docker\Docker\Resources\bin;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\Scripts\;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\dotnet\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\NoteBook FanControl\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\extras\CUPTI\libx64;C:\tools\cuda\bin;C:\Program Files\PuTTY\;C:\Program Files\Calibre2\;C:\apache-maven-3.6.\bin;C:\Users\Stefano\Downloads\platform-tools_r28.0.1-windows\platform-tools;C:\Program Files\Java\jre1.8.0_181\bin;C:\Users\Stefano\AppData\Local\Programs\Python\Launcher\;C:\Users\Stefano\AppData\Local\Microsoft\WindowsApps;C:\Users\Stefano\AppData\Local\GitHubDesktop\bin;C:\apache-maven-3.6.0\bin;;. (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:44,800] INFO Client environment:java.io.tmpdir=C:\Users\Stefano\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:44,801] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:44,801] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:44,801] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:44,801] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:44,801] INFO Client environment:user.name=Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:44,802] INFO Client environment:user.home=C:\Users\Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:44,802] INFO Client environment:user.dir=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:44,803] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@1622f1b (org.apache.zookeeper.ZooKeeper)
[2019-01-25 11:26:44,823] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-25 11:26:44,824] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-25 11:26:44,828] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:53876 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-25 11:26:44,828] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-25 11:26:44,832] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:53876 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:26:44,835] INFO Established session 0x10003b9f7140002 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:53876 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:26:44,839] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10003b9f7140002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-25 11:26:44,845] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-25 11:26:44,891] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140002 type:create cxid:0x1 zxid:0xb79 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:44,903] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140002 type:create cxid:0x2 zxid:0xb7a txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:44,910] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140002 type:create cxid:0x3 zxid:0xb7b txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:44,913] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140002 type:create cxid:0x4 zxid:0xb7c txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:44,916] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140002 type:create cxid:0x5 zxid:0xb7d txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:44,921] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140002 type:create cxid:0x6 zxid:0xb7e txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:44,923] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140002 type:create cxid:0x7 zxid:0xb7f txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:44,926] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140002 type:create cxid:0x8 zxid:0xb80 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:44,928] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140002 type:create cxid:0x9 zxid:0xb81 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:44,930] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140002 type:create cxid:0xa zxid:0xb82 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:44,933] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140002 type:create cxid:0xb zxid:0xb83 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:44,935] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140002 type:create cxid:0xc zxid:0xb84 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:44,938] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140002 type:create cxid:0xd zxid:0xb85 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:26:45,073] INFO Cluster ID = RvEiz9fYQgKWcHR6fHb3dg (kafka.server.KafkaServer)
[2019-01-25 11:26:45,159] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-25 11:26:45,171] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-25 11:26:45,207] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-25 11:26:45,207] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-25 11:26:45,211] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-25 11:26:45,269] INFO Loading logs. (kafka.log.LogManager)
[2019-01-25 11:26:45,337] INFO [Log partition=aggregated_data-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:45,340] INFO [Log partition=aggregated_data-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,381] INFO [Log partition=aggregated_data-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,387] INFO [Log partition=aggregated_data-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 78 ms (kafka.log.Log)
[2019-01-25 11:26:45,405] INFO [Log partition=aggregated_data-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:45,405] INFO [Log partition=aggregated_data-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,422] INFO [Log partition=aggregated_data-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,424] INFO [Log partition=aggregated_data-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-01-25 11:26:45,435] WARN [Log partition=alltools-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\alltools-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\alltools-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547979859855}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:45,437] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,454] INFO [ProducerStateManager partition=alltools-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:45,458] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:45,459] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,469] INFO [ProducerStateManager partition=alltools-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:45,488] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,491] INFO [ProducerStateManager partition=alltools-1] Loading producer state from snapshot file 'C:\tmp\logs3\alltools-1\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:45,506] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 76 ms (kafka.log.Log)
[2019-01-25 11:26:45,519] WARN [Log partition=alltools-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\alltools-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\alltools-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547977368170}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:45,520] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,525] INFO [ProducerStateManager partition=alltools-2] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:45,526] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:45,527] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,537] INFO [ProducerStateManager partition=alltools-2] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:45,547] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,550] INFO [ProducerStateManager partition=alltools-2] Loading producer state from snapshot file 'C:\tmp\logs3\alltools-2\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:45,554] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 39 ms (kafka.log.Log)
[2019-01-25 11:26:45,564] WARN [Log partition=edited-0, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\edited-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\edited-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996878625}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:45,565] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,573] INFO [ProducerStateManager partition=edited-0] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:45,575] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:45,575] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,582] INFO [ProducerStateManager partition=edited-0] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:45,595] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,598] INFO [ProducerStateManager partition=edited-0] Loading producer state from snapshot file 'C:\tmp\logs3\edited-0\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:45,603] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 42 ms (kafka.log.Log)
[2019-01-25 11:26:45,620] WARN [Log partition=edited-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\edited-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\edited-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996875547}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:45,620] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,625] INFO [ProducerStateManager partition=edited-2] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:45,626] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:45,627] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,637] INFO [ProducerStateManager partition=edited-2] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:45,645] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,648] INFO [ProducerStateManager partition=edited-2] Loading producer state from snapshot file 'C:\tmp\logs3\edited-2\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:45,649] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 33 ms (kafka.log.Log)
[2019-01-25 11:26:45,661] INFO [Log partition=edited10-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:45,662] INFO [Log partition=edited10-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,668] INFO [Log partition=edited10-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,673] INFO [Log partition=edited10-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-01-25 11:26:45,687] INFO [Log partition=edited10-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:45,688] INFO [Log partition=edited10-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,697] INFO [Log partition=edited10-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,699] INFO [Log partition=edited10-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-01-25 11:26:45,710] INFO [Log partition=edited11-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:45,711] INFO [Log partition=edited11-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,720] INFO [Log partition=edited11-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,723] INFO [Log partition=edited11-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-25 11:26:45,732] INFO [Log partition=edited12-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:45,733] INFO [Log partition=edited12-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,740] INFO [ProducerStateManager partition=edited12-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:45,749] INFO [Log partition=edited12-0, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,752] INFO [ProducerStateManager partition=edited12-0] Loading producer state from snapshot file 'C:\tmp\logs3\edited12-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:45,753] INFO [Log partition=edited12-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 25 ms (kafka.log.Log)
[2019-01-25 11:26:45,765] INFO [Log partition=edited12-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:45,766] INFO [Log partition=edited12-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,782] INFO [Log partition=edited12-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,786] INFO [Log partition=edited12-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-01-25 11:26:45,800] WARN [Log partition=edited6-0, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\edited6-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\edited6-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548158302054}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:45,802] INFO [Log partition=edited6-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,810] INFO [ProducerStateManager partition=edited6-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:45,813] INFO [Log partition=edited6-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:45,814] INFO [Log partition=edited6-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,825] INFO [ProducerStateManager partition=edited6-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:45,838] INFO [Log partition=edited6-0, dir=C:\tmp\logs3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,840] INFO [ProducerStateManager partition=edited6-0] Loading producer state from snapshot file 'C:\tmp\logs3\edited6-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:45,841] INFO [Log partition=edited6-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 46 ms (kafka.log.Log)
[2019-01-25 11:26:45,856] WARN [Log partition=edited6-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\edited6-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\edited6-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548176773646}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:45,857] INFO [Log partition=edited6-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,862] INFO [ProducerStateManager partition=edited6-2] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:45,863] INFO [Log partition=edited6-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:45,864] INFO [Log partition=edited6-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,876] INFO [ProducerStateManager partition=edited6-2] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:45,885] INFO [Log partition=edited6-2, dir=C:\tmp\logs3] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,888] INFO [ProducerStateManager partition=edited6-2] Loading producer state from snapshot file 'C:\tmp\logs3\edited6-2\00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:45,890] INFO [Log partition=edited6-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 38 ms (kafka.log.Log)
[2019-01-25 11:26:45,900] WARN [Log partition=edited8-0, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\edited8-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\edited8-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548341369651}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:45,901] INFO [Log partition=edited8-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,909] INFO [ProducerStateManager partition=edited8-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:45,910] INFO [Log partition=edited8-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:45,911] INFO [Log partition=edited8-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,921] INFO [ProducerStateManager partition=edited8-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:45,927] INFO [Log partition=edited8-0, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,929] INFO [ProducerStateManager partition=edited8-0] Loading producer state from snapshot file 'C:\tmp\logs3\edited8-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:45,932] INFO [Log partition=edited8-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 36 ms (kafka.log.Log)
[2019-01-25 11:26:45,944] INFO [Log partition=edited8-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:45,945] INFO [Log partition=edited8-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,955] INFO [Log partition=edited8-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,957] INFO [Log partition=edited8-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-25 11:26:45,968] INFO [Log partition=edited9-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:45,969] INFO [Log partition=edited9-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,979] INFO [Log partition=edited9-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,982] INFO [Log partition=edited9-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-01-25 11:26:45,991] INFO [Log partition=mytools-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:45,992] INFO [Log partition=mytools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:45,996] INFO [Log partition=mytools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,001] INFO [Log partition=mytools-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-01-25 11:26:46,008] INFO [Log partition=mytools-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:46,008] INFO [Log partition=mytools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,019] INFO [Log partition=mytools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,022] INFO [Log partition=mytools-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-01-25 11:26:46,029] INFO [Log partition=tools-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:46,030] INFO [Log partition=tools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,035] INFO [Log partition=tools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,037] INFO [Log partition=tools-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-01-25 11:26:46,046] INFO [Log partition=tools-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:46,047] INFO [Log partition=tools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,061] INFO [Log partition=tools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,063] INFO [Log partition=tools-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-01-25 11:26:46,074] INFO [Log partition=tools1-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:46,077] INFO [Log partition=tools1-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,085] INFO [Log partition=tools1-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,086] INFO [Log partition=tools1-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-25 11:26:46,094] INFO [Log partition=tools1-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:46,095] INFO [Log partition=tools1-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,105] INFO [Log partition=tools1-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,107] INFO [Log partition=tools1-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 11:26:46,119] INFO [Log partition=tools10-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:46,120] INFO [Log partition=tools10-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,133] INFO [ProducerStateManager partition=tools10-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:46,145] INFO [Log partition=tools10-1, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,147] INFO [ProducerStateManager partition=tools10-1] Loading producer state from snapshot file 'C:\tmp\logs3\tools10-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:46,148] INFO [Log partition=tools10-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 34 ms (kafka.log.Log)
[2019-01-25 11:26:46,159] INFO [Log partition=tools10-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:46,160] INFO [Log partition=tools10-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,167] INFO [Log partition=tools10-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,169] INFO [Log partition=tools10-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-01-25 11:26:46,176] INFO [Log partition=tools11-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:46,178] INFO [Log partition=tools11-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,189] INFO [Log partition=tools11-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,191] INFO [Log partition=tools11-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-01-25 11:26:46,202] INFO [Log partition=tools11-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:46,203] INFO [Log partition=tools11-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,208] INFO [Log partition=tools11-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,210] INFO [Log partition=tools11-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-01-25 11:26:46,220] INFO [Log partition=tools12-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:46,222] INFO [Log partition=tools12-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,226] INFO [Log partition=tools12-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,229] INFO [Log partition=tools12-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-01-25 11:26:46,241] INFO [Log partition=tools12-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:46,242] INFO [Log partition=tools12-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,256] INFO [Log partition=tools12-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,258] INFO [Log partition=tools12-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-01-25 11:26:46,265] WARN [Log partition=tools2-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools2-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools2-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547992951029}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:46,267] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,272] INFO [ProducerStateManager partition=tools2-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:46,274] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:46,276] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,281] INFO [ProducerStateManager partition=tools2-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:46,289] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,292] INFO [ProducerStateManager partition=tools2-1] Loading producer state from snapshot file 'C:\tmp\logs3\tools2-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:46,292] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 31 ms (kafka.log.Log)
[2019-01-25 11:26:46,303] INFO [Log partition=tools2-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:46,303] INFO [Log partition=tools2-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,315] INFO [Log partition=tools2-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,318] INFO [Log partition=tools2-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-01-25 11:26:46,327] WARN [Log partition=tools3-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools3-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools3-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547993388462}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:46,327] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,332] INFO [ProducerStateManager partition=tools3-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:46,337] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:46,338] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,344] INFO [ProducerStateManager partition=tools3-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:46,353] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,356] INFO [ProducerStateManager partition=tools3-1] Loading producer state from snapshot file 'C:\tmp\logs3\tools3-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:46,357] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 34 ms (kafka.log.Log)
[2019-01-25 11:26:46,362] INFO [Log partition=tools3-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:46,363] INFO [Log partition=tools3-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,373] INFO [Log partition=tools3-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,375] INFO [Log partition=tools3-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 11:26:46,385] INFO [Log partition=tools4-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:46,386] INFO [Log partition=tools4-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,395] INFO [Log partition=tools4-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,397] INFO [Log partition=tools4-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-01-25 11:26:46,405] WARN [Log partition=tools4-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools4-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools4-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547993897061}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:46,405] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,410] INFO [ProducerStateManager partition=tools4-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:46,412] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:46,413] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,419] INFO [ProducerStateManager partition=tools4-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:46,429] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,430] INFO [ProducerStateManager partition=tools4-2] Loading producer state from snapshot file 'C:\tmp\logs3\tools4-2\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:46,432] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 31 ms (kafka.log.Log)
[2019-01-25 11:26:46,443] WARN [Log partition=tools5-0, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools5-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools5-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996871342}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:46,443] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,455] INFO [ProducerStateManager partition=tools5-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:46,456] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:46,457] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,468] INFO [ProducerStateManager partition=tools5-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:46,477] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,478] INFO [ProducerStateManager partition=tools5-0] Loading producer state from snapshot file 'C:\tmp\logs3\tools5-0\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:46,479] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 38 ms (kafka.log.Log)
[2019-01-25 11:26:46,491] WARN [Log partition=tools5-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools5-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools5-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996876577}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:46,492] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,500] INFO [ProducerStateManager partition=tools5-1] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:46,503] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:46,504] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,512] INFO [ProducerStateManager partition=tools5-1] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:46,524] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,526] INFO [ProducerStateManager partition=tools5-1] Loading producer state from snapshot file 'C:\tmp\logs3\tools5-1\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:46,527] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 39 ms (kafka.log.Log)
[2019-01-25 11:26:46,539] WARN [Log partition=tools6-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools6-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools6-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548321919981}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:46,540] INFO [Log partition=tools6-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,545] INFO [ProducerStateManager partition=tools6-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:46,546] INFO [Log partition=tools6-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:46,547] INFO [Log partition=tools6-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,558] INFO [ProducerStateManager partition=tools6-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:46,571] INFO [Log partition=tools6-1, dir=C:\tmp\logs3] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,573] INFO [ProducerStateManager partition=tools6-1] Loading producer state from snapshot file 'C:\tmp\logs3\tools6-1\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:46,574] INFO [Log partition=tools6-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 38 ms (kafka.log.Log)
[2019-01-25 11:26:46,585] WARN [Log partition=tools6-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools6-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools6-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548158302054}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:46,588] INFO [Log partition=tools6-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,592] INFO [ProducerStateManager partition=tools6-2] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:46,593] INFO [Log partition=tools6-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:46,594] INFO [Log partition=tools6-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,605] INFO [ProducerStateManager partition=tools6-2] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:46,612] INFO [Log partition=tools6-2, dir=C:\tmp\logs3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,617] INFO [ProducerStateManager partition=tools6-2] Loading producer state from snapshot file 'C:\tmp\logs3\tools6-2\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:46,621] INFO [Log partition=tools6-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 40 ms (kafka.log.Log)
[2019-01-25 11:26:46,627] INFO [Log partition=tools7-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:46,628] INFO [Log partition=tools7-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,633] INFO [Log partition=tools7-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,637] INFO [Log partition=tools7-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2019-01-25 11:26:46,644] WARN [Log partition=tools7-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools7-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools7-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548156023437}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:46,644] INFO [Log partition=tools7-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,650] INFO [ProducerStateManager partition=tools7-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:46,653] INFO [Log partition=tools7-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:46,654] INFO [Log partition=tools7-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,659] INFO [ProducerStateManager partition=tools7-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:46,672] INFO [Log partition=tools7-2, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,673] INFO [ProducerStateManager partition=tools7-2] Loading producer state from snapshot file 'C:\tmp\logs3\tools7-2\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:46,674] INFO [Log partition=tools7-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 33 ms (kafka.log.Log)
[2019-01-25 11:26:46,688] INFO [Log partition=tools8-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:46,688] INFO [Log partition=tools8-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,693] INFO [Log partition=tools8-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,695] INFO [Log partition=tools8-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2019-01-25 11:26:46,704] INFO [Log partition=tools8-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:46,705] INFO [Log partition=tools8-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,717] INFO [Log partition=tools8-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,720] INFO [Log partition=tools8-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-01-25 11:26:46,726] WARN [Log partition=__consumer_offsets-11, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\__consumer_offsets-11\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\__consumer_offsets-11\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548354913655}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:46,728] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,736] INFO [ProducerStateManager partition=__consumer_offsets-11] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:46,738] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:46,740] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,751] INFO [ProducerStateManager partition=__consumer_offsets-11] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:46,766] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs3] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,770] INFO [ProducerStateManager partition=__consumer_offsets-11] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-11\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:46,771] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 47 ms (kafka.log.Log)
[2019-01-25 11:26:46,778] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:46,779] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,791] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,794] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-01-25 11:26:46,804] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:46,805] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,815] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,818] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-01-25 11:26:46,827] WARN [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547989834290}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:46,827] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,849] INFO [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 151 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:46,853] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:46,856] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,876] INFO [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 151 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:46,885] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Loading producer state till offset 151 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,888] INFO [ProducerStateManager partition=__consumer_offsets-2] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-2\00000000000000000151.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:46,889] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 151 in 64 ms (kafka.log.Log)
[2019-01-25 11:26:46,896] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:46,896] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,903] INFO [ProducerStateManager partition=__consumer_offsets-20] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:46,912] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,914] INFO [ProducerStateManager partition=__consumer_offsets-20] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-20\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:46,916] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 22 ms (kafka.log.Log)
[2019-01-25 11:26:46,929] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:46,930] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,939] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,941] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-01-25 11:26:46,953] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:46,954] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,962] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,965] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-01-25 11:26:46,975] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:46,975] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,989] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:46,991] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-01-25 11:26:47,001] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:47,001] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:47,008] INFO [ProducerStateManager partition=__consumer_offsets-32] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:47,015] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\logs3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:47,017] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-32\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:47,020] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 24 ms (kafka.log.Log)
[2019-01-25 11:26:47,030] WARN [Log partition=__consumer_offsets-35, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\__consumer_offsets-35\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\__consumer_offsets-35\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548327517176}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:47,031] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:47,041] INFO [ProducerStateManager partition=__consumer_offsets-35] Writing producer snapshot at offset 69 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:47,043] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:47,045] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:47,056] INFO [ProducerStateManager partition=__consumer_offsets-35] Writing producer snapshot at offset 69 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:47,064] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs3] Loading producer state till offset 69 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:47,067] INFO [ProducerStateManager partition=__consumer_offsets-35] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-35\00000000000000000069.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:47,068] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 69 in 41 ms (kafka.log.Log)
[2019-01-25 11:26:47,075] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:47,076] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:47,089] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:47,091] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-01-25 11:26:47,100] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:47,101] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:47,114] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:47,117] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-01-25 11:26:47,126] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:47,126] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:47,137] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:47,138] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-25 11:26:47,145] WARN [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\__consumer_offsets-47\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\__consumer_offsets-47\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547992512270}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-25 11:26:47,147] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:47,158] INFO [ProducerStateManager partition=__consumer_offsets-47] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:47,159] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:47,160] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:47,170] INFO [ProducerStateManager partition=__consumer_offsets-47] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:47,181] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:47,183] INFO [ProducerStateManager partition=__consumer_offsets-47] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-47\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:47,188] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 46 ms (kafka.log.Log)
[2019-01-25 11:26:47,193] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:47,193] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:47,203] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:47,205] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-01-25 11:26:47,212] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-25 11:26:47,213] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:47,223] INFO [ProducerStateManager partition=__consumer_offsets-8] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-25 11:26:47,231] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\logs3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-25 11:26:47,235] INFO [ProducerStateManager partition=__consumer_offsets-8] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-8\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-25 11:26:47,235] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 27 ms (kafka.log.Log)
[2019-01-25 11:26:47,240] INFO Logs loading complete in 1970 ms. (kafka.log.LogManager)
[2019-01-25 11:26:47,256] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-25 11:26:47,258] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-25 11:26:47,498] INFO Awaiting socket connections on localhost:9095. (kafka.network.Acceptor)
[2019-01-25 11:26:47,534] INFO [SocketServer brokerId=3] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-25 11:26:47,562] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-25 11:26:47,572] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-25 11:26:47,572] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-25 11:26:47,588] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-25 11:26:47,648] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-25 11:26:47,653] INFO Result of znode creation at /brokers/ids/3 is: OK (kafka.zk.KafkaZkClient)
[2019-01-25 11:26:47,657] INFO Registered broker 3 at path /brokers/ids/3 with addresses: ArrayBuffer(EndPoint(localhost,9095,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-25 11:26:47,731] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-25 11:26:47,736] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-25 11:26:47,741] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-25 11:26:47,763] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:26:47,767] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:26:47,774] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:47,792] INFO [ProducerId Manager 3]: Acquired new producerId block (brokerId:3,blockStartProducerId:32000,blockEndProducerId:32999) by writing to Zk with path version 33 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-25 11:26:47,820] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-25 11:26:47,822] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-25 11:26:47,829] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-25 11:26:47,871] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-25 11:26:47,916] INFO [SocketServer brokerId=3] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-25 11:26:47,923] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-25 11:26:47,924] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-25 11:26:47,928] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2019-01-25 11:26:48,026] INFO Replica loaded for partition tools2-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,027] INFO Replica loaded for partition tools2-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,036] INFO Replica loaded for partition tools1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,036] INFO Replica loaded for partition tools1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,046] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,063] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,063] INFO Replica loaded for partition alltools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,079] INFO Replica loaded for partition alltools-1 with initial high watermark 6 (kafka.cluster.Replica)
[2019-01-25 11:26:48,079] INFO Replica loaded for partition edited8-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,084] INFO Replica loaded for partition edited8-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 11:26:48,092] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,097] INFO Replica loaded for partition edited12-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,098] INFO Replica loaded for partition edited12-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,101] INFO Replica loaded for partition edited-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,107] INFO Replica loaded for partition edited-2 with initial high watermark 8 (kafka.cluster.Replica)
[2019-01-25 11:26:48,111] INFO Replica loaded for partition edited11-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,117] INFO Replica loaded for partition tools10-1 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 11:26:48,119] INFO Replica loaded for partition tools10-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,122] INFO Replica loaded for partition mytools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,124] INFO Replica loaded for partition mytools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,128] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 11:26:48,134] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,139] INFO Replica loaded for partition tools7-2 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 11:26:48,140] INFO Replica loaded for partition tools7-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,146] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,152] INFO Replica loaded for partition tools6-1 with initial high watermark 6 (kafka.cluster.Replica)
[2019-01-25 11:26:48,152] INFO Replica loaded for partition tools6-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,153] INFO Replica loaded for partition tools5-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,161] INFO Replica loaded for partition tools5-0 with initial high watermark 10 (kafka.cluster.Replica)
[2019-01-25 11:26:48,171] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 5 (kafka.cluster.Replica)
[2019-01-25 11:26:48,171] INFO Replica loaded for partition tools8-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,176] INFO Replica loaded for partition tools8-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,183] INFO Replica loaded for partition edited-0 with initial high watermark 8 (kafka.cluster.Replica)
[2019-01-25 11:26:48,184] INFO Replica loaded for partition edited-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,187] INFO Replica loaded for partition edited6-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,192] INFO Replica loaded for partition edited6-2 with initial high watermark 4 (kafka.cluster.Replica)
[2019-01-25 11:26:48,193] INFO Replica loaded for partition tools3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,198] INFO Replica loaded for partition tools3-1 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 11:26:48,205] INFO Replica loaded for partition tools11-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,205] INFO Replica loaded for partition tools11-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,209] INFO Replica loaded for partition alltools-2 with initial high watermark 5 (kafka.cluster.Replica)
[2019-01-25 11:26:48,210] INFO Replica loaded for partition alltools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,211] INFO Replica loaded for partition tools12-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,221] INFO Replica loaded for partition tools12-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,221] INFO Replica loaded for partition tools4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,228] INFO Replica loaded for partition tools4-2 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 11:26:48,233] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-25 11:26:48,236] INFO Replica loaded for partition edited8-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,237] INFO Replica loaded for partition edited8-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,240] INFO Replica loaded for partition edited10-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,243] INFO Replica loaded for partition edited10-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,249] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,250] INFO Replica loaded for partition tools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,256] INFO Replica loaded for partition tools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,259] INFO Replica loaded for partition mytools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,259] INFO Replica loaded for partition mytools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,263] INFO Replica loaded for partition tools10-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,267] INFO Replica loaded for partition tools10-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,270] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 151 (kafka.cluster.Replica)
[2019-01-25 11:26:48,272] INFO Replica loaded for partition tools2-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,275] INFO Replica loaded for partition tools2-1 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 11:26:48,278] INFO Replica loaded for partition tools3-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,279] INFO Replica loaded for partition tools3-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,286] INFO Replica loaded for partition tools1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,289] INFO Replica loaded for partition tools1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,294] INFO Replica loaded for partition tools4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,294] INFO Replica loaded for partition tools4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,299] INFO Replica loaded for partition aggregated_data-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,303] INFO Replica loaded for partition aggregated_data-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,307] INFO Replica loaded for partition tools5-1 with initial high watermark 5 (kafka.cluster.Replica)
[2019-01-25 11:26:48,307] INFO Replica loaded for partition tools5-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,311] INFO Replica loaded for partition edited9-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,311] INFO Replica loaded for partition tools6-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,315] INFO Replica loaded for partition tools6-2 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-25 11:26:48,320] INFO Replica loaded for partition edited12-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,323] INFO Replica loaded for partition edited12-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-25 11:26:48,328] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-25 11:26:48,334] INFO Replica loaded for partition tools12-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,335] INFO Replica loaded for partition tools12-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,335] INFO Replica loaded for partition tools11-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,343] INFO Replica loaded for partition tools11-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,351] INFO Replica loaded for partition edited6-0 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-25 11:26:48,351] INFO Replica loaded for partition edited6-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,358] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,363] INFO Replica loaded for partition aggregated_data-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,363] INFO Replica loaded for partition aggregated_data-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,368] INFO Replica loaded for partition edited10-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,369] INFO Replica loaded for partition edited10-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,373] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 69 (kafka.cluster.Replica)
[2019-01-25 11:26:48,390] INFO Replica loaded for partition tools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,390] INFO Replica loaded for partition tools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,396] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,402] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,403] INFO Replica loaded for partition tools7-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,406] INFO Replica loaded for partition tools7-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,411] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-25 11:26:48,417] INFO Replica loaded for partition tools8-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,421] INFO Replica loaded for partition tools8-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:26:48,425] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(edited12-0, tools2-2, edited-2, aggregated_data-2, tools12-2, tools3-2, tools5-1, tools4-2, tools6-1, alltools-1, tools-2, tools7-1, tools6-2, edited-0, tools1-1, edited10-0, tools11-1, edited8-0, tools10-2, tools2-1, aggregated_data-1, tools12-1, tools4-0, tools3-1, edited8-1, tools5-0, mytools-2, tools-1, tools8-0, edited6-0, tools1-0, edited12-1, tools11-0, tools10-1, mytools-1, alltools-2, tools7-2, tools8-2, edited10-1, edited6-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:26:48,463] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:26:48,471] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(tools4-0 -> (offset=0, leaderEpoch=25), tools10-2 -> (offset=0, leaderEpoch=1), tools1-1 -> (offset=0, leaderEpoch=25), tools2-2 -> (offset=0, leaderEpoch=25), tools-2 -> (offset=0, leaderEpoch=25), edited6-0 -> (offset=3, leaderEpoch=21), alltools-2 -> (offset=5, leaderEpoch=26), tools8-0 -> (offset=0, leaderEpoch=3), edited8-1 -> (offset=0, leaderEpoch=5), edited10-1 -> (offset=0, leaderEpoch=1), tools5-1 -> (offset=5, leaderEpoch=25), tools6-2 -> (offset=3, leaderEpoch=7), tools11-1 -> (offset=0, leaderEpoch=1), tools12-2 -> (offset=0, leaderEpoch=1), edited12-1 -> (offset=0, leaderEpoch=1), tools7-2 -> (offset=1, leaderEpoch=15), edited-0 -> (offset=8, leaderEpoch=25), tools3-2 -> (offset=0, leaderEpoch=25), aggregated_data-2 -> (offset=0, leaderEpoch=1), mytools-2 -> (offset=0, leaderEpoch=25)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:26:48,477] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(aggregated_data-1 -> (offset=0, leaderEpoch=2), tools1-0 -> (offset=0, leaderEpoch=24), tools11-0 -> (offset=0, leaderEpoch=2), tools12-1 -> (offset=0, leaderEpoch=2), edited10-0 -> (offset=0, leaderEpoch=2), mytools-1 -> (offset=0, leaderEpoch=24), edited8-0 -> (offset=1, leaderEpoch=4), edited-2 -> (offset=8, leaderEpoch=24), tools4-2 -> (offset=1, leaderEpoch=24), tools3-1 -> (offset=1, leaderEpoch=24), tools6-1 -> (offset=6, leaderEpoch=21), tools5-0 -> (offset=10, leaderEpoch=24), edited6-2 -> (offset=4, leaderEpoch=17), tools-1 -> (offset=0, leaderEpoch=24), edited12-0 -> (offset=1, leaderEpoch=2), tools2-1 -> (offset=1, leaderEpoch=24), tools10-1 -> (offset=1, leaderEpoch=2), alltools-1 -> (offset=6, leaderEpoch=27), tools8-2 -> (offset=0, leaderEpoch=6), tools7-1 -> (offset=0, leaderEpoch=12)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:26:48,480] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:26:48,516] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Truncating to 8 has no effect as the largest offset in the log is 7 (kafka.log.Log)
[2019-01-25 11:26:48,517] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Truncating to 8 has no effect as the largest offset in the log is 7 (kafka.log.Log)
[2019-01-25 11:26:48,519] INFO [Log partition=edited8-0, dir=C:\tmp\logs3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 11:26:48,522] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.Log)
[2019-01-25 11:26:48,527] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:26:48,527] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in edited10-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:26:48,534] INFO [Log partition=tools-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:26:48,539] INFO [Log partition=edited10-0, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:26:48,539] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in edited10-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:26:48,540] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:26:48,541] INFO [Log partition=edited10-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:26:48,545] INFO [Log partition=tools-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:26:48,553] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in edited12-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:26:48,553] INFO [Log partition=edited12-0, dir=C:\tmp\logs3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 11:26:48,554] INFO [Log partition=edited12-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:26:48,557] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Truncating to 6 has no effect as the largest offset in the log is 5 (kafka.log.Log)
[2019-01-25 11:26:48,563] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools11-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:26:48,564] INFO [Log partition=tools10-1, dir=C:\tmp\logs3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 11:26:48,566] INFO [Log partition=tools11-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:26:48,567] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 11:26:48,570] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools12-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:26:48,575] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools1-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:26:48,576] INFO [Log partition=tools12-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:26:48,576] INFO [Log partition=tools1-0, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:26:48,577] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in aggregated_data-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:26:48,578] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in aggregated_data-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:26:48,587] INFO [Log partition=aggregated_data-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:26:48,588] INFO [Log partition=aggregated_data-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:26:48,588] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools10-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:26:48,589] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools11-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:26:48,590] INFO [Log partition=tools10-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:26:48,590] INFO [Log partition=tools11-0, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:26:48,591] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools1-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:26:48,591] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools12-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:26:48,592] INFO [Log partition=tools1-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:26:48,593] INFO [Log partition=tools12-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:26:48,593] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools2-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:26:48,602] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in mytools-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:26:48,603] INFO [Log partition=tools2-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:26:48,604] INFO [Log partition=mytools-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:26:48,605] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools3-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:26:48,606] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Truncating to 10 has no effect as the largest offset in the log is 9 (kafka.log.Log)
[2019-01-25 11:26:48,606] INFO [Log partition=tools3-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:26:48,607] INFO [Log partition=tools6-1, dir=C:\tmp\logs3] Truncating to 6 has no effect as the largest offset in the log is 5 (kafka.log.Log)
[2019-01-25 11:26:48,608] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in mytools-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:26:48,608] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 11:26:48,609] INFO [Log partition=mytools-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:26:48,610] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 11:26:48,619] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.Log)
[2019-01-25 11:26:48,620] INFO [Log partition=edited6-2, dir=C:\tmp\logs3] Truncating to 4 has no effect as the largest offset in the log is 3 (kafka.log.Log)
[2019-01-25 11:26:48,621] INFO [Log partition=tools6-2, dir=C:\tmp\logs3] Truncating to 3 has no effect as the largest offset in the log is 2 (kafka.log.Log)
[2019-01-25 11:26:48,621] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools8-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:26:48,622] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools4-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:26:48,625] INFO [Log partition=tools8-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:26:48,630] INFO [Log partition=tools4-0, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:26:48,631] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools7-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:26:48,632] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in edited8-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:26:48,633] INFO [Log partition=tools7-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:26:48,635] INFO [Log partition=edited8-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:26:48,641] INFO [Log partition=edited6-0, dir=C:\tmp\logs3] Truncating to 3 has no effect as the largest offset in the log is 2 (kafka.log.Log)
[2019-01-25 11:26:48,641] INFO [Log partition=tools7-2, dir=C:\tmp\logs3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 11:26:48,642] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools8-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:26:48,643] INFO [Log partition=tools8-0, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:26:48,655] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(__consumer_offsets-8, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-47, __consumer_offsets-38, __consumer_offsets-17, edited11-0, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-14, edited9-0, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-32) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:26:48,659] INFO [Partition tools4-0 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,661] INFO [Partition __consumer_offsets-29 broker=3] __consumer_offsets-29 starts at Leader Epoch 19 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:48,664] INFO [Partition tools10-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,670] INFO [Partition tools1-1 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,674] INFO [Partition tools2-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,677] INFO [Partition tools-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,682] INFO [Partition edited6-0 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,687] INFO [Partition alltools-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,690] INFO [Partition tools8-0 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,692] INFO [Partition __consumer_offsets-26 broker=3] __consumer_offsets-26 starts at Leader Epoch 19 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:48,694] INFO [Partition edited8-1 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,700] INFO [Partition edited10-1 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,701] INFO [Partition __consumer_offsets-23 broker=3] __consumer_offsets-23 starts at Leader Epoch 19 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:48,706] INFO [Partition tools5-1 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,710] INFO [Partition edited11-0 broker=3] edited11-0 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:48,710] INFO [Partition tools6-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,716] INFO [Partition tools11-1 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,721] INFO [Partition __consumer_offsets-20 broker=3] __consumer_offsets-20 starts at Leader Epoch 19 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:48,722] INFO [Partition tools12-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,728] INFO [Partition edited12-1 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,730] INFO [Partition __consumer_offsets-17 broker=3] __consumer_offsets-17 starts at Leader Epoch 19 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:48,733] INFO [Partition tools7-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,737] INFO [Partition __consumer_offsets-14 broker=3] __consumer_offsets-14 starts at Leader Epoch 19 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:48,738] INFO [Partition edited-0 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,750] INFO [Partition tools3-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,751] INFO [Partition __consumer_offsets-11 broker=3] __consumer_offsets-11 starts at Leader Epoch 19 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:48,756] INFO [Partition aggregated_data-1 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,758] INFO [Partition aggregated_data-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,766] INFO [Partition mytools-2 broker=1] Expanding ISR from 1 to 1,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,761] INFO [Partition __consumer_offsets-8 broker=3] __consumer_offsets-8 starts at Leader Epoch 19 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:48,774] INFO [Partition __consumer_offsets-5 broker=3] __consumer_offsets-5 starts at Leader Epoch 19 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:48,781] INFO [Partition __consumer_offsets-2 broker=3] __consumer_offsets-2 starts at Leader Epoch 19 from offset 151. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:48,788] INFO [Partition edited9-0 broker=3] edited9-0 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:48,803] INFO [Partition __consumer_offsets-47 broker=3] __consumer_offsets-47 starts at Leader Epoch 19 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:48,810] INFO [Partition __consumer_offsets-38 broker=3] __consumer_offsets-38 starts at Leader Epoch 19 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:48,822] INFO [Partition __consumer_offsets-35 broker=3] __consumer_offsets-35 starts at Leader Epoch 19 from offset 69. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:48,823] INFO [Partition tools1-0 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,826] INFO [Partition tools11-0 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,828] INFO [Partition __consumer_offsets-44 broker=3] __consumer_offsets-44 starts at Leader Epoch 19 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:48,829] INFO [Partition tools12-1 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,834] INFO [Partition edited10-0 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,834] INFO [Partition __consumer_offsets-32 broker=3] __consumer_offsets-32 starts at Leader Epoch 19 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:48,838] INFO [Partition mytools-1 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,841] INFO [Partition __consumer_offsets-41 broker=3] __consumer_offsets-41 starts at Leader Epoch 19 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:26:48,843] INFO [Partition edited8-0 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,848] INFO [Partition edited-2 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,856] INFO [Partition tools4-2 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,857] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:48,860] INFO [Partition tools3-1 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,859] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:48,865] INFO [Partition tools6-1 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,862] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:48,870] INFO [Partition tools5-0 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,870] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:48,874] INFO [Partition edited6-2 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,874] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:48,879] INFO [Partition tools-1 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,874] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:48,880] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:48,884] INFO [Partition edited12-0 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,883] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:48,888] INFO [Partition tools2-1 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,886] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:48,892] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:48,893] INFO [Partition tools10-1 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,892] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:48,893] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:48,897] INFO [Partition alltools-1 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,894] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:48,902] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:48,904] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:48,905] INFO [Partition tools8-2 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,905] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:48,909] INFO [Partition tools7-1 broker=2] Expanding ISR from 2 to 2,3 (kafka.cluster.Partition)
[2019-01-25 11:26:48,954] INFO [GroupCoordinator 3]: Loading group metadata for alltoolsStream with generation 72 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:26:48,957] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-2 in 98 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:48,959] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-5 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:48,970] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-8 in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:48,976] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-11 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:48,977] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-14 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:48,981] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-17 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:48,991] INFO [GroupCoordinator 3]: Loading group metadata for console-consumer-8229 with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:26:49,000] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-20 in 14 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:49,002] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:49,003] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-26 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:49,007] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:49,012] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-32 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:49,024] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-35 in 11 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:49,024] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:49,025] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:49,032] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-44 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:49,038] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-47 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:26:59,003] INFO [GroupCoordinator 3]: Member consumer-1-be6338b8-ce07-4f97-a924-37d44b902eea in group console-consumer-8229 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:26:59,006] INFO [GroupCoordinator 3]: Preparing to rebalance group console-consumer-8229 in state PreparingRebalance with old generation 1 (__consumer_offsets-20) (reason: removing member consumer-1-be6338b8-ce07-4f97-a924-37d44b902eea on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:26:59,017] INFO [GroupCoordinator 3]: Group console-consumer-8229 with generation 2 is now empty (__consumer_offsets-20) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:27:26,989] INFO Accepted socket connection from /127.0.0.1:53899 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-25 11:27:26,991] INFO Client attempting to establish new session at /127.0.0.1:53899 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:27:26,994] INFO Established session 0x10003b9f7140003 with negotiated timeout 30000 for client /127.0.0.1:53899 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:27:27,248] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140003 type:setData cxid:0x6 zxid:0xbc7 txntype:-1 reqpath:n/a Error Path:/config/topics/tools14 Error:KeeperErrorCode = NoNode for /config/topics/tools14 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:27:27,294] INFO Processed session termination for sessionid: 0x10003b9f7140003 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:27:27,297] INFO Closed socket connection for client /127.0.0.1:53899 which had sessionid 0x10003b9f7140003 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-25 11:27:27,313] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools14-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:27:27,313] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools14-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:27:27,314] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(tools14-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:27:27,320] INFO [Log partition=tools14-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:27:27,321] INFO [Log partition=tools14-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:27:27,321] INFO [Log partition=tools14-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:27:27,323] INFO [Log partition=tools14-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-01-25 11:27:27,323] INFO [Log partition=tools14-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-01-25 11:27:27,323] INFO [Log partition=tools14-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-01-25 11:27:27,325] INFO Created log for partition tools14-1 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:27:27,325] INFO Created log for partition tools14-0 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:27:27,325] INFO Created log for partition tools14-2 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:27:27,326] INFO [Partition tools14-1 broker=2] No checkpointed highwatermark is found for partition tools14-1 (kafka.cluster.Partition)
[2019-01-25 11:27:27,327] INFO [Partition tools14-0 broker=1] No checkpointed highwatermark is found for partition tools14-0 (kafka.cluster.Partition)
[2019-01-25 11:27:27,327] INFO Replica loaded for partition tools14-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:27:27,327] INFO [Partition tools14-2 broker=3] No checkpointed highwatermark is found for partition tools14-2 (kafka.cluster.Partition)
[2019-01-25 11:27:27,327] INFO Replica loaded for partition tools14-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:27:27,327] INFO Replica loaded for partition tools14-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:27:27,327] INFO Replica loaded for partition tools14-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:27:27,328] INFO Replica loaded for partition tools14-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:27:27,330] INFO [Partition tools14-1 broker=2] tools14-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:27:27,330] INFO Replica loaded for partition tools14-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:27:27,330] INFO [Partition tools14-0 broker=1] tools14-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:27:27,332] INFO [Partition tools14-2 broker=3] tools14-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:27:27,336] INFO Replica loaded for partition tools14-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:27:27,339] INFO Replica loaded for partition tools14-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:27:27,340] INFO Replica loaded for partition tools14-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:27:27,342] INFO [Log partition=tools14-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:27:27,345] INFO [Log partition=tools14-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-01-25 11:27:27,346] INFO [Log partition=tools14-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:27:27,346] INFO Created log for partition tools14-2 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:27:27,346] INFO [Log partition=tools14-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:27:27,347] INFO [Partition tools14-2 broker=2] No checkpointed highwatermark is found for partition tools14-2 (kafka.cluster.Partition)
[2019-01-25 11:27:27,347] INFO Replica loaded for partition tools14-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:27:27,347] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(tools14-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:27:27,348] INFO [Log partition=tools14-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-01-25 11:27:27,349] INFO [Log partition=tools14-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-01-25 11:27:27,349] INFO Created log for partition tools14-1 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:27:27,350] INFO Created log for partition tools14-0 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:27:27,357] INFO [Partition tools14-0 broker=3] No checkpointed highwatermark is found for partition tools14-0 (kafka.cluster.Partition)
[2019-01-25 11:27:27,357] INFO Replica loaded for partition tools14-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:27:27,358] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools14-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:27:27,358] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(tools14-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:27:27,359] INFO [Partition tools14-1 broker=1] No checkpointed highwatermark is found for partition tools14-1 (kafka.cluster.Partition)
[2019-01-25 11:27:27,360] INFO Replica loaded for partition tools14-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:27:27,360] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(tools14-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:27:27,362] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools14-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:27:27,363] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:27:27,365] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools14-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:27:27,366] INFO [Log partition=tools14-2, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:27:27,384] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:27:27,387] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(tools14-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:27:27,392] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools14-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:27:27,394] INFO [Log partition=tools14-1, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:27:27,498] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools14-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:27:27,499] INFO [Log partition=tools14-0, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:27:45,115] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:53909 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-25 11:27:45,117] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:53909 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:27:45,122] INFO Established session 0x10003b9f7140004 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:53909 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 11:27:45,398] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140004 type:setData cxid:0x6 zxid:0xbd3 txntype:-1 reqpath:n/a Error Path:/config/topics/aggregateddata Error:KeeperErrorCode = NoNode for /config/topics/aggregateddata (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:27:45,447] INFO Processed session termination for sessionid: 0x10003b9f7140004 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 11:27:45,450] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:53909 which had sessionid 0x10003b9f7140004 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-25 11:27:45,455] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(aggregateddata-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:27:45,455] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(aggregateddata-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:27:45,456] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(aggregateddata-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:27:45,463] INFO [Log partition=aggregateddata-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:27:45,464] INFO [Log partition=aggregateddata-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:27:45,465] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:27:45,465] INFO [Log partition=aggregateddata-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-01-25 11:27:45,466] INFO [Log partition=aggregateddata-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-01-25 11:27:45,466] INFO Created log for partition aggregateddata-2 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:27:45,467] INFO [Partition aggregateddata-2 broker=2] No checkpointed highwatermark is found for partition aggregateddata-2 (kafka.cluster.Partition)
[2019-01-25 11:27:45,467] INFO Created log for partition aggregateddata-0 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:27:45,468] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-01-25 11:27:45,468] INFO Replica loaded for partition aggregateddata-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:27:45,469] INFO Replica loaded for partition aggregateddata-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:27:45,469] INFO [Partition aggregateddata-0 broker=3] No checkpointed highwatermark is found for partition aggregateddata-0 (kafka.cluster.Partition)
[2019-01-25 11:27:45,469] INFO [Partition aggregateddata-2 broker=2] aggregateddata-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:27:45,469] INFO Created log for partition aggregateddata-1 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:27:45,470] INFO [Partition aggregateddata-1 broker=1] No checkpointed highwatermark is found for partition aggregateddata-1 (kafka.cluster.Partition)
[2019-01-25 11:27:45,469] INFO Replica loaded for partition aggregateddata-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:27:45,471] INFO Replica loaded for partition aggregateddata-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:27:45,471] INFO Replica loaded for partition aggregateddata-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:27:45,471] INFO Replica loaded for partition aggregateddata-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:27:45,472] INFO [Partition aggregateddata-0 broker=3] aggregateddata-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:27:45,472] INFO [Partition aggregateddata-1 broker=1] aggregateddata-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 11:27:45,474] INFO Replica loaded for partition aggregateddata-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:27:45,477] INFO Replica loaded for partition aggregateddata-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:27:45,478] INFO Replica loaded for partition aggregateddata-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:27:45,482] INFO [Log partition=aggregateddata-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:27:45,484] INFO [Log partition=aggregateddata-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-01-25 11:27:45,484] INFO [Log partition=aggregateddata-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:27:45,485] INFO Created log for partition aggregateddata-0 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:27:45,485] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 11:27:45,486] INFO [Partition aggregateddata-0 broker=2] No checkpointed highwatermark is found for partition aggregateddata-0 (kafka.cluster.Partition)
[2019-01-25 11:27:45,486] INFO Replica loaded for partition aggregateddata-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:27:45,486] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(aggregateddata-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:27:45,486] INFO [Log partition=aggregateddata-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-01-25 11:27:45,487] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(aggregateddata-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:27:45,487] INFO Created log for partition aggregateddata-2 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:27:45,488] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-01-25 11:27:45,488] INFO [Partition aggregateddata-2 broker=1] No checkpointed highwatermark is found for partition aggregateddata-2 (kafka.cluster.Partition)
[2019-01-25 11:27:45,488] INFO Replica loaded for partition aggregateddata-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:27:45,489] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(aggregateddata-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:27:45,489] INFO Created log for partition aggregateddata-1 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 11:27:45,489] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(aggregateddata-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:27:45,490] INFO [Partition aggregateddata-1 broker=3] No checkpointed highwatermark is found for partition aggregateddata-1 (kafka.cluster.Partition)
[2019-01-25 11:27:45,490] INFO Replica loaded for partition aggregateddata-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 11:27:45,491] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(aggregateddata-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:27:45,491] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in aggregateddata-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:27:45,492] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(aggregateddata-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:27:45,492] INFO [Log partition=aggregateddata-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:27:45,515] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in aggregateddata-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:27:45,515] INFO [Log partition=aggregateddata-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:27:45,590] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in aggregateddata-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:27:45,591] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:27:54,827] INFO [GroupCoordinator 3]: Preparing to rebalance group connect-test-sink in state PreparingRebalance with old generation 0 (__consumer_offsets-35) (reason: Adding new member consumer-1-6f79f131-50b7-4237-8875-7148f2344916) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:27:54,831] INFO [GroupCoordinator 3]: Stabilized group connect-test-sink generation 1 (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:27:54,839] INFO [GroupCoordinator 3]: Assignment received from leader for group connect-test-sink for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:28:13,652] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-78833 in state PreparingRebalance with old generation 0 (__consumer_offsets-0) (reason: Adding new member consumer-1-f6706a7b-1c7d-4102-85b7-d9b77d84340c) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:28:13,658] INFO [GroupCoordinator 1]: Stabilized group console-consumer-78833 generation 1 (__consumer_offsets-0) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:28:13,667] INFO [GroupCoordinator 1]: Assignment received from leader for group console-consumer-78833 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:28:19,753] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 72 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-3488dc3e-3217-44be-9f8d-41c26185210f-StreamThread-1-consumer-98cc26cb-5a74-46f5-83c9-87e791b684b1) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:28:19,754] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 73 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:28:19,763] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 73 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:29:00,845] INFO [GroupCoordinator 3]: Preparing to rebalance group connect-test-sink in state PreparingRebalance with old generation 1 (__consumer_offsets-35) (reason: removing member consumer-1-6f79f131-50b7-4237-8875-7148f2344916 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:29:00,845] INFO [GroupCoordinator 3]: Group connect-test-sink with generation 2 is now empty (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:31:14,152] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(tools6-1, tools8-2, tools11-0, tools10-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:31:14,153] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools2-2, aggregated_data-2, tools12-2, tools3-2, tools5-1, edited6-0, edited12-1, tools-2, edited-0, tools1-1, alltools-2, tools7-2, tools4-0, edited8-1, mytools-2, edited10-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:31:14,156] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools4-0, tools1-1, tools2-2, tools-2, edited6-0, alltools-2, tools11-0, edited8-1, edited10-1, tools5-1, tools12-2, edited12-1, tools6-1, tools7-2, edited-0, tools3-2, tools10-1, tools8-2, aggregated_data-2, mytools-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:31:14,156] INFO [Partition tools1-1 broker=3] tools1-1 starts at Leader Epoch 26 from offset 0. Previous Leader Epoch was: 25 (kafka.cluster.Partition)
[2019-01-25 11:31:14,157] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(tools8-2 -> (offset=0, leaderEpoch=7), tools6-1 -> (offset=6, leaderEpoch=22), tools11-0 -> (offset=0, leaderEpoch=3), tools10-1 -> (offset=1, leaderEpoch=3)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:31:14,162] INFO [Partition tools2-2 broker=3] tools2-2 starts at Leader Epoch 26 from offset 0. Previous Leader Epoch was: 25 (kafka.cluster.Partition)
[2019-01-25 11:31:14,165] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(tools4-0 -> (offset=0, leaderEpoch=26), tools1-1 -> (offset=0, leaderEpoch=26), tools2-2 -> (offset=0, leaderEpoch=26), tools-2 -> (offset=0, leaderEpoch=26), edited6-0 -> (offset=3, leaderEpoch=22), alltools-2 -> (offset=5, leaderEpoch=27), edited8-1 -> (offset=0, leaderEpoch=6), edited10-1 -> (offset=0, leaderEpoch=2), tools5-1 -> (offset=5, leaderEpoch=26), tools12-2 -> (offset=0, leaderEpoch=2), edited12-1 -> (offset=0, leaderEpoch=2), tools7-2 -> (offset=1, leaderEpoch=16), edited-0 -> (offset=8, leaderEpoch=26), tools3-2 -> (offset=0, leaderEpoch=26), aggregated_data-2 -> (offset=0, leaderEpoch=2), mytools-2 -> (offset=0, leaderEpoch=26)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 11:31:14,165] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:31:14,166] INFO [Partition edited12-1 broker=3] edited12-1 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-25 11:31:14,171] INFO [Partition tools10-1 broker=3] tools10-1 starts at Leader Epoch 3 from offset 1. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-25 11:31:14,175] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition edited-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:31:14,175] INFO [Partition tools6-1 broker=3] tools6-1 starts at Leader Epoch 22 from offset 6. Previous Leader Epoch was: 21 (kafka.cluster.Partition)
[2019-01-25 11:31:14,175] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition edited10-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:31:14,176] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition tools-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:31:14,177] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition alltools-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:31:14,178] INFO [Log partition=edited12-1, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:31:14,179] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition aggregated_data-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:31:14,179] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition tools12-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:31:14,179] INFO [Log partition=tools1-1, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:31:14,179] INFO [Partition tools7-2 broker=3] tools7-2 starts at Leader Epoch 16 from offset 1. Previous Leader Epoch was: 15 (kafka.cluster.Partition)
[2019-01-25 11:31:14,179] INFO [Log partition=tools2-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:31:14,181] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition tools3-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:31:14,181] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition mytools-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:31:14,181] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition tools5-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:31:14,182] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition edited8-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:31:14,182] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition tools4-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:31:14,182] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition edited6-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:31:14,183] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Retrying leaderEpoch request for partition tools7-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 11:31:14,184] INFO [Partition edited-0 broker=3] edited-0 starts at Leader Epoch 26 from offset 8. Previous Leader Epoch was: 25 (kafka.cluster.Partition)
[2019-01-25 11:31:14,188] INFO [Partition alltools-2 broker=3] alltools-2 starts at Leader Epoch 27 from offset 5. Previous Leader Epoch was: 26 (kafka.cluster.Partition)
[2019-01-25 11:31:14,192] INFO [Partition tools11-0 broker=3] tools11-0 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-25 11:31:14,195] INFO [Partition edited8-1 broker=3] edited8-1 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-01-25 11:31:14,199] INFO [Partition mytools-2 broker=3] mytools-2 starts at Leader Epoch 26 from offset 0. Previous Leader Epoch was: 25 (kafka.cluster.Partition)
[2019-01-25 11:31:14,202] INFO [Partition tools3-2 broker=3] tools3-2 starts at Leader Epoch 26 from offset 0. Previous Leader Epoch was: 25 (kafka.cluster.Partition)
[2019-01-25 11:31:14,209] INFO [Partition tools5-1 broker=3] tools5-1 starts at Leader Epoch 26 from offset 5. Previous Leader Epoch was: 25 (kafka.cluster.Partition)
[2019-01-25 11:31:14,213] INFO [Partition tools4-0 broker=3] tools4-0 starts at Leader Epoch 26 from offset 0. Previous Leader Epoch was: 25 (kafka.cluster.Partition)
[2019-01-25 11:31:14,216] INFO [Partition tools12-2 broker=3] tools12-2 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-25 11:31:14,220] INFO [Partition edited6-0 broker=3] edited6-0 starts at Leader Epoch 22 from offset 3. Previous Leader Epoch was: 21 (kafka.cluster.Partition)
[2019-01-25 11:31:14,224] INFO [Partition aggregated_data-2 broker=3] aggregated_data-2 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-25 11:31:14,228] INFO [Partition tools-2 broker=3] tools-2 starts at Leader Epoch 26 from offset 0. Previous Leader Epoch was: 25 (kafka.cluster.Partition)
[2019-01-25 11:31:14,232] INFO [Partition edited10-1 broker=3] edited10-1 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-25 11:31:14,235] INFO [Partition tools8-2 broker=3] tools8-2 starts at Leader Epoch 7 from offset 0. Previous Leader Epoch was: 6 (kafka.cluster.Partition)
[2019-01-25 11:31:14,377] INFO [Log partition=tools10-1, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 11:31:14,378] INFO [Log partition=tools11-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:31:14,379] INFO [Log partition=tools6-1, dir=C:\tmp\logs2] Truncating to 6 has no effect as the largest offset in the log is 5 (kafka.log.Log)
[2019-01-25 11:31:14,379] INFO [Log partition=tools8-2, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:31:15,192] INFO [Log partition=edited-0, dir=C:\tmp\logs1] Truncating to 8 has no effect as the largest offset in the log is 7 (kafka.log.Log)
[2019-01-25 11:31:15,193] INFO [Log partition=edited10-1, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:31:15,194] INFO [Log partition=tools-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:31:15,194] INFO [Log partition=alltools-2, dir=C:\tmp\logs1] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.Log)
[2019-01-25 11:31:15,194] INFO [Log partition=aggregated_data-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:31:15,195] INFO [Log partition=tools12-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:31:15,195] INFO [Log partition=tools3-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:31:15,196] INFO [Log partition=mytools-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:31:15,196] INFO [Log partition=tools5-1, dir=C:\tmp\logs1] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.Log)
[2019-01-25 11:31:15,197] INFO [Log partition=edited8-1, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:31:15,197] INFO [Log partition=tools4-0, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 11:31:15,198] INFO [Log partition=edited6-0, dir=C:\tmp\logs1] Truncating to 3 has no effect as the largest offset in the log is 2 (kafka.log.Log)
[2019-01-25 11:31:15,198] INFO [Log partition=tools7-2, dir=C:\tmp\logs1] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 11:33:37,853] INFO [GroupCoordinator 3]: Preparing to rebalance group connect-test-sink in state PreparingRebalance with old generation 2 (__consumer_offsets-35) (reason: Adding new member consumer-1-5e550842-cd2e-4081-885c-d298f15ee833) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:33:37,854] INFO [GroupCoordinator 3]: Stabilized group connect-test-sink generation 3 (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:33:37,857] INFO [GroupCoordinator 3]: Assignment received from leader for group connect-test-sink for generation 3 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:34:38,777] INFO [GroupCoordinator 1]: Member consumer-1-f6706a7b-1c7d-4102-85b7-d9b77d84340c in group console-consumer-78833 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:34:38,778] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-78833 in state PreparingRebalance with old generation 1 (__consumer_offsets-0) (reason: removing member consumer-1-f6706a7b-1c7d-4102-85b7-d9b77d84340c on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:34:38,780] INFO [GroupCoordinator 1]: Group console-consumer-78833 with generation 2 is now empty (__consumer_offsets-0) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:36:08,792] INFO [GroupMetadataManager brokerId=1] Group console-consumer-78833 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:36:08,794] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:36:26,326] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:36:47,771] INFO [GroupMetadataManager brokerId=3] Group console-consumer-8229 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:36:47,772] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:46:08,789] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:46:26,320] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:46:47,766] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:47:32,972] INFO [GroupCoordinator 3]: Member alltoolsStream-3488dc3e-3217-44be-9f8d-41c26185210f-StreamThread-1-consumer-98cc26cb-5a74-46f5-83c9-87e791b684b1 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:47:32,973] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 73 (__consumer_offsets-2) (reason: removing member alltoolsStream-3488dc3e-3217-44be-9f8d-41c26185210f-StreamThread-1-consumer-98cc26cb-5a74-46f5-83c9-87e791b684b1 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:47:32,973] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 74 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 11:56:08,788] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:56:26,321] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 11:56:47,768] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 12:00:06,229] INFO [GroupCoordinator 3]: Member consumer-1-5e550842-cd2e-4081-885c-d298f15ee833 in group connect-test-sink has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 12:00:06,232] INFO [GroupCoordinator 3]: Preparing to rebalance group connect-test-sink in state PreparingRebalance with old generation 3 (__consumer_offsets-35) (reason: removing member consumer-1-5e550842-cd2e-4081-885c-d298f15ee833 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 12:00:06,232] INFO [GroupCoordinator 3]: Group connect-test-sink with generation 4 is now empty (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 12:06:08,800] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 12:06:26,326] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 12:06:47,775] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 12:08:46,380] INFO Accepted socket connection from /127.0.0.1:54450 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-25 12:08:46,380] INFO Client attempting to establish new session at /127.0.0.1:54450 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 12:08:46,396] INFO Established session 0x10003b9f7140005 with negotiated timeout 30000 for client /127.0.0.1:54450 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 12:08:46,630] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140005 type:setData cxid:0x6 zxid:0xbf3 txntype:-1 reqpath:n/a Error Path:/config/topics/tools13 Error:KeeperErrorCode = NoNode for /config/topics/tools13 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 12:08:46,677] INFO Processed session termination for sessionid: 0x10003b9f7140005 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 12:08:46,693] INFO Closed socket connection for client /127.0.0.1:54450 which had sessionid 0x10003b9f7140005 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-25 12:08:46,693] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools13-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 12:08:46,693] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(tools13-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 12:08:46,693] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools13-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 12:08:46,708] INFO [Log partition=tools13-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 12:08:46,708] INFO [Log partition=tools13-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 12:08:46,708] INFO [Log partition=tools13-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 12:08:46,708] INFO [Log partition=tools13-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-25 12:08:46,708] INFO Created log for partition tools13-0 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 12:08:46,708] INFO [Log partition=tools13-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 12:08:46,708] INFO [Partition tools13-0 broker=1] No checkpointed highwatermark is found for partition tools13-0 (kafka.cluster.Partition)
[2019-01-25 12:08:46,708] INFO Replica loaded for partition tools13-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 12:08:46,708] INFO [Log partition=tools13-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 12:08:46,708] INFO Created log for partition tools13-1 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 12:08:46,708] INFO Replica loaded for partition tools13-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 12:08:46,708] INFO Created log for partition tools13-2 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 12:08:46,708] INFO [Partition tools13-1 broker=2] No checkpointed highwatermark is found for partition tools13-1 (kafka.cluster.Partition)
[2019-01-25 12:08:46,708] INFO [Partition tools13-0 broker=1] tools13-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 12:08:46,708] INFO [Partition tools13-2 broker=3] No checkpointed highwatermark is found for partition tools13-2 (kafka.cluster.Partition)
[2019-01-25 12:08:46,708] INFO Replica loaded for partition tools13-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 12:08:46,708] INFO Replica loaded for partition tools13-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 12:08:46,708] INFO Replica loaded for partition tools13-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 12:08:46,708] INFO [Partition tools13-1 broker=2] tools13-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 12:08:46,708] INFO Replica loaded for partition tools13-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 12:08:46,708] INFO [Partition tools13-2 broker=3] tools13-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 12:08:46,724] INFO Replica loaded for partition tools13-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 12:08:46,724] INFO Replica loaded for partition tools13-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 12:08:46,724] INFO Replica loaded for partition tools13-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 12:08:46,724] INFO [Log partition=tools13-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 12:08:46,724] INFO [Log partition=tools13-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 12:08:46,724] INFO [Log partition=tools13-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 12:08:46,724] INFO [Log partition=tools13-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 12:08:46,724] INFO Created log for partition tools13-1 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 12:08:46,724] INFO [Partition tools13-1 broker=1] No checkpointed highwatermark is found for partition tools13-1 (kafka.cluster.Partition)
[2019-01-25 12:08:46,724] INFO [Log partition=tools13-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 12:08:46,724] INFO [Log partition=tools13-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 12:08:46,724] INFO Replica loaded for partition tools13-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 12:08:46,724] INFO Created log for partition tools13-2 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 12:08:46,724] INFO Created log for partition tools13-0 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 12:08:46,724] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools13-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 12:08:46,724] INFO [Partition tools13-2 broker=2] No checkpointed highwatermark is found for partition tools13-2 (kafka.cluster.Partition)
[2019-01-25 12:08:46,724] INFO [Partition tools13-0 broker=3] No checkpointed highwatermark is found for partition tools13-0 (kafka.cluster.Partition)
[2019-01-25 12:08:46,724] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(tools13-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 12:08:46,724] INFO Replica loaded for partition tools13-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 12:08:46,739] INFO Replica loaded for partition tools13-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 12:08:46,739] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(tools13-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 12:08:46,739] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools13-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 12:08:46,739] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(tools13-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 12:08:46,739] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(tools13-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 12:08:46,771] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools13-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 12:08:46,771] INFO [Log partition=tools13-1, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 12:08:46,958] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools13-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 12:08:46,958] INFO [Log partition=tools13-0, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 12:08:47,005] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools13-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 12:08:47,005] INFO [Log partition=tools13-2, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 12:09:05,092] INFO Accepted socket connection from /127.0.0.1:54457 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-25 12:09:05,092] INFO Client attempting to establish new session at /127.0.0.1:54457 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 12:09:05,108] INFO Established session 0x10003b9f7140006 with negotiated timeout 30000 for client /127.0.0.1:54457 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 12:09:05,342] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140006 type:setData cxid:0x6 zxid:0xbff txntype:-1 reqpath:n/a Error Path:/config/topics/edited13 Error:KeeperErrorCode = NoNode for /config/topics/edited13 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 12:09:05,389] INFO Processed session termination for sessionid: 0x10003b9f7140006 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 12:09:05,405] INFO Closed socket connection for client /127.0.0.1:54457 which had sessionid 0x10003b9f7140006 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-25 12:09:05,405] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(edited13-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 12:09:05,405] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(edited13-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 12:09:05,405] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(edited13-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 12:09:05,405] INFO [Log partition=edited13-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 12:09:05,405] INFO [Log partition=edited13-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 12:09:05,405] INFO [Log partition=edited13-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 12:09:05,405] INFO [Log partition=edited13-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 12:09:05,405] INFO Created log for partition edited13-1 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 12:09:05,405] INFO [Log partition=edited13-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 12:09:05,405] INFO [Partition edited13-1 broker=1] No checkpointed highwatermark is found for partition edited13-1 (kafka.cluster.Partition)
[2019-01-25 12:09:05,405] INFO [Log partition=edited13-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 12:09:05,405] INFO Created log for partition edited13-0 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 12:09:05,405] INFO Replica loaded for partition edited13-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 12:09:05,405] INFO Created log for partition edited13-2 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 12:09:05,420] INFO Replica loaded for partition edited13-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 12:09:05,420] INFO [Partition edited13-0 broker=3] No checkpointed highwatermark is found for partition edited13-0 (kafka.cluster.Partition)
[2019-01-25 12:09:05,420] INFO [Partition edited13-1 broker=1] edited13-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 12:09:05,420] INFO [Partition edited13-2 broker=2] No checkpointed highwatermark is found for partition edited13-2 (kafka.cluster.Partition)
[2019-01-25 12:09:05,420] INFO Replica loaded for partition edited13-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 12:09:05,420] INFO Replica loaded for partition edited13-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 12:09:05,420] INFO Replica loaded for partition edited13-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 12:09:05,420] INFO Replica loaded for partition edited13-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 12:09:05,420] INFO [Partition edited13-0 broker=3] edited13-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 12:09:05,420] INFO [Partition edited13-2 broker=2] edited13-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 12:09:05,420] INFO Replica loaded for partition edited13-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 12:09:05,420] INFO Replica loaded for partition edited13-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 12:09:05,420] INFO Replica loaded for partition edited13-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 12:09:05,420] INFO [Log partition=edited13-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 12:09:05,436] INFO [Log partition=edited13-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 12:09:05,436] INFO [Log partition=edited13-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 12:09:05,436] INFO [Log partition=edited13-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 12:09:05,436] INFO Created log for partition edited13-0 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 12:09:05,436] INFO [Partition edited13-0 broker=1] No checkpointed highwatermark is found for partition edited13-0 (kafka.cluster.Partition)
[2019-01-25 12:09:05,436] INFO Replica loaded for partition edited13-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 12:09:05,436] INFO [Log partition=edited13-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 12:09:05,436] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(edited13-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 12:09:05,436] INFO [Log partition=edited13-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 12:09:05,436] INFO Created log for partition edited13-2 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 12:09:05,436] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(edited13-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 12:09:05,436] INFO Created log for partition edited13-1 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 12:09:05,436] INFO [Partition edited13-2 broker=3] No checkpointed highwatermark is found for partition edited13-2 (kafka.cluster.Partition)
[2019-01-25 12:09:05,436] INFO Replica loaded for partition edited13-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 12:09:05,436] INFO [Partition edited13-1 broker=2] No checkpointed highwatermark is found for partition edited13-1 (kafka.cluster.Partition)
[2019-01-25 12:09:05,436] INFO Replica loaded for partition edited13-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 12:09:05,436] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(edited13-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 12:09:05,436] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(edited13-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 12:09:05,436] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(edited13-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 12:09:05,436] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(edited13-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 12:09:05,515] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in edited13-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 12:09:05,515] INFO [Log partition=edited13-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 12:09:05,608] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in edited13-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 12:09:05,608] INFO [Log partition=edited13-0, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 12:09:05,858] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in edited13-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 12:09:05,858] INFO [Log partition=edited13-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 12:09:24,270] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-83131 in state PreparingRebalance with old generation 0 (__consumer_offsets-37) (reason: Adding new member consumer-1-5d186f12-02b3-41db-9884-a3e9794b9226) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 12:09:24,270] INFO [GroupCoordinator 2]: Stabilized group console-consumer-83131 generation 1 (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 12:09:24,285] INFO [GroupCoordinator 2]: Assignment received from leader for group console-consumer-83131 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 12:10:40,855] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 74 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-10228d5b-949f-4092-a019-c66f97bbed14-StreamThread-1-consumer-24680b4a-c0e8-4a18-b872-fed0deac0741) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 12:10:40,855] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 75 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 12:10:40,855] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 75 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 12:11:39,064] INFO [GroupCoordinator 3]: Member alltoolsStream-10228d5b-949f-4092-a019-c66f97bbed14-StreamThread-1-consumer-24680b4a-c0e8-4a18-b872-fed0deac0741 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 12:11:39,064] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 75 (__consumer_offsets-2) (reason: removing member alltoolsStream-10228d5b-949f-4092-a019-c66f97bbed14-StreamThread-1-consumer-24680b4a-c0e8-4a18-b872-fed0deac0741 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 12:11:39,064] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 76 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 12:12:01,445] INFO [GroupCoordinator 3]: Preparing to rebalance group console-consumer-76089 in state PreparingRebalance with old generation 0 (__consumer_offsets-41) (reason: Adding new member consumer-1-589fc908-54c2-4dbf-bf4c-a62e5522f56c) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 12:12:01,445] INFO [GroupCoordinator 3]: Stabilized group console-consumer-76089 generation 1 (__consumer_offsets-41) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 12:12:01,445] INFO [GroupCoordinator 3]: Assignment received from leader for group console-consumer-76089 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 12:12:39,987] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 76 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-c993b07c-0242-4f16-ab6a-9d464eac4d32-StreamThread-1-consumer-4ce6051b-8249-4505-94ee-9a766e023fd9) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 12:12:39,987] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 77 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 12:12:40,003] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 77 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 12:15:50,029] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 77 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-88450ff1-de0e-4f2b-97f7-8b7fab90575b-StreamThread-1-consumer-08a64c8e-ce4e-45c5-83ec-d6e3eb18790b) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 12:15:50,732] INFO [GroupCoordinator 3]: Member alltoolsStream-c993b07c-0242-4f16-ab6a-9d464eac4d32-StreamThread-1-consumer-4ce6051b-8249-4505-94ee-9a766e023fd9 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 12:15:50,732] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 78 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 12:15:50,747] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 78 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 12:16:08,790] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 12:16:18,832] INFO [GroupCoordinator 3]: Member alltoolsStream-88450ff1-de0e-4f2b-97f7-8b7fab90575b-StreamThread-1-consumer-08a64c8e-ce4e-45c5-83ec-d6e3eb18790b in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 12:16:18,832] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 78 (__consumer_offsets-2) (reason: removing member alltoolsStream-88450ff1-de0e-4f2b-97f7-8b7fab90575b-StreamThread-1-consumer-08a64c8e-ce4e-45c5-83ec-d6e3eb18790b on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 12:16:18,832] INFO [GroupCoordinator 3]: Group alltoolsStream with generation 79 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 12:16:26,330] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 12:16:47,778] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 12:26:08,794] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 12:26:26,320] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 12:26:47,769] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 12:36:08,795] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 12:36:26,320] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 12:36:47,767] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 12:46:08,790] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 12:46:26,322] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 12:46:47,767] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 12:56:08,803] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 12:56:26,331] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 12:56:47,771] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 13:06:08,788] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 13:06:26,320] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 13:06:47,766] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 13:16:08,788] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 13:16:26,320] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 13:16:47,767] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 13:26:08,788] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 13:26:26,321] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 13:26:47,767] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 13:36:08,788] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 13:36:26,321] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 13:36:47,767] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 13:46:08,789] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 13:46:26,321] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 13:46:47,766] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 13:56:08,788] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 13:56:26,320] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 13:56:47,766] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 14:06:08,788] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 14:06:26,321] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 14:06:47,766] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 14:16:08,788] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 14:16:26,335] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 14:16:47,770] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 14:26:08,798] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 14:26:26,321] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 14:26:47,766] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 14:36:08,788] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 14:36:26,321] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 14:36:47,767] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 14:46:08,788] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 14:46:26,321] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 14:46:47,766] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 14:56:08,798] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 14:56:26,329] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 14:56:47,773] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 15:06:08,799] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 15:06:26,321] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 15:06:47,766] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 15:16:08,797] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 15:16:26,321] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 15:16:47,766] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 15:26:08,797] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 15:26:26,320] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 15:26:47,773] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 15:33:18,328] INFO [GroupCoordinator 2]: Member consumer-1-5d186f12-02b3-41db-9884-a3e9794b9226 in group console-consumer-83131 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 15:33:18,343] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-83131 in state PreparingRebalance with old generation 1 (__consumer_offsets-37) (reason: removing member consumer-1-5d186f12-02b3-41db-9884-a3e9794b9226 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 15:33:18,343] INFO [GroupCoordinator 2]: Group console-consumer-83131 with generation 2 is now empty (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 15:33:21,823] INFO [GroupCoordinator 3]: Member consumer-1-589fc908-54c2-4dbf-bf4c-a62e5522f56c in group console-consumer-76089 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 15:33:21,825] INFO [GroupCoordinator 3]: Preparing to rebalance group console-consumer-76089 in state PreparingRebalance with old generation 1 (__consumer_offsets-41) (reason: removing member consumer-1-589fc908-54c2-4dbf-bf4c-a62e5522f56c on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 15:33:21,825] INFO [GroupCoordinator 3]: Group console-consumer-76089 with generation 2 is now empty (__consumer_offsets-41) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 15:33:59,938] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:61574 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-25 15:33:59,954] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:61574 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 15:33:59,954] INFO Established session 0x10003b9f7140007 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:61574 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 15:34:00,266] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140007 type:setData cxid:0x6 zxid:0xc0b txntype:-1 reqpath:n/a Error Path:/config/topics/randommessages Error:KeeperErrorCode = NoNode for /config/topics/randommessages (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 15:34:00,313] INFO Processed session termination for sessionid: 0x10003b9f7140007 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 15:34:00,313] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:61574 which had sessionid 0x10003b9f7140007 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-25 15:34:00,344] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(randommessages-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 15:34:00,344] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(randommessages-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 15:34:00,344] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(randommessages-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 15:34:00,360] INFO [Log partition=randommessages-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 15:34:00,360] INFO [Log partition=randommessages-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 15:34:00,360] INFO [Log partition=randommessages-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 15:34:00,360] INFO Created log for partition randommessages-2 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 15:34:00,360] INFO [Partition randommessages-2 broker=1] No checkpointed highwatermark is found for partition randommessages-2 (kafka.cluster.Partition)
[2019-01-25 15:34:00,360] INFO Replica loaded for partition randommessages-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 15:34:00,360] INFO [Log partition=randommessages-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 15:34:00,360] INFO [Log partition=randommessages-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 15:34:00,360] INFO Replica loaded for partition randommessages-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 15:34:00,360] INFO Created log for partition randommessages-0 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 15:34:00,360] INFO [Partition randommessages-2 broker=1] randommessages-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 15:34:00,360] INFO [Log partition=randommessages-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 15:34:00,360] INFO [Partition randommessages-0 broker=2] No checkpointed highwatermark is found for partition randommessages-0 (kafka.cluster.Partition)
[2019-01-25 15:34:00,360] INFO Replica loaded for partition randommessages-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 15:34:00,360] INFO Replica loaded for partition randommessages-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 15:34:00,360] INFO Created log for partition randommessages-1 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 15:34:00,360] INFO [Partition randommessages-0 broker=2] randommessages-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 15:34:00,360] INFO [Partition randommessages-1 broker=3] No checkpointed highwatermark is found for partition randommessages-1 (kafka.cluster.Partition)
[2019-01-25 15:34:00,360] INFO Replica loaded for partition randommessages-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 15:34:00,360] INFO Replica loaded for partition randommessages-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 15:34:00,360] INFO [Partition randommessages-1 broker=3] randommessages-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 15:34:00,376] INFO Replica loaded for partition randommessages-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 15:34:00,376] INFO Replica loaded for partition randommessages-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 15:34:00,376] INFO Replica loaded for partition randommessages-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 15:34:00,376] INFO [Log partition=randommessages-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 15:34:00,376] INFO [Log partition=randommessages-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 15:34:00,376] INFO [Log partition=randommessages-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 15:34:00,376] INFO [Log partition=randommessages-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 15:34:00,376] INFO Created log for partition randommessages-1 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 15:34:00,376] INFO Created log for partition randommessages-2 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 15:34:00,376] INFO [Partition randommessages-1 broker=1] No checkpointed highwatermark is found for partition randommessages-1 (kafka.cluster.Partition)
[2019-01-25 15:34:00,376] INFO [Log partition=randommessages-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 15:34:00,376] INFO Replica loaded for partition randommessages-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 15:34:00,376] INFO [Partition randommessages-2 broker=2] No checkpointed highwatermark is found for partition randommessages-2 (kafka.cluster.Partition)
[2019-01-25 15:34:00,376] INFO Replica loaded for partition randommessages-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 15:34:00,376] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(randommessages-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 15:34:00,376] INFO [Log partition=randommessages-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 15:34:00,376] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(randommessages-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 15:34:00,376] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(randommessages-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 15:34:00,376] INFO Created log for partition randommessages-0 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 15:34:00,391] INFO [Partition randommessages-0 broker=3] No checkpointed highwatermark is found for partition randommessages-0 (kafka.cluster.Partition)
[2019-01-25 15:34:00,391] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(randommessages-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 15:34:00,391] INFO Replica loaded for partition randommessages-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 15:34:00,391] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(randommessages-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 15:34:00,391] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(randommessages-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 15:34:00,564] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in randommessages-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 15:34:00,564] INFO [Log partition=randommessages-1, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 15:34:00,579] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in randommessages-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 15:34:00,579] INFO [Log partition=randommessages-0, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 15:34:00,657] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in randommessages-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 15:34:00,657] INFO [Log partition=randommessages-2, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 15:34:36,235] INFO Accepted socket connection from /127.0.0.1:61582 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-25 15:34:36,235] INFO Client attempting to establish new session at /127.0.0.1:61582 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 15:34:36,251] INFO Established session 0x10003b9f7140008 with negotiated timeout 30000 for client /127.0.0.1:61582 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 15:34:36,485] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140008 type:setData cxid:0x6 zxid:0xc17 txntype:-1 reqpath:n/a Error Path:/config/topics/pairs Error:KeeperErrorCode = NoNode for /config/topics/pairs (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 15:34:36,547] INFO Processed session termination for sessionid: 0x10003b9f7140008 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 15:34:36,547] INFO Closed socket connection for client /127.0.0.1:61582 which had sessionid 0x10003b9f7140008 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-25 15:34:36,547] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(pairs-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 15:34:36,547] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(pairs-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 15:34:36,547] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(pairs-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 15:34:36,563] INFO [Log partition=pairs-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 15:34:36,563] INFO [Log partition=pairs-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 15:34:36,563] INFO [Log partition=pairs-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 15:34:36,563] INFO [Log partition=pairs-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 15:34:36,563] INFO Created log for partition pairs-0 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 15:34:36,563] INFO Created log for partition pairs-2 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 15:34:36,563] INFO [Partition pairs-0 broker=1] No checkpointed highwatermark is found for partition pairs-0 (kafka.cluster.Partition)
[2019-01-25 15:34:36,563] INFO [Partition pairs-2 broker=3] No checkpointed highwatermark is found for partition pairs-2 (kafka.cluster.Partition)
[2019-01-25 15:34:36,563] INFO Replica loaded for partition pairs-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 15:34:36,563] INFO Replica loaded for partition pairs-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 15:34:36,563] INFO Replica loaded for partition pairs-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 15:34:36,563] INFO Replica loaded for partition pairs-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 15:34:36,563] INFO [Partition pairs-0 broker=1] pairs-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 15:34:36,563] INFO [Partition pairs-2 broker=3] pairs-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 15:34:36,563] INFO Replica loaded for partition pairs-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 15:34:36,563] INFO Replica loaded for partition pairs-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 15:34:36,563] INFO [Log partition=pairs-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 15:34:36,579] INFO [Log partition=pairs-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-01-25 15:34:36,579] INFO Created log for partition pairs-1 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 15:34:36,579] INFO [Log partition=pairs-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 15:34:36,579] INFO [Log partition=pairs-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 15:34:36,579] INFO [Partition pairs-1 broker=2] No checkpointed highwatermark is found for partition pairs-1 (kafka.cluster.Partition)
[2019-01-25 15:34:36,579] INFO Replica loaded for partition pairs-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 15:34:36,579] INFO Replica loaded for partition pairs-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 15:34:36,579] INFO [Partition pairs-1 broker=2] pairs-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 15:34:36,579] INFO [Log partition=pairs-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 15:34:36,579] INFO Created log for partition pairs-2 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 15:34:36,579] INFO [Log partition=pairs-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 15:34:36,579] INFO [Partition pairs-2 broker=1] No checkpointed highwatermark is found for partition pairs-2 (kafka.cluster.Partition)
[2019-01-25 15:34:36,579] INFO Created log for partition pairs-1 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 15:34:36,579] INFO Replica loaded for partition pairs-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 15:34:36,579] INFO [Partition pairs-1 broker=3] No checkpointed highwatermark is found for partition pairs-1 (kafka.cluster.Partition)
[2019-01-25 15:34:36,579] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(pairs-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 15:34:36,579] INFO Replica loaded for partition pairs-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 15:34:36,579] INFO Replica loaded for partition pairs-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 15:34:36,579] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(pairs-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 15:34:36,579] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(pairs-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 15:34:36,579] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(pairs-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 15:34:36,579] INFO [Log partition=pairs-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 15:34:36,594] INFO [Log partition=pairs-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-25 15:34:36,594] INFO Created log for partition pairs-0 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 15:34:36,594] INFO [Partition pairs-0 broker=2] No checkpointed highwatermark is found for partition pairs-0 (kafka.cluster.Partition)
[2019-01-25 15:34:36,594] INFO Replica loaded for partition pairs-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 15:34:36,594] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(pairs-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 15:34:36,594] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(pairs-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 15:34:36,819] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in pairs-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 15:34:36,819] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in pairs-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 15:34:36,819] INFO [Log partition=pairs-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 15:34:36,819] INFO [Log partition=pairs-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 15:34:36,913] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in pairs-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 15:34:36,913] INFO [Log partition=pairs-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 15:36:08,799] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 15:36:26,321] INFO [GroupMetadataManager brokerId=2] Group console-consumer-83131 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 15:36:26,321] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 15:36:47,773] INFO [GroupMetadataManager brokerId=3] Group console-consumer-76089 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 15:36:47,773] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 15:46:08,801] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 15:46:26,334] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 15:46:47,769] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 15:56:08,803] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 15:56:26,327] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 15:56:47,766] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 16:06:08,789] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 16:06:26,320] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 16:06:47,766] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 16:11:48,353] INFO [GroupCoordinator 3]: Preparing to rebalance group console-consumer-36876 in state PreparingRebalance with old generation 0 (__consumer_offsets-11) (reason: Adding new member consumer-1-7aa4b2cb-ca81-43f0-9858-88d039e0c35e) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 16:11:48,369] INFO [GroupCoordinator 3]: Stabilized group console-consumer-36876 generation 1 (__consumer_offsets-11) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 16:11:48,369] INFO [GroupCoordinator 3]: Assignment received from leader for group console-consumer-36876 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 16:11:59,811] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-45809 in state PreparingRebalance with old generation 0 (__consumer_offsets-27) (reason: Adding new member consumer-1-ff2df082-8162-467d-a239-c936679ea777) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 16:11:59,827] INFO [GroupCoordinator 1]: Stabilized group console-consumer-45809 generation 1 (__consumer_offsets-27) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 16:11:59,843] INFO [GroupCoordinator 1]: Assignment received from leader for group console-consumer-45809 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 16:12:37,602] INFO [GroupCoordinator 3]: Preparing to rebalance group pair-logger-consumer in state PreparingRebalance with old generation 0 (__consumer_offsets-38) (reason: Adding new member consumer-1-7f144b02-3028-42e8-a8eb-075fc6ac785a) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 16:12:37,603] INFO [GroupCoordinator 3]: Stabilized group pair-logger-consumer generation 1 (__consumer_offsets-38) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 16:12:37,609] INFO [GroupCoordinator 3]: Assignment received from leader for group pair-logger-consumer for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 16:12:37,614] INFO [GroupCoordinator 2]: Preparing to rebalance group pairing-stream-app in state PreparingRebalance with old generation 0 (__consumer_offsets-31) (reason: Adding new member pairing-stream-app-821881f3-eb79-4ba8-99b7-f2553548294c-StreamThread-1-consumer-a13b8041-a371-4767-ac60-eb4ebd872cb3) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 16:12:37,616] INFO [GroupCoordinator 2]: Stabilized group pairing-stream-app generation 1 (__consumer_offsets-31) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 16:12:37,757] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140000 type:setData cxid:0x32a zxid:0xc22 txntype:-1 reqpath:n/a Error Path:/config/topics/pairing-stream-app-pairs-store-changelog Error:KeeperErrorCode = NoNode for /config/topics/pairing-stream-app-pairs-store-changelog (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 16:12:37,773] INFO Topic creation Map(pairing-stream-app-pairs-store-changelog-2 -> ArrayBuffer(2), pairing-stream-app-pairs-store-changelog-1 -> ArrayBuffer(1), pairing-stream-app-pairs-store-changelog-0 -> ArrayBuffer(3)) (kafka.zk.AdminZkClient)
[2019-01-25 16:12:37,819] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(pairing-stream-app-pairs-store-changelog-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 16:12:37,819] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(pairing-stream-app-pairs-store-changelog-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 16:12:37,819] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(pairing-stream-app-pairs-store-changelog-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 16:12:37,819] INFO [Log partition=pairing-stream-app-pairs-store-changelog-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 16:12:37,819] INFO [Log partition=pairing-stream-app-pairs-store-changelog-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 16:12:37,835] INFO [Log partition=pairing-stream-app-pairs-store-changelog-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 16:12:37,835] INFO [Log partition=pairing-stream-app-pairs-store-changelog-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 16:12:37,835] INFO Created log for partition pairing-stream-app-pairs-store-changelog-1 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 16:12:37,835] INFO [Log partition=pairing-stream-app-pairs-store-changelog-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 16:12:37,835] INFO [Partition pairing-stream-app-pairs-store-changelog-1 broker=1] No checkpointed highwatermark is found for partition pairing-stream-app-pairs-store-changelog-1 (kafka.cluster.Partition)
[2019-01-25 16:12:37,835] INFO Replica loaded for partition pairing-stream-app-pairs-store-changelog-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 16:12:37,835] INFO [Partition pairing-stream-app-pairs-store-changelog-1 broker=1] pairing-stream-app-pairs-store-changelog-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 16:12:37,835] INFO [Log partition=pairing-stream-app-pairs-store-changelog-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 16:12:37,835] INFO Created log for partition pairing-stream-app-pairs-store-changelog-0 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 16:12:37,835] INFO [Partition pairing-stream-app-pairs-store-changelog-0 broker=3] No checkpointed highwatermark is found for partition pairing-stream-app-pairs-store-changelog-0 (kafka.cluster.Partition)
[2019-01-25 16:12:37,835] INFO Replica loaded for partition pairing-stream-app-pairs-store-changelog-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 16:12:37,835] INFO [Partition pairing-stream-app-pairs-store-changelog-0 broker=3] pairing-stream-app-pairs-store-changelog-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 16:12:37,835] INFO Created log for partition pairing-stream-app-pairs-store-changelog-2 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 16:12:37,835] INFO [Partition pairing-stream-app-pairs-store-changelog-2 broker=2] No checkpointed highwatermark is found for partition pairing-stream-app-pairs-store-changelog-2 (kafka.cluster.Partition)
[2019-01-25 16:12:37,835] INFO Replica loaded for partition pairing-stream-app-pairs-store-changelog-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 16:12:37,851] INFO [Partition pairing-stream-app-pairs-store-changelog-2 broker=2] pairing-stream-app-pairs-store-changelog-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 16:12:37,866] INFO [GroupCoordinator 2]: Assignment received from leader for group pairing-stream-app for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 16:13:09,415] INFO [GroupCoordinator 3]: Preparing to rebalance group pair-logger-consumer in state PreparingRebalance with old generation 1 (__consumer_offsets-38) (reason: removing member consumer-1-7f144b02-3028-42e8-a8eb-075fc6ac785a on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 16:13:09,415] INFO [GroupCoordinator 3]: Group pair-logger-consumer with generation 2 is now empty (__consumer_offsets-38) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 16:13:18,988] INFO [GroupCoordinator 2]: Member pairing-stream-app-821881f3-eb79-4ba8-99b7-f2553548294c-StreamThread-1-consumer-a13b8041-a371-4767-ac60-eb4ebd872cb3 in group pairing-stream-app has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 16:13:18,988] INFO [GroupCoordinator 2]: Preparing to rebalance group pairing-stream-app in state PreparingRebalance with old generation 1 (__consumer_offsets-31) (reason: removing member pairing-stream-app-821881f3-eb79-4ba8-99b7-f2553548294c-StreamThread-1-consumer-a13b8041-a371-4767-ac60-eb4ebd872cb3 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 16:13:18,988] INFO [GroupCoordinator 2]: Group pairing-stream-app with generation 2 is now empty (__consumer_offsets-31) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 16:16:08,795] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 16:16:26,327] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 16:16:47,780] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 16:26:08,788] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 16:26:26,320] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 16:26:47,767] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 16:36:08,788] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 16:36:26,320] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 16:36:47,767] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 16:46:08,789] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 16:46:26,321] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 16:46:47,767] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 16:56:08,788] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 16:56:26,320] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 16:56:47,766] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 17:06:08,792] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 17:06:26,328] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 17:06:47,767] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 17:16:08,789] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 17:16:26,321] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 17:16:47,766] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 17:26:08,795] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 17:26:26,332] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 17:26:47,766] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 17:36:08,797] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 17:36:26,330] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 17:36:47,769] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 17:46:08,793] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 17:46:26,321] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 17:46:47,779] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 17:56:08,796] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 17:56:26,322] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 17:56:47,772] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 18:57:46,213] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9094-127.0.0.1:53905-0 (kafka.network.Processor)
[2019-01-25 18:57:46,233] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9094-127.0.0.1:62117-11 (kafka.network.Processor)
[2019-01-25 18:57:46,218] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9094-127.0.0.1:62110-11 (kafka.network.Processor)
[2019-01-25 18:57:46,306] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=657163683, epoch=46673) to node 3: java.io.IOException: Connection to 3 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-25 18:57:46,187] WARN Client session timed out, have not heard from server in 3407175ms for sessionid 0x10003b9f7140002 (org.apache.zookeeper.ClientCnxn)
[2019-01-25 18:57:46,363] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=1541928415, epoch=46757) to node 1: java.io.IOException: Connection to 1 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-25 18:57:46,233] INFO [GroupCoordinator 1]: Member consumer-1-ff2df082-8162-467d-a239-c936679ea777 in group console-consumer-45809 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 18:57:46,391] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=657163683, epoch=46673)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 3 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:97)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:97)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-25 18:57:46,343] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=1574342802, epoch=46739) to node 2: java.io.IOException: Connection to 2 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-25 18:57:46,306] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9095-127.0.0.1:53902-0 (kafka.network.Processor)
[2019-01-25 18:57:46,265] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=935520570, epoch=46689) to node 2: java.io.IOException: Connection to 2 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-25 18:57:46,291] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9095-127.0.0.1:54064-2 (kafka.network.Processor)
[2019-01-25 18:57:46,265] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=852023533, epoch=46210) to node 3: java.io.IOException: Connection to 3 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-25 18:57:46,970] WARN Client session timed out, have not heard from server in 3407172ms for sessionid 0x10003b9f7140001 (org.apache.zookeeper.ClientCnxn)
[2019-01-25 18:57:47,005] INFO Client session timed out, have not heard from server in 3407172ms for sessionid 0x10003b9f7140001, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-01-25 18:57:46,291] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9095-127.0.0.1:62108-9 (kafka.network.Processor)
[2019-01-25 18:57:46,218] INFO [GroupCoordinator 3]: Member consumer-1-7aa4b2cb-ca81-43f0-9858-88d039e0c35e in group console-consumer-36876 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 18:57:47,034] WARN Unable to read additional data from client sessionid 0x10003b9f7140001, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-25 18:57:47,083] INFO Closed socket connection for client /127.0.0.1:53856 which had sessionid 0x10003b9f7140001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-25 18:57:46,951] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=852023533, epoch=46210)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 3 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:97)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:97)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-25 18:57:46,233] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9093-127.0.0.1:62109-13 (kafka.network.Processor)
[2019-01-25 18:57:46,233] WARN Attempting to send response via channel for which there is no open connection, connection id 127.0.0.1:9093-127.0.0.1:53894-0 (kafka.network.Processor)
[2019-01-25 18:57:46,871] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=935520570, epoch=46689)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 2 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:97)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:97)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-25 18:57:46,630] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-45809 in state PreparingRebalance with old generation 1 (__consumer_offsets-27) (reason: removing member consumer-1-ff2df082-8162-467d-a239-c936679ea777 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 18:57:46,670] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1574342802, epoch=46739)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 2 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:97)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:97)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-25 18:57:47,095] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=229869549, epoch=46777) to node 1: java.io.IOException: Connection to 1 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-25 18:57:47,101] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=229869549, epoch=46777)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 1 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:97)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:97)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-25 18:57:46,594] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1541928415, epoch=46757)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 1 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:97)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:97)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-25 18:57:46,385] INFO Client session timed out, have not heard from server in 3407175ms for sessionid 0x10003b9f7140002, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-01-25 18:57:47,068] INFO [GroupCoordinator 3]: Preparing to rebalance group console-consumer-36876 in state PreparingRebalance with old generation 1 (__consumer_offsets-11) (reason: removing member consumer-1-7aa4b2cb-ca81-43f0-9858-88d039e0c35e on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 18:57:47,099] INFO [GroupCoordinator 1]: Group console-consumer-45809 with generation 2 is now empty (__consumer_offsets-27) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 18:57:47,109] INFO [GroupCoordinator 3]: Group console-consumer-36876 with generation 2 is now empty (__consumer_offsets-11) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 18:57:47,107] INFO Expiring session 0x10003b9f7140002, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 18:57:47,108] WARN Unable to read additional data from client sessionid 0x10003b9f7140002, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-25 18:57:47,119] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:53876 which had sessionid 0x10003b9f7140002 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-25 18:57:47,121] INFO Expiring session 0x10003b9f7140000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 18:57:47,133] INFO Expiring session 0x10003b9f7140001, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 18:57:47,135] INFO Processed session termination for sessionid: 0x10003b9f7140002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 18:57:47,150] INFO [GroupCoordinator 3]: Preparing to rebalance group console-consumer-36876 in state PreparingRebalance with old generation 2 (__consumer_offsets-11) (reason: Adding new member consumer-1-d2d1db9a-894e-426f-b29e-00f7a6888d38) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 18:57:47,136] INFO Processed session termination for sessionid: 0x10003b9f7140000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 18:57:47,140] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-45809 in state PreparingRebalance with old generation 2 (__consumer_offsets-27) (reason: Adding new member consumer-1-b56b1ebf-c03d-4835-9045-a4ffec732e42) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 18:57:47,140] WARN Client session timed out, have not heard from server in 3406917ms for sessionid 0x10003b9f7140000 (org.apache.zookeeper.ClientCnxn)
[2019-01-25 18:57:47,438] INFO Client session timed out, have not heard from server in 3406917ms for sessionid 0x10003b9f7140000, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-01-25 18:57:47,437] INFO [GroupCoordinator 3]: Stabilized group console-consumer-36876 generation 3 (__consumer_offsets-11) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 18:57:47,434] INFO Processed session termination for sessionid: 0x10003b9f7140001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 18:57:47,439] INFO [GroupCoordinator 1]: Stabilized group console-consumer-45809 generation 3 (__consumer_offsets-27) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 18:57:47,534] INFO [GroupCoordinator 3]: Assignment received from leader for group console-consumer-36876 for generation 3 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 18:57:47,436] INFO Closed socket connection for client /127.0.0.1:53839 which had sessionid 0x10003b9f7140000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-25 18:57:47,566] INFO [GroupCoordinator 1]: Assignment received from leader for group console-consumer-45809 for generation 3 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 18:57:48,612] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-25 18:57:48,612] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-25 18:57:48,612] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:63106 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-25 18:57:48,643] INFO Client attempting to renew session 0x10003b9f7140002 at /0:0:0:0:0:0:0:1:63106 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 18:57:48,643] INFO Invalid session 0x10003b9f7140002 for client /0:0:0:0:0:0:0:1:63106, probably expired (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 18:57:48,643] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:63106 which had sessionid 0x10003b9f7140002 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-25 18:57:48,643] WARN Unable to reconnect to ZooKeeper service, session 0x10003b9f7140002 has expired (org.apache.zookeeper.ClientCnxn)
[2019-01-25 18:57:48,643] INFO Unable to reconnect to ZooKeeper service, session 0x10003b9f7140002 has expired, closing socket connection (org.apache.zookeeper.ClientCnxn)
[2019-01-25 18:57:48,643] INFO EventThread shut down for session: 0x10003b9f7140002 (org.apache.zookeeper.ClientCnxn)
[2019-01-25 18:57:48,659] INFO [ZooKeeperClient] Session expired. (kafka.zookeeper.ZooKeeperClient)
[2019-01-25 18:57:48,690] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-25 18:57:48,690] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@1622f1b (org.apache.zookeeper.ZooKeeper)
[2019-01-25 18:57:48,706] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-25 18:57:48,706] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-25 18:57:48,706] INFO Accepted socket connection from /127.0.0.1:63110 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-25 18:57:48,706] INFO Client attempting to establish new session at /127.0.0.1:63110 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 18:57:48,721] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10003b9f7140009, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-25 18:57:48,737] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-25 18:57:48,721] INFO Established session 0x10003b9f7140009 with negotiated timeout 6000 for client /127.0.0.1:63110 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 18:57:48,784] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-25 18:57:48,784] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-25 18:57:48,784] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:63111 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-25 18:57:48,784] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-25 18:57:48,816] INFO Client attempting to renew session 0x10003b9f7140001 at /0:0:0:0:0:0:0:1:63111 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 18:57:48,816] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-25 18:57:48,862] INFO Invalid session 0x10003b9f7140001 for client /0:0:0:0:0:0:0:1:63111, probably expired (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 18:57:48,862] WARN Unable to reconnect to ZooKeeper service, session 0x10003b9f7140001 has expired (org.apache.zookeeper.ClientCnxn)
[2019-01-25 18:57:48,862] INFO EventThread shut down for session: 0x10003b9f7140001 (org.apache.zookeeper.ClientCnxn)
[2019-01-25 18:57:48,862] INFO Result of znode creation at /brokers/ids/3 is: OK (kafka.zk.KafkaZkClient)
[2019-01-25 18:57:48,862] INFO Unable to reconnect to ZooKeeper service, session 0x10003b9f7140001 has expired, closing socket connection (org.apache.zookeeper.ClientCnxn)
[2019-01-25 18:57:48,878] INFO Registered broker 3 at path /brokers/ids/3 with addresses: ArrayBuffer(EndPoint(localhost,9095,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-25 18:57:48,862] INFO [ZooKeeperClient] Session expired. (kafka.zookeeper.ZooKeeperClient)
[2019-01-25 18:57:48,862] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:63112 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-25 18:57:48,878] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:63111 which had sessionid 0x10003b9f7140001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-25 18:57:48,878] INFO Client attempting to renew session 0x10003b9f7140000 at /0:0:0:0:0:0:0:1:63112 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 18:57:48,878] INFO Invalid session 0x10003b9f7140000 for client /0:0:0:0:0:0:0:1:63112, probably expired (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 18:57:48,878] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:63112 which had sessionid 0x10003b9f7140000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-25 18:57:48,878] WARN Unable to reconnect to ZooKeeper service, session 0x10003b9f7140000 has expired (org.apache.zookeeper.ClientCnxn)
[2019-01-25 18:57:48,909] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-25 18:57:48,909] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@1622f1b (org.apache.zookeeper.ZooKeeper)
[2019-01-25 18:57:48,893] INFO Unable to reconnect to ZooKeeper service, session 0x10003b9f7140000 has expired, closing socket connection (org.apache.zookeeper.ClientCnxn)
[2019-01-25 18:57:48,893] INFO EventThread shut down for session: 0x10003b9f7140000 (org.apache.zookeeper.ClientCnxn)
[2019-01-25 18:57:48,925] INFO [ZooKeeperClient] Session expired. (kafka.zookeeper.ZooKeeperClient)
[2019-01-25 18:57:48,940] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-25 18:57:48,940] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-25 18:57:48,940] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:63115 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-25 18:57:48,956] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:63115 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 18:57:48,956] INFO Established session 0x10003b9f714000a with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:63115 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 18:57:48,956] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10003b9f714000a, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-25 18:57:49,018] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-25 18:57:49,034] INFO Result of znode creation at /brokers/ids/2 is: OK (kafka.zk.KafkaZkClient)
[2019-01-25 18:57:49,034] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-25 18:57:49,049] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(localhost,9094,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-25 18:57:49,049] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@1622f1b (org.apache.zookeeper.ZooKeeper)
[2019-01-25 18:57:49,081] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-25 18:57:49,081] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-25 18:57:49,081] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:63118 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-25 18:57:49,081] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:63118 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 18:57:49,081] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10003b9f714000b, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-25 18:57:49,081] INFO Established session 0x10003b9f714000b with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:63118 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 18:57:49,112] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-25 18:57:49,190] INFO Result of znode creation at /brokers/ids/1 is: OK (kafka.zk.KafkaZkClient)
[2019-01-25 18:57:49,190] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(localhost,9093,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-25 18:57:49,690] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools10-2, pairs-1, aggregated_data-1, tools1-0, randommessages-0, tools8-0, tools12-1, tools14-0, edited10-0, tools6-2, tools11-1, mytools-1, edited8-0, edited-2, tools13-0, edited13-2, tools4-2, tools3-1, tools5-0, edited6-2, tools-1, edited12-0, tools2-1, aggregateddata-1, alltools-1, tools7-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 18:57:49,690] INFO [Partition alltools-1 broker=3] alltools-1 starts at Leader Epoch 28 from offset 6. Previous Leader Epoch was: 27 (kafka.cluster.Partition)
[2019-01-25 18:57:49,706] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140009 type:multi cxid:0x16d zxid:0xc50 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 18:57:49,721] INFO [Partition edited8-0 broker=3] edited8-0 starts at Leader Epoch 5 from offset 1. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-25 18:57:49,721] INFO [Partition edited13-2 broker=3] edited13-2 starts at Leader Epoch 1 from offset 2. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-25 18:57:49,721] INFO Got user-level KeeperException when processing sessionid:0x10003b9f7140009 type:multi cxid:0x16f zxid:0xc51 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 18:57:49,737] INFO [Partition edited-2 broker=3] edited-2 starts at Leader Epoch 25 from offset 8. Previous Leader Epoch was: 24 (kafka.cluster.Partition)
[2019-01-25 18:57:49,752] INFO [Partition mytools-1 broker=3] mytools-1 starts at Leader Epoch 25 from offset 0. Previous Leader Epoch was: 24 (kafka.cluster.Partition)
[2019-01-25 18:57:49,784] INFO [Partition tools5-0 broker=3] tools5-0 starts at Leader Epoch 25 from offset 10. Previous Leader Epoch was: 24 (kafka.cluster.Partition)
[2019-01-25 18:57:49,815] INFO [Partition aggregateddata-1 broker=3] aggregateddata-1 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-25 18:57:49,831] INFO [Partition tools8-0 broker=3] tools8-0 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-25 18:57:49,831] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools13-0, tools8-0, tools11-1, tools10-2, aggregateddata-1, tools14-0, tools6-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 18:57:49,846] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(tools10-2 -> (offset=0, leaderEpoch=2), tools8-0 -> (offset=0, leaderEpoch=4), tools14-0 -> (offset=0, leaderEpoch=1), tools6-2 -> (offset=3, leaderEpoch=8), tools11-1 -> (offset=0, leaderEpoch=2), tools13-0 -> (offset=2, leaderEpoch=1), aggregateddata-1 -> (offset=1, leaderEpoch=1)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 18:57:49,846] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(edited12-0, tools-1, edited-2, randommessages-0, tools4-2, tools1-0, alltools-1, tools7-1, mytools-1, edited10-0, edited8-0, tools2-1, aggregated_data-1, tools12-1, edited13-2, pairs-1, tools3-1, tools5-0, edited6-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 18:57:49,846] INFO [Partition edited6-2 broker=3] edited6-2 starts at Leader Epoch 18 from offset 4. Previous Leader Epoch was: 17 (kafka.cluster.Partition)
[2019-01-25 18:57:49,893] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(pairs-1 -> (offset=5, leaderEpoch=1), aggregated_data-1 -> (offset=0, leaderEpoch=3), tools1-0 -> (offset=0, leaderEpoch=25), randommessages-0 -> (offset=11, leaderEpoch=1), tools12-1 -> (offset=0, leaderEpoch=3), edited10-0 -> (offset=0, leaderEpoch=3), mytools-1 -> (offset=0, leaderEpoch=25), edited8-0 -> (offset=1, leaderEpoch=5), edited-2 -> (offset=8, leaderEpoch=25), edited13-2 -> (offset=2, leaderEpoch=1), tools4-2 -> (offset=1, leaderEpoch=25), tools3-1 -> (offset=1, leaderEpoch=25), tools5-0 -> (offset=10, leaderEpoch=25), edited6-2 -> (offset=4, leaderEpoch=18), tools-1 -> (offset=0, leaderEpoch=25), edited12-0 -> (offset=1, leaderEpoch=3), tools2-1 -> (offset=1, leaderEpoch=25), alltools-1 -> (offset=6, leaderEpoch=28), tools7-1 -> (offset=0, leaderEpoch=13)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 18:57:49,909] INFO [Partition pairs-1 broker=3] pairs-1 starts at Leader Epoch 1 from offset 5. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-25 18:57:49,924] INFO [Partition tools12-1 broker=3] tools12-1 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-25 18:57:49,924] INFO [Partition tools3-1 broker=3] tools3-1 starts at Leader Epoch 25 from offset 1. Previous Leader Epoch was: 24 (kafka.cluster.Partition)
[2019-01-25 18:57:49,971] INFO [Partition tools4-2 broker=3] tools4-2 starts at Leader Epoch 25 from offset 1. Previous Leader Epoch was: 24 (kafka.cluster.Partition)
[2019-01-25 18:57:49,971] INFO [Partition edited10-0 broker=3] edited10-0 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-25 18:57:49,987] INFO [Partition tools14-0 broker=3] tools14-0 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-25 18:57:50,002] INFO [Partition tools-1 broker=3] tools-1 starts at Leader Epoch 25 from offset 0. Previous Leader Epoch was: 24 (kafka.cluster.Partition)
[2019-01-25 18:57:50,002] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(edited8-2, __consumer_offsets-30, pairing-stream-app-pairs-store-changelog-1, __consumer_offsets-21, tools7-0, __consumer_offsets-27, __consumer_offsets-9, tools3-0, tools4-1, tools5-2, __consumer_offsets-33, tools1-2, edited-1, test-0, mytools-0, __consumer_offsets-36, edited12-2, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, pairs-0, __consumer_offsets-15, __consumer_offsets-24, alltools-0, aggregated_data-0, __consumer_offsets-48, tools-0, randommessages-2, edited10-2, __consumer_offsets-6, edited6-1, __consumer_offsets-0, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, tools12-0, edited13-1, tools2-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 18:57:50,018] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-22, pairing-stream-app-pairs-store-changelog-2, __consumer_offsets-4, tools8-1, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-37, aggregateddata-2, tools10-0, tools14-1, my-example-topic-0, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, tools11-2, tools13-1, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-10, tools6-0, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-01-25 18:57:50,018] INFO [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 4 from offset 6. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-25 18:57:50,018] INFO [Partition randommessages-0 broker=3] randommessages-0 starts at Leader Epoch 1 from offset 11. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-25 18:57:50,034] INFO [Partition pairing-stream-app-pairs-store-changelog-2 broker=2] pairing-stream-app-pairs-store-changelog-2 starts at Leader Epoch 1 from offset 11. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-25 18:57:50,034] INFO [Partition __consumer_offsets-10 broker=2] __consumer_offsets-10 starts at Leader Epoch 19 from offset 43. Previous Leader Epoch was: 18 (kafka.cluster.Partition)
[2019-01-25 18:57:50,034] INFO [Partition tools10-2 broker=3] tools10-2 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-25 18:57:50,049] WARN [LeaderEpochCache __consumer_offsets-10] New epoch entry EpochEntry(epoch=19, startOffset=43) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=18, startOffset=43)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,049] INFO [Partition edited6-1 broker=1] edited6-1 starts at Leader Epoch 4 from offset 7. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-25 18:57:50,065] INFO [Partition __consumer_offsets-7 broker=2] __consumer_offsets-7 starts at Leader Epoch 19 from offset 6. Previous Leader Epoch was: 18 (kafka.cluster.Partition)
[2019-01-25 18:57:50,065] WARN [LeaderEpochCache __consumer_offsets-7] New epoch entry EpochEntry(epoch=19, startOffset=6) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=18, startOffset=6)). Cache now contains 4 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,065] INFO [Partition tools2-1 broker=3] tools2-1 starts at Leader Epoch 25 from offset 1. Previous Leader Epoch was: 24 (kafka.cluster.Partition)
[2019-01-25 18:57:50,049] WARN [LeaderEpochCache edited6-1] New epoch entry EpochEntry(epoch=4, startOffset=7) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=7)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,065] INFO [Partition __consumer_offsets-4 broker=2] __consumer_offsets-4 starts at Leader Epoch 19 from offset 0. Previous Leader Epoch was: 18 (kafka.cluster.Partition)
[2019-01-25 18:57:50,081] WARN [LeaderEpochCache __consumer_offsets-4] New epoch entry EpochEntry(epoch=19, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=18, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,081] INFO [Partition tools1-0 broker=3] tools1-0 starts at Leader Epoch 25 from offset 0. Previous Leader Epoch was: 24 (kafka.cluster.Partition)
[2019-01-25 18:57:50,081] INFO [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-25 18:57:50,081] WARN [LeaderEpochCache __consumer_offsets-48] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,081] INFO [Partition tools6-0 broker=2] tools6-0 starts at Leader Epoch 8 from offset 5. Previous Leader Epoch was: 7 (kafka.cluster.Partition)
[2019-01-25 18:57:50,081] INFO [Partition aggregated_data-1 broker=3] aggregated_data-1 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-25 18:57:50,081] INFO [Partition mytools-0 broker=1] mytools-0 starts at Leader Epoch 7 from offset 1. Previous Leader Epoch was: 6 (kafka.cluster.Partition)
[2019-01-25 18:57:50,081] WARN [LeaderEpochCache mytools-0] New epoch entry EpochEntry(epoch=7, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=6, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,096] INFO [Partition __consumer_offsets-1 broker=2] __consumer_offsets-1 starts at Leader Epoch 19 from offset 3. Previous Leader Epoch was: 18 (kafka.cluster.Partition)
[2019-01-25 18:57:50,096] WARN [LeaderEpochCache __consumer_offsets-1] New epoch entry EpochEntry(epoch=19, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=18, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,096] INFO [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-25 18:57:50,096] WARN [LeaderEpochCache __consumer_offsets-45] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,096] INFO [Partition tools6-2 broker=3] tools6-2 starts at Leader Epoch 8 from offset 3. Previous Leader Epoch was: 7 (kafka.cluster.Partition)
[2019-01-25 18:57:50,096] INFO [Partition tools4-1 broker=1] tools4-1 starts at Leader Epoch 7 from offset 0. Previous Leader Epoch was: 6 (kafka.cluster.Partition)
[2019-01-25 18:57:50,096] WARN [LeaderEpochCache tools4-1] New epoch entry EpochEntry(epoch=7, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=6, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,112] INFO [Partition edited12-0 broker=3] edited12-0 starts at Leader Epoch 3 from offset 1. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-25 18:57:50,112] INFO [Partition tools11-2 broker=2] tools11-2 starts at Leader Epoch 2 from offset 1. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-25 18:57:50,112] INFO [Partition edited10-2 broker=1] edited10-2 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-25 18:57:50,112] INFO [Partition tools11-1 broker=3] tools11-1 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-25 18:57:50,112] INFO [Partition tools13-1 broker=2] tools13-1 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-25 18:57:50,112] WARN [LeaderEpochCache tools13-1] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,112] INFO [Partition tools5-2 broker=1] tools5-2 starts at Leader Epoch 7 from offset 8. Previous Leader Epoch was: 6 (kafka.cluster.Partition)
[2019-01-25 18:57:50,112] WARN [LeaderEpochCache tools5-2] New epoch entry EpochEntry(epoch=7, startOffset=8) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=6, startOffset=8)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,127] INFO [Partition tools13-0 broker=3] tools13-0 starts at Leader Epoch 1 from offset 2. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-25 18:57:50,127] INFO [Partition __consumer_offsets-49 broker=2] __consumer_offsets-49 starts at Leader Epoch 19 from offset 0. Previous Leader Epoch was: 18 (kafka.cluster.Partition)
[2019-01-25 18:57:50,127] WARN [LeaderEpochCache __consumer_offsets-49] New epoch entry EpochEntry(epoch=19, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=18, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,127] INFO [Partition tools3-0 broker=1] tools3-0 starts at Leader Epoch 7 from offset 0. Previous Leader Epoch was: 6 (kafka.cluster.Partition)
[2019-01-25 18:57:50,127] INFO [Partition tools7-1 broker=3] tools7-1 starts at Leader Epoch 13 from offset 0. Previous Leader Epoch was: 12 (kafka.cluster.Partition)
[2019-01-25 18:57:50,127] WARN [LeaderEpochCache tools3-0] New epoch entry EpochEntry(epoch=7, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=6, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,143] INFO [Partition __consumer_offsets-46 broker=2] __consumer_offsets-46 starts at Leader Epoch 19 from offset 3. Previous Leader Epoch was: 18 (kafka.cluster.Partition)
[2019-01-25 18:57:50,143] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:50,143] WARN [LeaderEpochCache __consumer_offsets-46] New epoch entry EpochEntry(epoch=19, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=18, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,143] INFO [Partition pairs-0 broker=1] pairs-0 starts at Leader Epoch 1 from offset 5. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-25 18:57:50,143] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:50,143] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:50,159] INFO [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 4 from offset 3. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-25 18:57:50,143] INFO [Partition __consumer_offsets-43 broker=2] __consumer_offsets-43 starts at Leader Epoch 19 from offset 0. Previous Leader Epoch was: 18 (kafka.cluster.Partition)
[2019-01-25 18:57:50,159] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:50,159] WARN [LeaderEpochCache __consumer_offsets-43] New epoch entry EpochEntry(epoch=19, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=18, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,159] WARN [LeaderEpochCache __consumer_offsets-42] New epoch entry EpochEntry(epoch=4, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,159] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:50,159] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:50,159] INFO [Partition my-example-topic-0 broker=2] my-example-topic-0 starts at Leader Epoch 17 from offset 0. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-25 18:57:50,159] WARN [LeaderEpochCache my-example-topic-0] New epoch entry EpochEntry(epoch=17, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=16, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,159] INFO [Partition tools-0 broker=1] tools-0 starts at Leader Epoch 7 from offset 1. Previous Leader Epoch was: 6 (kafka.cluster.Partition)
[2019-01-25 18:57:50,159] WARN [LeaderEpochCache tools-0] New epoch entry EpochEntry(epoch=7, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=6, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,174] INFO [Partition __consumer_offsets-40 broker=2] __consumer_offsets-40 starts at Leader Epoch 19 from offset 3. Previous Leader Epoch was: 18 (kafka.cluster.Partition)
[2019-01-25 18:57:50,174] WARN [LeaderEpochCache __consumer_offsets-40] New epoch entry EpochEntry(epoch=19, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=18, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,190] INFO [Partition randommessages-2 broker=1] randommessages-2 starts at Leader Epoch 1 from offset 11. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-25 18:57:50,190] INFO [Partition __consumer_offsets-37 broker=2] __consumer_offsets-37 starts at Leader Epoch 19 from offset 8. Previous Leader Epoch was: 18 (kafka.cluster.Partition)
[2019-01-25 18:57:50,190] INFO [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 4 from offset 31. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-25 18:57:50,190] WARN [LeaderEpochCache __consumer_offsets-39] New epoch entry EpochEntry(epoch=4, startOffset=31) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=31)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,205] INFO [Partition __consumer_offsets-34 broker=2] __consumer_offsets-34 starts at Leader Epoch 19 from offset 6. Previous Leader Epoch was: 18 (kafka.cluster.Partition)
[2019-01-25 18:57:50,205] WARN [LeaderEpochCache __consumer_offsets-34] New epoch entry EpochEntry(epoch=19, startOffset=6) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=18, startOffset=6)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,205] INFO [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-25 18:57:50,205] WARN [LeaderEpochCache __consumer_offsets-36] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,205] INFO [Partition __consumer_offsets-31 broker=2] __consumer_offsets-31 starts at Leader Epoch 19 from offset 37. Previous Leader Epoch was: 18 (kafka.cluster.Partition)
[2019-01-25 18:57:50,205] INFO [Partition tools12-0 broker=1] tools12-0 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-25 18:57:50,221] INFO [Partition tools8-1 broker=2] tools8-1 starts at Leader Epoch 2 from offset 1. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-25 18:57:50,221] INFO [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 4 from offset 3. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-25 18:57:50,221] INFO [Log partition=edited-2, dir=C:\tmp\logs2] Truncating to 8 has no effect as the largest offset in the log is 7 (kafka.log.Log)
[2019-01-25 18:57:50,221] INFO [Log partition=edited8-0, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 18:57:50,221] INFO [Log partition=edited10-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 18:57:50,221] INFO [Log partition=tools-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 18:57:50,237] INFO [Log partition=pairs-1, dir=C:\tmp\logs2] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.Log)
[2019-01-25 18:57:50,237] INFO [Log partition=edited13-2, dir=C:\tmp\logs2] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-01-25 18:57:50,237] INFO [Log partition=edited12-0, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 18:57:50,237] INFO [Log partition=alltools-1, dir=C:\tmp\logs2] Truncating to 6 has no effect as the largest offset in the log is 5 (kafka.log.Log)
[2019-01-25 18:57:50,237] INFO [Log partition=randommessages-0, dir=C:\tmp\logs2] Truncating to 11 has no effect as the largest offset in the log is 10 (kafka.log.Log)
[2019-01-25 18:57:50,237] INFO [Log partition=tools1-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 18:57:50,237] INFO [Log partition=tools2-1, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 18:57:50,237] INFO [Log partition=mytools-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 18:57:50,237] INFO [Log partition=tools12-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 18:57:50,237] INFO [Log partition=aggregated_data-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 18:57:50,237] INFO [Log partition=tools5-0, dir=C:\tmp\logs2] Truncating to 10 has no effect as the largest offset in the log is 9 (kafka.log.Log)
[2019-01-25 18:57:50,221] WARN [LeaderEpochCache __consumer_offsets-33] New epoch entry EpochEntry(epoch=4, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,237] INFO [Log partition=tools3-1, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 18:57:50,237] INFO [Log partition=tools4-2, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 18:57:50,237] INFO [Log partition=edited6-2, dir=C:\tmp\logs2] Truncating to 4 has no effect as the largest offset in the log is 3 (kafka.log.Log)
[2019-01-25 18:57:50,237] INFO [Log partition=tools7-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 18:57:50,237] INFO [Partition aggregateddata-2 broker=2] aggregateddata-2 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-25 18:57:50,237] WARN [LeaderEpochCache aggregateddata-2] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,237] INFO [Log partition=tools11-1, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 18:57:50,237] INFO [Log partition=tools10-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 18:57:50,237] INFO [Log partition=tools14-0, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 18:57:50,237] INFO [Log partition=tools13-0, dir=C:\tmp\logs1] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-01-25 18:57:50,237] INFO [Log partition=tools6-2, dir=C:\tmp\logs1] Truncating to 3 has no effect as the largest offset in the log is 2 (kafka.log.Log)
[2019-01-25 18:57:50,252] INFO [Log partition=tools8-0, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 18:57:50,252] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs1] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 18:57:50,252] INFO [Partition pairs-1 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-25 18:57:50,252] INFO [Partition tools10-2 broker=3] Expanding ISR from 3 to 3,1 (kafka.cluster.Partition)
[2019-01-25 18:57:50,252] INFO [Partition __consumer_offsets-19 broker=2] __consumer_offsets-19 starts at Leader Epoch 19 from offset 7. Previous Leader Epoch was: 18 (kafka.cluster.Partition)
[2019-01-25 18:57:50,252] WARN [LeaderEpochCache __consumer_offsets-19] New epoch entry EpochEntry(epoch=19, startOffset=7) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=18, startOffset=7)). Cache now contains 5 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,252] INFO [Partition aggregated_data-0 broker=1] aggregated_data-0 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-25 18:57:50,252] INFO [Partition tools8-0 broker=3] Expanding ISR from 3 to 3,1 (kafka.cluster.Partition)
[2019-01-25 18:57:50,252] INFO [Partition aggregated_data-1 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-25 18:57:50,252] INFO [Partition tools1-2 broker=1] tools1-2 starts at Leader Epoch 7 from offset 0. Previous Leader Epoch was: 6 (kafka.cluster.Partition)
[2019-01-25 18:57:50,252] WARN [LeaderEpochCache tools1-2] New epoch entry EpochEntry(epoch=7, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=6, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,268] INFO [Partition tools14-0 broker=3] Expanding ISR from 3 to 3,1 (kafka.cluster.Partition)
[2019-01-25 18:57:50,268] INFO [Partition __consumer_offsets-28 broker=2] __consumer_offsets-28 starts at Leader Epoch 19 from offset 0. Previous Leader Epoch was: 18 (kafka.cluster.Partition)
[2019-01-25 18:57:50,268] WARN [LeaderEpochCache __consumer_offsets-28] New epoch entry EpochEntry(epoch=19, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=18, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,268] INFO [Partition tools1-0 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-25 18:57:50,268] INFO [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-25 18:57:50,268] INFO [Partition tools6-2 broker=3] Expanding ISR from 3 to 3,1 (kafka.cluster.Partition)
[2019-01-25 18:57:50,268] WARN [LeaderEpochCache __consumer_offsets-30] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,268] INFO [Partition tools10-0 broker=2] tools10-0 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-25 18:57:50,268] INFO [Partition randommessages-0 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-25 18:57:50,284] INFO [Partition tools11-1 broker=3] Expanding ISR from 3 to 3,1 (kafka.cluster.Partition)
[2019-01-25 18:57:50,284] INFO [Partition __consumer_offsets-25 broker=2] __consumer_offsets-25 starts at Leader Epoch 19 from offset 0. Previous Leader Epoch was: 18 (kafka.cluster.Partition)
[2019-01-25 18:57:50,284] WARN [LeaderEpochCache __consumer_offsets-25] New epoch entry EpochEntry(epoch=19, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=18, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,284] INFO [Partition tools12-1 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-25 18:57:50,284] INFO [Partition test-0 broker=1] test-0 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-25 18:57:50,284] INFO [Partition tools13-0 broker=3] Expanding ISR from 3 to 3,1 (kafka.cluster.Partition)
[2019-01-25 18:57:50,284] WARN [LeaderEpochCache test-0] New epoch entry EpochEntry(epoch=2, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,284] INFO [Partition edited10-0 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-25 18:57:50,284] INFO [Partition tools14-1 broker=2] tools14-1 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-25 18:57:50,284] INFO [Partition aggregateddata-1 broker=3] Expanding ISR from 3 to 3,1 (kafka.cluster.Partition)
[2019-01-25 18:57:50,284] INFO [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 4 from offset 3. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-25 18:57:50,299] INFO [Partition mytools-1 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-25 18:57:50,299] INFO [Partition __consumer_offsets-16 broker=2] __consumer_offsets-16 starts at Leader Epoch 19 from offset 0. Previous Leader Epoch was: 18 (kafka.cluster.Partition)
[2019-01-25 18:57:50,299] WARN [LeaderEpochCache __consumer_offsets-16] New epoch entry EpochEntry(epoch=19, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=18, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,299] INFO [Partition edited8-0 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-25 18:57:50,299] INFO [Partition tools2-0 broker=1] tools2-0 starts at Leader Epoch 7 from offset 0. Previous Leader Epoch was: 6 (kafka.cluster.Partition)
[2019-01-25 18:57:50,299] WARN [LeaderEpochCache tools2-0] New epoch entry EpochEntry(epoch=7, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=6, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,299] INFO [Partition edited-2 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-25 18:57:50,299] INFO [Partition __consumer_offsets-22 broker=2] __consumer_offsets-22 starts at Leader Epoch 19 from offset 5. Previous Leader Epoch was: 18 (kafka.cluster.Partition)
[2019-01-25 18:57:50,299] WARN [LeaderEpochCache __consumer_offsets-22] New epoch entry EpochEntry(epoch=19, startOffset=5) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=18, startOffset=5)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,315] INFO [Partition edited13-2 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-25 18:57:50,315] INFO [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 4 from offset 3. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-25 18:57:50,315] WARN [LeaderEpochCache __consumer_offsets-24] New epoch entry EpochEntry(epoch=4, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,315] INFO [Partition tools4-2 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-25 18:57:50,315] INFO [Partition __consumer_offsets-13 broker=2] __consumer_offsets-13 starts at Leader Epoch 19 from offset 6. Previous Leader Epoch was: 18 (kafka.cluster.Partition)
[2019-01-25 18:57:50,315] INFO [Partition tools3-1 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-25 18:57:50,315] WARN [LeaderEpochCache __consumer_offsets-13] New epoch entry EpochEntry(epoch=19, startOffset=6) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=18, startOffset=6)). Cache now contains 5 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,315] INFO [Partition edited12-2 broker=1] edited12-2 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-25 18:57:50,315] WARN [LeaderEpochCache edited12-2] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,315] INFO [Partition tools5-0 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-25 18:57:50,330] INFO [Partition edited6-2 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-25 18:57:50,330] INFO [Partition tools-1 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-25 18:57:50,330] INFO [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 4 from offset 3. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-25 18:57:50,330] WARN [LeaderEpochCache __consumer_offsets-21] New epoch entry EpochEntry(epoch=4, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,330] INFO [Partition edited12-0 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-25 18:57:50,330] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(alltools-0, tools7-0, edited8-2, mytools-0, edited10-2, tools5-2, tools2-0, edited13-1, tools12-0, edited12-2, pairs-0, tools3-0, randommessages-2, aggregated_data-0, edited6-1, tools1-2, tools4-1, tools-0, edited-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 18:57:50,330] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(edited8-2 -> (offset=0, leaderEpoch=3), tools7-0 -> (offset=1, leaderEpoch=4), tools3-0 -> (offset=0, leaderEpoch=7), tools4-1 -> (offset=0, leaderEpoch=7), tools5-2 -> (offset=8, leaderEpoch=7), tools1-2 -> (offset=0, leaderEpoch=7), edited-1 -> (offset=9, leaderEpoch=7), mytools-0 -> (offset=1, leaderEpoch=7), edited12-2 -> (offset=0, leaderEpoch=1), pairs-0 -> (offset=5, leaderEpoch=1), alltools-0 -> (offset=4, leaderEpoch=8), aggregated_data-0 -> (offset=1, leaderEpoch=1), tools-0 -> (offset=1, leaderEpoch=7), randommessages-2 -> (offset=11, leaderEpoch=1), edited10-2 -> (offset=1, leaderEpoch=1), edited6-1 -> (offset=7, leaderEpoch=4), tools12-0 -> (offset=1, leaderEpoch=1), edited13-1 -> (offset=0, leaderEpoch=1), tools2-0 -> (offset=0, leaderEpoch=7)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 18:57:50,346] INFO [Partition tools2-1 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-25 18:57:50,346] INFO [Partition alltools-1 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-25 18:57:50,346] INFO [Partition edited8-2 broker=1] edited8-2 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-25 18:57:50,346] WARN [LeaderEpochCache edited8-2] New epoch entry EpochEntry(epoch=3, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,346] INFO [Partition tools7-1 broker=3] Expanding ISR from 3 to 3,2 (kafka.cluster.Partition)
[2019-01-25 18:57:50,362] INFO [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 4 from offset 3. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-25 18:57:50,362] WARN [LeaderEpochCache __consumer_offsets-18] New epoch entry EpochEntry(epoch=4, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,362] INFO [Partition pairing-stream-app-pairs-store-changelog-1 broker=1] pairing-stream-app-pairs-store-changelog-1 starts at Leader Epoch 1 from offset 10. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-25 18:57:50,362] INFO [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-25 18:57:50,362] WARN [LeaderEpochCache __consumer_offsets-15] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,377] INFO [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-25 18:57:50,377] WARN [LeaderEpochCache __consumer_offsets-12] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,377] INFO [Partition edited-1 broker=1] edited-1 starts at Leader Epoch 7 from offset 9. Previous Leader Epoch was: 6 (kafka.cluster.Partition)
[2019-01-25 18:57:50,377] WARN [LeaderEpochCache edited-1] New epoch entry EpochEntry(epoch=7, startOffset=9) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=6, startOffset=9)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,393] INFO [Partition tools7-0 broker=1] tools7-0 starts at Leader Epoch 4 from offset 1. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-25 18:57:50,393] WARN [LeaderEpochCache tools7-0] New epoch entry EpochEntry(epoch=4, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,393] INFO [Partition edited13-1 broker=1] edited13-1 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-25 18:57:50,393] WARN [LeaderEpochCache edited13-1] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,409] INFO [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-25 18:57:50,409] WARN [LeaderEpochCache __consumer_offsets-9] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,409] INFO [Partition alltools-0 broker=1] alltools-0 starts at Leader Epoch 8 from offset 4. Previous Leader Epoch was: 7 (kafka.cluster.Partition)
[2019-01-25 18:57:50,409] WARN [LeaderEpochCache alltools-0] New epoch entry EpochEntry(epoch=8, startOffset=4) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=7, startOffset=4)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,424] INFO [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-25 18:57:50,424] WARN [LeaderEpochCache __consumer_offsets-6] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,424] INFO [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-25 18:57:50,424] WARN [LeaderEpochCache __consumer_offsets-3] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:50,440] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(aggregateddata-2, tools10-0, tools11-2, tools13-1, tools14-1, tools6-0, tools8-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 18:57:50,440] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(tools8-1 -> (offset=1, leaderEpoch=2), aggregateddata-2 -> (offset=0, leaderEpoch=1), tools10-0 -> (offset=0, leaderEpoch=2), tools14-1 -> (offset=1, leaderEpoch=1), tools11-2 -> (offset=1, leaderEpoch=2), tools13-1 -> (offset=0, leaderEpoch=1), tools6-0 -> (offset=5, leaderEpoch=8)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 18:57:50,705] INFO [Log partition=edited10-2, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 18:57:50,705] INFO [Log partition=edited-1, dir=C:\tmp\logs2] Truncating to 9 has no effect as the largest offset in the log is 8 (kafka.log.Log)
[2019-01-25 18:57:50,705] INFO [Log partition=mytools-0, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 18:57:50,705] INFO [Log partition=randommessages-2, dir=C:\tmp\logs2] Truncating to 11 has no effect as the largest offset in the log is 10 (kafka.log.Log)
[2019-01-25 18:57:50,705] INFO [Log partition=tools-0, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 18:57:50,705] INFO [Log partition=pairs-0, dir=C:\tmp\logs2] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.Log)
[2019-01-25 18:57:50,705] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in edited12-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:50,705] INFO [Log partition=edited12-2, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 18:57:50,705] INFO [Log partition=alltools-0, dir=C:\tmp\logs2] Truncating to 4 has no effect as the largest offset in the log is 3 (kafka.log.Log)
[2019-01-25 18:57:50,705] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in edited13-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:50,705] INFO [Log partition=edited13-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 18:57:50,705] INFO [Log partition=tools12-0, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 18:57:50,705] INFO [Log partition=aggregated_data-0, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 18:57:50,705] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools1-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:50,705] INFO [Log partition=tools1-2, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 18:57:50,705] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in edited8-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:50,705] INFO [Log partition=edited8-2, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 18:57:50,705] INFO [Log partition=edited6-1, dir=C:\tmp\logs2] Truncating to 7 has no effect as the largest offset in the log is 6 (kafka.log.Log)
[2019-01-25 18:57:50,705] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools2-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:50,705] INFO [Log partition=tools2-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 18:57:50,705] INFO [Log partition=tools5-2, dir=C:\tmp\logs2] Truncating to 8 has no effect as the largest offset in the log is 7 (kafka.log.Log)
[2019-01-25 18:57:50,705] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools3-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:50,705] INFO [Log partition=tools3-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 18:57:50,705] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools4-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:50,705] INFO [Log partition=tools4-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 18:57:50,705] INFO [Log partition=tools7-0, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 18:57:50,720] INFO [Log partition=tools10-0, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 18:57:50,720] INFO [Log partition=tools11-2, dir=C:\tmp\logs1] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 18:57:50,720] INFO [Log partition=tools14-1, dir=C:\tmp\logs1] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 18:57:50,720] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools13-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:50,720] INFO [Log partition=tools13-1, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 18:57:50,720] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in aggregateddata-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:50,720] INFO [Log partition=aggregateddata-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 18:57:50,720] INFO [Log partition=tools6-0, dir=C:\tmp\logs1] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.Log)
[2019-01-25 18:57:50,720] INFO [Log partition=tools8-1, dir=C:\tmp\logs1] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 18:57:54,771] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(edited12-0, tools-1, edited-2, randommessages-0, tools4-2, tools1-0, alltools-1, tools7-1, mytools-1, edited10-0, edited8-0, tools2-1, aggregated_data-1, tools12-1, edited13-2, tools3-1, pairs-1, tools5-0, edited6-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 18:57:54,771] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(pairs-1, aggregated_data-1, tools1-0, randommessages-0, tools12-1, edited10-0, mytools-1, edited8-0, edited-2, edited13-2, tools4-2, tools3-1, tools5-0, edited6-2, tools-1, edited12-0, tools2-1, alltools-1, tools7-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 18:57:54,787] INFO [Partition edited8-0 broker=2] edited8-0 starts at Leader Epoch 6 from offset 1. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2019-01-25 18:57:54,787] WARN [LeaderEpochCache edited8-0] New epoch entry EpochEntry(epoch=6, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:54,787] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools10-2, tools8-0, tools14-0, tools6-2, tools11-1, tools13-0, aggregateddata-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 18:57:54,787] INFO [Partition tools8-0 broker=1] tools8-0 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-25 18:57:54,787] WARN [LeaderEpochCache tools8-0] New epoch entry EpochEntry(epoch=5, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=3, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:54,787] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(pairs-1 -> (offset=5, leaderEpoch=2), aggregated_data-1 -> (offset=0, leaderEpoch=4), tools1-0 -> (offset=0, leaderEpoch=26), randommessages-0 -> (offset=11, leaderEpoch=2), tools12-1 -> (offset=0, leaderEpoch=4), edited10-0 -> (offset=0, leaderEpoch=4), mytools-1 -> (offset=0, leaderEpoch=26), edited8-0 -> (offset=1, leaderEpoch=6), edited-2 -> (offset=8, leaderEpoch=26), edited13-2 -> (offset=2, leaderEpoch=2), tools4-2 -> (offset=1, leaderEpoch=26), tools3-1 -> (offset=1, leaderEpoch=26), tools5-0 -> (offset=10, leaderEpoch=26), edited6-2 -> (offset=4, leaderEpoch=19), tools-1 -> (offset=0, leaderEpoch=26), edited12-0 -> (offset=1, leaderEpoch=4), tools2-1 -> (offset=1, leaderEpoch=26), alltools-1 -> (offset=6, leaderEpoch=29), tools7-1 -> (offset=0, leaderEpoch=14)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 18:57:54,802] INFO [Partition alltools-1 broker=2] alltools-1 starts at Leader Epoch 29 from offset 6. Previous Leader Epoch was: 28 (kafka.cluster.Partition)
[2019-01-25 18:57:54,787] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:54,802] WARN [LeaderEpochCache alltools-1] New epoch entry EpochEntry(epoch=29, startOffset=6) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=27, startOffset=6)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:54,802] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools13-0, tools8-0, tools11-1, tools10-2, aggregateddata-1, tools14-0, tools6-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 18:57:54,818] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(tools10-2 -> (offset=0, leaderEpoch=3), tools8-0 -> (offset=0, leaderEpoch=5), tools14-0 -> (offset=0, leaderEpoch=2), tools6-2 -> (offset=3, leaderEpoch=9), tools11-1 -> (offset=0, leaderEpoch=3), tools13-0 -> (offset=2, leaderEpoch=2), aggregateddata-1 -> (offset=1, leaderEpoch=2)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 18:57:54,818] INFO [Partition aggregateddata-1 broker=1] aggregateddata-1 starts at Leader Epoch 2 from offset 1. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-25 18:57:54,818] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:54,833] INFO [Partition edited-2 broker=2] edited-2 starts at Leader Epoch 26 from offset 8. Previous Leader Epoch was: 25 (kafka.cluster.Partition)
[2019-01-25 18:57:54,833] WARN [LeaderEpochCache edited-2] New epoch entry EpochEntry(epoch=26, startOffset=8) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=24, startOffset=8)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:54,833] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition edited-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:54,833] INFO [Log partition=edited8-0, dir=C:\tmp\logs3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 18:57:54,833] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition edited10-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:54,833] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition tools-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:54,833] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition pairs-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:54,833] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition edited13-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:54,833] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition edited12-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:54,833] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Truncating to 6 has no effect as the largest offset in the log is 5 (kafka.log.Log)
[2019-01-25 18:57:54,833] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition randommessages-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:54,833] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition tools1-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:54,833] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition tools2-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:54,849] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition mytools-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:54,849] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition tools12-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:54,849] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition aggregated_data-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:54,849] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition tools5-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:54,849] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition tools3-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:54,849] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition tools4-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:54,849] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition edited6-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:54,849] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Retrying leaderEpoch request for partition tools7-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:54,849] INFO [Partition edited13-2 broker=2] edited13-2 starts at Leader Epoch 2 from offset 2. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-25 18:57:54,865] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Retrying leaderEpoch request for partition tools11-1 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:54,880] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Retrying leaderEpoch request for partition tools10-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:54,880] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Retrying leaderEpoch request for partition tools14-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:54,880] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Retrying leaderEpoch request for partition tools13-0 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:54,880] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Retrying leaderEpoch request for partition tools6-2 as the leader reported an error: UNKNOWN_LEADER_EPOCH (kafka.server.ReplicaFetcherThread)
[2019-01-25 18:57:54,880] INFO [Log partition=tools8-0, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 18:57:54,880] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 18:57:54,865] INFO [Partition tools14-0 broker=1] tools14-0 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-25 18:57:54,880] WARN [LeaderEpochCache tools14-0] New epoch entry EpochEntry(epoch=2, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:54,896] INFO [Partition mytools-1 broker=2] mytools-1 starts at Leader Epoch 26 from offset 0. Previous Leader Epoch was: 25 (kafka.cluster.Partition)
[2019-01-25 18:57:54,896] WARN [LeaderEpochCache mytools-1] New epoch entry EpochEntry(epoch=26, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=24, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:54,912] INFO [Partition tools10-2 broker=1] tools10-2 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-25 18:57:54,912] INFO [Partition tools5-0 broker=2] tools5-0 starts at Leader Epoch 26 from offset 10. Previous Leader Epoch was: 25 (kafka.cluster.Partition)
[2019-01-25 18:57:54,912] WARN [LeaderEpochCache tools5-0] New epoch entry EpochEntry(epoch=26, startOffset=10) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=24, startOffset=10)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:54,912] WARN [LeaderEpochCache tools10-2] New epoch entry EpochEntry(epoch=3, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:54,943] INFO [Partition edited6-2 broker=2] edited6-2 starts at Leader Epoch 19 from offset 4. Previous Leader Epoch was: 18 (kafka.cluster.Partition)
[2019-01-25 18:57:54,943] WARN [LeaderEpochCache edited6-2] New epoch entry EpochEntry(epoch=19, startOffset=4) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=17, startOffset=4)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:54,990] INFO [Partition tools6-2 broker=1] tools6-2 starts at Leader Epoch 9 from offset 3. Previous Leader Epoch was: 8 (kafka.cluster.Partition)
[2019-01-25 18:57:55,005] WARN [LeaderEpochCache tools6-2] New epoch entry EpochEntry(epoch=9, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=7, startOffset=3)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:55,036] INFO [Partition tools11-1 broker=1] tools11-1 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-25 18:57:55,036] INFO [Partition tools3-1 broker=2] tools3-1 starts at Leader Epoch 26 from offset 1. Previous Leader Epoch was: 25 (kafka.cluster.Partition)
[2019-01-25 18:57:55,052] WARN [LeaderEpochCache tools3-1] New epoch entry EpochEntry(epoch=26, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=24, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:55,036] WARN [LeaderEpochCache tools11-1] New epoch entry EpochEntry(epoch=3, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:55,068] INFO [Partition pairs-1 broker=2] pairs-1 starts at Leader Epoch 2 from offset 5. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-25 18:57:55,068] INFO [Partition tools13-0 broker=1] tools13-0 starts at Leader Epoch 2 from offset 2. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-25 18:57:55,083] INFO [Partition tools12-1 broker=2] tools12-1 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-25 18:57:55,099] WARN [LeaderEpochCache tools12-1] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:55,130] INFO [Partition tools4-2 broker=2] tools4-2 starts at Leader Epoch 26 from offset 1. Previous Leader Epoch was: 25 (kafka.cluster.Partition)
[2019-01-25 18:57:55,130] WARN [LeaderEpochCache tools4-2] New epoch entry EpochEntry(epoch=26, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=24, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:55,130] INFO [Partition edited10-0 broker=2] edited10-0 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-25 18:57:55,130] WARN [LeaderEpochCache edited10-0] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:55,146] INFO [Partition tools-1 broker=2] tools-1 starts at Leader Epoch 26 from offset 0. Previous Leader Epoch was: 25 (kafka.cluster.Partition)
[2019-01-25 18:57:55,146] WARN [LeaderEpochCache tools-1] New epoch entry EpochEntry(epoch=26, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=24, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:55,146] INFO [Partition randommessages-0 broker=2] randommessages-0 starts at Leader Epoch 2 from offset 11. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-25 18:57:55,177] INFO [Partition tools1-0 broker=2] tools1-0 starts at Leader Epoch 26 from offset 0. Previous Leader Epoch was: 25 (kafka.cluster.Partition)
[2019-01-25 18:57:55,177] WARN [LeaderEpochCache tools1-0] New epoch entry EpochEntry(epoch=26, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=24, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:55,193] INFO [Partition tools2-1 broker=2] tools2-1 starts at Leader Epoch 26 from offset 1. Previous Leader Epoch was: 25 (kafka.cluster.Partition)
[2019-01-25 18:57:55,193] WARN [LeaderEpochCache tools2-1] New epoch entry EpochEntry(epoch=26, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=24, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:55,208] INFO [Partition aggregated_data-1 broker=2] aggregated_data-1 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-25 18:57:55,208] WARN [LeaderEpochCache aggregated_data-1] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:55,208] INFO [Partition edited12-0 broker=2] edited12-0 starts at Leader Epoch 4 from offset 1. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-25 18:57:55,208] WARN [LeaderEpochCache edited12-0] New epoch entry EpochEntry(epoch=4, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:55,224] INFO [Partition tools7-1 broker=2] tools7-1 starts at Leader Epoch 14 from offset 0. Previous Leader Epoch was: 13 (kafka.cluster.Partition)
[2019-01-25 18:57:55,240] WARN [LeaderEpochCache tools7-1] New epoch entry EpochEntry(epoch=14, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=12, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 18:57:55,880] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Truncating to 8 has no effect as the largest offset in the log is 7 (kafka.log.Log)
[2019-01-25 18:57:55,880] INFO [Log partition=edited10-0, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 18:57:55,880] INFO [Log partition=tools-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 18:57:55,880] INFO [Log partition=pairs-1, dir=C:\tmp\logs3] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.Log)
[2019-01-25 18:57:55,880] INFO [Log partition=edited13-2, dir=C:\tmp\logs3] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-01-25 18:57:55,880] INFO [Log partition=edited12-0, dir=C:\tmp\logs3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 18:57:55,880] INFO [Log partition=randommessages-0, dir=C:\tmp\logs3] Truncating to 11 has no effect as the largest offset in the log is 10 (kafka.log.Log)
[2019-01-25 18:57:55,880] INFO [Log partition=tools1-0, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 18:57:55,880] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 18:57:55,880] INFO [Log partition=mytools-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 18:57:55,880] INFO [Log partition=tools12-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 18:57:55,880] INFO [Log partition=aggregated_data-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 18:57:55,880] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Truncating to 10 has no effect as the largest offset in the log is 9 (kafka.log.Log)
[2019-01-25 18:57:55,880] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 18:57:55,880] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-25 18:57:55,880] INFO [Log partition=edited6-2, dir=C:\tmp\logs3] Truncating to 4 has no effect as the largest offset in the log is 3 (kafka.log.Log)
[2019-01-25 18:57:55,880] INFO [Log partition=tools7-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 18:57:55,911] INFO [Log partition=tools11-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 18:57:55,911] INFO [Log partition=tools10-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 18:57:55,911] INFO [Log partition=tools14-0, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 18:57:55,911] INFO [Log partition=tools13-0, dir=C:\tmp\logs3] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-01-25 18:57:55,911] INFO [Log partition=tools6-2, dir=C:\tmp\logs3] Truncating to 3 has no effect as the largest offset in the log is 2 (kafka.log.Log)
[2019-01-25 19:02:48,026] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 19:02:48,026] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 19:02:48,026] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 19:02:48,026] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 19:02:48,026] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 19:02:48,026] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 19:03:05,550] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 19:03:05,550] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 19:03:05,550] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 19:03:05,550] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 19:03:05,550] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 19:03:05,550] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 19:03:27,006] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 19:03:27,006] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 19:03:27,006] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 19:03:27,006] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 19:03:27,006] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 19:03:27,006] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 19:06:02,848] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 19:06:20,390] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 19:06:41,822] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 19:16:02,846] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 19:16:20,384] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 19:16:41,821] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 19:26:02,844] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 19:26:20,381] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 19:26:41,827] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 19:36:02,852] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 19:36:20,379] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 19:36:41,827] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 19:46:02,848] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 19:46:20,387] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 19:46:41,822] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 19:56:02,854] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 19:56:20,381] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 19:56:41,827] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 20:06:02,844] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 20:06:20,389] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 20:06:41,821] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 20:16:02,851] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 20:16:20,381] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 20:16:41,832] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 20:26:02,854] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 20:26:20,381] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 20:26:41,829] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 20:36:02,847] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 20:36:20,390] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 20:36:41,823] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 20:46:02,853] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 20:46:20,387] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 20:46:41,822] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 20:56:02,845] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 20:56:20,377] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 20:56:41,823] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 21:06:02,845] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 21:06:20,377] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 21:06:41,823] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 21:16:02,845] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 21:16:20,377] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 21:16:41,830] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 21:26:02,852] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 21:26:20,377] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 21:26:41,829] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 21:36:02,852] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 21:36:20,378] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 21:36:41,830] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 21:46:02,846] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 21:46:20,380] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 21:46:41,829] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 21:56:02,850] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 21:56:20,377] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 21:56:41,829] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 22:06:02,845] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 22:06:20,377] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 22:06:41,829] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 22:16:02,845] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 22:16:20,376] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 22:16:41,830] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 22:26:02,846] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 22:26:20,377] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 22:26:41,830] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 22:27:45,705] INFO [GroupCoordinator 1]: Member consumer-1-b56b1ebf-c03d-4835-9045-a4ffec732e42 in group console-consumer-45809 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 22:27:45,705] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-45809 in state PreparingRebalance with old generation 3 (__consumer_offsets-27) (reason: removing member consumer-1-b56b1ebf-c03d-4835-9045-a4ffec732e42 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 22:27:45,705] INFO [GroupCoordinator 1]: Group console-consumer-45809 with generation 4 is now empty (__consumer_offsets-27) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 22:27:51,096] INFO [GroupCoordinator 3]: Member consumer-1-d2d1db9a-894e-426f-b29e-00f7a6888d38 in group console-consumer-36876 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 22:27:51,096] INFO [GroupCoordinator 3]: Preparing to rebalance group console-consumer-36876 in state PreparingRebalance with old generation 3 (__consumer_offsets-11) (reason: removing member consumer-1-d2d1db9a-894e-426f-b29e-00f7a6888d38 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 22:27:51,096] INFO [GroupCoordinator 3]: Group console-consumer-36876 with generation 4 is now empty (__consumer_offsets-11) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 22:28:20,767] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:64673 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-25 22:28:20,783] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:64673 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 22:28:20,783] INFO Established session 0x10003b9f714000c with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:64673 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 22:28:21,189] INFO Got user-level KeeperException when processing sessionid:0x10003b9f714000c type:setData cxid:0x6 zxid:0xcc9 txntype:-1 reqpath:n/a Error Path:/config/topics/stack Error:KeeperErrorCode = NoNode for /config/topics/stack (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 22:28:21,235] INFO Processed session termination for sessionid: 0x10003b9f714000c (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 22:28:21,235] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:64673 which had sessionid 0x10003b9f714000c (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-25 22:28:21,298] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(stack-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 22:28:21,298] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(stack-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 22:28:21,298] INFO [Log partition=stack-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 22:28:21,298] INFO [Log partition=stack-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 22:28:21,313] INFO Created log for partition stack-0 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 22:28:21,313] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(stack-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 22:28:21,313] INFO [Log partition=stack-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 22:28:21,313] INFO [Partition stack-0 broker=1] No checkpointed highwatermark is found for partition stack-0 (kafka.cluster.Partition)
[2019-01-25 22:28:21,313] INFO Replica loaded for partition stack-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 22:28:21,313] INFO Replica loaded for partition stack-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 22:28:21,313] INFO [Partition stack-0 broker=1] stack-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 22:28:21,313] INFO [Log partition=stack-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-25 22:28:21,313] INFO Created log for partition stack-2 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 22:28:21,313] INFO [Partition stack-2 broker=3] No checkpointed highwatermark is found for partition stack-2 (kafka.cluster.Partition)
[2019-01-25 22:28:21,313] INFO Replica loaded for partition stack-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 22:28:21,313] INFO Replica loaded for partition stack-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 22:28:21,313] INFO [Partition stack-2 broker=3] stack-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 22:28:21,313] INFO Replica loaded for partition stack-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 22:28:21,329] INFO Replica loaded for partition stack-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 22:28:21,329] INFO [Log partition=stack-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 22:28:21,329] INFO [Log partition=stack-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 22:28:21,329] INFO [Log partition=stack-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 22:28:21,329] INFO Created log for partition stack-2 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 22:28:21,329] INFO [Partition stack-2 broker=1] No checkpointed highwatermark is found for partition stack-2 (kafka.cluster.Partition)
[2019-01-25 22:28:21,329] INFO Replica loaded for partition stack-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 22:28:21,329] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(stack-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 22:28:21,329] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(stack-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 22:28:21,329] INFO [Log partition=stack-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 22:28:21,329] INFO Created log for partition stack-1 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 22:28:21,329] INFO [Partition stack-1 broker=3] No checkpointed highwatermark is found for partition stack-1 (kafka.cluster.Partition)
[2019-01-25 22:28:21,329] INFO Replica loaded for partition stack-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 22:28:21,329] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(stack-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 22:28:21,329] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(stack-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 22:28:21,329] INFO [Log partition=stack-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 22:28:21,345] INFO [Log partition=stack-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 22:28:21,345] INFO Created log for partition stack-1 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 22:28:21,345] INFO [Partition stack-1 broker=2] No checkpointed highwatermark is found for partition stack-1 (kafka.cluster.Partition)
[2019-01-25 22:28:21,345] INFO Replica loaded for partition stack-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 22:28:21,345] INFO Replica loaded for partition stack-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 22:28:21,345] INFO [Partition stack-1 broker=2] stack-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 22:28:21,345] INFO Replica loaded for partition stack-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 22:28:21,360] INFO [Log partition=stack-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 22:28:21,360] INFO [Log partition=stack-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 22:28:21,360] INFO Created log for partition stack-0 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 22:28:21,360] INFO [Partition stack-0 broker=2] No checkpointed highwatermark is found for partition stack-0 (kafka.cluster.Partition)
[2019-01-25 22:28:21,360] INFO Replica loaded for partition stack-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 22:28:21,360] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(stack-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 22:28:21,360] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(stack-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 22:28:21,454] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in stack-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 22:28:21,454] INFO [Log partition=stack-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 22:28:21,470] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in stack-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 22:28:21,470] INFO [Log partition=stack-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 22:28:21,533] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in stack-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 22:28:21,533] INFO [Log partition=stack-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 22:28:59,971] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-5283 in state PreparingRebalance with old generation 0 (__consumer_offsets-27) (reason: Adding new member consumer-1-76cccde4-e2c9-4a0d-b250-d7e8ef6927b7) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 22:28:59,971] INFO [GroupCoordinator 1]: Stabilized group console-consumer-5283 generation 1 (__consumer_offsets-27) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 22:28:59,987] INFO [GroupCoordinator 1]: Assignment received from leader for group console-consumer-5283 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 22:29:18,096] INFO [GroupCoordinator 3]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 79 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-5a81ba2c-a80d-4e0d-a896-5c7c89b4a75e-StreamThread-1-consumer-ecee91ee-823e-4183-aa3f-90147e0ca3e2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 22:29:18,096] INFO [GroupCoordinator 3]: Stabilized group alltoolsStream generation 80 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 22:29:18,096] INFO [GroupCoordinator 3]: Assignment received from leader for group alltoolsStream for generation 80 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 22:29:18,128] INFO [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 162 (kafka.log.ProducerStateManager)
[2019-01-25 22:29:18,128] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Rolled new log segment at offset 162 in 21 ms. (kafka.log.Log)
[2019-01-25 22:29:27,266] ERROR Failed to clean up log for __consumer_offsets-2 in dir C:\tmp\logs3 due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex.cleaned -> C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex.swap: Impossibile accedere al file. Il file  utilizzato da un altro processo.

	at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsFileCopy.move(Unknown Source)
	at sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
	at java.nio.file.Files.move(Unknown Source)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:809)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:205)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:490)
	at kafka.log.Log.$anonfun$replaceSegments$4(Log.scala:1892)
	at kafka.log.Log.$anonfun$replaceSegments$4$adapted(Log.scala:1892)
	at scala.collection.immutable.List.foreach(List.scala:388)
	at kafka.log.Log.replaceSegments(Log.scala:1892)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:583)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:515)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:514)
	at scala.collection.immutable.List.foreach(List.scala:388)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:514)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:353)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
	Suppressed: java.nio.file.FileSystemException: C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex.cleaned -> C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex.swap: Impossibile accedere al file. Il file  utilizzato da un altro processo.

		at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
		at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
		at sun.nio.fs.WindowsFileCopy.move(Unknown Source)
		at sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
		at java.nio.file.Files.move(Unknown Source)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:806)
		... 16 more
[2019-01-25 22:29:27,266] INFO [ReplicaManager broker=3] Stopping serving replicas in dir C:\tmp\logs3 (kafka.server.ReplicaManager)
[2019-01-25 22:29:27,266] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(tools4-0, tools10-2, tools1-1, pairs-1, tools2-2, __consumer_offsets-8, tools-2, edited6-0, aggregated_data-1, alltools-2, tools1-0, __consumer_offsets-35, randommessages-0, __consumer_offsets-41, tools11-0, __consumer_offsets-23, randommessages-1, tools8-0, tools12-1, __consumer_offsets-47, tools14-0, edited8-1, edited10-1, tools13-2, edited10-0, tools5-1, tools6-2, tools11-1, mytools-1, edited8-0, edited-2, tools13-0, __consumer_offsets-38, __consumer_offsets-17, pairs-2, edited13-2, edited11-0, tools4-2, tools12-2, stack-1, tools3-1, __consumer_offsets-11, edited12-1, tools6-1, tools7-2, pairing-stream-app-pairs-store-changelog-0, __consumer_offsets-2, edited-0, __consumer_offsets-14, tools5-0, edited9-0, edited6-2, tools3-2, tools-1, edited12-0, aggregateddata-0, tools2-1, aggregateddata-1, __consumer_offsets-20, __consumer_offsets-44, tools14-2, tools10-1, alltools-1, tools8-2, aggregated_data-2, tools7-1, __consumer_offsets-5, __consumer_offsets-26, stack-2, mytools-2, __consumer_offsets-29, __consumer_offsets-32, edited13-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 22:29:27,282] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(tools4-0, tools10-2, tools1-1, pairs-1, tools2-2, __consumer_offsets-8, tools-2, edited6-0, aggregated_data-1, alltools-2, tools1-0, __consumer_offsets-35, randommessages-0, __consumer_offsets-41, tools11-0, __consumer_offsets-23, randommessages-1, tools8-0, tools12-1, __consumer_offsets-47, tools14-0, edited8-1, edited10-1, tools13-2, edited10-0, tools5-1, tools6-2, tools11-1, mytools-1, edited8-0, edited-2, tools13-0, __consumer_offsets-38, __consumer_offsets-17, pairs-2, edited13-2, edited11-0, tools4-2, tools12-2, stack-1, tools3-1, __consumer_offsets-11, edited12-1, tools6-1, tools7-2, pairing-stream-app-pairs-store-changelog-0, __consumer_offsets-2, edited-0, __consumer_offsets-14, tools5-0, edited9-0, edited6-2, tools3-2, tools-1, edited12-0, aggregateddata-0, tools2-1, aggregateddata-1, __consumer_offsets-20, __consumer_offsets-44, tools14-2, tools10-1, alltools-1, tools8-2, aggregated_data-2, tools7-1, __consumer_offsets-5, __consumer_offsets-26, stack-2, mytools-2, __consumer_offsets-29, __consumer_offsets-32, edited13-0) (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-25 22:29:27,313] ERROR Failed to clean up log for __consumer_offsets-2 in dir C:\tmp\logs3 due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex.cleaned: Impossibile accedere al file. Il file  utilizzato da un altro processo.

	at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(Unknown Source)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(Unknown Source)
	at java.nio.file.Files.deleteIfExists(Unknown Source)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2150)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:645)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:424)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:540)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:515)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:514)
	at scala.collection.immutable.List.foreach(List.scala:388)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:514)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:353)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-25 22:29:27,344] INFO [ReplicaManager broker=3] Broker 3 stopped fetcher for partitions tools4-0,tools10-2,tools1-1,pairs-1,tools2-2,__consumer_offsets-8,tools-2,edited6-0,aggregated_data-1,alltools-2,tools1-0,__consumer_offsets-35,randommessages-0,__consumer_offsets-41,tools11-0,__consumer_offsets-23,randommessages-1,tools8-0,tools12-1,__consumer_offsets-47,tools14-0,edited8-1,edited10-1,tools13-2,edited10-0,tools5-1,tools6-2,tools11-1,mytools-1,edited8-0,edited-2,tools13-0,__consumer_offsets-38,__consumer_offsets-17,pairs-2,edited13-2,edited11-0,tools4-2,tools12-2,stack-1,tools3-1,__consumer_offsets-11,edited12-1,tools6-1,tools7-2,pairing-stream-app-pairs-store-changelog-0,__consumer_offsets-2,edited-0,__consumer_offsets-14,tools5-0,edited9-0,edited6-2,tools3-2,tools-1,edited12-0,aggregateddata-0,tools2-1,aggregateddata-1,__consumer_offsets-20,__consumer_offsets-44,tools14-2,tools10-1,alltools-1,tools8-2,aggregated_data-2,tools7-1,__consumer_offsets-5,__consumer_offsets-26,stack-2,mytools-2,__consumer_offsets-29,__consumer_offsets-32,edited13-0 and stopped moving logs for partitions  because they are in the failed log directory C:\tmp\logs3. (kafka.server.ReplicaManager)
[2019-01-25 22:29:27,360] INFO Stopping serving logs in dir C:\tmp\logs3 (kafka.log.LogManager)
[2019-01-25 22:29:27,360] ERROR Failed to clean up log for __consumer_offsets-2 in dir C:\tmp\logs3 due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex.cleaned: Impossibile accedere al file. Il file  utilizzato da un altro processo.

	at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(Unknown Source)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(Unknown Source)
	at java.nio.file.Files.deleteIfExists(Unknown Source)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2150)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:645)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:424)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:540)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:515)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:514)
	at scala.collection.immutable.List.foreach(List.scala:388)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:514)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:353)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-25 22:29:27,360] ERROR Shutdown broker because all log dirs in C:\tmp\logs3 have failed (kafka.log.LogManager)
[2019-01-25 22:29:27,873] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=1552886327, epoch=24804) to node 3: java.io.IOException: Connection to 3 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-25 22:29:27,874] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1552886327, epoch=24804)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 3 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:97)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:97)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-25 22:29:27,877] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=630434981, epoch=24816) to node 3: java.io.IOException: Connection to 3 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-25 22:29:27,877] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=630434981, epoch=24816)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 3 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:97)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:97)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-25 22:29:27,877] WARN Exception causing close of session 0x10003b9f7140009: Connessione in corso interrotta forzatamente dall'host remoto (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-25 22:29:27,877] INFO Closed socket connection for client /127.0.0.1:63110 which had sessionid 0x10003b9f7140009 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-25 22:29:30,892] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Connection to node 3 (localhost/127.0.0.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-25 22:29:30,892] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=1552886327, epoch=INITIAL) to node 3: java.io.IOException: Connection to localhost:9095 (id: 3 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-25 22:29:30,892] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={tools2-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[26]), aggregated_data-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[2]), tools12-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[2]), edited13-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0]), pairs-2=(offset=5, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0]), tools3-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[26]), randommessages-1=(offset=10, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0]), tools5-1=(offset=5, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[26]), edited6-0=(offset=3, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[22]), edited12-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[2]), tools-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[26]), edited-0=(offset=8, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[26]), tools1-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[26]), alltools-2=(offset=5, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[27]), tools7-2=(offset=1, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[16]), tools4-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[26]), edited8-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[6]), stack-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0]), mytools-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[26]), edited10-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[2])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1552886327, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9095 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-25 22:29:30,939] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Connection to node 3 (localhost/127.0.0.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-25 22:29:30,939] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=630434981, epoch=INITIAL) to node 3: java.io.IOException: Connection to localhost:9095 (id: 3 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-25 22:29:30,939] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={tools13-2=(offset=1, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0]), tools14-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0]), tools6-1=(offset=6, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[22]), tools8-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[7]), tools11-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), tools10-1=(offset=1, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), aggregateddata-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=630434981, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9095 (id: 3 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-25 22:29:31,861] INFO Expiring session 0x10003b9f7140009, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 22:29:31,862] INFO Processed session termination for sessionid: 0x10003b9f7140009 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 22:29:32,002] INFO Got user-level KeeperException when processing sessionid:0x10003b9f714000b type:multi cxid:0x120 zxid:0xcf1 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 22:29:32,002] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(tools11-0, tools13-2, tools6-1, aggregateddata-0, tools14-2, tools10-1, tools8-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 22:29:32,002] INFO [Partition tools14-2 broker=2] tools14-2 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-25 22:29:32,002] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools4-0, tools1-1, tools2-2, tools-2, edited6-0, alltools-2, randommessages-1, edited8-1, edited10-1, tools5-1, pairs-2, tools12-2, edited12-1, tools7-2, edited-0, tools3-2, aggregated_data-2, stack-2, mytools-2, edited13-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 22:29:32,002] INFO [Partition tools1-1 broker=1] tools1-1 starts at Leader Epoch 27 from offset 0. Previous Leader Epoch was: 26 (kafka.cluster.Partition)
[2019-01-25 22:29:32,002] WARN [LeaderEpochCache tools1-1] New epoch entry EpochEntry(epoch=27, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=25, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 22:29:32,002] INFO Got user-level KeeperException when processing sessionid:0x10003b9f714000b type:multi cxid:0x122 zxid:0xcf2 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 22:29:32,018] INFO [Partition tools10-1 broker=2] tools10-1 starts at Leader Epoch 4 from offset 1. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-25 22:29:32,018] INFO [Partition tools2-2 broker=1] tools2-2 starts at Leader Epoch 27 from offset 0. Previous Leader Epoch was: 26 (kafka.cluster.Partition)
[2019-01-25 22:29:32,018] WARN [LeaderEpochCache tools2-2] New epoch entry EpochEntry(epoch=27, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=25, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 22:29:32,018] WARN [LeaderEpochCache tools10-1] New epoch entry EpochEntry(epoch=4, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 22:29:32,018] INFO [Partition edited12-1 broker=1] edited12-1 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-25 22:29:32,018] WARN [LeaderEpochCache edited12-1] New epoch entry EpochEntry(epoch=3, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 22:29:32,033] INFO [Partition aggregateddata-0 broker=2] aggregateddata-0 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-25 22:29:32,033] INFO [Partition tools6-1 broker=2] tools6-1 starts at Leader Epoch 23 from offset 6. Previous Leader Epoch was: 22 (kafka.cluster.Partition)
[2019-01-25 22:29:32,033] WARN [LeaderEpochCache tools6-1] New epoch entry EpochEntry(epoch=23, startOffset=6) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=21, startOffset=6)). Cache now contains 5 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 22:29:32,033] INFO [Partition tools7-2 broker=1] tools7-2 starts at Leader Epoch 17 from offset 1. Previous Leader Epoch was: 16 (kafka.cluster.Partition)
[2019-01-25 22:29:32,033] WARN [LeaderEpochCache tools7-2] New epoch entry EpochEntry(epoch=17, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=15, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 22:29:32,049] INFO [Partition tools13-2 broker=2] tools13-2 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-25 22:29:32,049] INFO [Partition edited-0 broker=1] edited-0 starts at Leader Epoch 27 from offset 8. Previous Leader Epoch was: 26 (kafka.cluster.Partition)
[2019-01-25 22:29:32,049] WARN [LeaderEpochCache edited-0] New epoch entry EpochEntry(epoch=27, startOffset=8) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=25, startOffset=8)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 22:29:32,049] INFO [Partition tools11-0 broker=2] tools11-0 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: 3 (kafka.cluster.Partition)
[2019-01-25 22:29:32,049] WARN [LeaderEpochCache tools11-0] New epoch entry EpochEntry(epoch=4, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 22:29:32,049] INFO [Partition alltools-2 broker=1] alltools-2 starts at Leader Epoch 28 from offset 5. Previous Leader Epoch was: 27 (kafka.cluster.Partition)
[2019-01-25 22:29:32,049] WARN [LeaderEpochCache alltools-2] New epoch entry EpochEntry(epoch=28, startOffset=5) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=26, startOffset=5)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 22:29:32,065] INFO [Partition tools8-2 broker=2] tools8-2 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: 7 (kafka.cluster.Partition)
[2019-01-25 22:29:32,065] WARN [LeaderEpochCache tools8-2] New epoch entry EpochEntry(epoch=8, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=6, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 22:29:32,065] INFO [Partition edited8-1 broker=1] edited8-1 starts at Leader Epoch 7 from offset 0. Previous Leader Epoch was: 6 (kafka.cluster.Partition)
[2019-01-25 22:29:32,065] WARN [LeaderEpochCache edited8-1] New epoch entry EpochEntry(epoch=7, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=5, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 22:29:32,065] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-01-25 22:29:32,065] INFO [Partition mytools-2 broker=1] mytools-2 starts at Leader Epoch 27 from offset 0. Previous Leader Epoch was: 26 (kafka.cluster.Partition)
[2019-01-25 22:29:32,065] WARN [LeaderEpochCache mytools-2] New epoch entry EpochEntry(epoch=27, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=25, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 22:29:32,080] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-01-25 22:29:32,080] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-01-25 22:29:32,080] INFO [Partition edited13-0 broker=1] edited13-0 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-25 22:29:32,080] INFO [Partition pairs-2 broker=1] pairs-2 starts at Leader Epoch 1 from offset 5. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-25 22:29:32,096] INFO [Partition tools3-2 broker=1] tools3-2 starts at Leader Epoch 27 from offset 0. Previous Leader Epoch was: 26 (kafka.cluster.Partition)
[2019-01-25 22:29:32,096] WARN [LeaderEpochCache tools3-2] New epoch entry EpochEntry(epoch=27, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=25, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 22:29:32,096] INFO [Partition tools4-0 broker=1] tools4-0 starts at Leader Epoch 27 from offset 0. Previous Leader Epoch was: 26 (kafka.cluster.Partition)
[2019-01-25 22:29:32,096] WARN [LeaderEpochCache tools4-0] New epoch entry EpochEntry(epoch=27, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=25, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 22:29:32,096] INFO [Partition tools5-1 broker=1] tools5-1 starts at Leader Epoch 27 from offset 5. Previous Leader Epoch was: 26 (kafka.cluster.Partition)
[2019-01-25 22:29:32,096] WARN [LeaderEpochCache tools5-1] New epoch entry EpochEntry(epoch=27, startOffset=5) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=25, startOffset=5)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 22:29:32,112] INFO [Partition stack-2 broker=1] stack-2 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-25 22:29:32,112] INFO [Partition tools12-2 broker=1] tools12-2 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-25 22:29:32,112] WARN [LeaderEpochCache tools12-2] New epoch entry EpochEntry(epoch=3, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 22:29:32,112] INFO [Partition edited6-0 broker=1] edited6-0 starts at Leader Epoch 23 from offset 3. Previous Leader Epoch was: 22 (kafka.cluster.Partition)
[2019-01-25 22:29:32,112] WARN [LeaderEpochCache edited6-0] New epoch entry EpochEntry(epoch=23, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=21, startOffset=3)). Cache now contains 4 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 22:29:32,127] INFO [Partition aggregated_data-2 broker=1] aggregated_data-2 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-25 22:29:32,127] WARN [LeaderEpochCache aggregated_data-2] New epoch entry EpochEntry(epoch=3, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 22:29:32,127] INFO [Partition tools-2 broker=1] tools-2 starts at Leader Epoch 27 from offset 0. Previous Leader Epoch was: 26 (kafka.cluster.Partition)
[2019-01-25 22:29:32,127] WARN [LeaderEpochCache tools-2] New epoch entry EpochEntry(epoch=27, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=25, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 22:29:32,143] INFO [Partition edited10-1 broker=1] edited10-1 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-25 22:29:32,143] WARN [LeaderEpochCache edited10-1] New epoch entry EpochEntry(epoch=3, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-25 22:29:32,143] INFO [Partition randommessages-1 broker=1] randommessages-1 starts at Leader Epoch 1 from offset 10. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-25 22:29:32,143] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-01-25 22:29:32,158] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-01-25 22:29:32,158] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-01-25 22:36:02,845] INFO [GroupMetadataManager brokerId=1] Group console-consumer-45809 transitioned to Dead in generation 4 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 22:36:02,845] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 22:36:20,377] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 22:46:02,847] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 22:46:20,377] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 22:56:02,848] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 22:56:20,381] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 23:06:02,845] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 23:06:20,378] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 23:16:02,845] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 23:16:20,377] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 23:25:07,863] INFO [GroupCoordinator 1]: Member consumer-1-76cccde4-e2c9-4a0d-b250-d7e8ef6927b7 in group console-consumer-5283 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 23:25:07,864] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-5283 in state PreparingRebalance with old generation 1 (__consumer_offsets-27) (reason: removing member consumer-1-76cccde4-e2c9-4a0d-b250-d7e8ef6927b7 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 23:25:07,864] INFO [GroupCoordinator 1]: Group console-consumer-5283 with generation 2 is now empty (__consumer_offsets-27) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 23:25:43,673] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:65010 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-25 23:25:43,673] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:65010 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 23:25:43,689] INFO Established session 0x10003b9f714000d with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:65010 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 23:25:44,049] INFO Got user-level KeeperException when processing sessionid:0x10003b9f714000d type:setData cxid:0x5 zxid:0xcf4 txntype:-1 reqpath:n/a Error Path:/config/topics/stack1 Error:KeeperErrorCode = NoNode for /config/topics/stack1 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 23:25:44,096] INFO Processed session termination for sessionid: 0x10003b9f714000d (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 23:25:44,096] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:65010 which had sessionid 0x10003b9f714000d (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-25 23:25:44,112] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(stack1-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 23:25:44,112] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(stack1-2, stack1-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 23:25:44,112] INFO [Log partition=stack1-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 23:25:44,127] INFO [Log partition=stack1-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-25 23:25:44,127] INFO Created log for partition stack1-1 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 23:25:44,127] INFO [Partition stack1-1 broker=1] No checkpointed highwatermark is found for partition stack1-1 (kafka.cluster.Partition)
[2019-01-25 23:25:44,127] INFO Replica loaded for partition stack1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 23:25:44,127] INFO Replica loaded for partition stack1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 23:25:44,127] INFO [Partition stack1-1 broker=1] stack1-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 23:25:44,127] INFO [Log partition=stack1-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 23:25:44,127] INFO Replica loaded for partition stack1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 23:25:44,127] INFO [Log partition=stack1-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 23:25:44,127] INFO Created log for partition stack1-2 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 23:25:44,127] INFO [Partition stack1-2 broker=2] No checkpointed highwatermark is found for partition stack1-2 (kafka.cluster.Partition)
[2019-01-25 23:25:44,127] INFO Replica loaded for partition stack1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 23:25:44,127] INFO Replica loaded for partition stack1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 23:25:44,127] INFO [Partition stack1-2 broker=2] stack1-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 23:25:44,143] INFO [Log partition=stack1-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 23:25:44,143] INFO [Log partition=stack1-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 23:25:44,143] INFO Created log for partition stack1-2 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 23:25:44,143] INFO [Partition stack1-2 broker=1] No checkpointed highwatermark is found for partition stack1-2 (kafka.cluster.Partition)
[2019-01-25 23:25:44,143] INFO Replica loaded for partition stack1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 23:25:44,143] INFO Replica loaded for partition stack1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 23:25:44,143] INFO [Log partition=stack1-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 23:25:44,143] INFO [Log partition=stack1-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 23:25:44,143] INFO [Log partition=stack1-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 23:25:44,143] INFO Created log for partition stack1-0 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 23:25:44,143] INFO [Log partition=stack1-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 23:25:44,143] INFO [Partition stack1-0 broker=2] No checkpointed highwatermark is found for partition stack1-0 (kafka.cluster.Partition)
[2019-01-25 23:25:44,143] INFO Replica loaded for partition stack1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 23:25:44,143] INFO Replica loaded for partition stack1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 23:25:44,143] INFO Created log for partition stack1-0 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 23:25:44,143] INFO [Partition stack1-0 broker=2] stack1-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 23:25:44,159] INFO [Partition stack1-0 broker=1] No checkpointed highwatermark is found for partition stack1-0 (kafka.cluster.Partition)
[2019-01-25 23:25:44,159] INFO Replica loaded for partition stack1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 23:25:44,159] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(stack1-2, stack1-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 23:25:44,159] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(stack1-2 -> (offset=0, leaderEpoch=0), stack1-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 23:25:44,159] INFO Replica loaded for partition stack1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 23:25:44,159] INFO [Log partition=stack1-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 23:25:44,159] INFO [Log partition=stack1-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 23:25:44,159] INFO Created log for partition stack1-1 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 23:25:44,159] INFO [Partition stack1-1 broker=2] No checkpointed highwatermark is found for partition stack1-1 (kafka.cluster.Partition)
[2019-01-25 23:25:44,159] INFO Replica loaded for partition stack1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 23:25:44,159] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(stack1-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 23:25:44,174] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(stack1-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 23:25:44,284] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in stack1-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 23:25:44,284] INFO [Log partition=stack1-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 23:25:44,596] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in stack1-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 23:25:44,596] INFO [Log partition=stack1-0, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 23:25:44,596] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in stack1-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 23:25:44,596] INFO [Log partition=stack1-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 23:25:54,361] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:65016 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-25 23:25:54,361] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:65016 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 23:25:54,361] INFO Established session 0x10003b9f714000e with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:65016 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-25 23:25:54,689] INFO Got user-level KeeperException when processing sessionid:0x10003b9f714000e type:setData cxid:0x5 zxid:0xd00 txntype:-1 reqpath:n/a Error Path:/config/topics/editedstack Error:KeeperErrorCode = NoNode for /config/topics/editedstack (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 23:25:54,751] INFO Processed session termination for sessionid: 0x10003b9f714000e (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 23:25:54,751] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:65016 which had sessionid 0x10003b9f714000e (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-25 23:25:54,751] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(editedstack-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 23:25:54,751] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(editedstack-2, editedstack-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 23:25:54,751] INFO [Log partition=editedstack-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 23:25:54,751] INFO [Log partition=editedstack-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 23:25:54,767] INFO [Log partition=editedstack-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 23:25:54,767] INFO Created log for partition editedstack-1 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 23:25:54,767] INFO [Log partition=editedstack-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 23:25:54,767] INFO [Partition editedstack-1 broker=1] No checkpointed highwatermark is found for partition editedstack-1 (kafka.cluster.Partition)
[2019-01-25 23:25:54,767] INFO Replica loaded for partition editedstack-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 23:25:54,767] INFO Created log for partition editedstack-2 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 23:25:54,767] INFO Replica loaded for partition editedstack-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 23:25:54,767] INFO [Partition editedstack-2 broker=2] No checkpointed highwatermark is found for partition editedstack-2 (kafka.cluster.Partition)
[2019-01-25 23:25:54,767] INFO [Partition editedstack-1 broker=1] editedstack-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 23:25:54,767] INFO Replica loaded for partition editedstack-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 23:25:54,767] INFO Replica loaded for partition editedstack-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 23:25:54,767] INFO [Partition editedstack-2 broker=2] editedstack-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 23:25:54,767] INFO Replica loaded for partition editedstack-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 23:25:54,767] INFO [Log partition=editedstack-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 23:25:54,783] INFO [Log partition=editedstack-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 23:25:54,783] INFO [Log partition=editedstack-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 23:25:54,783] INFO Created log for partition editedstack-2 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 23:25:54,783] INFO [Partition editedstack-2 broker=1] No checkpointed highwatermark is found for partition editedstack-2 (kafka.cluster.Partition)
[2019-01-25 23:25:54,783] INFO Replica loaded for partition editedstack-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 23:25:54,783] INFO [Log partition=editedstack-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-25 23:25:54,783] INFO Replica loaded for partition editedstack-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 23:25:54,783] INFO Created log for partition editedstack-0 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 23:25:54,783] INFO [Partition editedstack-0 broker=2] No checkpointed highwatermark is found for partition editedstack-0 (kafka.cluster.Partition)
[2019-01-25 23:25:54,783] INFO Replica loaded for partition editedstack-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 23:25:54,783] INFO Replica loaded for partition editedstack-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 23:25:54,783] INFO [Partition editedstack-0 broker=2] editedstack-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 23:25:54,783] INFO [Log partition=editedstack-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 23:25:54,783] INFO Replica loaded for partition editedstack-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 23:25:54,783] INFO [Log partition=editedstack-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-25 23:25:54,798] INFO [Log partition=editedstack-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 23:25:54,798] INFO Created log for partition editedstack-0 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 23:25:54,798] INFO [Partition editedstack-0 broker=1] No checkpointed highwatermark is found for partition editedstack-0 (kafka.cluster.Partition)
[2019-01-25 23:25:54,798] INFO Replica loaded for partition editedstack-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 23:25:54,798] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(editedstack-0, editedstack-2) (kafka.server.ReplicaFetcherManager)
[2019-01-25 23:25:54,798] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(editedstack-2 -> (offset=0, leaderEpoch=0), editedstack-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 23:25:54,798] INFO [Log partition=editedstack-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-25 23:25:54,798] INFO Created log for partition editedstack-1 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 23:25:54,798] INFO [Partition editedstack-1 broker=2] No checkpointed highwatermark is found for partition editedstack-1 (kafka.cluster.Partition)
[2019-01-25 23:25:54,798] INFO Replica loaded for partition editedstack-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 23:25:54,798] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(editedstack-1) (kafka.server.ReplicaFetcherManager)
[2019-01-25 23:25:54,798] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(editedstack-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-25 23:25:54,845] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in editedstack-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 23:25:54,845] INFO [Log partition=editedstack-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 23:25:54,845] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in editedstack-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 23:25:54,845] INFO [Log partition=editedstack-0, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 23:25:55,064] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in editedstack-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-25 23:25:55,064] INFO [Log partition=editedstack-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-25 23:26:01,641] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-57831 in state PreparingRebalance with old generation 0 (__consumer_offsets-15) (reason: Adding new member consumer-1-b7bac741-7611-4073-ba3a-79163667610e) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 23:26:01,641] INFO [GroupCoordinator 1]: Stabilized group console-consumer-57831 generation 1 (__consumer_offsets-15) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 23:26:01,657] INFO [GroupCoordinator 1]: Assignment received from leader for group console-consumer-57831 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 23:26:02,845] INFO [GroupMetadataManager brokerId=1] Group console-consumer-5283 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 23:26:02,845] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 23:26:20,376] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 23:28:02,001] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-60422 in state PreparingRebalance with old generation 0 (__consumer_offsets-25) (reason: Adding new member consumer-1-a58e07c0-3dfa-4402-ba47-5cbf7226c79b) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 23:28:02,001] INFO [GroupCoordinator 2]: Stabilized group console-consumer-60422 generation 1 (__consumer_offsets-25) (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 23:28:02,001] INFO [GroupCoordinator 2]: Assignment received from leader for group console-consumer-60422 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-25 23:36:02,845] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 23:36:20,376] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 23:46:02,845] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 23:46:20,378] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 23:50:46,160] INFO Got user-level KeeperException when processing sessionid:0x10003b9f714000a type:setData cxid:0x15 zxid:0xd0b txntype:-1 reqpath:n/a Error Path:/config/topics/anstack Error:KeeperErrorCode = NoNode for /config/topics/anstack (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-25 23:50:46,166] INFO Topic creation Map(anstack-0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2019-01-25 23:50:46,171] INFO [KafkaApi-2] Auto creation of topic anstack with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2019-01-25 23:50:46,182] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(anstack-0) (kafka.server.ReplicaFetcherManager)
[2019-01-25 23:50:46,187] INFO [Log partition=anstack-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-25 23:50:46,189] INFO [Log partition=anstack-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-01-25 23:50:46,190] INFO Created log for partition anstack-0 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-25 23:50:46,191] INFO [Partition anstack-0 broker=1] No checkpointed highwatermark is found for partition anstack-0 (kafka.cluster.Partition)
[2019-01-25 23:50:46,191] INFO Replica loaded for partition anstack-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-25 23:50:46,191] INFO [Partition anstack-0 broker=1] anstack-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-25 23:56:02,846] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-25 23:56:20,376] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 00:06:02,846] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 00:06:20,377] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 00:16:02,844] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 00:16:20,377] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 00:17:48,099] INFO [GroupCoordinator 2]: Member consumer-1-a58e07c0-3dfa-4402-ba47-5cbf7226c79b in group console-consumer-60422 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 00:17:48,099] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-60422 in state PreparingRebalance with old generation 1 (__consumer_offsets-25) (reason: removing member consumer-1-a58e07c0-3dfa-4402-ba47-5cbf7226c79b on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 00:17:48,099] INFO [GroupCoordinator 2]: Group console-consumer-60422 with generation 2 is now empty (__consumer_offsets-25) (kafka.coordinator.group.GroupCoordinator)
