[2019-01-26 19:38:07,473] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-01-26 19:38:07,473] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-26 19:38:07,473] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-26 19:38:07,473] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-26 19:38:07,473] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-01-26 19:38:07,505] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-01-26 19:38:07,505] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-01-26 19:38:07,520] INFO Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:38:07,520] INFO Server environment:host.name=ITdif.mshome.net (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:38:07,520] INFO Server environment:java.version=1.8.0_181 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:38:07,520] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:38:07,520] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_181 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:38:07,520] INFO Server environment:java.class.path=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-connect-jdbc-5.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\mysql-connector-java-5.1.42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:38:07,520] INFO Server environment:java.library.path=C:\Program Files\Java\jre1.8.0_181\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Docker\Docker\Resources\bin;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\Scripts\;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\dotnet\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\NoteBook FanControl\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\extras\CUPTI\libx64;C:\tools\cuda\bin;C:\Program Files\PuTTY\;C:\Program Files\Calibre2\;C:\apache-maven-3.6.\bin;C:\Users\Stefano\Downloads\platform-tools_r28.0.1-windows\platform-tools;C:\Program Files\Java\jre1.8.0_181\bin;C:\Users\Stefano\AppData\Local\Programs\Python\Launcher\;C:\Users\Stefano\AppData\Local\Microsoft\WindowsApps;C:\Users\Stefano\AppData\Local\GitHubDesktop\bin;C:\apache-maven-3.6.0\bin;;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:38:07,520] INFO Server environment:java.io.tmpdir=C:\Users\Stefano\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:38:07,520] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:38:07,520] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:38:07,520] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:38:07,520] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:38:07,520] INFO Server environment:user.name=Stefano (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:38:07,520] INFO Server environment:user.home=C:\Users\Stefano (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:38:07,520] INFO Server environment:user.dir=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:38:07,536] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:38:07,536] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:38:07,536] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:38:07,583] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-01-26 19:38:07,583] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-26 19:38:13,866] INFO Expiring session 0x10003b9f714000b, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:38:13,866] INFO Expiring session 0x10003b9f714000a, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:38:13,866] INFO Processed session termination for sessionid: 0x10003b9f714000b (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:38:13,866] INFO Processed session termination for sessionid: 0x10003b9f714000a (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:38:13,866] INFO Creating new log file: log.d11 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-01-26 19:38:34,280] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-26 19:38:35,030] INFO starting (kafka.server.KafkaServer)
[2019-01-26 19:38:35,030] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-26 19:38:35,061] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-26 19:38:35,077] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:38:35,077] INFO Client environment:host.name=ITdif.mshome.net (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:38:35,077] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:38:35,077] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:38:35,077] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:38:35,077] INFO Client environment:java.class.path=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-connect-jdbc-5.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\mysql-connector-java-5.1.42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:38:35,077] INFO Client environment:java.library.path=C:\Program Files\Java\jre1.8.0_181\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Docker\Docker\Resources\bin;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\Scripts\;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\dotnet\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\NoteBook FanControl\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\extras\CUPTI\libx64;C:\tools\cuda\bin;C:\Program Files\PuTTY\;C:\Program Files\Calibre2\;C:\apache-maven-3.6.\bin;C:\Users\Stefano\Downloads\platform-tools_r28.0.1-windows\platform-tools;C:\Program Files\Java\jre1.8.0_181\bin;C:\Users\Stefano\AppData\Local\Programs\Python\Launcher\;C:\Users\Stefano\AppData\Local\Microsoft\WindowsApps;C:\Users\Stefano\AppData\Local\GitHubDesktop\bin;C:\apache-maven-3.6.0\bin;;. (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:38:35,077] INFO Client environment:java.io.tmpdir=C:\Users\Stefano\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:38:35,077] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:38:35,077] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:38:35,077] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:38:35,077] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:38:35,077] INFO Client environment:user.name=Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:38:35,077] INFO Client environment:user.home=C:\Users\Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:38:35,077] INFO Client environment:user.dir=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:38:35,077] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@1622f1b (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:38:35,108] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-26 19:38:35,108] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-26 19:38:35,108] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-26 19:38:35,108] INFO Accepted socket connection from /127.0.0.1:62068 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-26 19:38:35,108] INFO Client attempting to establish new session at /127.0.0.1:62068 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:38:35,123] INFO Established session 0x1000aa33c1e0000 with negotiated timeout 6000 for client /127.0.0.1:62068 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:38:35,123] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000aa33c1e0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-26 19:38:35,123] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-26 19:38:35,201] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0000 type:create cxid:0x1 zxid:0xd14 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:38:35,217] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0000 type:create cxid:0x2 zxid:0xd15 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:38:35,217] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0000 type:create cxid:0x3 zxid:0xd16 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:38:35,233] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0000 type:create cxid:0x4 zxid:0xd17 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:38:35,233] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0000 type:create cxid:0x5 zxid:0xd18 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:38:35,233] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0000 type:create cxid:0x6 zxid:0xd19 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:38:35,233] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0000 type:create cxid:0x7 zxid:0xd1a txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:38:35,233] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0000 type:create cxid:0x8 zxid:0xd1b txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:38:35,233] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0000 type:create cxid:0x9 zxid:0xd1c txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:38:35,248] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0000 type:create cxid:0xa zxid:0xd1d txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:38:35,248] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0000 type:create cxid:0xb zxid:0xd1e txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:38:35,248] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0000 type:create cxid:0xc zxid:0xd1f txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:38:35,248] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0000 type:create cxid:0xd zxid:0xd20 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:38:35,498] INFO Cluster ID = RvEiz9fYQgKWcHR6fHb3dg (kafka.server.KafkaServer)
[2019-01-26 19:38:35,592] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-26 19:38:35,608] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-26 19:38:35,655] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-26 19:38:35,655] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-26 19:38:35,655] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-26 19:38:35,733] INFO Loading logs. (kafka.log.LogManager)
[2019-01-26 19:38:35,826] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:35,826] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:35,889] INFO [ProducerStateManager partition=aggregateddata-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:35,904] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs1] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:35,920] INFO [ProducerStateManager partition=aggregateddata-1] Loading producer state from snapshot file 'C:\tmp\logs1\aggregateddata-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:35,936] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 141 ms (kafka.log.Log)
[2019-01-26 19:38:35,951] INFO [Log partition=aggregateddata-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:35,951] INFO [Log partition=aggregateddata-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:35,951] INFO [Log partition=aggregateddata-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:35,967] INFO [Log partition=aggregateddata-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:35,967] WARN [Log partition=aggregated_data-0, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\aggregated_data-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\aggregated_data-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548410540359}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:35,967] INFO [Log partition=aggregated_data-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:35,983] INFO [ProducerStateManager partition=aggregated_data-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:35,983] INFO [Log partition=aggregated_data-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:35,983] INFO [Log partition=aggregated_data-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:35,998] INFO [ProducerStateManager partition=aggregated_data-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:35,998] INFO [Log partition=aggregated_data-0, dir=C:\tmp\logs1] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,014] INFO [ProducerStateManager partition=aggregated_data-0] Loading producer state from snapshot file 'C:\tmp\logs1\aggregated_data-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:36,014] INFO [Log partition=aggregated_data-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 47 ms (kafka.log.Log)
[2019-01-26 19:38:36,014] INFO [Log partition=aggregated_data-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:36,014] INFO [Log partition=aggregated_data-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,029] INFO [Log partition=aggregated_data-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,029] INFO [Log partition=aggregated_data-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:38:36,045] WARN [Log partition=alltools-0, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\alltools-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\alltools-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547977751460}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:36,045] INFO [Log partition=alltools-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,045] INFO [ProducerStateManager partition=alltools-0] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:36,045] INFO [Log partition=alltools-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:36,061] INFO [Log partition=alltools-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,061] INFO [ProducerStateManager partition=alltools-0] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:36,076] INFO [Log partition=alltools-0, dir=C:\tmp\logs1] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,076] INFO [ProducerStateManager partition=alltools-0] Loading producer state from snapshot file 'C:\tmp\logs1\alltools-0\00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:36,076] INFO [Log partition=alltools-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 47 ms (kafka.log.Log)
[2019-01-26 19:38:36,092] WARN [Log partition=alltools-2, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\alltools-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\alltools-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547977368170}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:36,092] INFO [Log partition=alltools-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,108] INFO [ProducerStateManager partition=alltools-2] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:36,108] INFO [Log partition=alltools-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:36,108] INFO [Log partition=alltools-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,108] INFO [ProducerStateManager partition=alltools-2] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:36,123] INFO [Log partition=alltools-2, dir=C:\tmp\logs1] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,123] INFO [ProducerStateManager partition=alltools-2] Loading producer state from snapshot file 'C:\tmp\logs1\alltools-2\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:36,123] INFO [Log partition=alltools-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:36,139] INFO [Log partition=anstack-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:36,139] INFO [Log partition=anstack-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,154] INFO [Log partition=anstack-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,154] INFO [Log partition=anstack-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:38:36,170] WARN [Log partition=edited-0, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\edited-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\edited-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996878625}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:36,170] INFO [Log partition=edited-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,186] INFO [ProducerStateManager partition=edited-0] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:36,186] INFO [Log partition=edited-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:36,186] INFO [Log partition=edited-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,201] INFO [ProducerStateManager partition=edited-0] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:36,217] INFO [Log partition=edited-0, dir=C:\tmp\logs1] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,217] INFO [ProducerStateManager partition=edited-0] Loading producer state from snapshot file 'C:\tmp\logs1\edited-0\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:36,217] INFO [Log partition=edited-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 47 ms (kafka.log.Log)
[2019-01-26 19:38:36,233] WARN [Log partition=edited-1, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\edited-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\edited-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996876577}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:36,233] INFO [Log partition=edited-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,233] INFO [ProducerStateManager partition=edited-1] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:36,248] INFO [Log partition=edited-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:36,248] INFO [Log partition=edited-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,248] INFO [ProducerStateManager partition=edited-1] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:36,264] INFO [Log partition=edited-1, dir=C:\tmp\logs1] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,264] INFO [ProducerStateManager partition=edited-1] Loading producer state from snapshot file 'C:\tmp\logs1\edited-1\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:36,264] INFO [Log partition=edited-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 9 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:36,295] INFO [Log partition=edited10-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:36,295] INFO [Log partition=edited10-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,295] INFO [Log partition=edited10-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,311] INFO [Log partition=edited10-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-01-26 19:38:36,311] WARN [Log partition=edited10-2, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\edited10-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\edited10-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548410034606}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:36,311] INFO [Log partition=edited10-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,326] INFO [ProducerStateManager partition=edited10-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:36,326] INFO [Log partition=edited10-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:36,326] INFO [Log partition=edited10-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,342] INFO [ProducerStateManager partition=edited10-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:36,342] INFO [Log partition=edited10-2, dir=C:\tmp\logs1] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,342] INFO [ProducerStateManager partition=edited10-2] Loading producer state from snapshot file 'C:\tmp\logs1\edited10-2\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:36,357] INFO [Log partition=edited10-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 46 ms (kafka.log.Log)
[2019-01-26 19:38:36,357] INFO [Log partition=edited12-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:36,357] INFO [Log partition=edited12-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,373] INFO [Log partition=edited12-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,373] INFO [Log partition=edited12-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:38:36,389] INFO [Log partition=edited12-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:36,389] INFO [Log partition=edited12-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,404] INFO [Log partition=edited12-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,404] INFO [Log partition=edited12-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:38:36,420] INFO [Log partition=edited13-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:36,420] INFO [Log partition=edited13-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,436] INFO [Log partition=edited13-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,451] INFO [Log partition=edited13-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:36,451] INFO [Log partition=edited13-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:36,451] INFO [Log partition=edited13-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,467] INFO [Log partition=edited13-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,467] INFO [Log partition=edited13-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:38:36,482] WARN [Log partition=edited6-0, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\edited6-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\edited6-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548158302054}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:36,482] INFO [Log partition=edited6-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,482] INFO [ProducerStateManager partition=edited6-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:36,498] INFO [Log partition=edited6-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:36,498] INFO [Log partition=edited6-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,498] INFO [ProducerStateManager partition=edited6-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:36,514] INFO [Log partition=edited6-0, dir=C:\tmp\logs1] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,514] INFO [ProducerStateManager partition=edited6-0] Loading producer state from snapshot file 'C:\tmp\logs1\edited6-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:36,529] INFO [Log partition=edited6-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 62 ms (kafka.log.Log)
[2019-01-26 19:38:36,529] WARN [Log partition=edited6-1, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\edited6-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\edited6-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548321919981}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:36,529] INFO [Log partition=edited6-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,545] INFO [ProducerStateManager partition=edited6-1] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:36,545] INFO [Log partition=edited6-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:36,545] INFO [Log partition=edited6-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,561] INFO [ProducerStateManager partition=edited6-1] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:36,561] INFO [Log partition=edited6-1, dir=C:\tmp\logs1] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,576] INFO [ProducerStateManager partition=edited6-1] Loading producer state from snapshot file 'C:\tmp\logs1\edited6-1\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:36,576] INFO [Log partition=edited6-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 47 ms (kafka.log.Log)
[2019-01-26 19:38:36,592] INFO [Log partition=edited8-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:36,592] INFO [Log partition=edited8-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,607] INFO [Log partition=edited8-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,607] INFO [Log partition=edited8-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:36,623] INFO [Log partition=edited8-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:36,623] INFO [Log partition=edited8-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,639] INFO [Log partition=edited8-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,639] INFO [Log partition=edited8-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:38:36,654] INFO [Log partition=editedstack-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:36,654] INFO [Log partition=editedstack-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,670] INFO [Log partition=editedstack-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,670] INFO [Log partition=editedstack-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:38:36,670] INFO [Log partition=editedstack-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:36,686] INFO [Log partition=editedstack-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,686] INFO [Log partition=editedstack-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,701] INFO [Log partition=editedstack-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:36,701] INFO [Log partition=editedstack-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:36,701] INFO [Log partition=editedstack-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,717] INFO [Log partition=editedstack-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,717] INFO [Log partition=editedstack-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:38:36,717] WARN [Log partition=mytools-0, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\mytools-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\mytools-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547991919170}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:36,717] INFO [Log partition=mytools-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,732] INFO [ProducerStateManager partition=mytools-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:36,732] INFO [Log partition=mytools-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:36,732] INFO [Log partition=mytools-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,748] INFO [ProducerStateManager partition=mytools-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:36,748] INFO [Log partition=mytools-0, dir=C:\tmp\logs1] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,764] INFO [ProducerStateManager partition=mytools-0] Loading producer state from snapshot file 'C:\tmp\logs1\mytools-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:36,764] INFO [Log partition=mytools-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 47 ms (kafka.log.Log)
[2019-01-26 19:38:36,779] INFO [Log partition=mytools-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:36,779] INFO [Log partition=mytools-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,779] INFO [Log partition=mytools-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,779] INFO [Log partition=mytools-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:38:36,795] INFO [Log partition=pairing-stream-app-pairs-store-changelog-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:36,795] INFO [Log partition=pairing-stream-app-pairs-store-changelog-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,810] INFO [ProducerStateManager partition=pairing-stream-app-pairs-store-changelog-1] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:36,810] INFO [Log partition=pairing-stream-app-pairs-store-changelog-1, dir=C:\tmp\logs1] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,826] INFO [ProducerStateManager partition=pairing-stream-app-pairs-store-changelog-1] Loading producer state from snapshot file 'C:\tmp\logs1\pairing-stream-app-pairs-store-changelog-1\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:36,826] INFO [Log partition=pairing-stream-app-pairs-store-changelog-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:36,842] INFO [Log partition=pairs-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:36,842] INFO [Log partition=pairs-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,857] INFO [ProducerStateManager partition=pairs-0] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:36,857] INFO [Log partition=pairs-0, dir=C:\tmp\logs1] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,857] INFO [ProducerStateManager partition=pairs-0] Loading producer state from snapshot file 'C:\tmp\logs1\pairs-0\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:36,857] INFO [Log partition=pairs-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:36,873] INFO [Log partition=pairs-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:36,873] INFO [Log partition=pairs-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,889] INFO [ProducerStateManager partition=pairs-2] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:36,889] INFO [Log partition=pairs-2, dir=C:\tmp\logs1] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,904] INFO [ProducerStateManager partition=pairs-2] Loading producer state from snapshot file 'C:\tmp\logs1\pairs-2\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:36,904] INFO [Log partition=pairs-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:36,904] INFO [Log partition=randommessages-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:36,904] INFO [Log partition=randommessages-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,920] INFO [ProducerStateManager partition=randommessages-1] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:36,920] INFO [Log partition=randommessages-1, dir=C:\tmp\logs1] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,935] INFO [ProducerStateManager partition=randommessages-1] Loading producer state from snapshot file 'C:\tmp\logs1\randommessages-1\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:36,935] INFO [Log partition=randommessages-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:36,935] INFO [Log partition=randommessages-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:36,935] INFO [Log partition=randommessages-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,951] INFO [ProducerStateManager partition=randommessages-2] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:36,951] INFO [Log partition=randommessages-2, dir=C:\tmp\logs1] Loading producer state till offset 11 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,967] INFO [ProducerStateManager partition=randommessages-2] Loading producer state from snapshot file 'C:\tmp\logs1\randommessages-2\00000000000000000011.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:36,967] INFO [Log partition=randommessages-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 11 in 32 ms (kafka.log.Log)
[2019-01-26 19:38:36,967] INFO [Log partition=stack-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:36,967] INFO [Log partition=stack-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,982] INFO [Log partition=stack-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:36,982] INFO [Log partition=stack-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:38:36,998] INFO [Log partition=stack-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:36,998] INFO [Log partition=stack-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,014] INFO [Log partition=stack-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,014] INFO [Log partition=stack-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:38:37,014] INFO [Log partition=stack1-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:37,029] INFO [Log partition=stack1-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,029] INFO [ProducerStateManager partition=stack1-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:37,045] INFO [Log partition=stack1-0, dir=C:\tmp\logs1] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,045] INFO [ProducerStateManager partition=stack1-0] Loading producer state from snapshot file 'C:\tmp\logs1\stack1-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:37,045] INFO [Log partition=stack1-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:37,060] WARN [Log partition=stack1-1, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\stack1-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\stack1-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548456670939}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:37,060] INFO [Log partition=stack1-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,076] INFO [ProducerStateManager partition=stack1-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:37,076] INFO [Log partition=stack1-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:37,076] INFO [Log partition=stack1-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,092] INFO [ProducerStateManager partition=stack1-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:37,092] INFO [Log partition=stack1-1, dir=C:\tmp\logs1] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,092] INFO [ProducerStateManager partition=stack1-1] Loading producer state from snapshot file 'C:\tmp\logs1\stack1-1\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:37,107] INFO [Log partition=stack1-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 47 ms (kafka.log.Log)
[2019-01-26 19:38:37,107] WARN [Log partition=stack1-2, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\stack1-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\stack1-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548456671954}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:37,107] INFO [Log partition=stack1-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,123] INFO [ProducerStateManager partition=stack1-2] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:37,123] INFO [Log partition=stack1-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:37,123] INFO [Log partition=stack1-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,139] INFO [ProducerStateManager partition=stack1-2] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:37,139] INFO [Log partition=stack1-2, dir=C:\tmp\logs1] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,154] INFO [ProducerStateManager partition=stack1-2] Loading producer state from snapshot file 'C:\tmp\logs1\stack1-2\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:37,154] INFO [Log partition=stack1-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 47 ms (kafka.log.Log)
[2019-01-26 19:38:37,154] INFO [Log partition=test-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:37,154] INFO [Log partition=test-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,170] INFO [Log partition=test-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,170] INFO [Log partition=test-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:38:37,185] WARN [Log partition=tools-0, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\tools-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\tools-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547991352625}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:37,185] INFO [Log partition=tools-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,201] INFO [ProducerStateManager partition=tools-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:37,201] INFO [Log partition=tools-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:37,201] INFO [Log partition=tools-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,217] INFO [ProducerStateManager partition=tools-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:37,232] INFO [Log partition=tools-0, dir=C:\tmp\logs1] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,232] INFO [ProducerStateManager partition=tools-0] Loading producer state from snapshot file 'C:\tmp\logs1\tools-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:37,232] INFO [Log partition=tools-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 47 ms (kafka.log.Log)
[2019-01-26 19:38:37,248] INFO [Log partition=tools-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:37,248] INFO [Log partition=tools-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,248] INFO [Log partition=tools-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,264] INFO [Log partition=tools-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:38:37,264] INFO [Log partition=tools1-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:37,264] INFO [Log partition=tools1-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,279] INFO [Log partition=tools1-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,279] INFO [Log partition=tools1-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:38:37,295] INFO [Log partition=tools1-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:37,295] INFO [Log partition=tools1-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,295] INFO [Log partition=tools1-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,310] INFO [Log partition=tools1-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:38:37,310] INFO [Log partition=tools10-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:37,310] INFO [Log partition=tools10-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,326] INFO [Log partition=tools10-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,326] INFO [Log partition=tools10-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:38:37,342] INFO [Log partition=tools10-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:37,342] INFO [Log partition=tools10-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,357] INFO [Log partition=tools10-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,357] INFO [Log partition=tools10-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:37,373] INFO [Log partition=tools11-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:37,373] INFO [Log partition=tools11-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,389] INFO [Log partition=tools11-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,389] INFO [Log partition=tools11-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:38:37,404] WARN [Log partition=tools11-2, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\tools11-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\tools11-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548410540359}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:37,404] INFO [Log partition=tools11-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,420] INFO [ProducerStateManager partition=tools11-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:37,420] INFO [Log partition=tools11-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:37,420] INFO [Log partition=tools11-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,435] INFO [ProducerStateManager partition=tools11-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:37,451] INFO [Log partition=tools11-2, dir=C:\tmp\logs1] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,451] INFO [ProducerStateManager partition=tools11-2] Loading producer state from snapshot file 'C:\tmp\logs1\tools11-2\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:37,451] INFO [Log partition=tools11-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 47 ms (kafka.log.Log)
[2019-01-26 19:38:37,467] WARN [Log partition=tools12-0, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\tools12-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\tools12-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548410940127}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:37,467] INFO [Log partition=tools12-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,467] INFO [ProducerStateManager partition=tools12-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:37,482] INFO [Log partition=tools12-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:37,482] INFO [Log partition=tools12-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,482] INFO [ProducerStateManager partition=tools12-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:37,498] INFO [Log partition=tools12-0, dir=C:\tmp\logs1] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,498] INFO [ProducerStateManager partition=tools12-0] Loading producer state from snapshot file 'C:\tmp\logs1\tools12-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:37,498] INFO [Log partition=tools12-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:37,513] INFO [Log partition=tools12-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:37,513] INFO [Log partition=tools12-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,529] INFO [Log partition=tools12-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,529] INFO [Log partition=tools12-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:38:37,529] INFO [Log partition=tools13-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:37,529] INFO [Log partition=tools13-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,545] INFO [ProducerStateManager partition=tools13-0] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:37,545] INFO [Log partition=tools13-0, dir=C:\tmp\logs1] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,560] INFO [ProducerStateManager partition=tools13-0] Loading producer state from snapshot file 'C:\tmp\logs1\tools13-0\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:37,560] INFO [Log partition=tools13-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:37,560] INFO [Log partition=tools13-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:37,560] INFO [Log partition=tools13-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,576] INFO [Log partition=tools13-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,576] INFO [Log partition=tools13-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:38:37,592] INFO [Log partition=tools14-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:37,592] INFO [Log partition=tools14-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,592] INFO [Log partition=tools14-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,607] INFO [Log partition=tools14-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:37,607] INFO [Log partition=tools14-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:37,607] INFO [Log partition=tools14-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,623] INFO [ProducerStateManager partition=tools14-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:37,623] INFO [Log partition=tools14-1, dir=C:\tmp\logs1] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,623] INFO [ProducerStateManager partition=tools14-1] Loading producer state from snapshot file 'C:\tmp\logs1\tools14-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:37,623] INFO [Log partition=tools14-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 16 ms (kafka.log.Log)
[2019-01-26 19:38:37,638] INFO [Log partition=tools2-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:37,638] INFO [Log partition=tools2-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,654] INFO [Log partition=tools2-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,654] INFO [Log partition=tools2-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:38:37,670] INFO [Log partition=tools2-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:37,670] INFO [Log partition=tools2-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,685] INFO [Log partition=tools2-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,685] INFO [Log partition=tools2-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:38:37,701] INFO [Log partition=tools3-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:37,701] INFO [Log partition=tools3-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,701] INFO [Log partition=tools3-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,717] INFO [Log partition=tools3-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:38:37,717] INFO [Log partition=tools3-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:37,732] INFO [Log partition=tools3-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,732] INFO [Log partition=tools3-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,732] INFO [Log partition=tools3-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:38:37,748] INFO [Log partition=tools4-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:37,748] INFO [Log partition=tools4-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,748] INFO [Log partition=tools4-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,764] INFO [Log partition=tools4-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:38:37,764] INFO [Log partition=tools4-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:37,764] INFO [Log partition=tools4-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,779] INFO [Log partition=tools4-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,779] INFO [Log partition=tools4-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:38:37,795] WARN [Log partition=tools5-1, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\tools5-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\tools5-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996876577}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:37,795] INFO [Log partition=tools5-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,795] INFO [ProducerStateManager partition=tools5-1] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:37,810] INFO [Log partition=tools5-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:37,810] INFO [Log partition=tools5-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,810] INFO [ProducerStateManager partition=tools5-1] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:37,826] INFO [Log partition=tools5-1, dir=C:\tmp\logs1] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,826] INFO [ProducerStateManager partition=tools5-1] Loading producer state from snapshot file 'C:\tmp\logs1\tools5-1\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:37,826] INFO [Log partition=tools5-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 47 ms (kafka.log.Log)
[2019-01-26 19:38:37,842] WARN [Log partition=tools5-2, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\tools5-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\tools5-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996835000}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:37,842] INFO [Log partition=tools5-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,857] INFO [ProducerStateManager partition=tools5-2] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:37,857] INFO [Log partition=tools5-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:37,857] INFO [Log partition=tools5-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,873] INFO [ProducerStateManager partition=tools5-2] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:37,873] INFO [Log partition=tools5-2, dir=C:\tmp\logs1] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,873] INFO [ProducerStateManager partition=tools5-2] Loading producer state from snapshot file 'C:\tmp\logs1\tools5-2\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:37,888] INFO [Log partition=tools5-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 62 ms (kafka.log.Log)
[2019-01-26 19:38:37,888] WARN [Log partition=tools6-0, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\tools6-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\tools6-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548176773646}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:37,888] INFO [Log partition=tools6-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,904] INFO [ProducerStateManager partition=tools6-0] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:37,904] INFO [Log partition=tools6-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:37,904] INFO [Log partition=tools6-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,920] INFO [ProducerStateManager partition=tools6-0] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:37,935] INFO [Log partition=tools6-0, dir=C:\tmp\logs1] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,935] INFO [ProducerStateManager partition=tools6-0] Loading producer state from snapshot file 'C:\tmp\logs1\tools6-0\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:37,935] INFO [Log partition=tools6-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 47 ms (kafka.log.Log)
[2019-01-26 19:38:37,951] WARN [Log partition=tools6-2, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\tools6-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\tools6-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548158302054}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:37,951] INFO [Log partition=tools6-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,951] INFO [ProducerStateManager partition=tools6-2] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:37,966] INFO [Log partition=tools6-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:37,966] INFO [Log partition=tools6-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,966] INFO [ProducerStateManager partition=tools6-2] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:37,982] INFO [Log partition=tools6-2, dir=C:\tmp\logs1] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:37,982] INFO [ProducerStateManager partition=tools6-2] Loading producer state from snapshot file 'C:\tmp\logs1\tools6-2\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:37,982] INFO [Log partition=tools6-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:37,998] WARN [Log partition=tools7-0, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\tools7-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\tools7-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548173477306}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:37,998] INFO [Log partition=tools7-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,013] INFO [ProducerStateManager partition=tools7-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:38,013] INFO [Log partition=tools7-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:38,013] INFO [Log partition=tools7-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,029] INFO [ProducerStateManager partition=tools7-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:38,045] INFO [Log partition=tools7-0, dir=C:\tmp\logs1] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,045] INFO [ProducerStateManager partition=tools7-0] Loading producer state from snapshot file 'C:\tmp\logs1\tools7-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:38,045] INFO [Log partition=tools7-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 47 ms (kafka.log.Log)
[2019-01-26 19:38:38,060] WARN [Log partition=tools7-2, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\tools7-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\tools7-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548156023437}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:38,060] INFO [Log partition=tools7-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,060] INFO [ProducerStateManager partition=tools7-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:38,076] INFO [Log partition=tools7-2, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:38,076] INFO [Log partition=tools7-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,076] INFO [ProducerStateManager partition=tools7-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:38,091] INFO [Log partition=tools7-2, dir=C:\tmp\logs1] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,091] INFO [ProducerStateManager partition=tools7-2] Loading producer state from snapshot file 'C:\tmp\logs1\tools7-2\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:38,091] INFO [Log partition=tools7-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:38,107] INFO [Log partition=tools8-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:38,107] INFO [Log partition=tools8-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,123] INFO [Log partition=tools8-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,123] INFO [Log partition=tools8-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:38:38,138] WARN [Log partition=tools8-1, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\tools8-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\tools8-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548341369651}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:38,138] INFO [Log partition=tools8-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,154] INFO [ProducerStateManager partition=tools8-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:38,154] INFO [Log partition=tools8-1, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:38,154] INFO [Log partition=tools8-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,170] INFO [ProducerStateManager partition=tools8-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:38,170] INFO [Log partition=tools8-1, dir=C:\tmp\logs1] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,185] INFO [ProducerStateManager partition=tools8-1] Loading producer state from snapshot file 'C:\tmp\logs1\tools8-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:38,185] INFO [Log partition=tools8-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 47 ms (kafka.log.Log)
[2019-01-26 19:38:38,185] WARN [Log partition=__consumer_offsets-0, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\__consumer_offsets-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\__consumer_offsets-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547994284686}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:38,185] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,201] INFO [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:38,201] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:38,201] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,216] INFO [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:38,216] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\logs1] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,232] INFO [ProducerStateManager partition=__consumer_offsets-0] Loading producer state from snapshot file 'C:\tmp\logs1\__consumer_offsets-0\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:38,232] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 47 ms (kafka.log.Log)
[2019-01-26 19:38:38,232] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:38,232] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,248] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,248] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:38:38,263] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:38,263] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,263] INFO [ProducerStateManager partition=__consumer_offsets-15] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:38,279] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\logs1] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,279] INFO [ProducerStateManager partition=__consumer_offsets-15] Loading producer state from snapshot file 'C:\tmp\logs1\__consumer_offsets-15\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:38,279] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:38,295] WARN [Log partition=__consumer_offsets-18, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\__consumer_offsets-18\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\__consumer_offsets-18\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548177188378}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:38,295] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,310] INFO [ProducerStateManager partition=__consumer_offsets-18] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:38,310] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:38,310] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,310] INFO [ProducerStateManager partition=__consumer_offsets-18] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:38,326] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\logs1] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,326] INFO [ProducerStateManager partition=__consumer_offsets-18] Loading producer state from snapshot file 'C:\tmp\logs1\__consumer_offsets-18\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:38,326] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:38,341] WARN [Log partition=__consumer_offsets-21, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\__consumer_offsets-21\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\__consumer_offsets-21\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547985284682}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:38,341] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,341] INFO [ProducerStateManager partition=__consumer_offsets-21] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:38,341] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:38,341] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,341] INFO [ProducerStateManager partition=__consumer_offsets-21] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:38,373] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\logs1] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,373] INFO [ProducerStateManager partition=__consumer_offsets-21] Loading producer state from snapshot file 'C:\tmp\logs1\__consumer_offsets-21\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:38,373] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 47 ms (kafka.log.Log)
[2019-01-26 19:38:38,373] WARN [Log partition=__consumer_offsets-24, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\__consumer_offsets-24\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\__consumer_offsets-24\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547991284687}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:38,373] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,388] INFO [ProducerStateManager partition=__consumer_offsets-24] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:38,388] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:38,388] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,404] INFO [ProducerStateManager partition=__consumer_offsets-24] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:38,404] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\logs1] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,404] INFO [ProducerStateManager partition=__consumer_offsets-24] Loading producer state from snapshot file 'C:\tmp\logs1\__consumer_offsets-24\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:38,404] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:38,419] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:38,419] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,435] INFO [ProducerStateManager partition=__consumer_offsets-27] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:38,435] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\logs1] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,435] INFO [ProducerStateManager partition=__consumer_offsets-27] Loading producer state from snapshot file 'C:\tmp\logs1\__consumer_offsets-27\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:38,435] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 16 ms (kafka.log.Log)
[2019-01-26 19:38:38,451] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:38,451] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,466] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,466] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:38:38,466] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:38,482] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,482] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,482] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:38:38,498] WARN [Log partition=__consumer_offsets-33, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\__consumer_offsets-33\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\__consumer_offsets-33\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548156193182}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:38,498] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,498] INFO [ProducerStateManager partition=__consumer_offsets-33] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:38,513] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:38,513] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,529] INFO [ProducerStateManager partition=__consumer_offsets-33] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:38,529] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\logs1] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,529] INFO [ProducerStateManager partition=__consumer_offsets-33] Loading producer state from snapshot file 'C:\tmp\logs1\__consumer_offsets-33\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:38,529] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:38,545] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:38,545] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,560] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,560] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:38:38,560] WARN [Log partition=__consumer_offsets-39, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\__consumer_offsets-39\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\__consumer_offsets-39\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548010498324}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:38,560] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,576] INFO [ProducerStateManager partition=__consumer_offsets-39] Writing producer snapshot at offset 31 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:38,576] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:38,576] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,591] INFO [ProducerStateManager partition=__consumer_offsets-39] Writing producer snapshot at offset 31 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:38,591] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\logs1] Loading producer state till offset 31 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,591] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file 'C:\tmp\logs1\__consumer_offsets-39\00000000000000000031.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:38,591] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 31 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:38,607] WARN [Log partition=__consumer_offsets-42, dir=C:\tmp\logs1] Found a corrupted index file corresponding to log file C:\tmp\logs1\__consumer_offsets-42\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs1\__consumer_offsets-42\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548156193185}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:38,607] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,623] INFO [ProducerStateManager partition=__consumer_offsets-42] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:38,623] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:38,623] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,623] INFO [ProducerStateManager partition=__consumer_offsets-42] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:38,623] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\logs1] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,638] INFO [ProducerStateManager partition=__consumer_offsets-42] Loading producer state from snapshot file 'C:\tmp\logs1\__consumer_offsets-42\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:38,638] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:38,654] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:38,654] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,669] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,669] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:38:38,669] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:38,669] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,685] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,685] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:38:38,685] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:38,701] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,701] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,716] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:38,716] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\logs1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:38,716] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,732] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:38,732] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:38:38,748] INFO Logs loading complete in 3015 ms. (kafka.log.LogManager)
[2019-01-26 19:38:38,763] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-26 19:38:38,763] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-26 19:38:39,138] INFO Awaiting socket connections on localhost:9093. (kafka.network.Acceptor)
[2019-01-26 19:38:39,169] INFO [SocketServer brokerId=1] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-26 19:38:39,201] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:38:39,201] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:38:39,216] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:38:39,216] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-26 19:38:39,279] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-26 19:38:39,279] INFO Result of znode creation at /brokers/ids/1 is: OK (kafka.zk.KafkaZkClient)
[2019-01-26 19:38:39,279] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(localhost,9093,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-26 19:38:39,357] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:38:39,357] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:38:39,372] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:38:39,404] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 19:38:39,404] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 19:38:39,419] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 15 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:38:39,435] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:33000,blockEndProducerId:33999) by writing to Zk with path version 34 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-26 19:38:39,482] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-26 19:38:39,482] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-26 19:38:39,497] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-26 19:38:39,560] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-26 19:38:39,622] INFO [SocketServer brokerId=1] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-26 19:38:39,638] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-26 19:38:39,638] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-26 19:38:39,638] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2019-01-26 19:38:39,794] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(tools4-0, edited8-2, tools10-2, tools1-1, __consumer_offsets-30, tools2-2, pairing-stream-app-pairs-store-changelog-1, tools-2, __consumer_offsets-21, stack1-1, tools7-0, edited6-0, __consumer_offsets-27, __consumer_offsets-9, tools3-0, tools4-1, alltools-2, tools5-2, __consumer_offsets-33, tools1-2, randommessages-1, tools8-0, edited-1, test-0, tools14-0, edited8-1, mytools-0, __consumer_offsets-36, edited12-2, __consumer_offsets-42, __consumer_offsets-3, stack-0, __consumer_offsets-18, edited10-1, tools5-1, pairs-0, __consumer_offsets-15, __consumer_offsets-24, tools6-2, tools11-1, alltools-0, tools13-0, pairs-2, anstack-0, aggregated_data-0, __consumer_offsets-48, tools-0, tools12-2, randommessages-2, edited10-2, edited12-1, tools7-2, __consumer_offsets-6, edited-0, editedstack-1, tools3-2, edited6-1, aggregateddata-1, __consumer_offsets-0, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, aggregated_data-2, stack-2, mytools-2, tools12-0, edited13-0, edited13-1, tools2-0) (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:38:39,825] INFO Replica loaded for partition tools2-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:39,825] INFO Replica loaded for partition tools2-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:39,825] INFO [Partition tools2-2 broker=1] tools2-2 starts at Leader Epoch 27 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:39,857] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 6 (kafka.cluster.Replica)
[2019-01-26 19:38:39,872] INFO [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 4 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:39,872] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0000 type:multi cxid:0x1c3 zxid:0xd2f txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:38:39,888] INFO Replica loaded for partition edited6-1 with initial high watermark 7 (kafka.cluster.Replica)
[2019-01-26 19:38:39,888] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0000 type:multi cxid:0x1c6 zxid:0xd30 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:38:39,888] INFO Replica loaded for partition edited6-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:39,888] INFO [Partition edited6-1 broker=1] edited6-1 starts at Leader Epoch 4 from offset 7. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:39,904] INFO Replica loaded for partition stack-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:39,904] INFO Replica loaded for partition stack-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:39,919] INFO [Partition stack-0 broker=1] stack-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:39,919] INFO Replica loaded for partition tools1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:39,919] INFO Replica loaded for partition tools1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:39,935] INFO [Partition tools1-1 broker=1] tools1-1 starts at Leader Epoch 27 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:39,935] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:39,950] INFO [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:39,950] INFO Replica loaded for partition mytools-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-26 19:38:39,950] INFO Replica loaded for partition mytools-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:39,966] INFO [Partition mytools-0 broker=1] mytools-0 starts at Leader Epoch 7 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:39,966] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:39,966] INFO [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:39,982] INFO Replica loaded for partition tools5-2 with initial high watermark 8 (kafka.cluster.Replica)
[2019-01-26 19:38:39,982] INFO Replica loaded for partition tools5-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:39,982] INFO [Partition tools5-2 broker=1] tools5-2 starts at Leader Epoch 7 from offset 8. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:39,997] INFO Replica loaded for partition edited10-2 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-26 19:38:39,997] INFO Replica loaded for partition edited10-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,013] INFO [Partition edited10-2 broker=1] edited10-2 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,013] INFO Replica loaded for partition tools4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,013] INFO Replica loaded for partition tools4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,013] INFO [Partition tools4-1 broker=1] tools4-1 starts at Leader Epoch 7 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,028] INFO Replica loaded for partition tools3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,028] INFO Replica loaded for partition tools3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,028] INFO [Partition tools3-0 broker=1] tools3-0 starts at Leader Epoch 7 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,044] INFO Replica loaded for partition pairs-0 with initial high watermark 5 (kafka.cluster.Replica)
[2019-01-26 19:38:40,044] INFO Replica loaded for partition pairs-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,044] INFO [Partition pairs-0 broker=1] pairs-0 starts at Leader Epoch 1 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,060] INFO Replica loaded for partition tools-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-26 19:38:40,060] INFO Replica loaded for partition tools-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,060] INFO [Partition tools-0 broker=1] tools-0 starts at Leader Epoch 7 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,075] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-26 19:38:40,075] INFO [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 4 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,075] INFO Replica loaded for partition randommessages-2 with initial high watermark 11 (kafka.cluster.Replica)
[2019-01-26 19:38:40,091] INFO Replica loaded for partition randommessages-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,091] INFO [Partition randommessages-2 broker=1] randommessages-2 starts at Leader Epoch 1 from offset 11. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,091] INFO Replica loaded for partition edited12-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,091] INFO Replica loaded for partition edited12-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,107] INFO [Partition edited12-1 broker=1] edited12-1 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,122] INFO Replica loaded for partition editedstack-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,122] INFO Replica loaded for partition editedstack-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,122] INFO [Partition editedstack-1 broker=1] editedstack-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,138] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 31 (kafka.cluster.Replica)
[2019-01-26 19:38:40,138] INFO [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 4 from offset 31. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,153] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,153] INFO [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,169] INFO Replica loaded for partition tools12-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-26 19:38:40,169] INFO Replica loaded for partition tools12-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,185] INFO [Partition tools12-0 broker=1] tools12-0 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,185] INFO Replica loaded for partition stack1-1 with initial high watermark 6 (kafka.cluster.Replica)
[2019-01-26 19:38:40,185] INFO Replica loaded for partition stack1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,185] INFO [Partition stack1-1 broker=1] stack1-1 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,200] INFO Replica loaded for partition tools7-2 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-26 19:38:40,200] INFO Replica loaded for partition tools7-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,200] INFO [Partition tools7-2 broker=1] tools7-2 starts at Leader Epoch 17 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,216] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-26 19:38:40,216] INFO [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 4 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,216] INFO Replica loaded for partition aggregated_data-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-26 19:38:40,232] INFO Replica loaded for partition aggregated_data-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,232] INFO [Partition aggregated_data-0 broker=1] aggregated_data-0 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,232] INFO Replica loaded for partition anstack-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,247] INFO [Partition anstack-0 broker=1] anstack-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,247] INFO Replica loaded for partition aggregateddata-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,263] INFO Replica loaded for partition aggregateddata-1 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-26 19:38:40,263] INFO [Partition aggregateddata-1 broker=1] aggregateddata-1 starts at Leader Epoch 2 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,278] INFO Replica loaded for partition tools8-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,294] INFO Replica loaded for partition tools8-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,294] INFO [Partition tools8-0 broker=1] tools8-0 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,294] INFO Replica loaded for partition edited-0 with initial high watermark 8 (kafka.cluster.Replica)
[2019-01-26 19:38:40,294] INFO Replica loaded for partition edited-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,294] INFO [Partition edited-0 broker=1] edited-0 starts at Leader Epoch 27 from offset 8. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,310] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,310] INFO [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,325] INFO Replica loaded for partition tools1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,325] INFO Replica loaded for partition tools1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,325] INFO [Partition tools1-2 broker=1] tools1-2 starts at Leader Epoch 7 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,341] INFO Replica loaded for partition test-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,341] INFO [Partition test-0 broker=1] test-0 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,357] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 8 (kafka.cluster.Replica)
[2019-01-26 19:38:40,357] INFO [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 4 from offset 8. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,357] INFO Replica loaded for partition alltools-2 with initial high watermark 5 (kafka.cluster.Replica)
[2019-01-26 19:38:40,357] INFO Replica loaded for partition alltools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,372] INFO [Partition alltools-2 broker=1] alltools-2 starts at Leader Epoch 28 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,372] INFO Replica loaded for partition edited8-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,372] INFO Replica loaded for partition edited8-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,372] INFO [Partition edited8-1 broker=1] edited8-1 starts at Leader Epoch 7 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,388] INFO Replica loaded for partition tools2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,388] INFO Replica loaded for partition tools2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,388] INFO [Partition tools2-0 broker=1] tools2-0 starts at Leader Epoch 7 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,403] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-26 19:38:40,403] INFO [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 4 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,419] INFO Replica loaded for partition tools14-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,419] INFO Replica loaded for partition tools14-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,419] INFO [Partition tools14-0 broker=1] tools14-0 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,435] INFO Replica loaded for partition edited12-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,435] INFO Replica loaded for partition edited12-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,435] INFO [Partition edited12-2 broker=1] edited12-2 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,450] INFO Replica loaded for partition mytools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,450] INFO Replica loaded for partition mytools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,450] INFO [Partition mytools-2 broker=1] mytools-2 starts at Leader Epoch 27 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,466] INFO Replica loaded for partition tools10-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,466] INFO Replica loaded for partition tools10-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,482] INFO [Partition tools10-2 broker=1] tools10-2 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,482] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-26 19:38:40,497] INFO [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 4 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,497] INFO Replica loaded for partition edited13-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,497] INFO Replica loaded for partition edited13-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,497] INFO [Partition edited13-0 broker=1] edited13-0 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,513] INFO Replica loaded for partition pairs-2 with initial high watermark 5 (kafka.cluster.Replica)
[2019-01-26 19:38:40,513] INFO Replica loaded for partition pairs-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,513] INFO [Partition pairs-2 broker=1] pairs-2 starts at Leader Epoch 1 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,528] INFO Replica loaded for partition edited8-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,528] INFO Replica loaded for partition edited8-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,528] INFO [Partition edited8-2 broker=1] edited8-2 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,544] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-26 19:38:40,544] INFO [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 4 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,560] INFO Replica loaded for partition tools3-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,560] INFO Replica loaded for partition tools3-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,560] INFO [Partition tools3-2 broker=1] tools3-2 starts at Leader Epoch 27 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,575] INFO Replica loaded for partition pairing-stream-app-pairs-store-changelog-1 with initial high watermark 10 (kafka.cluster.Replica)
[2019-01-26 19:38:40,575] INFO [Partition pairing-stream-app-pairs-store-changelog-1 broker=1] pairing-stream-app-pairs-store-changelog-1 starts at Leader Epoch 1 from offset 10. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,575] INFO Replica loaded for partition tools5-1 with initial high watermark 5 (kafka.cluster.Replica)
[2019-01-26 19:38:40,591] INFO Replica loaded for partition tools5-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,591] INFO [Partition tools5-1 broker=1] tools5-1 starts at Leader Epoch 27 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,606] INFO Replica loaded for partition tools4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,606] INFO Replica loaded for partition tools4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,606] INFO [Partition tools4-0 broker=1] tools4-0 starts at Leader Epoch 27 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,622] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-26 19:38:40,622] INFO [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 4 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,622] INFO Replica loaded for partition tools6-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,638] INFO Replica loaded for partition tools6-2 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-26 19:38:40,638] INFO [Partition tools6-2 broker=1] tools6-2 starts at Leader Epoch 9 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,638] INFO Replica loaded for partition edited-1 with initial high watermark 9 (kafka.cluster.Replica)
[2019-01-26 19:38:40,638] INFO Replica loaded for partition edited-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,638] INFO [Partition edited-1 broker=1] edited-1 starts at Leader Epoch 7 from offset 9. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,653] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,653] INFO [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,669] INFO Replica loaded for partition tools7-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-26 19:38:40,669] INFO Replica loaded for partition tools7-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,685] INFO [Partition tools7-0 broker=1] tools7-0 starts at Leader Epoch 4 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,685] INFO Replica loaded for partition stack-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,685] INFO Replica loaded for partition stack-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,700] INFO [Partition stack-2 broker=1] stack-2 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,700] INFO Replica loaded for partition edited13-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,700] INFO Replica loaded for partition edited13-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,700] INFO [Partition edited13-1 broker=1] edited13-1 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,716] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,716] INFO [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,716] INFO Replica loaded for partition tools11-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,731] INFO Replica loaded for partition tools11-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,731] INFO [Partition tools11-1 broker=1] tools11-1 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,731] INFO Replica loaded for partition tools12-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,747] INFO Replica loaded for partition tools12-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,747] INFO [Partition tools12-2 broker=1] tools12-2 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,747] INFO Replica loaded for partition edited6-0 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-26 19:38:40,763] INFO Replica loaded for partition edited6-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,763] INFO [Partition edited6-0 broker=1] edited6-0 starts at Leader Epoch 23 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,778] INFO Replica loaded for partition edited10-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,778] INFO Replica loaded for partition edited10-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,778] INFO [Partition edited10-1 broker=1] edited10-1 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,794] INFO Replica loaded for partition aggregated_data-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,794] INFO Replica loaded for partition aggregated_data-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,794] INFO [Partition aggregated_data-2 broker=1] aggregated_data-2 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,810] INFO Replica loaded for partition alltools-0 with initial high watermark 4 (kafka.cluster.Replica)
[2019-01-26 19:38:40,810] INFO Replica loaded for partition alltools-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,810] INFO [Partition alltools-0 broker=1] alltools-0 starts at Leader Epoch 8 from offset 4. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,825] INFO Replica loaded for partition tools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,825] INFO Replica loaded for partition tools-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,825] INFO [Partition tools-2 broker=1] tools-2 starts at Leader Epoch 27 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,841] INFO Replica loaded for partition tools13-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,841] INFO Replica loaded for partition tools13-0 with initial high watermark 2 (kafka.cluster.Replica)
[2019-01-26 19:38:40,841] INFO [Partition tools13-0 broker=1] tools13-0 starts at Leader Epoch 2 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,856] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,856] INFO [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,872] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,872] INFO [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,888] INFO Replica loaded for partition randommessages-1 with initial high watermark 10 (kafka.cluster.Replica)
[2019-01-26 19:38:40,888] INFO Replica loaded for partition randommessages-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,888] INFO [Partition randommessages-1 broker=1] randommessages-1 starts at Leader Epoch 1 from offset 10. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:40,903] INFO Replica loaded for partition tools6-0 with initial high watermark 5 (kafka.cluster.Replica)
[2019-01-26 19:38:40,903] INFO Replica loaded for partition tools11-2 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-26 19:38:40,919] INFO Replica loaded for partition tools13-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,919] INFO Replica loaded for partition editedstack-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,919] INFO Replica loaded for partition stack1-2 with initial high watermark 6 (kafka.cluster.Replica)
[2019-01-26 19:38:40,935] INFO Replica loaded for partition tools8-1 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-26 19:38:40,935] INFO Replica loaded for partition aggregateddata-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,935] INFO Replica loaded for partition editedstack-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,950] INFO Replica loaded for partition tools10-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:40,950] INFO Replica loaded for partition stack1-0 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-26 19:38:40,950] INFO Replica loaded for partition tools14-1 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-26 19:38:40,950] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:38:40,981] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:38:40,981] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:38:40,997] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:38:41,013] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:38:41,013] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:38:41,013] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:38:41,028] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 47 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:38:41,028] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:38:41,028] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:38:41,044] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:38:41,044] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:38:41,044] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:38:41,059] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:38:41,059] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:38:41,059] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:38:41,059] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:38:41,059] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:38:41,075] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:38:41,075] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:38:41,091] INFO [GroupCoordinator 1]: Loading group metadata for console-consumer-57831 with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 19:38:41,106] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 62 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:38:41,106] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(editedstack-0, tools8-1, stack1-2, aggregateddata-2, tools10-0, tools14-1, tools11-2, stack1-0, tools13-1, tools6-0, editedstack-2) (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:38:41,106] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:38:41,106] INFO Replica loaded for partition tools6-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:41,122] INFO [Partition tools6-0 broker=1] tools6-0 starts at Leader Epoch 9 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:41,122] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:38:41,138] INFO Replica loaded for partition tools11-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:41,138] INFO [Partition tools11-2 broker=1] tools11-2 starts at Leader Epoch 3 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:41,138] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:38:41,138] INFO Replica loaded for partition tools13-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:41,153] INFO [Partition tools13-1 broker=1] tools13-1 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:41,153] INFO Replica loaded for partition editedstack-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:41,153] INFO [GroupCoordinator 1]: Loading group metadata for group2 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 19:38:41,153] INFO [Partition editedstack-2 broker=1] editedstack-2 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:41,169] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:38:41,169] INFO Replica loaded for partition stack1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:41,169] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:38:41,169] INFO [Partition stack1-2 broker=1] stack1-2 starts at Leader Epoch 1 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:41,184] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:38:41,184] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:38:41,200] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:38:41,200] INFO Replica loaded for partition aggregateddata-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:41,200] INFO [Partition aggregateddata-2 broker=1] aggregateddata-2 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:41,200] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:38:41,216] INFO Replica loaded for partition tools8-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:41,216] INFO [Partition tools8-1 broker=1] tools8-1 starts at Leader Epoch 3 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:41,216] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:38:41,216] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:38:41,231] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:38:41,231] INFO Replica loaded for partition tools10-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:41,231] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:38:41,231] INFO [Partition tools10-0 broker=1] tools10-0 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:41,231] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:38:41,247] INFO Replica loaded for partition editedstack-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:41,247] INFO [Partition editedstack-0 broker=1] editedstack-0 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:41,263] INFO Replica loaded for partition tools14-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:41,263] INFO [Partition tools14-1 broker=1] tools14-1 starts at Leader Epoch 2 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:41,263] INFO Replica loaded for partition stack1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:38:41,263] INFO [Partition stack1-0 broker=1] stack1-0 starts at Leader Epoch 1 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:38:51,120] INFO [GroupCoordinator 1]: Member consumer-1-b7bac741-7611-4073-ba3a-79163667610e in group console-consumer-57831 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 19:38:51,120] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-57831 in state PreparingRebalance with old generation 1 (__consumer_offsets-15) (reason: removing member consumer-1-b7bac741-7611-4073-ba3a-79163667610e on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 19:38:51,135] INFO [GroupCoordinator 1]: Group console-consumer-57831 with generation 2 is now empty (__consumer_offsets-15) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 19:38:54,229] INFO [Partition edited10-2 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-26 19:38:54,229] INFO [Partition edited-1 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-26 19:38:54,244] INFO [Partition tools-0 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-26 19:38:54,244] INFO [Partition randommessages-2 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-26 19:38:54,244] INFO [Partition edited12-2 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-26 19:38:54,260] INFO [Partition tools11-1 broker=1] Shrinking ISR from 3,1 to 1 (kafka.cluster.Partition)
[2019-01-26 19:38:54,260] INFO [Partition tools10-2 broker=1] Shrinking ISR from 3,1 to 1 (kafka.cluster.Partition)
[2019-01-26 19:38:54,260] INFO [Partition aggregated_data-0 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-26 19:38:54,275] INFO [Partition tools2-0 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-26 19:38:54,275] INFO [Partition tools3-0 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-26 19:38:54,275] INFO [Partition tools8-0 broker=1] Shrinking ISR from 3,1 to 1 (kafka.cluster.Partition)
[2019-01-26 19:38:54,275] INFO [Partition tools7-0 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-26 19:38:54,291] INFO [Partition stack-0 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-26 19:38:54,291] INFO [Partition stack1-1 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-26 19:38:54,291] INFO [Partition pairs-0 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-26 19:38:54,307] INFO [Partition aggregateddata-1 broker=1] Shrinking ISR from 3,1 to 1 (kafka.cluster.Partition)
[2019-01-26 19:38:54,307] INFO [Partition alltools-0 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-26 19:38:54,307] INFO [Partition editedstack-1 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-26 19:38:54,307] INFO [Partition edited8-2 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-26 19:38:54,322] INFO [Partition tools4-1 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-26 19:38:54,322] INFO [Partition mytools-0 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-26 19:38:54,322] INFO [Partition edited13-1 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-26 19:38:54,338] INFO [Partition tools14-0 broker=1] Shrinking ISR from 3,1 to 1 (kafka.cluster.Partition)
[2019-01-26 19:38:54,338] INFO [Partition tools13-0 broker=1] Shrinking ISR from 3,1 to 1 (kafka.cluster.Partition)
[2019-01-26 19:38:54,338] INFO [Partition tools12-0 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-26 19:38:54,353] INFO [Partition tools1-2 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-26 19:38:54,353] INFO [Partition tools6-2 broker=1] Shrinking ISR from 3,1 to 1 (kafka.cluster.Partition)
[2019-01-26 19:38:54,353] INFO [Partition edited6-1 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-26 19:38:54,353] INFO [Partition tools5-2 broker=1] Shrinking ISR from 1,2 to 1 (kafka.cluster.Partition)
[2019-01-26 19:38:56,263] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-26 19:38:56,935] INFO starting (kafka.server.KafkaServer)
[2019-01-26 19:38:56,935] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-26 19:38:56,966] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-26 19:38:56,966] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:38:56,966] INFO Client environment:host.name=ITdif.mshome.net (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:38:56,966] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:38:56,966] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:38:56,966] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:38:56,966] INFO Client environment:java.class.path=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-connect-jdbc-5.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\mysql-connector-java-5.1.42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:38:56,966] INFO Client environment:java.library.path=C:\Program Files\Java\jre1.8.0_181\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Docker\Docker\Resources\bin;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\Scripts\;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\dotnet\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\NoteBook FanControl\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\extras\CUPTI\libx64;C:\tools\cuda\bin;C:\Program Files\PuTTY\;C:\Program Files\Calibre2\;C:\apache-maven-3.6.\bin;C:\Users\Stefano\Downloads\platform-tools_r28.0.1-windows\platform-tools;C:\Program Files\Java\jre1.8.0_181\bin;C:\Users\Stefano\AppData\Local\Programs\Python\Launcher\;C:\Users\Stefano\AppData\Local\Microsoft\WindowsApps;C:\Users\Stefano\AppData\Local\GitHubDesktop\bin;C:\apache-maven-3.6.0\bin;;. (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:38:56,966] INFO Client environment:java.io.tmpdir=C:\Users\Stefano\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:38:56,966] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:38:56,966] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:38:56,966] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:38:56,966] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:38:56,966] INFO Client environment:user.name=Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:38:56,966] INFO Client environment:user.home=C:\Users\Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:38:56,966] INFO Client environment:user.dir=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:38:56,966] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@1622f1b (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:38:56,997] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-26 19:38:56,997] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-26 19:38:57,013] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62085 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-26 19:38:57,013] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-26 19:38:57,013] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:62085 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:38:57,013] INFO Established session 0x1000aa33c1e0001 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:62085 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:38:57,013] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1000aa33c1e0001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-26 19:38:57,029] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-26 19:38:57,075] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0001 type:create cxid:0x1 zxid:0xd4f txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:38:57,091] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0001 type:create cxid:0x2 zxid:0xd50 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:38:57,091] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0001 type:create cxid:0x3 zxid:0xd51 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:38:57,091] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0001 type:create cxid:0x4 zxid:0xd52 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:38:57,107] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0001 type:create cxid:0x5 zxid:0xd53 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:38:57,107] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0001 type:create cxid:0x6 zxid:0xd54 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:38:57,107] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0001 type:create cxid:0x7 zxid:0xd55 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:38:57,107] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0001 type:create cxid:0x8 zxid:0xd56 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:38:57,107] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0001 type:create cxid:0x9 zxid:0xd57 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:38:57,107] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0001 type:create cxid:0xa zxid:0xd58 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:38:57,122] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0001 type:create cxid:0xb zxid:0xd59 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:38:57,122] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0001 type:create cxid:0xc zxid:0xd5a txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:38:57,122] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0001 type:create cxid:0xd zxid:0xd5b txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:38:57,310] INFO Cluster ID = RvEiz9fYQgKWcHR6fHb3dg (kafka.server.KafkaServer)
[2019-01-26 19:38:57,404] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-26 19:38:57,419] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-26 19:38:57,450] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-26 19:38:57,450] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-26 19:38:57,450] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-26 19:38:57,528] INFO Loading logs. (kafka.log.LogManager)
[2019-01-26 19:38:57,622] INFO [Log partition=aggregateddata-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:57,622] INFO [Log partition=aggregateddata-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:57,669] INFO [Log partition=aggregateddata-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:57,685] INFO [Log partition=aggregateddata-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 94 ms (kafka.log.Log)
[2019-01-26 19:38:57,700] INFO [Log partition=aggregateddata-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:57,700] INFO [Log partition=aggregateddata-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:57,716] INFO [Log partition=aggregateddata-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:57,716] INFO [Log partition=aggregateddata-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:57,732] WARN [Log partition=aggregated_data-0, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\aggregated_data-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\aggregated_data-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548410540359}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:57,732] INFO [Log partition=aggregated_data-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:57,763] INFO [ProducerStateManager partition=aggregated_data-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:57,763] INFO [Log partition=aggregated_data-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:57,763] INFO [Log partition=aggregated_data-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:57,778] INFO [ProducerStateManager partition=aggregated_data-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:57,794] INFO [Log partition=aggregated_data-0, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:57,794] INFO [ProducerStateManager partition=aggregated_data-0] Loading producer state from snapshot file 'C:\tmp\logs2\aggregated_data-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:57,810] INFO [Log partition=aggregated_data-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 78 ms (kafka.log.Log)
[2019-01-26 19:38:57,825] INFO [Log partition=aggregated_data-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:57,825] INFO [Log partition=aggregated_data-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:57,841] INFO [Log partition=aggregated_data-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:57,841] INFO [Log partition=aggregated_data-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:57,857] WARN [Log partition=alltools-0, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\alltools-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\alltools-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547977751460}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:57,857] INFO [Log partition=alltools-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:57,857] INFO [ProducerStateManager partition=alltools-0] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:57,857] INFO [Log partition=alltools-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:57,857] INFO [Log partition=alltools-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:57,872] INFO [ProducerStateManager partition=alltools-0] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:57,872] INFO [Log partition=alltools-0, dir=C:\tmp\logs2] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:57,888] INFO [ProducerStateManager partition=alltools-0] Loading producer state from snapshot file 'C:\tmp\logs2\alltools-0\00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:57,888] INFO [Log partition=alltools-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 47 ms (kafka.log.Log)
[2019-01-26 19:38:57,888] WARN [Log partition=alltools-1, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\alltools-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\alltools-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547979859855}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:57,888] INFO [Log partition=alltools-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:57,903] INFO [ProducerStateManager partition=alltools-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:57,903] INFO [Log partition=alltools-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:57,903] INFO [Log partition=alltools-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:57,919] INFO [ProducerStateManager partition=alltools-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:57,935] INFO [Log partition=alltools-1, dir=C:\tmp\logs2] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:57,935] INFO [ProducerStateManager partition=alltools-1] Loading producer state from snapshot file 'C:\tmp\logs2\alltools-1\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:57,935] INFO [Log partition=alltools-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 47 ms (kafka.log.Log)
[2019-01-26 19:38:57,950] WARN [Log partition=edited-1, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\edited-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\edited-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996876577}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:57,950] INFO [Log partition=edited-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:57,966] INFO [ProducerStateManager partition=edited-1] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:57,966] INFO [Log partition=edited-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:57,966] INFO [Log partition=edited-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:57,981] INFO [ProducerStateManager partition=edited-1] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:57,981] INFO [Log partition=edited-1, dir=C:\tmp\logs2] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:57,981] INFO [ProducerStateManager partition=edited-1] Loading producer state from snapshot file 'C:\tmp\logs2\edited-1\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:57,997] INFO [Log partition=edited-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 9 in 47 ms (kafka.log.Log)
[2019-01-26 19:38:57,997] WARN [Log partition=edited-2, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\edited-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\edited-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996875547}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:57,997] INFO [Log partition=edited-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,013] INFO [ProducerStateManager partition=edited-2] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:58,013] INFO [Log partition=edited-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:58,013] INFO [Log partition=edited-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,028] INFO [ProducerStateManager partition=edited-2] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:58,044] INFO [Log partition=edited-2, dir=C:\tmp\logs2] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,044] INFO [ProducerStateManager partition=edited-2] Loading producer state from snapshot file 'C:\tmp\logs2\edited-2\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:58,044] INFO [Log partition=edited-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 47 ms (kafka.log.Log)
[2019-01-26 19:38:58,060] INFO [Log partition=edited10-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:58,060] INFO [Log partition=edited10-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,075] INFO [Log partition=edited10-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,075] INFO [Log partition=edited10-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:38:58,091] WARN [Log partition=edited10-2, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\edited10-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\edited10-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548410034606}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:58,091] INFO [Log partition=edited10-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,091] INFO [ProducerStateManager partition=edited10-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:58,091] INFO [Log partition=edited10-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:58,106] INFO [Log partition=edited10-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,106] INFO [ProducerStateManager partition=edited10-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:58,122] INFO [Log partition=edited10-2, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,122] INFO [ProducerStateManager partition=edited10-2] Loading producer state from snapshot file 'C:\tmp\logs2\edited10-2\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:58,122] INFO [Log partition=edited10-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 47 ms (kafka.log.Log)
[2019-01-26 19:38:58,153] WARN [Log partition=edited12-0, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\edited12-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\edited12-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548410940127}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:58,169] INFO [Log partition=edited12-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,185] INFO [ProducerStateManager partition=edited12-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:58,200] INFO [Log partition=edited12-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:58,200] INFO [Log partition=edited12-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,216] INFO [ProducerStateManager partition=edited12-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:58,231] INFO [Log partition=edited12-0, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,231] INFO [ProducerStateManager partition=edited12-0] Loading producer state from snapshot file 'C:\tmp\logs2\edited12-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:58,231] INFO [Log partition=edited12-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 93 ms (kafka.log.Log)
[2019-01-26 19:38:58,247] INFO [Log partition=edited12-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:58,247] INFO [Log partition=edited12-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,263] INFO [Log partition=edited12-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,263] INFO [Log partition=edited12-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:38:58,263] INFO [Log partition=edited13-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:58,278] INFO [Log partition=edited13-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,278] INFO [Log partition=edited13-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,278] INFO [Log partition=edited13-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:38:58,294] INFO [Log partition=edited13-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:58,294] INFO [Log partition=edited13-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,294] INFO [ProducerStateManager partition=edited13-2] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:58,310] INFO [Log partition=edited13-2, dir=C:\tmp\logs2] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,325] INFO [ProducerStateManager partition=edited13-2] Loading producer state from snapshot file 'C:\tmp\logs2\edited13-2\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:58,325] INFO [Log partition=edited13-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:58,325] WARN [Log partition=edited6-1, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\edited6-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\edited6-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548321919981}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:58,341] INFO [Log partition=edited6-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,341] INFO [ProducerStateManager partition=edited6-1] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:58,356] INFO [Log partition=edited6-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:58,356] INFO [Log partition=edited6-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,356] INFO [ProducerStateManager partition=edited6-1] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:58,372] INFO [Log partition=edited6-1, dir=C:\tmp\logs2] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,372] INFO [ProducerStateManager partition=edited6-1] Loading producer state from snapshot file 'C:\tmp\logs2\edited6-1\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:58,372] INFO [Log partition=edited6-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 47 ms (kafka.log.Log)
[2019-01-26 19:38:58,388] WARN [Log partition=edited6-2, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\edited6-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\edited6-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548176773646}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:58,388] INFO [Log partition=edited6-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,388] INFO [ProducerStateManager partition=edited6-2] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:58,403] INFO [Log partition=edited6-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:58,403] INFO [Log partition=edited6-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,403] INFO [ProducerStateManager partition=edited6-2] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:58,435] INFO [Log partition=edited6-2, dir=C:\tmp\logs2] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,435] INFO [ProducerStateManager partition=edited6-2] Loading producer state from snapshot file 'C:\tmp\logs2\edited6-2\00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:58,435] INFO [Log partition=edited6-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 47 ms (kafka.log.Log)
[2019-01-26 19:38:58,450] WARN [Log partition=edited8-0, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\edited8-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\edited8-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548341369651}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:58,450] INFO [Log partition=edited8-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,466] INFO [ProducerStateManager partition=edited8-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:58,466] INFO [Log partition=edited8-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:58,466] INFO [Log partition=edited8-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,481] INFO [ProducerStateManager partition=edited8-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:58,497] INFO [Log partition=edited8-0, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,497] INFO [ProducerStateManager partition=edited8-0] Loading producer state from snapshot file 'C:\tmp\logs2\edited8-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:58,497] INFO [Log partition=edited8-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 47 ms (kafka.log.Log)
[2019-01-26 19:38:58,513] INFO [Log partition=edited8-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:58,513] INFO [Log partition=edited8-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,513] INFO [Log partition=edited8-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,528] INFO [Log partition=edited8-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:38:58,528] INFO [Log partition=editedstack-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:58,528] INFO [Log partition=editedstack-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,544] INFO [Log partition=editedstack-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,544] INFO [Log partition=editedstack-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:38:58,559] INFO [Log partition=editedstack-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:58,559] INFO [Log partition=editedstack-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,559] INFO [Log partition=editedstack-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,575] INFO [Log partition=editedstack-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:38:58,575] INFO [Log partition=editedstack-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:58,591] INFO [Log partition=editedstack-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,591] INFO [Log partition=editedstack-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,591] INFO [Log partition=editedstack-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:38:58,606] INFO [Log partition=my-example-topic-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:58,606] INFO [Log partition=my-example-topic-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,622] INFO [Log partition=my-example-topic-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,622] INFO [Log partition=my-example-topic-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:38:58,622] WARN [Log partition=mytools-0, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\mytools-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\mytools-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547991919170}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:58,622] INFO [Log partition=mytools-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,638] INFO [ProducerStateManager partition=mytools-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:58,638] INFO [Log partition=mytools-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:58,638] INFO [Log partition=mytools-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,653] INFO [ProducerStateManager partition=mytools-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:58,653] INFO [Log partition=mytools-0, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,669] INFO [ProducerStateManager partition=mytools-0] Loading producer state from snapshot file 'C:\tmp\logs2\mytools-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:58,669] INFO [Log partition=mytools-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 47 ms (kafka.log.Log)
[2019-01-26 19:38:58,669] INFO [Log partition=mytools-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:58,669] INFO [Log partition=mytools-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,684] INFO [Log partition=mytools-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,684] INFO [Log partition=mytools-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:38:58,700] INFO [Log partition=pairing-stream-app-pairs-store-changelog-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:58,700] INFO [Log partition=pairing-stream-app-pairs-store-changelog-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,716] INFO [ProducerStateManager partition=pairing-stream-app-pairs-store-changelog-2] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:58,716] INFO [Log partition=pairing-stream-app-pairs-store-changelog-2, dir=C:\tmp\logs2] Loading producer state till offset 11 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,731] INFO [ProducerStateManager partition=pairing-stream-app-pairs-store-changelog-2] Loading producer state from snapshot file 'C:\tmp\logs2\pairing-stream-app-pairs-store-changelog-2\00000000000000000011.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:58,731] INFO [Log partition=pairing-stream-app-pairs-store-changelog-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 11 in 47 ms (kafka.log.Log)
[2019-01-26 19:38:58,731] INFO [Log partition=pairs-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:58,731] INFO [Log partition=pairs-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,747] INFO [ProducerStateManager partition=pairs-0] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:58,747] INFO [Log partition=pairs-0, dir=C:\tmp\logs2] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,747] INFO [ProducerStateManager partition=pairs-0] Loading producer state from snapshot file 'C:\tmp\logs2\pairs-0\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:58,763] INFO [Log partition=pairs-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 32 ms (kafka.log.Log)
[2019-01-26 19:38:58,763] INFO [Log partition=pairs-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:58,763] INFO [Log partition=pairs-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,778] INFO [ProducerStateManager partition=pairs-1] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:58,794] INFO [Log partition=pairs-1, dir=C:\tmp\logs2] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,794] INFO [ProducerStateManager partition=pairs-1] Loading producer state from snapshot file 'C:\tmp\logs2\pairs-1\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:58,794] INFO [Log partition=pairs-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:58,810] INFO [Log partition=randommessages-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:58,810] INFO [Log partition=randommessages-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,825] INFO [ProducerStateManager partition=randommessages-0] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:58,841] INFO [Log partition=randommessages-0, dir=C:\tmp\logs2] Loading producer state till offset 11 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,841] INFO [ProducerStateManager partition=randommessages-0] Loading producer state from snapshot file 'C:\tmp\logs2\randommessages-0\00000000000000000011.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:58,841] INFO [Log partition=randommessages-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 11 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:58,856] INFO [Log partition=randommessages-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:58,856] INFO [Log partition=randommessages-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,856] INFO [ProducerStateManager partition=randommessages-2] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:58,872] INFO [Log partition=randommessages-2, dir=C:\tmp\logs2] Loading producer state till offset 11 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,872] INFO [ProducerStateManager partition=randommessages-2] Loading producer state from snapshot file 'C:\tmp\logs2\randommessages-2\00000000000000000011.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:58,872] INFO [Log partition=randommessages-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 11 in 16 ms (kafka.log.Log)
[2019-01-26 19:38:58,888] INFO [Log partition=stack-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:58,888] INFO [Log partition=stack-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,903] INFO [Log partition=stack-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,903] INFO [Log partition=stack-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:38:58,919] INFO [Log partition=stack-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:58,919] INFO [Log partition=stack-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,934] INFO [Log partition=stack-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,934] INFO [Log partition=stack-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:58,950] INFO [Log partition=stack1-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:58,950] INFO [Log partition=stack1-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,966] INFO [ProducerStateManager partition=stack1-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:58,966] INFO [Log partition=stack1-0, dir=C:\tmp\logs2] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,966] INFO [ProducerStateManager partition=stack1-0] Loading producer state from snapshot file 'C:\tmp\logs2\stack1-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:58,966] INFO [Log partition=stack1-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 16 ms (kafka.log.Log)
[2019-01-26 19:38:58,981] WARN [Log partition=stack1-1, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\stack1-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\stack1-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548456670939}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:58,981] INFO [Log partition=stack1-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:58,997] INFO [ProducerStateManager partition=stack1-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:58,997] INFO [Log partition=stack1-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:58,997] INFO [Log partition=stack1-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,013] INFO [ProducerStateManager partition=stack1-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,013] INFO [Log partition=stack1-1, dir=C:\tmp\logs2] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,028] INFO [ProducerStateManager partition=stack1-1] Loading producer state from snapshot file 'C:\tmp\logs2\stack1-1\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,028] INFO [Log partition=stack1-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 47 ms (kafka.log.Log)
[2019-01-26 19:38:59,028] WARN [Log partition=stack1-2, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\stack1-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\stack1-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548456671954}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:59,028] INFO [Log partition=stack1-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,044] INFO [ProducerStateManager partition=stack1-2] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,044] INFO [Log partition=stack1-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:59,044] INFO [Log partition=stack1-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,059] INFO [ProducerStateManager partition=stack1-2] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,059] INFO [Log partition=stack1-2, dir=C:\tmp\logs2] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,059] INFO [ProducerStateManager partition=stack1-2] Loading producer state from snapshot file 'C:\tmp\logs2\stack1-2\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,075] INFO [Log partition=stack1-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 47 ms (kafka.log.Log)
[2019-01-26 19:38:59,075] WARN [Log partition=tools-0, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547991352625}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:59,075] INFO [Log partition=tools-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,075] INFO [ProducerStateManager partition=tools-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,091] INFO [Log partition=tools-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:59,091] INFO [Log partition=tools-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,091] INFO [ProducerStateManager partition=tools-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,106] INFO [Log partition=tools-0, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,106] INFO [ProducerStateManager partition=tools-0] Loading producer state from snapshot file 'C:\tmp\logs2\tools-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,106] INFO [Log partition=tools-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:59,122] INFO [Log partition=tools-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:59,122] INFO [Log partition=tools-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,138] INFO [Log partition=tools-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,153] INFO [Log partition=tools-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:59,153] INFO [Log partition=tools1-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:59,169] INFO [Log partition=tools1-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,169] INFO [Log partition=tools1-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,184] INFO [Log partition=tools1-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:59,184] INFO [Log partition=tools1-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:59,184] INFO [Log partition=tools1-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,200] INFO [Log partition=tools1-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,200] INFO [Log partition=tools1-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:38:59,216] INFO [Log partition=tools10-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:59,216] INFO [Log partition=tools10-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,231] INFO [Log partition=tools10-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,231] INFO [Log partition=tools10-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:59,247] WARN [Log partition=tools10-1, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools10-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools10-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548410034606}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:59,247] INFO [Log partition=tools10-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,262] INFO [ProducerStateManager partition=tools10-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,262] INFO [Log partition=tools10-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:59,262] INFO [Log partition=tools10-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,278] INFO [ProducerStateManager partition=tools10-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,278] INFO [Log partition=tools10-1, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,294] INFO [ProducerStateManager partition=tools10-1] Loading producer state from snapshot file 'C:\tmp\logs2\tools10-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,294] INFO [Log partition=tools10-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 47 ms (kafka.log.Log)
[2019-01-26 19:38:59,294] INFO [Log partition=tools11-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:59,309] INFO [Log partition=tools11-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,309] INFO [Log partition=tools11-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,325] INFO [Log partition=tools11-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:59,325] WARN [Log partition=tools11-2, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools11-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools11-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548410540359}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:59,325] INFO [Log partition=tools11-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,341] INFO [ProducerStateManager partition=tools11-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,341] INFO [Log partition=tools11-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:59,341] INFO [Log partition=tools11-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,356] INFO [ProducerStateManager partition=tools11-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,356] INFO [Log partition=tools11-2, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,372] INFO [ProducerStateManager partition=tools11-2] Loading producer state from snapshot file 'C:\tmp\logs2\tools11-2\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,372] INFO [Log partition=tools11-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 47 ms (kafka.log.Log)
[2019-01-26 19:38:59,372] WARN [Log partition=tools12-0, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools12-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools12-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548410940127}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:59,372] INFO [Log partition=tools12-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,387] INFO [ProducerStateManager partition=tools12-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,387] INFO [Log partition=tools12-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:59,387] INFO [Log partition=tools12-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,403] INFO [ProducerStateManager partition=tools12-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,403] INFO [Log partition=tools12-0, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,403] INFO [ProducerStateManager partition=tools12-0] Loading producer state from snapshot file 'C:\tmp\logs2\tools12-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,403] INFO [Log partition=tools12-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:59,419] INFO [Log partition=tools12-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:59,419] INFO [Log partition=tools12-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,434] INFO [Log partition=tools12-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,434] INFO [Log partition=tools12-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:38:59,450] INFO [Log partition=tools13-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:59,450] INFO [Log partition=tools13-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,466] INFO [Log partition=tools13-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,466] INFO [Log partition=tools13-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-01-26 19:38:59,481] INFO [Log partition=tools13-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:59,481] INFO [Log partition=tools13-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,497] INFO [ProducerStateManager partition=tools13-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,497] INFO [Log partition=tools13-2, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,512] INFO [ProducerStateManager partition=tools13-2] Loading producer state from snapshot file 'C:\tmp\logs2\tools13-2\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,512] INFO [Log partition=tools13-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:59,512] INFO [Log partition=tools14-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:59,512] INFO [Log partition=tools14-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,528] INFO [ProducerStateManager partition=tools14-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,528] INFO [Log partition=tools14-1, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,544] INFO [ProducerStateManager partition=tools14-1] Loading producer state from snapshot file 'C:\tmp\logs2\tools14-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,544] INFO [Log partition=tools14-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 32 ms (kafka.log.Log)
[2019-01-26 19:38:59,544] INFO [Log partition=tools14-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:59,544] INFO [Log partition=tools14-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,559] INFO [Log partition=tools14-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,559] INFO [Log partition=tools14-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:38:59,575] INFO [Log partition=tools2-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:59,575] INFO [Log partition=tools2-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,575] INFO [Log partition=tools2-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,575] INFO [Log partition=tools2-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:38:59,590] WARN [Log partition=tools2-1, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools2-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools2-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547992951029}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:59,590] INFO [Log partition=tools2-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,606] INFO [ProducerStateManager partition=tools2-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,606] INFO [Log partition=tools2-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:59,606] INFO [Log partition=tools2-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,622] INFO [ProducerStateManager partition=tools2-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,622] INFO [Log partition=tools2-1, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,622] INFO [ProducerStateManager partition=tools2-1] Loading producer state from snapshot file 'C:\tmp\logs2\tools2-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,637] INFO [Log partition=tools2-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 47 ms (kafka.log.Log)
[2019-01-26 19:38:59,637] INFO [Log partition=tools3-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:59,637] INFO [Log partition=tools3-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,653] INFO [Log partition=tools3-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,653] INFO [Log partition=tools3-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:38:59,653] WARN [Log partition=tools3-1, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools3-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools3-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547993388462}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:59,653] INFO [Log partition=tools3-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,669] INFO [ProducerStateManager partition=tools3-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,669] INFO [Log partition=tools3-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:59,669] INFO [Log partition=tools3-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,684] INFO [ProducerStateManager partition=tools3-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,684] INFO [Log partition=tools3-1, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,684] INFO [ProducerStateManager partition=tools3-1] Loading producer state from snapshot file 'C:\tmp\logs2\tools3-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,684] INFO [Log partition=tools3-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:59,700] INFO [Log partition=tools4-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:59,700] INFO [Log partition=tools4-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,715] INFO [Log partition=tools4-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,715] INFO [Log partition=tools4-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:38:59,715] WARN [Log partition=tools4-2, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools4-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools4-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547993897061}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:59,715] INFO [Log partition=tools4-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,715] INFO [ProducerStateManager partition=tools4-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,731] INFO [Log partition=tools4-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:59,731] INFO [Log partition=tools4-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,747] INFO [ProducerStateManager partition=tools4-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,747] INFO [Log partition=tools4-2, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,762] INFO [ProducerStateManager partition=tools4-2] Loading producer state from snapshot file 'C:\tmp\logs2\tools4-2\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,762] INFO [Log partition=tools4-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 47 ms (kafka.log.Log)
[2019-01-26 19:38:59,762] WARN [Log partition=tools5-0, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools5-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools5-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996871342}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:59,762] INFO [Log partition=tools5-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,778] INFO [ProducerStateManager partition=tools5-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,778] INFO [Log partition=tools5-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:59,778] INFO [Log partition=tools5-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,794] INFO [ProducerStateManager partition=tools5-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,794] INFO [Log partition=tools5-0, dir=C:\tmp\logs2] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,809] INFO [ProducerStateManager partition=tools5-0] Loading producer state from snapshot file 'C:\tmp\logs2\tools5-0\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,809] INFO [Log partition=tools5-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 47 ms (kafka.log.Log)
[2019-01-26 19:38:59,809] WARN [Log partition=tools5-2, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools5-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools5-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996835000}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:59,809] INFO [Log partition=tools5-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,825] INFO [ProducerStateManager partition=tools5-2] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,825] INFO [Log partition=tools5-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:59,825] INFO [Log partition=tools5-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,840] INFO [ProducerStateManager partition=tools5-2] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,840] INFO [Log partition=tools5-2, dir=C:\tmp\logs2] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,840] INFO [ProducerStateManager partition=tools5-2] Loading producer state from snapshot file 'C:\tmp\logs2\tools5-2\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,840] INFO [Log partition=tools5-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 31 ms (kafka.log.Log)
[2019-01-26 19:38:59,856] WARN [Log partition=tools6-0, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools6-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools6-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548176773646}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:59,856] INFO [Log partition=tools6-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,856] INFO [ProducerStateManager partition=tools6-0] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,872] INFO [Log partition=tools6-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:59,872] INFO [Log partition=tools6-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,887] INFO [ProducerStateManager partition=tools6-0] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,887] INFO [Log partition=tools6-0, dir=C:\tmp\logs2] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,887] INFO [ProducerStateManager partition=tools6-0] Loading producer state from snapshot file 'C:\tmp\logs2\tools6-0\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,903] INFO [Log partition=tools6-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 47 ms (kafka.log.Log)
[2019-01-26 19:38:59,903] WARN [Log partition=tools6-1, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools6-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools6-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548321919981}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:59,903] INFO [Log partition=tools6-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,919] INFO [ProducerStateManager partition=tools6-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,919] INFO [Log partition=tools6-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:59,919] INFO [Log partition=tools6-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,950] INFO [ProducerStateManager partition=tools6-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,950] INFO [Log partition=tools6-1, dir=C:\tmp\logs2] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,965] INFO [ProducerStateManager partition=tools6-1] Loading producer state from snapshot file 'C:\tmp\logs2\tools6-1\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,965] INFO [Log partition=tools6-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 62 ms (kafka.log.Log)
[2019-01-26 19:38:59,965] WARN [Log partition=tools7-0, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools7-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools7-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548173477306}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:38:59,965] INFO [Log partition=tools7-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,981] INFO [ProducerStateManager partition=tools7-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,981] INFO [Log partition=tools7-0, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:38:59,981] INFO [Log partition=tools7-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,997] INFO [ProducerStateManager partition=tools7-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:38:59,997] INFO [Log partition=tools7-0, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:38:59,997] INFO [ProducerStateManager partition=tools7-0] Loading producer state from snapshot file 'C:\tmp\logs2\tools7-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,012] INFO [Log partition=tools7-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 47 ms (kafka.log.Log)
[2019-01-26 19:39:00,012] INFO [Log partition=tools7-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:00,012] INFO [Log partition=tools7-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,028] INFO [Log partition=tools7-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,028] INFO [Log partition=tools7-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:39:00,044] WARN [Log partition=tools8-1, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\tools8-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\tools8-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548341369651}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:39:00,044] INFO [Log partition=tools8-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,044] INFO [ProducerStateManager partition=tools8-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,059] INFO [Log partition=tools8-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:00,059] INFO [Log partition=tools8-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,059] INFO [ProducerStateManager partition=tools8-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,075] INFO [Log partition=tools8-1, dir=C:\tmp\logs2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,075] INFO [ProducerStateManager partition=tools8-1] Loading producer state from snapshot file 'C:\tmp\logs2\tools8-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,075] INFO [Log partition=tools8-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 31 ms (kafka.log.Log)
[2019-01-26 19:39:00,090] INFO [Log partition=tools8-2, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:00,090] INFO [Log partition=tools8-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,122] INFO [Log partition=tools8-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,122] INFO [Log partition=tools8-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-01-26 19:39:00,137] WARN [Log partition=__consumer_offsets-1, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\__consumer_offsets-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\__consumer_offsets-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548362705403}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:39:00,137] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,169] INFO [ProducerStateManager partition=__consumer_offsets-1] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,169] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:00,169] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,184] INFO [ProducerStateManager partition=__consumer_offsets-1] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,200] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\logs2] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,200] INFO [ProducerStateManager partition=__consumer_offsets-1] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-1\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,215] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 78 ms (kafka.log.Log)
[2019-01-26 19:39:00,231] WARN [Log partition=__consumer_offsets-10, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\__consumer_offsets-10\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\__consumer_offsets-10\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547979865822}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:39:00,231] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,247] INFO [ProducerStateManager partition=__consumer_offsets-10] Writing producer snapshot at offset 43 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,262] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:00,262] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,293] INFO [ProducerStateManager partition=__consumer_offsets-10] Writing producer snapshot at offset 43 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,309] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\logs2] Loading producer state till offset 43 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,309] INFO [ProducerStateManager partition=__consumer_offsets-10] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-10\00000000000000000043.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,309] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 43 in 94 ms (kafka.log.Log)
[2019-01-26 19:39:00,309] WARN [Log partition=__consumer_offsets-13, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\__consumer_offsets-13\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\__consumer_offsets-13\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548333787424}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:39:00,309] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,325] INFO [ProducerStateManager partition=__consumer_offsets-13] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,325] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:00,325] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,340] INFO [ProducerStateManager partition=__consumer_offsets-13] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,340] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\logs2] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,340] INFO [ProducerStateManager partition=__consumer_offsets-13] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-13\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,356] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 47 ms (kafka.log.Log)
[2019-01-26 19:39:00,356] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:00,356] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,372] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,372] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:39:00,387] WARN [Log partition=__consumer_offsets-19, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\__consumer_offsets-19\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\__consumer_offsets-19\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548155030377}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:39:00,387] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,387] INFO [ProducerStateManager partition=__consumer_offsets-19] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,403] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:00,403] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,403] INFO [ProducerStateManager partition=__consumer_offsets-19] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,418] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\logs2] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,418] INFO [ProducerStateManager partition=__consumer_offsets-19] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-19\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,418] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 46 ms (kafka.log.Log)
[2019-01-26 19:39:00,434] WARN [Log partition=__consumer_offsets-22, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\__consumer_offsets-22\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\__consumer_offsets-22\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548322401427}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:39:00,434] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,450] INFO [ProducerStateManager partition=__consumer_offsets-22] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,450] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:00,450] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,450] INFO [ProducerStateManager partition=__consumer_offsets-22] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,465] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\logs2] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,465] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-22\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,465] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 31 ms (kafka.log.Log)
[2019-01-26 19:39:00,481] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:00,481] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,497] INFO [ProducerStateManager partition=__consumer_offsets-25] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,497] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\logs2] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,497] INFO [ProducerStateManager partition=__consumer_offsets-25] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-25\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,497] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 16 ms (kafka.log.Log)
[2019-01-26 19:39:00,512] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:00,512] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,528] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,528] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:39:00,543] WARN [Log partition=__consumer_offsets-31, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\__consumer_offsets-31\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\__consumer_offsets-31\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548408838731}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:39:00,543] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,559] INFO [ProducerStateManager partition=__consumer_offsets-31] Writing producer snapshot at offset 37 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,559] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:00,575] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,575] INFO [ProducerStateManager partition=__consumer_offsets-31] Writing producer snapshot at offset 37 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,590] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\logs2] Loading producer state till offset 37 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,606] INFO [ProducerStateManager partition=__consumer_offsets-31] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-31\00000000000000000037.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,606] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 37 in 63 ms (kafka.log.Log)
[2019-01-26 19:39:00,606] WARN [Log partition=__consumer_offsets-34, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\__consumer_offsets-34\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\__consumer_offsets-34\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548082054556}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:39:00,622] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,622] INFO [ProducerStateManager partition=__consumer_offsets-34] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,622] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:00,622] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,637] INFO [ProducerStateManager partition=__consumer_offsets-34] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,637] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\logs2] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,653] INFO [ProducerStateManager partition=__consumer_offsets-34] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-34\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,653] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 47 ms (kafka.log.Log)
[2019-01-26 19:39:00,653] WARN [Log partition=__consumer_offsets-37, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\__consumer_offsets-37\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\__consumer_offsets-37\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548173625567}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:39:00,653] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,668] INFO [ProducerStateManager partition=__consumer_offsets-37] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,668] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:00,668] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,684] INFO [ProducerStateManager partition=__consumer_offsets-37] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,684] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\logs2] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,700] INFO [ProducerStateManager partition=__consumer_offsets-37] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-37\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,700] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 47 ms (kafka.log.Log)
[2019-01-26 19:39:00,715] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:00,715] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,731] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,731] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-26 19:39:00,746] WARN [Log partition=__consumer_offsets-40, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\__consumer_offsets-40\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\__consumer_offsets-40\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547994301596}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:39:00,746] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,762] INFO [ProducerStateManager partition=__consumer_offsets-40] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,762] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:00,762] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,778] INFO [ProducerStateManager partition=__consumer_offsets-40] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,793] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\logs2] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,793] INFO [ProducerStateManager partition=__consumer_offsets-40] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-40\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,793] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 47 ms (kafka.log.Log)
[2019-01-26 19:39:00,809] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:00,809] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,809] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,825] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:39:00,825] WARN [Log partition=__consumer_offsets-46, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\__consumer_offsets-46\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\__consumer_offsets-46\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547993701594}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:39:00,825] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,840] INFO [ProducerStateManager partition=__consumer_offsets-46] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,840] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:00,840] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,856] INFO [ProducerStateManager partition=__consumer_offsets-46] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,856] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\logs2] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,871] INFO [ProducerStateManager partition=__consumer_offsets-46] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-46\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,871] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 46 ms (kafka.log.Log)
[2019-01-26 19:39:00,871] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:00,871] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,887] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,887] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:39:00,903] WARN [Log partition=__consumer_offsets-7, dir=C:\tmp\logs2] Found a corrupted index file corresponding to log file C:\tmp\logs2\__consumer_offsets-7\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs2\__consumer_offsets-7\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548333787424}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:39:00,903] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,903] INFO [ProducerStateManager partition=__consumer_offsets-7] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,903] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\logs2] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:00,903] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,918] INFO [ProducerStateManager partition=__consumer_offsets-7] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,934] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\logs2] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:00,934] INFO [ProducerStateManager partition=__consumer_offsets-7] Loading producer state from snapshot file 'C:\tmp\logs2\__consumer_offsets-7\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:00,934] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 47 ms (kafka.log.Log)
[2019-01-26 19:39:00,950] INFO Logs loading complete in 3422 ms. (kafka.log.LogManager)
[2019-01-26 19:39:00,965] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-26 19:39:00,965] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-26 19:39:01,269] INFO Awaiting socket connections on localhost:9094. (kafka.network.Acceptor)
[2019-01-26 19:39:01,316] INFO [SocketServer brokerId=2] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-26 19:39:01,347] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:39:01,347] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:39:01,347] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:39:01,363] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-26 19:39:01,441] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-26 19:39:01,441] INFO Result of znode creation at /brokers/ids/2 is: OK (kafka.zk.KafkaZkClient)
[2019-01-26 19:39:01,441] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(localhost,9094,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-26 19:39:01,550] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:39:01,566] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:39:01,566] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:39:01,597] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 19:39:01,597] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 19:39:01,597] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:39:01,613] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:34000,blockEndProducerId:34999) by writing to Zk with path version 35 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-26 19:39:01,644] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-26 19:39:01,644] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-26 19:39:01,660] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-26 19:39:01,707] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-26 19:39:01,785] INFO [SocketServer brokerId=2] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-26 19:39:01,785] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-26 19:39:01,785] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-26 19:39:01,800] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2019-01-26 19:39:01,910] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-22, pairing-stream-app-pairs-store-changelog-2, pairs-1, __consumer_offsets-4, __consumer_offsets-7, __consumer_offsets-46, aggregated_data-1, __consumer_offsets-25, tools1-0, randommessages-0, tools11-0, __consumer_offsets-49, tools12-1, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-37, tools13-2, edited10-0, mytools-1, edited8-0, my-example-topic-0, edited-2, edited13-2, tools4-2, stack-1, tools3-1, __consumer_offsets-19, tools6-1, __consumer_offsets-13, __consumer_offsets-43, tools5-0, edited6-2, tools-1, edited12-0, aggregateddata-0, tools2-1, tools14-2, tools10-1, alltools-1, tools8-2, tools7-1, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:39:01,925] INFO Replica loaded for partition pairing-stream-app-pairs-store-changelog-2 with initial high watermark 11 (kafka.cluster.Replica)
[2019-01-26 19:39:01,941] INFO [Partition pairing-stream-app-pairs-store-changelog-2 broker=2] pairing-stream-app-pairs-store-changelog-2 starts at Leader Epoch 1 from offset 11. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:01,972] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 43 (kafka.cluster.Replica)
[2019-01-26 19:39:01,972] INFO [Partition __consumer_offsets-10 broker=2] __consumer_offsets-10 starts at Leader Epoch 19 from offset 43. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:01,988] INFO Replica loaded for partition edited8-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:01,988] INFO Replica loaded for partition edited8-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-26 19:39:01,988] INFO [Partition edited8-0 broker=2] edited8-0 starts at Leader Epoch 6 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,003] INFO Replica loaded for partition alltools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,003] INFO Replica loaded for partition alltools-1 with initial high watermark 6 (kafka.cluster.Replica)
[2019-01-26 19:39:02,003] INFO [Partition alltools-1 broker=2] alltools-1 starts at Leader Epoch 29 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,035] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 6 (kafka.cluster.Replica)
[2019-01-26 19:39:02,035] INFO [Partition __consumer_offsets-7 broker=2] __consumer_offsets-7 starts at Leader Epoch 19 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,050] INFO Replica loaded for partition tools14-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,050] INFO Replica loaded for partition tools14-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,050] INFO [Partition tools14-2 broker=2] tools14-2 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,066] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,066] INFO [Partition __consumer_offsets-4 broker=2] __consumer_offsets-4 starts at Leader Epoch 19 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,082] INFO Replica loaded for partition edited13-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,082] INFO Replica loaded for partition edited13-2 with initial high watermark 2 (kafka.cluster.Replica)
[2019-01-26 19:39:02,082] INFO [Partition edited13-2 broker=2] edited13-2 starts at Leader Epoch 2 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,097] INFO Replica loaded for partition edited-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,097] INFO Replica loaded for partition edited-2 with initial high watermark 8 (kafka.cluster.Replica)
[2019-01-26 19:39:02,097] INFO [Partition edited-2 broker=2] edited-2 starts at Leader Epoch 26 from offset 8. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,113] INFO Replica loaded for partition mytools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,113] INFO Replica loaded for partition mytools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,113] INFO [Partition mytools-1 broker=2] mytools-1 starts at Leader Epoch 26 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,128] INFO Replica loaded for partition tools10-1 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-26 19:39:02,128] INFO Replica loaded for partition tools10-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,144] INFO [Partition tools10-1 broker=2] tools10-1 starts at Leader Epoch 4 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,144] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-26 19:39:02,144] INFO [Partition __consumer_offsets-1 broker=2] __consumer_offsets-1 starts at Leader Epoch 19 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,160] INFO Replica loaded for partition aggregateddata-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,160] INFO Replica loaded for partition aggregateddata-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,160] INFO [Partition aggregateddata-0 broker=2] aggregateddata-0 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,175] INFO Replica loaded for partition tools6-1 with initial high watermark 6 (kafka.cluster.Replica)
[2019-01-26 19:39:02,175] INFO Replica loaded for partition tools6-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,191] INFO [Partition tools6-1 broker=2] tools6-1 starts at Leader Epoch 23 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,191] INFO Replica loaded for partition tools5-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,191] INFO Replica loaded for partition tools5-0 with initial high watermark 10 (kafka.cluster.Replica)
[2019-01-26 19:39:02,207] INFO [Partition tools5-0 broker=2] tools5-0 starts at Leader Epoch 26 from offset 10. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,207] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,207] INFO [Partition __consumer_offsets-49 broker=2] __consumer_offsets-49 starts at Leader Epoch 19 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,222] INFO Replica loaded for partition stack-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,222] INFO Replica loaded for partition stack-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,222] INFO [Partition stack-1 broker=2] stack-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,238] INFO Replica loaded for partition edited6-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,238] INFO Replica loaded for partition edited6-2 with initial high watermark 4 (kafka.cluster.Replica)
[2019-01-26 19:39:02,238] INFO [Partition edited6-2 broker=2] edited6-2 starts at Leader Epoch 19 from offset 4. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,253] INFO Replica loaded for partition tools13-2 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-26 19:39:02,253] INFO Replica loaded for partition tools13-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,253] INFO [Partition tools13-2 broker=2] tools13-2 starts at Leader Epoch 1 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,269] INFO Replica loaded for partition tools11-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,269] INFO Replica loaded for partition tools11-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,269] INFO [Partition tools11-0 broker=2] tools11-0 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,285] INFO Replica loaded for partition pairs-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,300] INFO Replica loaded for partition pairs-1 with initial high watermark 5 (kafka.cluster.Replica)
[2019-01-26 19:39:02,300] INFO [Partition pairs-1 broker=2] pairs-1 starts at Leader Epoch 2 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,316] INFO Replica loaded for partition tools3-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,316] INFO Replica loaded for partition tools3-1 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-26 19:39:02,316] INFO [Partition tools3-1 broker=2] tools3-1 starts at Leader Epoch 26 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,331] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-26 19:39:02,331] INFO [Partition __consumer_offsets-46 broker=2] __consumer_offsets-46 starts at Leader Epoch 19 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,347] INFO Replica loaded for partition tools12-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,347] INFO Replica loaded for partition tools12-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,347] INFO [Partition tools12-1 broker=2] tools12-1 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,363] INFO Replica loaded for partition tools4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,363] INFO Replica loaded for partition tools4-2 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-26 19:39:02,363] INFO [Partition tools4-2 broker=2] tools4-2 starts at Leader Epoch 26 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,378] INFO Replica loaded for partition edited10-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,378] INFO Replica loaded for partition edited10-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,378] INFO [Partition edited10-0 broker=2] edited10-0 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,394] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,394] INFO [Partition __consumer_offsets-43 broker=2] __consumer_offsets-43 starts at Leader Epoch 19 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,410] INFO Replica loaded for partition tools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,410] INFO Replica loaded for partition tools-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,410] INFO [Partition tools-1 broker=2] tools-1 starts at Leader Epoch 26 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,425] INFO Replica loaded for partition my-example-topic-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,425] INFO [Partition my-example-topic-0 broker=2] my-example-topic-0 starts at Leader Epoch 17 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,441] INFO Replica loaded for partition randommessages-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,441] INFO Replica loaded for partition randommessages-0 with initial high watermark 11 (kafka.cluster.Replica)
[2019-01-26 19:39:02,456] INFO [Partition randommessages-0 broker=2] randommessages-0 starts at Leader Epoch 2 from offset 11. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,456] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-26 19:39:02,472] INFO [Partition __consumer_offsets-40 broker=2] __consumer_offsets-40 starts at Leader Epoch 19 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,472] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 8 (kafka.cluster.Replica)
[2019-01-26 19:39:02,488] INFO [Partition __consumer_offsets-37 broker=2] __consumer_offsets-37 starts at Leader Epoch 19 from offset 8. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,488] INFO Replica loaded for partition tools2-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,488] INFO Replica loaded for partition tools2-1 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-26 19:39:02,503] INFO [Partition tools2-1 broker=2] tools2-1 starts at Leader Epoch 26 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,503] INFO Replica loaded for partition tools1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,503] INFO Replica loaded for partition tools1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,503] INFO [Partition tools1-0 broker=2] tools1-0 starts at Leader Epoch 26 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,519] INFO Replica loaded for partition aggregated_data-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,519] INFO Replica loaded for partition aggregated_data-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,519] INFO [Partition aggregated_data-1 broker=2] aggregated_data-1 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,535] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 6 (kafka.cluster.Replica)
[2019-01-26 19:39:02,535] INFO [Partition __consumer_offsets-34 broker=2] __consumer_offsets-34 starts at Leader Epoch 19 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,550] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 37 (kafka.cluster.Replica)
[2019-01-26 19:39:02,550] INFO [Partition __consumer_offsets-31 broker=2] __consumer_offsets-31 starts at Leader Epoch 19 from offset 37. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,566] INFO Replica loaded for partition edited12-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,566] INFO Replica loaded for partition edited12-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-26 19:39:02,566] INFO [Partition edited12-0 broker=2] edited12-0 starts at Leader Epoch 4 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,582] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 7 (kafka.cluster.Replica)
[2019-01-26 19:39:02,582] INFO [Partition __consumer_offsets-19 broker=2] __consumer_offsets-19 starts at Leader Epoch 19 from offset 7. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,597] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,597] INFO [Partition __consumer_offsets-28 broker=2] __consumer_offsets-28 starts at Leader Epoch 19 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,613] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,613] INFO [Partition __consumer_offsets-16 broker=2] __consumer_offsets-16 starts at Leader Epoch 19 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,628] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 2 (kafka.cluster.Replica)
[2019-01-26 19:39:02,628] INFO [Partition __consumer_offsets-25 broker=2] __consumer_offsets-25 starts at Leader Epoch 19 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,644] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 5 (kafka.cluster.Replica)
[2019-01-26 19:39:02,644] INFO [Partition __consumer_offsets-22 broker=2] __consumer_offsets-22 starts at Leader Epoch 19 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,644] INFO Replica loaded for partition tools7-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,660] INFO Replica loaded for partition tools7-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,660] INFO [Partition tools7-1 broker=2] tools7-1 starts at Leader Epoch 14 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,660] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 6 (kafka.cluster.Replica)
[2019-01-26 19:39:02,675] INFO [Partition __consumer_offsets-13 broker=2] __consumer_offsets-13 starts at Leader Epoch 19 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,675] INFO Replica loaded for partition tools8-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,675] INFO Replica loaded for partition tools8-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,675] INFO [Partition tools8-2 broker=2] tools8-2 starts at Leader Epoch 8 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:39:02,691] INFO Replica loaded for partition edited6-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,706] INFO Replica loaded for partition edited6-1 with initial high watermark 7 (kafka.cluster.Replica)
[2019-01-26 19:39:02,706] INFO Replica loaded for partition stack-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,706] INFO Replica loaded for partition stack-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,706] INFO Replica loaded for partition mytools-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,722] INFO Replica loaded for partition mytools-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-26 19:39:02,722] INFO Replica loaded for partition tools5-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,722] INFO Replica loaded for partition tools5-2 with initial high watermark 8 (kafka.cluster.Replica)
[2019-01-26 19:39:02,722] INFO Replica loaded for partition edited10-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,738] INFO Replica loaded for partition edited10-2 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-26 19:39:02,738] INFO Replica loaded for partition tools4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,738] INFO Replica loaded for partition tools4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,738] INFO Replica loaded for partition tools3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,738] INFO Replica loaded for partition tools3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,753] INFO Replica loaded for partition pairs-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,753] INFO Replica loaded for partition pairs-0 with initial high watermark 5 (kafka.cluster.Replica)
[2019-01-26 19:39:02,753] INFO Replica loaded for partition tools-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,753] INFO Replica loaded for partition tools-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-26 19:39:02,769] INFO Replica loaded for partition tools6-0 with initial high watermark 5 (kafka.cluster.Replica)
[2019-01-26 19:39:02,769] INFO Replica loaded for partition tools6-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,769] INFO Replica loaded for partition randommessages-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,785] INFO Replica loaded for partition randommessages-2 with initial high watermark 11 (kafka.cluster.Replica)
[2019-01-26 19:39:02,785] INFO Replica loaded for partition editedstack-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,785] INFO Replica loaded for partition editedstack-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,800] INFO Replica loaded for partition tools11-2 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-26 19:39:02,800] INFO Replica loaded for partition tools11-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,800] INFO Replica loaded for partition tools13-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,800] INFO Replica loaded for partition tools13-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,816] INFO Replica loaded for partition tools12-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,816] INFO Replica loaded for partition tools12-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-26 19:39:02,816] INFO Replica loaded for partition stack1-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,831] INFO Replica loaded for partition stack1-1 with initial high watermark 6 (kafka.cluster.Replica)
[2019-01-26 19:39:02,831] INFO Replica loaded for partition aggregated_data-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,847] INFO Replica loaded for partition aggregated_data-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-26 19:39:02,847] INFO Replica loaded for partition editedstack-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,847] INFO Replica loaded for partition editedstack-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,847] INFO Replica loaded for partition tools1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,863] INFO Replica loaded for partition tools1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,863] INFO Replica loaded for partition tools2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,863] INFO Replica loaded for partition tools2-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,878] INFO Replica loaded for partition edited12-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,878] INFO Replica loaded for partition edited12-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,878] INFO Replica loaded for partition edited8-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,894] INFO Replica loaded for partition edited8-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,894] INFO Replica loaded for partition stack1-2 with initial high watermark 6 (kafka.cluster.Replica)
[2019-01-26 19:39:02,894] INFO Replica loaded for partition stack1-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,910] INFO Replica loaded for partition edited-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,910] INFO Replica loaded for partition edited-1 with initial high watermark 9 (kafka.cluster.Replica)
[2019-01-26 19:39:02,925] INFO Replica loaded for partition tools8-1 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-26 19:39:02,925] INFO Replica loaded for partition tools8-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,925] INFO Replica loaded for partition tools7-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,941] INFO Replica loaded for partition tools7-0 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-26 19:39:02,941] INFO Replica loaded for partition aggregateddata-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,941] INFO Replica loaded for partition aggregateddata-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,941] INFO Replica loaded for partition edited13-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,956] INFO Replica loaded for partition edited13-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,956] INFO Replica loaded for partition editedstack-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,956] INFO Replica loaded for partition editedstack-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,972] INFO Replica loaded for partition tools10-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,972] INFO Replica loaded for partition tools10-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,972] INFO Replica loaded for partition alltools-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,972] INFO Replica loaded for partition alltools-0 with initial high watermark 4 (kafka.cluster.Replica)
[2019-01-26 19:39:02,988] INFO Replica loaded for partition stack1-0 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-26 19:39:02,988] INFO Replica loaded for partition stack1-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,988] INFO Replica loaded for partition tools14-1 with initial high watermark 1 (kafka.cluster.Replica)
[2019-01-26 19:39:02,988] INFO Replica loaded for partition tools14-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:39:02,988] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(edited8-2, mytools-0, editedstack-0, stack1-1, tools5-2, stack1-2, tools8-1, pairs-0, randommessages-2, aggregated_data-0, edited6-1, tools1-2, tools11-2, tools13-1, tools4-1, tools-0, editedstack-2, tools14-1, stack1-0, tools6-0, alltools-0, tools7-0, aggregateddata-2, tools10-0, edited10-2, tools2-0, edited13-1, tools12-0, edited12-2, tools3-0, stack-0, editedstack-1, edited-1) (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:39:03,034] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-26 19:39:03,050] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(edited8-2 -> (offset=0, leaderEpoch=3), stack1-1 -> (offset=6, leaderEpoch=0), editedstack-0 -> (offset=0, leaderEpoch=1), tools7-0 -> (offset=1, leaderEpoch=4), tools8-1 -> (offset=1, leaderEpoch=3), tools3-0 -> (offset=0, leaderEpoch=7), tools4-1 -> (offset=0, leaderEpoch=7), tools5-2 -> (offset=8, leaderEpoch=7), tools1-2 -> (offset=0, leaderEpoch=7), edited-1 -> (offset=9, leaderEpoch=7), stack1-2 -> (offset=6, leaderEpoch=1), mytools-0 -> (offset=1, leaderEpoch=7), edited12-2 -> (offset=0, leaderEpoch=1), stack-0 -> (offset=0, leaderEpoch=0), pairs-0 -> (offset=5, leaderEpoch=1), aggregateddata-2 -> (offset=0, leaderEpoch=2), tools10-0 -> (offset=0, leaderEpoch=3), tools14-1 -> (offset=1, leaderEpoch=2), alltools-0 -> (offset=4, leaderEpoch=8), aggregated_data-0 -> (offset=1, leaderEpoch=1), tools-0 -> (offset=1, leaderEpoch=7), randommessages-2 -> (offset=11, leaderEpoch=1), edited10-2 -> (offset=1, leaderEpoch=1), editedstack-1 -> (offset=0, leaderEpoch=0), tools11-2 -> (offset=1, leaderEpoch=3), stack1-0 -> (offset=3, leaderEpoch=1), tools13-1 -> (offset=0, leaderEpoch=2), edited6-1 -> (offset=7, leaderEpoch=4), tools6-0 -> (offset=5, leaderEpoch=9), tools12-0 -> (offset=1, leaderEpoch=1), editedstack-2 -> (offset=0, leaderEpoch=1), edited13-1 -> (offset=0, leaderEpoch=1), tools2-0 -> (offset=0, leaderEpoch=7)) (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:39:03,050] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:39:03,050] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:39:03,050] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:39:03,050] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:39:03,066] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:39:03,066] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:39:03,081] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:39:03,081] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:39:03,081] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:39:03,081] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:39:03,081] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:39:03,081] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:39:03,081] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:39:03,081] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:39:03,081] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:39:03,081] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:39:03,097] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:39:03,097] INFO [Log partition=edited10-2, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-26 19:39:03,113] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in stack-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-26 19:39:03,113] INFO [Log partition=stack-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-26 19:39:03,113] INFO [Log partition=stack1-1, dir=C:\tmp\logs2] Truncating to 6 has no effect as the largest offset in the log is 5 (kafka.log.Log)
[2019-01-26 19:39:03,113] INFO [Log partition=edited-1, dir=C:\tmp\logs2] Truncating to 9 has no effect as the largest offset in the log is 8 (kafka.log.Log)
[2019-01-26 19:39:03,113] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in editedstack-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-26 19:39:03,113] INFO [Log partition=editedstack-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-26 19:39:03,113] INFO [Log partition=randommessages-2, dir=C:\tmp\logs2] Truncating to 11 has no effect as the largest offset in the log is 10 (kafka.log.Log)
[2019-01-26 19:39:03,113] INFO [Log partition=tools-0, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-26 19:39:03,128] INFO [Log partition=pairs-0, dir=C:\tmp\logs2] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.Log)
[2019-01-26 19:39:03,144] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in edited12-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-26 19:39:03,144] INFO [Log partition=edited12-2, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-26 19:39:03,144] INFO [Log partition=alltools-0, dir=C:\tmp\logs2] Truncating to 4 has no effect as the largest offset in the log is 3 (kafka.log.Log)
[2019-01-26 19:39:03,159] INFO [Log partition=tools14-1, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-26 19:39:03,159] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in editedstack-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-26 19:39:03,159] INFO [Log partition=editedstack-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-26 19:39:03,159] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-22 in 109 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:39:03,175] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools13-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-26 19:39:03,175] INFO [Log partition=tools13-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-26 19:39:03,191] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in edited8-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-26 19:39:03,191] INFO [GroupCoordinator 2]: Loading group metadata for console-consumer-60422 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 19:39:03,191] INFO [Log partition=edited8-2, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-26 19:39:03,191] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:39:03,206] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools4-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-26 19:39:03,206] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:39:03,206] INFO [Log partition=tools4-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-26 19:39:03,222] INFO [Log partition=tools8-1, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-26 19:39:03,222] INFO [Log partition=stack1-2, dir=C:\tmp\logs2] Truncating to 6 has no effect as the largest offset in the log is 5 (kafka.log.Log)
[2019-01-26 19:39:03,222] INFO [GroupCoordinator 2]: Loading group metadata for pairing-stream-app with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 19:39:03,222] INFO [Log partition=stack1-0, dir=C:\tmp\logs2] Truncating to 3 has no effect as the largest offset in the log is 2 (kafka.log.Log)
[2019-01-26 19:39:03,238] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 32 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:39:03,238] INFO [Log partition=mytools-0, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-26 19:39:03,238] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in aggregateddata-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-26 19:39:03,238] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:39:03,238] INFO [Log partition=aggregateddata-2, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-26 19:39:03,238] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in edited13-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-26 19:39:03,253] INFO [Log partition=edited13-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-26 19:39:03,253] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 15 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:39:03,253] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools10-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-26 19:39:03,269] INFO [Log partition=tools10-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-26 19:39:03,269] INFO [Log partition=tools11-2, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-26 19:39:03,269] INFO [Log partition=tools12-0, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-26 19:39:03,269] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-40 in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:39:03,269] INFO [Log partition=aggregated_data-0, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-26 19:39:03,269] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:39:03,269] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools1-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-26 19:39:03,284] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:39:03,284] INFO [Log partition=tools1-2, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-26 19:39:03,284] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in editedstack-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-26 19:39:03,284] INFO [Log partition=editedstack-2, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-26 19:39:03,300] INFO [Log partition=edited6-1, dir=C:\tmp\logs2] Truncating to 7 has no effect as the largest offset in the log is 6 (kafka.log.Log)
[2019-01-26 19:39:03,300] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-46 in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:39:03,300] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools2-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-26 19:39:03,316] INFO [Log partition=tools2-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-26 19:39:03,316] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:39:03,316] INFO [Log partition=tools5-2, dir=C:\tmp\logs2] Truncating to 8 has no effect as the largest offset in the log is 7 (kafka.log.Log)
[2019-01-26 19:39:03,316] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:39:03,316] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in tools3-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-26 19:39:03,331] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:39:03,331] INFO [Log partition=tools3-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-26 19:39:03,331] INFO [Log partition=tools6-0, dir=C:\tmp\logs2] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.Log)
[2019-01-26 19:39:03,331] INFO [Log partition=tools7-0, dir=C:\tmp\logs2] Truncating to 1 has no effect as the largest offset in the log is 0 (kafka.log.Log)
[2019-01-26 19:39:03,347] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-22, pairing-stream-app-pairs-store-changelog-2, pairs-1, __consumer_offsets-4, __consumer_offsets-7, __consumer_offsets-46, aggregated_data-1, __consumer_offsets-25, tools1-0, randommessages-0, tools11-0, __consumer_offsets-49, tools12-1, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-37, tools13-2, edited10-0, mytools-1, edited8-0, my-example-topic-0, edited-2, edited13-2, tools4-2, stack-1, tools3-1, __consumer_offsets-19, tools6-1, __consumer_offsets-13, __consumer_offsets-43, tools5-0, edited6-2, tools-1, edited12-0, aggregateddata-0, tools2-1, tools14-2, tools10-1, alltools-1, tools8-2, tools7-1, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:39:03,347] INFO [Partition pairing-stream-app-pairs-store-changelog-2 broker=2] pairing-stream-app-pairs-store-changelog-2 starts at Leader Epoch 2 from offset 11. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-26 19:39:03,347] INFO [GroupCoordinator 2]: Loading group metadata for KafkaExampleConsumer with generation 4 (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 19:39:03,347] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-10 in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:39:03,347] WARN [LeaderEpochCache pairing-stream-app-pairs-store-changelog-2] New epoch entry EpochEntry(epoch=2, startOffset=11) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=11)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,347] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:39:03,347] INFO [Partition __consumer_offsets-10 broker=2] __consumer_offsets-10 starts at Leader Epoch 20 from offset 43. Previous Leader Epoch was: 19 (kafka.cluster.Partition)
[2019-01-26 19:39:03,347] WARN [LeaderEpochCache __consumer_offsets-10] New epoch entry EpochEntry(epoch=20, startOffset=43) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=19, startOffset=43)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,362] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 15 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:39:03,362] INFO [Partition edited8-0 broker=2] edited8-0 starts at Leader Epoch 7 from offset 1. Previous Leader Epoch was: 6 (kafka.cluster.Partition)
[2019-01-26 19:39:03,362] WARN [LeaderEpochCache edited8-0] New epoch entry EpochEntry(epoch=7, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=6, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,378] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:39:03,378] INFO [Partition alltools-1 broker=2] alltools-1 starts at Leader Epoch 30 from offset 6. Previous Leader Epoch was: 29 (kafka.cluster.Partition)
[2019-01-26 19:39:03,378] WARN [LeaderEpochCache alltools-1] New epoch entry EpochEntry(epoch=30, startOffset=6) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=29, startOffset=6)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,378] INFO [Partition __consumer_offsets-7 broker=2] __consumer_offsets-7 starts at Leader Epoch 20 from offset 6. Previous Leader Epoch was: 19 (kafka.cluster.Partition)
[2019-01-26 19:39:03,378] WARN [LeaderEpochCache __consumer_offsets-7] New epoch entry EpochEntry(epoch=20, startOffset=6) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=19, startOffset=6)). Cache now contains 4 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,394] INFO [Partition tools14-2 broker=2] tools14-2 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-26 19:39:03,394] WARN [LeaderEpochCache tools14-2] New epoch entry EpochEntry(epoch=2, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,409] INFO [Partition edited13-2 broker=2] edited13-2 starts at Leader Epoch 3 from offset 2. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-26 19:39:03,409] WARN [LeaderEpochCache edited13-2] New epoch entry EpochEntry(epoch=3, startOffset=2) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=2)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,409] INFO [Partition edited8-2 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-26 19:39:03,409] INFO [Partition stack1-1 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-26 19:39:03,409] INFO [Partition __consumer_offsets-4 broker=2] __consumer_offsets-4 starts at Leader Epoch 20 from offset 0. Previous Leader Epoch was: 19 (kafka.cluster.Partition)
[2019-01-26 19:39:03,425] INFO [Partition stack1-2 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-26 19:39:03,425] WARN [LeaderEpochCache __consumer_offsets-4] New epoch entry EpochEntry(epoch=20, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=19, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,425] INFO [Partition stack1-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-26 19:39:03,425] INFO [Partition edited-2 broker=2] edited-2 starts at Leader Epoch 27 from offset 8. Previous Leader Epoch was: 26 (kafka.cluster.Partition)
[2019-01-26 19:39:03,425] INFO [Partition editedstack-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-26 19:39:03,425] INFO [Partition editedstack-1 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-26 19:39:03,441] INFO [Partition editedstack-2 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-26 19:39:03,425] WARN [LeaderEpochCache edited-2] New epoch entry EpochEntry(epoch=27, startOffset=8) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=26, startOffset=8)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,441] INFO [Partition tools7-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-26 19:39:03,441] INFO [Partition tools10-1 broker=2] tools10-1 starts at Leader Epoch 5 from offset 1. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-26 19:39:03,441] INFO [Partition tools8-1 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-26 19:39:03,441] INFO [Partition tools3-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-26 19:39:03,441] INFO [Partition tools4-1 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-26 19:39:03,441] WARN [LeaderEpochCache tools10-1] New epoch entry EpochEntry(epoch=5, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,456] INFO [Partition tools5-2 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-26 19:39:03,456] INFO [Partition mytools-1 broker=2] mytools-1 starts at Leader Epoch 27 from offset 0. Previous Leader Epoch was: 26 (kafka.cluster.Partition)
[2019-01-26 19:39:03,456] INFO [Partition tools1-2 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-26 19:39:03,456] INFO [Partition edited-1 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-26 19:39:03,456] INFO [Partition mytools-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-26 19:39:03,456] INFO [Partition edited12-2 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-26 19:39:03,456] WARN [LeaderEpochCache mytools-1] New epoch entry EpochEntry(epoch=27, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=26, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,472] INFO [Partition stack-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-26 19:39:03,472] INFO [Partition __consumer_offsets-1 broker=2] __consumer_offsets-1 starts at Leader Epoch 20 from offset 3. Previous Leader Epoch was: 19 (kafka.cluster.Partition)
[2019-01-26 19:39:03,472] WARN [LeaderEpochCache __consumer_offsets-1] New epoch entry EpochEntry(epoch=20, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=19, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,472] INFO [Partition pairs-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-26 19:39:03,472] INFO [Partition aggregateddata-2 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-26 19:39:03,472] INFO [Partition tools10-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-26 19:39:03,487] INFO [Partition tools14-1 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-26 19:39:03,472] INFO [Partition aggregateddata-0 broker=2] aggregateddata-0 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-26 19:39:03,487] INFO [Partition alltools-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-26 19:39:03,487] WARN [LeaderEpochCache aggregateddata-0] New epoch entry EpochEntry(epoch=2, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,487] INFO [Partition aggregated_data-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-26 19:39:03,487] INFO [Partition tools-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-26 19:39:03,487] INFO [Partition randommessages-2 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-26 19:39:03,487] INFO [Partition tools6-1 broker=2] tools6-1 starts at Leader Epoch 24 from offset 6. Previous Leader Epoch was: 23 (kafka.cluster.Partition)
[2019-01-26 19:39:03,487] WARN [LeaderEpochCache tools6-1] New epoch entry EpochEntry(epoch=24, startOffset=6) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=23, startOffset=6)). Cache now contains 5 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,503] INFO [Partition edited10-2 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-26 19:39:03,503] INFO [Partition tools5-0 broker=2] tools5-0 starts at Leader Epoch 27 from offset 10. Previous Leader Epoch was: 26 (kafka.cluster.Partition)
[2019-01-26 19:39:03,503] INFO [Partition tools11-2 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-26 19:39:03,503] WARN [LeaderEpochCache tools5-0] New epoch entry EpochEntry(epoch=27, startOffset=10) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=26, startOffset=10)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,503] INFO [Partition tools13-1 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-26 19:39:03,503] INFO [Partition edited6-1 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-26 19:39:03,503] INFO [Partition tools6-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-26 19:39:03,503] INFO [Partition __consumer_offsets-49 broker=2] __consumer_offsets-49 starts at Leader Epoch 20 from offset 0. Previous Leader Epoch was: 19 (kafka.cluster.Partition)
[2019-01-26 19:39:03,519] INFO [Partition tools12-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-26 19:39:03,519] WARN [LeaderEpochCache __consumer_offsets-49] New epoch entry EpochEntry(epoch=20, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=19, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,519] INFO [Partition edited13-1 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-26 19:39:03,519] INFO [Partition stack-1 broker=2] stack-1 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-26 19:39:03,519] INFO [Partition tools2-0 broker=1] Expanding ISR from 1 to 1,2 (kafka.cluster.Partition)
[2019-01-26 19:39:03,519] WARN [LeaderEpochCache stack-1] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,534] INFO [Partition edited6-2 broker=2] edited6-2 starts at Leader Epoch 20 from offset 4. Previous Leader Epoch was: 19 (kafka.cluster.Partition)
[2019-01-26 19:39:03,534] WARN [LeaderEpochCache edited6-2] New epoch entry EpochEntry(epoch=20, startOffset=4) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=19, startOffset=4)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,534] INFO [Partition tools13-2 broker=2] tools13-2 starts at Leader Epoch 2 from offset 1. Previous Leader Epoch was: 1 (kafka.cluster.Partition)
[2019-01-26 19:39:03,534] WARN [LeaderEpochCache tools13-2] New epoch entry EpochEntry(epoch=2, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=1, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,550] INFO [Partition tools11-0 broker=2] tools11-0 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-26 19:39:03,550] WARN [LeaderEpochCache tools11-0] New epoch entry EpochEntry(epoch=5, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,550] INFO [Partition pairs-1 broker=2] pairs-1 starts at Leader Epoch 3 from offset 5. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-26 19:39:03,550] WARN [LeaderEpochCache pairs-1] New epoch entry EpochEntry(epoch=3, startOffset=5) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=5)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,566] INFO [Partition tools12-1 broker=2] tools12-1 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-26 19:39:03,566] WARN [LeaderEpochCache tools12-1] New epoch entry EpochEntry(epoch=5, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,566] INFO [Partition __consumer_offsets-46 broker=2] __consumer_offsets-46 starts at Leader Epoch 20 from offset 3. Previous Leader Epoch was: 19 (kafka.cluster.Partition)
[2019-01-26 19:39:03,566] WARN [LeaderEpochCache __consumer_offsets-46] New epoch entry EpochEntry(epoch=20, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=19, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,581] INFO [Partition tools3-1 broker=2] tools3-1 starts at Leader Epoch 27 from offset 1. Previous Leader Epoch was: 26 (kafka.cluster.Partition)
[2019-01-26 19:39:03,581] WARN [LeaderEpochCache tools3-1] New epoch entry EpochEntry(epoch=27, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=26, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,597] INFO [Partition tools4-2 broker=2] tools4-2 starts at Leader Epoch 27 from offset 1. Previous Leader Epoch was: 26 (kafka.cluster.Partition)
[2019-01-26 19:39:03,597] WARN [LeaderEpochCache tools4-2] New epoch entry EpochEntry(epoch=27, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=26, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,597] INFO [Partition edited10-0 broker=2] edited10-0 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-26 19:39:03,597] WARN [LeaderEpochCache edited10-0] New epoch entry EpochEntry(epoch=5, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,597] INFO [Partition __consumer_offsets-43 broker=2] __consumer_offsets-43 starts at Leader Epoch 20 from offset 0. Previous Leader Epoch was: 19 (kafka.cluster.Partition)
[2019-01-26 19:39:03,597] WARN [LeaderEpochCache __consumer_offsets-43] New epoch entry EpochEntry(epoch=20, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=19, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,612] INFO [Partition tools-1 broker=2] tools-1 starts at Leader Epoch 27 from offset 0. Previous Leader Epoch was: 26 (kafka.cluster.Partition)
[2019-01-26 19:39:03,612] WARN [LeaderEpochCache tools-1] New epoch entry EpochEntry(epoch=27, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=26, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,628] INFO [Partition my-example-topic-0 broker=2] my-example-topic-0 starts at Leader Epoch 18 from offset 0. Previous Leader Epoch was: 17 (kafka.cluster.Partition)
[2019-01-26 19:39:03,628] WARN [LeaderEpochCache my-example-topic-0] New epoch entry EpochEntry(epoch=18, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=17, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,628] INFO [Partition randommessages-0 broker=2] randommessages-0 starts at Leader Epoch 3 from offset 11. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-26 19:39:03,628] WARN [LeaderEpochCache randommessages-0] New epoch entry EpochEntry(epoch=3, startOffset=11) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=11)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,644] INFO [Partition __consumer_offsets-40 broker=2] __consumer_offsets-40 starts at Leader Epoch 20 from offset 3. Previous Leader Epoch was: 19 (kafka.cluster.Partition)
[2019-01-26 19:39:03,644] WARN [LeaderEpochCache __consumer_offsets-40] New epoch entry EpochEntry(epoch=20, startOffset=3) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=19, startOffset=3)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,659] INFO [Partition __consumer_offsets-37 broker=2] __consumer_offsets-37 starts at Leader Epoch 20 from offset 8. Previous Leader Epoch was: 19 (kafka.cluster.Partition)
[2019-01-26 19:39:03,659] WARN [LeaderEpochCache __consumer_offsets-37] New epoch entry EpochEntry(epoch=20, startOffset=8) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=19, startOffset=8)). Cache now contains 4 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,659] INFO [Partition tools2-1 broker=2] tools2-1 starts at Leader Epoch 27 from offset 1. Previous Leader Epoch was: 26 (kafka.cluster.Partition)
[2019-01-26 19:39:03,659] WARN [LeaderEpochCache tools2-1] New epoch entry EpochEntry(epoch=27, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=26, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,675] INFO [Partition tools1-0 broker=2] tools1-0 starts at Leader Epoch 27 from offset 0. Previous Leader Epoch was: 26 (kafka.cluster.Partition)
[2019-01-26 19:39:03,675] WARN [LeaderEpochCache tools1-0] New epoch entry EpochEntry(epoch=27, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=26, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,691] INFO [Partition aggregated_data-1 broker=2] aggregated_data-1 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-26 19:39:03,691] WARN [LeaderEpochCache aggregated_data-1] New epoch entry EpochEntry(epoch=5, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,691] INFO [Partition __consumer_offsets-34 broker=2] __consumer_offsets-34 starts at Leader Epoch 20 from offset 6. Previous Leader Epoch was: 19 (kafka.cluster.Partition)
[2019-01-26 19:39:03,691] WARN [LeaderEpochCache __consumer_offsets-34] New epoch entry EpochEntry(epoch=20, startOffset=6) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=19, startOffset=6)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,706] INFO [Partition __consumer_offsets-31 broker=2] __consumer_offsets-31 starts at Leader Epoch 20 from offset 37. Previous Leader Epoch was: 19 (kafka.cluster.Partition)
[2019-01-26 19:39:03,706] WARN [LeaderEpochCache __consumer_offsets-31] New epoch entry EpochEntry(epoch=20, startOffset=37) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=19, startOffset=37)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,706] INFO [Partition edited12-0 broker=2] edited12-0 starts at Leader Epoch 5 from offset 1. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2019-01-26 19:39:03,706] WARN [LeaderEpochCache edited12-0] New epoch entry EpochEntry(epoch=5, startOffset=1) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=4, startOffset=1)). Cache now contains 2 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,722] INFO [Partition __consumer_offsets-19 broker=2] __consumer_offsets-19 starts at Leader Epoch 20 from offset 7. Previous Leader Epoch was: 19 (kafka.cluster.Partition)
[2019-01-26 19:39:03,722] WARN [LeaderEpochCache __consumer_offsets-19] New epoch entry EpochEntry(epoch=20, startOffset=7) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=19, startOffset=7)). Cache now contains 5 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,737] INFO [Partition __consumer_offsets-28 broker=2] __consumer_offsets-28 starts at Leader Epoch 20 from offset 0. Previous Leader Epoch was: 19 (kafka.cluster.Partition)
[2019-01-26 19:39:03,737] WARN [LeaderEpochCache __consumer_offsets-28] New epoch entry EpochEntry(epoch=20, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=19, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,737] INFO [Partition __consumer_offsets-16 broker=2] __consumer_offsets-16 starts at Leader Epoch 20 from offset 0. Previous Leader Epoch was: 19 (kafka.cluster.Partition)
[2019-01-26 19:39:03,737] WARN [LeaderEpochCache __consumer_offsets-16] New epoch entry EpochEntry(epoch=20, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=19, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,753] INFO [Partition __consumer_offsets-25 broker=2] __consumer_offsets-25 starts at Leader Epoch 20 from offset 2. Previous Leader Epoch was: 19 (kafka.cluster.Partition)
[2019-01-26 19:39:03,753] INFO [Partition __consumer_offsets-22 broker=2] __consumer_offsets-22 starts at Leader Epoch 20 from offset 5. Previous Leader Epoch was: 19 (kafka.cluster.Partition)
[2019-01-26 19:39:03,753] WARN [LeaderEpochCache __consumer_offsets-22] New epoch entry EpochEntry(epoch=20, startOffset=5) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=19, startOffset=5)). Cache now contains 3 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,769] INFO [Partition tools7-1 broker=2] tools7-1 starts at Leader Epoch 15 from offset 0. Previous Leader Epoch was: 14 (kafka.cluster.Partition)
[2019-01-26 19:39:03,769] WARN [LeaderEpochCache tools7-1] New epoch entry EpochEntry(epoch=15, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=14, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,784] INFO [Partition __consumer_offsets-13 broker=2] __consumer_offsets-13 starts at Leader Epoch 20 from offset 6. Previous Leader Epoch was: 19 (kafka.cluster.Partition)
[2019-01-26 19:39:03,784] WARN [LeaderEpochCache __consumer_offsets-13] New epoch entry EpochEntry(epoch=20, startOffset=6) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=19, startOffset=6)). Cache now contains 5 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:03,784] INFO [Partition tools8-2 broker=2] tools8-2 starts at Leader Epoch 9 from offset 0. Previous Leader Epoch was: 8 (kafka.cluster.Partition)
[2019-01-26 19:39:03,784] WARN [LeaderEpochCache tools8-2] New epoch entry EpochEntry(epoch=9, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=8, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-26 19:39:17,800] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-26 19:39:18,487] INFO starting (kafka.server.KafkaServer)
[2019-01-26 19:39:18,487] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-26 19:39:18,518] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-26 19:39:18,518] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:39:18,518] INFO Client environment:host.name=ITdif.mshome.net (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:39:18,518] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:39:18,518] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:39:18,518] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:39:18,518] INFO Client environment:java.class.path=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-connect-jdbc-5.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\mysql-connector-java-5.1.42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:39:18,518] INFO Client environment:java.library.path=C:\Program Files\Java\jre1.8.0_181\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Docker\Docker\Resources\bin;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\Scripts\;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\dotnet\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\NoteBook FanControl\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\extras\CUPTI\libx64;C:\tools\cuda\bin;C:\Program Files\PuTTY\;C:\Program Files\Calibre2\;C:\apache-maven-3.6.\bin;C:\Users\Stefano\Downloads\platform-tools_r28.0.1-windows\platform-tools;C:\Program Files\Java\jre1.8.0_181\bin;C:\Users\Stefano\AppData\Local\Programs\Python\Launcher\;C:\Users\Stefano\AppData\Local\Microsoft\WindowsApps;C:\Users\Stefano\AppData\Local\GitHubDesktop\bin;C:\apache-maven-3.6.0\bin;;. (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:39:18,518] INFO Client environment:java.io.tmpdir=C:\Users\Stefano\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:39:18,518] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:39:18,518] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:39:18,518] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:39:18,518] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:39:18,518] INFO Client environment:user.name=Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:39:18,518] INFO Client environment:user.home=C:\Users\Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:39:18,518] INFO Client environment:user.dir=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:39:18,518] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@1622f1b (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:39:18,549] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-26 19:39:18,549] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-26 19:39:18,549] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62108 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-26 19:39:18,549] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-26 19:39:18,549] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:62108 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:39:18,565] INFO Established session 0x1000aa33c1e0002 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:62108 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:39:18,565] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1000aa33c1e0002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-26 19:39:18,565] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-26 19:39:18,627] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0002 type:create cxid:0x1 zxid:0xdb2 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:39:18,627] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0002 type:create cxid:0x2 zxid:0xdb3 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:39:18,643] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0002 type:create cxid:0x3 zxid:0xdb4 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:39:18,643] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0002 type:create cxid:0x4 zxid:0xdb5 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:39:18,643] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0002 type:create cxid:0x5 zxid:0xdb6 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:39:18,643] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0002 type:create cxid:0x6 zxid:0xdb7 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:39:18,643] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0002 type:create cxid:0x7 zxid:0xdb8 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:39:18,643] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0002 type:create cxid:0x8 zxid:0xdb9 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:39:18,659] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0002 type:create cxid:0x9 zxid:0xdba txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:39:18,659] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0002 type:create cxid:0xa zxid:0xdbb txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:39:18,659] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0002 type:create cxid:0xb zxid:0xdbc txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:39:18,659] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0002 type:create cxid:0xc zxid:0xdbd txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:39:18,659] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0002 type:create cxid:0xd zxid:0xdbe txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:39:18,846] INFO Cluster ID = RvEiz9fYQgKWcHR6fHb3dg (kafka.server.KafkaServer)
[2019-01-26 19:39:18,940] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-26 19:39:18,956] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-26 19:39:19,002] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-26 19:39:19,002] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-26 19:39:19,002] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-26 19:39:19,080] INFO Loading logs. (kafka.log.LogManager)
[2019-01-26 19:39:19,159] INFO [Log partition=aggregateddata-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:19,159] INFO [Log partition=aggregateddata-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,221] INFO [Log partition=aggregateddata-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,221] INFO [Log partition=aggregateddata-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 94 ms (kafka.log.Log)
[2019-01-26 19:39:19,237] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:19,237] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,252] INFO [ProducerStateManager partition=aggregateddata-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:19,268] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,268] INFO [ProducerStateManager partition=aggregateddata-1] Loading producer state from snapshot file 'C:\tmp\logs3\aggregateddata-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:19,284] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 47 ms (kafka.log.Log)
[2019-01-26 19:39:19,299] INFO [Log partition=aggregated_data-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:19,299] INFO [Log partition=aggregated_data-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,315] INFO [Log partition=aggregated_data-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,315] INFO [Log partition=aggregated_data-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:39:19,330] INFO [Log partition=aggregated_data-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:19,330] INFO [Log partition=aggregated_data-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,330] INFO [Log partition=aggregated_data-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,330] INFO [Log partition=aggregated_data-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:39:19,346] WARN [Log partition=alltools-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\alltools-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\alltools-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547979859855}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:39:19,346] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,362] INFO [ProducerStateManager partition=alltools-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:19,362] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:19,362] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,377] INFO [ProducerStateManager partition=alltools-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:19,393] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,393] INFO [ProducerStateManager partition=alltools-1] Loading producer state from snapshot file 'C:\tmp\logs3\alltools-1\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:19,393] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 47 ms (kafka.log.Log)
[2019-01-26 19:39:19,409] WARN [Log partition=alltools-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\alltools-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\alltools-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547977368170}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:39:19,409] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,424] INFO [ProducerStateManager partition=alltools-2] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:19,424] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:19,424] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,440] INFO [ProducerStateManager partition=alltools-2] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:19,455] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,455] INFO [ProducerStateManager partition=alltools-2] Loading producer state from snapshot file 'C:\tmp\logs3\alltools-2\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:19,455] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 46 ms (kafka.log.Log)
[2019-01-26 19:39:19,471] WARN [Log partition=edited-0, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\edited-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\edited-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996878625}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:39:19,471] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,487] INFO [ProducerStateManager partition=edited-0] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:19,487] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:19,487] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,502] INFO [ProducerStateManager partition=edited-0] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:19,518] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,518] INFO [ProducerStateManager partition=edited-0] Loading producer state from snapshot file 'C:\tmp\logs3\edited-0\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:19,518] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 47 ms (kafka.log.Log)
[2019-01-26 19:39:19,534] WARN [Log partition=edited-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\edited-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\edited-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996875547}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:39:19,534] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,549] INFO [ProducerStateManager partition=edited-2] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:19,549] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:19,565] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,565] INFO [ProducerStateManager partition=edited-2] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:19,580] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,580] INFO [ProducerStateManager partition=edited-2] Loading producer state from snapshot file 'C:\tmp\logs3\edited-2\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:19,580] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 46 ms (kafka.log.Log)
[2019-01-26 19:39:19,596] INFO [Log partition=edited10-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:19,596] INFO [Log partition=edited10-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,612] INFO [Log partition=edited10-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,612] INFO [Log partition=edited10-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:39:19,627] INFO [Log partition=edited10-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:19,627] INFO [Log partition=edited10-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,643] INFO [Log partition=edited10-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,643] INFO [Log partition=edited10-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:39:19,658] INFO [Log partition=edited11-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:19,658] INFO [Log partition=edited11-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,674] INFO [Log partition=edited11-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,674] INFO [Log partition=edited11-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:39:19,690] WARN [Log partition=edited12-0, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\edited12-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\edited12-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548410940127}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:39:19,690] INFO [Log partition=edited12-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,705] INFO [ProducerStateManager partition=edited12-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:19,705] INFO [Log partition=edited12-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:19,705] INFO [Log partition=edited12-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,721] INFO [ProducerStateManager partition=edited12-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:19,737] INFO [Log partition=edited12-0, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,737] INFO [ProducerStateManager partition=edited12-0] Loading producer state from snapshot file 'C:\tmp\logs3\edited12-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:19,737] INFO [Log partition=edited12-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 47 ms (kafka.log.Log)
[2019-01-26 19:39:19,752] INFO [Log partition=edited12-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:19,752] INFO [Log partition=edited12-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,768] INFO [Log partition=edited12-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,768] INFO [Log partition=edited12-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:39:19,783] INFO [Log partition=edited13-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:19,783] INFO [Log partition=edited13-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,783] INFO [Log partition=edited13-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,799] INFO [Log partition=edited13-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-26 19:39:19,799] INFO [Log partition=edited13-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:19,799] INFO [Log partition=edited13-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,815] INFO [ProducerStateManager partition=edited13-2] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:19,815] INFO [Log partition=edited13-2, dir=C:\tmp\logs3] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,830] INFO [ProducerStateManager partition=edited13-2] Loading producer state from snapshot file 'C:\tmp\logs3\edited13-2\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:19,830] INFO [Log partition=edited13-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 31 ms (kafka.log.Log)
[2019-01-26 19:39:19,830] WARN [Log partition=edited6-0, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\edited6-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\edited6-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548158302054}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:39:19,830] INFO [Log partition=edited6-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,846] INFO [ProducerStateManager partition=edited6-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:19,846] INFO [Log partition=edited6-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:19,846] INFO [Log partition=edited6-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,862] INFO [ProducerStateManager partition=edited6-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:19,877] INFO [Log partition=edited6-0, dir=C:\tmp\logs3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,877] INFO [ProducerStateManager partition=edited6-0] Loading producer state from snapshot file 'C:\tmp\logs3\edited6-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:19,877] INFO [Log partition=edited6-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 47 ms (kafka.log.Log)
[2019-01-26 19:39:19,893] WARN [Log partition=edited6-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\edited6-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\edited6-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548176773646}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:39:19,893] INFO [Log partition=edited6-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,908] INFO [ProducerStateManager partition=edited6-2] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:19,908] INFO [Log partition=edited6-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:19,908] INFO [Log partition=edited6-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,924] INFO [ProducerStateManager partition=edited6-2] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:19,940] INFO [Log partition=edited6-2, dir=C:\tmp\logs3] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,940] INFO [ProducerStateManager partition=edited6-2] Loading producer state from snapshot file 'C:\tmp\logs3\edited6-2\00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:19,940] INFO [Log partition=edited6-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 47 ms (kafka.log.Log)
[2019-01-26 19:39:19,955] WARN [Log partition=edited8-0, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\edited8-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\edited8-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548341369651}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:39:19,955] INFO [Log partition=edited8-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,955] INFO [ProducerStateManager partition=edited8-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:19,971] INFO [Log partition=edited8-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:19,971] INFO [Log partition=edited8-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,971] INFO [ProducerStateManager partition=edited8-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:19,987] INFO [Log partition=edited8-0, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:19,987] INFO [ProducerStateManager partition=edited8-0] Loading producer state from snapshot file 'C:\tmp\logs3\edited8-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:20,002] INFO [Log partition=edited8-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 47 ms (kafka.log.Log)
[2019-01-26 19:39:20,002] INFO [Log partition=edited8-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:20,002] INFO [Log partition=edited8-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,018] INFO [Log partition=edited8-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,018] INFO [Log partition=edited8-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:39:20,033] INFO [Log partition=edited9-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:20,033] INFO [Log partition=edited9-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,049] INFO [Log partition=edited9-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,049] INFO [Log partition=edited9-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:39:20,065] INFO [Log partition=mytools-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:20,065] INFO [Log partition=mytools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,080] INFO [Log partition=mytools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,080] INFO [Log partition=mytools-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:39:20,080] INFO [Log partition=mytools-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:20,080] INFO [Log partition=mytools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,096] INFO [Log partition=mytools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,096] INFO [Log partition=mytools-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:39:20,111] INFO [Log partition=pairing-stream-app-pairs-store-changelog-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:20,111] INFO [Log partition=pairing-stream-app-pairs-store-changelog-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,111] INFO [ProducerStateManager partition=pairing-stream-app-pairs-store-changelog-0] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:20,127] INFO [Log partition=pairing-stream-app-pairs-store-changelog-0, dir=C:\tmp\logs3] Loading producer state till offset 11 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,127] INFO [ProducerStateManager partition=pairing-stream-app-pairs-store-changelog-0] Loading producer state from snapshot file 'C:\tmp\logs3\pairing-stream-app-pairs-store-changelog-0\00000000000000000011.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:20,127] INFO [Log partition=pairing-stream-app-pairs-store-changelog-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 11 in 31 ms (kafka.log.Log)
[2019-01-26 19:39:20,158] INFO [Log partition=pairs-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:20,158] INFO [Log partition=pairs-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,174] INFO [ProducerStateManager partition=pairs-1] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:20,174] INFO [Log partition=pairs-1, dir=C:\tmp\logs3] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,190] INFO [ProducerStateManager partition=pairs-1] Loading producer state from snapshot file 'C:\tmp\logs3\pairs-1\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:20,190] INFO [Log partition=pairs-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 32 ms (kafka.log.Log)
[2019-01-26 19:39:20,190] INFO [Log partition=pairs-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:20,190] INFO [Log partition=pairs-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,205] INFO [ProducerStateManager partition=pairs-2] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:20,205] INFO [Log partition=pairs-2, dir=C:\tmp\logs3] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,205] INFO [ProducerStateManager partition=pairs-2] Loading producer state from snapshot file 'C:\tmp\logs3\pairs-2\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:20,221] INFO [Log partition=pairs-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 31 ms (kafka.log.Log)
[2019-01-26 19:39:20,221] INFO [Log partition=randommessages-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:20,221] INFO [Log partition=randommessages-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,236] INFO [ProducerStateManager partition=randommessages-0] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:20,252] INFO [Log partition=randommessages-0, dir=C:\tmp\logs3] Loading producer state till offset 11 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,252] INFO [ProducerStateManager partition=randommessages-0] Loading producer state from snapshot file 'C:\tmp\logs3\randommessages-0\00000000000000000011.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:20,252] INFO [Log partition=randommessages-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 11 in 31 ms (kafka.log.Log)
[2019-01-26 19:39:20,268] INFO [Log partition=randommessages-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:20,268] INFO [Log partition=randommessages-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,268] INFO [ProducerStateManager partition=randommessages-1] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:20,283] INFO [Log partition=randommessages-1, dir=C:\tmp\logs3] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,283] INFO [ProducerStateManager partition=randommessages-1] Loading producer state from snapshot file 'C:\tmp\logs3\randommessages-1\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:20,283] INFO [Log partition=randommessages-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 15 ms (kafka.log.Log)
[2019-01-26 19:39:20,299] INFO [Log partition=stack-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:20,299] INFO [Log partition=stack-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,315] INFO [Log partition=stack-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,315] INFO [Log partition=stack-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:39:20,330] INFO [Log partition=stack-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:20,330] INFO [Log partition=stack-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,330] INFO [Log partition=stack-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,330] INFO [Log partition=stack-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:39:20,346] INFO [Log partition=tools-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:20,346] INFO [Log partition=tools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,361] INFO [Log partition=tools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,361] INFO [Log partition=tools-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:39:20,361] INFO [Log partition=tools-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:20,361] INFO [Log partition=tools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,377] INFO [Log partition=tools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,377] INFO [Log partition=tools-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:39:20,393] INFO [Log partition=tools1-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:20,393] INFO [Log partition=tools1-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,408] INFO [Log partition=tools1-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,408] INFO [Log partition=tools1-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:39:20,424] INFO [Log partition=tools1-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:20,424] INFO [Log partition=tools1-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,440] INFO [Log partition=tools1-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,440] INFO [Log partition=tools1-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:39:20,455] WARN [Log partition=tools10-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools10-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools10-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548410034606}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:39:20,455] INFO [Log partition=tools10-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,471] INFO [ProducerStateManager partition=tools10-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:20,471] INFO [Log partition=tools10-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:20,471] INFO [Log partition=tools10-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,487] INFO [ProducerStateManager partition=tools10-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:20,502] INFO [Log partition=tools10-1, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,502] INFO [ProducerStateManager partition=tools10-1] Loading producer state from snapshot file 'C:\tmp\logs3\tools10-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:20,502] INFO [Log partition=tools10-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 47 ms (kafka.log.Log)
[2019-01-26 19:39:20,518] INFO [Log partition=tools10-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:20,518] INFO [Log partition=tools10-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,533] INFO [Log partition=tools10-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,533] INFO [Log partition=tools10-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:39:20,533] INFO [Log partition=tools11-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:20,549] INFO [Log partition=tools11-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,549] INFO [Log partition=tools11-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,549] INFO [Log partition=tools11-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:39:20,565] INFO [Log partition=tools11-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:20,565] INFO [Log partition=tools11-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,565] INFO [Log partition=tools11-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,580] INFO [Log partition=tools11-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:39:20,580] INFO [Log partition=tools12-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:20,580] INFO [Log partition=tools12-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,596] INFO [Log partition=tools12-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,596] INFO [Log partition=tools12-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:39:20,611] INFO [Log partition=tools12-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:20,611] INFO [Log partition=tools12-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,627] INFO [Log partition=tools12-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,627] INFO [Log partition=tools12-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-26 19:39:20,627] INFO [Log partition=tools13-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:20,627] INFO [Log partition=tools13-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,627] INFO [ProducerStateManager partition=tools13-0] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:20,643] INFO [Log partition=tools13-0, dir=C:\tmp\logs3] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,658] INFO [ProducerStateManager partition=tools13-0] Loading producer state from snapshot file 'C:\tmp\logs3\tools13-0\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:20,658] INFO [Log partition=tools13-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 31 ms (kafka.log.Log)
[2019-01-26 19:39:20,658] INFO [Log partition=tools13-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:20,658] INFO [Log partition=tools13-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,674] INFO [ProducerStateManager partition=tools13-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:20,674] INFO [Log partition=tools13-2, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,674] INFO [ProducerStateManager partition=tools13-2] Loading producer state from snapshot file 'C:\tmp\logs3\tools13-2\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:20,689] INFO [Log partition=tools13-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 31 ms (kafka.log.Log)
[2019-01-26 19:39:20,689] INFO [Log partition=tools14-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:20,689] INFO [Log partition=tools14-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,705] INFO [Log partition=tools14-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,705] INFO [Log partition=tools14-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:39:20,721] INFO [Log partition=tools14-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:20,721] INFO [Log partition=tools14-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,736] INFO [Log partition=tools14-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,736] INFO [Log partition=tools14-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:39:20,752] WARN [Log partition=tools2-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools2-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools2-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547992951029}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:39:20,752] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,752] INFO [ProducerStateManager partition=tools2-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:20,768] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:20,768] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,783] INFO [ProducerStateManager partition=tools2-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:20,799] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,799] INFO [ProducerStateManager partition=tools2-1] Loading producer state from snapshot file 'C:\tmp\logs3\tools2-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:20,799] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 47 ms (kafka.log.Log)
[2019-01-26 19:39:20,814] INFO [Log partition=tools2-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:20,814] INFO [Log partition=tools2-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,814] INFO [Log partition=tools2-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,830] INFO [Log partition=tools2-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:39:20,830] WARN [Log partition=tools3-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools3-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools3-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547993388462}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:39:20,830] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,846] INFO [ProducerStateManager partition=tools3-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:20,846] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:20,846] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,861] INFO [ProducerStateManager partition=tools3-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:20,877] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,877] INFO [ProducerStateManager partition=tools3-1] Loading producer state from snapshot file 'C:\tmp\logs3\tools3-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:20,877] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 47 ms (kafka.log.Log)
[2019-01-26 19:39:20,893] INFO [Log partition=tools3-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:20,893] INFO [Log partition=tools3-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,908] INFO [Log partition=tools3-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,908] INFO [Log partition=tools3-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:39:20,924] INFO [Log partition=tools4-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:20,924] INFO [Log partition=tools4-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,939] INFO [Log partition=tools4-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,939] INFO [Log partition=tools4-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:39:20,955] WARN [Log partition=tools4-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools4-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools4-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547993897061}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:39:20,955] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,971] INFO [ProducerStateManager partition=tools4-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:20,971] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:20,971] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:20,986] INFO [ProducerStateManager partition=tools4-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,002] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,002] INFO [ProducerStateManager partition=tools4-2] Loading producer state from snapshot file 'C:\tmp\logs3\tools4-2\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,002] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 47 ms (kafka.log.Log)
[2019-01-26 19:39:21,018] WARN [Log partition=tools5-0, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools5-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools5-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996871342}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:39:21,018] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,033] INFO [ProducerStateManager partition=tools5-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,033] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:21,033] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,049] INFO [ProducerStateManager partition=tools5-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,064] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,064] INFO [ProducerStateManager partition=tools5-0] Loading producer state from snapshot file 'C:\tmp\logs3\tools5-0\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,064] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 46 ms (kafka.log.Log)
[2019-01-26 19:39:21,080] WARN [Log partition=tools5-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools5-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools5-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996876577}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:39:21,080] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,080] INFO [ProducerStateManager partition=tools5-1] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,096] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:21,096] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,111] INFO [ProducerStateManager partition=tools5-1] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,127] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,127] INFO [ProducerStateManager partition=tools5-1] Loading producer state from snapshot file 'C:\tmp\logs3\tools5-1\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,127] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 47 ms (kafka.log.Log)
[2019-01-26 19:39:21,142] WARN [Log partition=tools6-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools6-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools6-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548321919981}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:39:21,142] INFO [Log partition=tools6-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,158] INFO [ProducerStateManager partition=tools6-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,158] INFO [Log partition=tools6-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:21,158] INFO [Log partition=tools6-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,174] INFO [ProducerStateManager partition=tools6-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,174] INFO [Log partition=tools6-1, dir=C:\tmp\logs3] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,189] INFO [ProducerStateManager partition=tools6-1] Loading producer state from snapshot file 'C:\tmp\logs3\tools6-1\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,189] INFO [Log partition=tools6-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 47 ms (kafka.log.Log)
[2019-01-26 19:39:21,189] WARN [Log partition=tools6-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools6-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools6-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548158302054}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:39:21,189] INFO [Log partition=tools6-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,205] INFO [ProducerStateManager partition=tools6-2] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,205] INFO [Log partition=tools6-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:21,205] INFO [Log partition=tools6-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,221] INFO [ProducerStateManager partition=tools6-2] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,236] INFO [Log partition=tools6-2, dir=C:\tmp\logs3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,236] INFO [ProducerStateManager partition=tools6-2] Loading producer state from snapshot file 'C:\tmp\logs3\tools6-2\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,236] INFO [Log partition=tools6-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 47 ms (kafka.log.Log)
[2019-01-26 19:39:21,252] INFO [Log partition=tools7-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:21,252] INFO [Log partition=tools7-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,252] INFO [Log partition=tools7-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,267] INFO [Log partition=tools7-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:39:21,267] WARN [Log partition=tools7-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools7-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools7-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548156023437}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:39:21,283] INFO [Log partition=tools7-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,283] INFO [ProducerStateManager partition=tools7-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,283] INFO [Log partition=tools7-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:21,283] INFO [Log partition=tools7-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,299] INFO [ProducerStateManager partition=tools7-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,299] INFO [Log partition=tools7-2, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,299] INFO [ProducerStateManager partition=tools7-2] Loading producer state from snapshot file 'C:\tmp\logs3\tools7-2\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,314] INFO [Log partition=tools7-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 47 ms (kafka.log.Log)
[2019-01-26 19:39:21,314] INFO [Log partition=tools8-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:21,314] INFO [Log partition=tools8-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,330] INFO [Log partition=tools8-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,330] INFO [Log partition=tools8-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:39:21,346] INFO [Log partition=tools8-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:21,346] INFO [Log partition=tools8-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,361] INFO [Log partition=tools8-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,361] INFO [Log partition=tools8-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-26 19:39:21,361] WARN [Log partition=__consumer_offsets-11, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\__consumer_offsets-11\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\__consumer_offsets-11\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548354913655}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:39:21,361] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,377] INFO [ProducerStateManager partition=__consumer_offsets-11] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,377] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:21,377] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,392] INFO [ProducerStateManager partition=__consumer_offsets-11] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,392] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs3] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,392] INFO [ProducerStateManager partition=__consumer_offsets-11] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-11\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,392] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 9 in 31 ms (kafka.log.Log)
[2019-01-26 19:39:21,408] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:21,408] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,424] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,424] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:39:21,439] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:21,439] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,455] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,455] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:39:21,471] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Found file C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.index.swap from interrupted swap operation. (kafka.log.Log)
[2019-01-26 19:39:21,471] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Deleting index files with suffix  for baseFile C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.index (kafka.log.Log)
[2019-01-26 19:39:21,471] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Found file C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.log.swap from interrupted swap operation. (kafka.log.Log)
[2019-01-26 19:39:21,486] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Deleting index files with suffix  for baseFile C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.log (kafka.log.Log)
[2019-01-26 19:39:21,486] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Deleting index files with suffix .swap for baseFile C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.log (kafka.log.Log)
[2019-01-26 19:39:21,502] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:21,502] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,517] INFO [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 162 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,517] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Recovering unflushed segment 162 (kafka.log.Log)
[2019-01-26 19:39:21,533] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Loading producer state till offset 162 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,533] INFO [ProducerStateManager partition=__consumer_offsets-2] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-2\00000000000000000162.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,549] INFO [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 163 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,549] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Loading producer state till offset 163 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,564] INFO [ProducerStateManager partition=__consumer_offsets-2] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-2\00000000000000000163.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,564] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Completed load of log with 2 segments, log start offset 0 and log end offset 163 in 93 ms (kafka.log.Log)
[2019-01-26 19:39:21,564] WARN [Log partition=__consumer_offsets-20, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\__consumer_offsets-20\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\__consumer_offsets-20\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548410887973}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:39:21,580] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,580] INFO [ProducerStateManager partition=__consumer_offsets-20] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,580] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:21,580] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,596] INFO [ProducerStateManager partition=__consumer_offsets-20] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,596] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\logs3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,611] INFO [ProducerStateManager partition=__consumer_offsets-20] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-20\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,611] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 47 ms (kafka.log.Log)
[2019-01-26 19:39:21,611] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:21,611] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,627] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,627] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:39:21,642] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:21,642] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,642] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,658] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:39:21,658] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:21,658] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,674] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,674] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:39:21,689] WARN [Log partition=__consumer_offsets-32, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\__consumer_offsets-32\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\__consumer_offsets-32\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548408890599}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:39:21,689] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,705] INFO [ProducerStateManager partition=__consumer_offsets-32] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,705] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:21,705] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,720] INFO [ProducerStateManager partition=__consumer_offsets-32] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,736] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\logs3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,736] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-32\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,736] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 47 ms (kafka.log.Log)
[2019-01-26 19:39:21,752] WARN [Log partition=__consumer_offsets-35, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\__consumer_offsets-35\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\__consumer_offsets-35\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548327517176}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:39:21,752] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,767] INFO [ProducerStateManager partition=__consumer_offsets-35] Writing producer snapshot at offset 76 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,767] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:21,767] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,783] INFO [ProducerStateManager partition=__consumer_offsets-35] Writing producer snapshot at offset 76 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,799] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs3] Loading producer state till offset 76 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,799] INFO [ProducerStateManager partition=__consumer_offsets-35] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-35\00000000000000000076.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,799] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 76 in 47 ms (kafka.log.Log)
[2019-01-26 19:39:21,814] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:21,814] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,814] INFO [ProducerStateManager partition=__consumer_offsets-38] Writing producer snapshot at offset 20 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,830] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\logs3] Loading producer state till offset 20 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,830] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-38\00000000000000000020.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,830] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 20 in 16 ms (kafka.log.Log)
[2019-01-26 19:39:21,845] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:21,845] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,845] INFO [ProducerStateManager partition=__consumer_offsets-41] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,861] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\logs3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,861] INFO [ProducerStateManager partition=__consumer_offsets-41] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-41\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,861] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 16 ms (kafka.log.Log)
[2019-01-26 19:39:21,877] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:21,877] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,908] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,908] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-26 19:39:21,908] WARN [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\__consumer_offsets-47\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\__consumer_offsets-47\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547992512270}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:39:21,908] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,924] INFO [ProducerStateManager partition=__consumer_offsets-47] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,924] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:21,924] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,939] INFO [ProducerStateManager partition=__consumer_offsets-47] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,955] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,955] INFO [ProducerStateManager partition=__consumer_offsets-47] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-47\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:21,955] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 47 ms (kafka.log.Log)
[2019-01-26 19:39:21,970] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:21,970] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,970] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:21,986] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:39:21,986] WARN [Log partition=__consumer_offsets-8, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\__consumer_offsets-8\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\__consumer_offsets-8\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548411290598}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:39:21,986] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:22,002] INFO [ProducerStateManager partition=__consumer_offsets-8] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:22,002] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:39:22,002] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:22,017] INFO [ProducerStateManager partition=__consumer_offsets-8] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:39:22,017] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\logs3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-26 19:39:22,033] INFO [ProducerStateManager partition=__consumer_offsets-8] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-8\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:39:22,033] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 47 ms (kafka.log.Log)
[2019-01-26 19:39:22,049] INFO Logs loading complete in 2969 ms. (kafka.log.LogManager)
[2019-01-26 19:39:22,064] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-26 19:39:22,064] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-26 19:39:22,314] ERROR Failed to clean up log for __consumer_offsets-2 in dir C:\tmp\logs3 due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex.cleaned -> C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex.swap: Impossibile accedere al file. Il file  utilizzato da un altro processo.

	at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsFileCopy.move(Unknown Source)
	at sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
	at java.nio.file.Files.move(Unknown Source)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:809)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:205)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:490)
	at kafka.log.Log.$anonfun$replaceSegments$4(Log.scala:1892)
	at kafka.log.Log.$anonfun$replaceSegments$4$adapted(Log.scala:1892)
	at scala.collection.immutable.List.foreach(List.scala:388)
	at kafka.log.Log.replaceSegments(Log.scala:1892)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:583)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:515)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:514)
	at scala.collection.immutable.List.foreach(List.scala:388)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:514)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:353)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
	Suppressed: java.nio.file.FileSystemException: C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex.cleaned -> C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex.swap: Impossibile accedere al file. Il file  utilizzato da un altro processo.

		at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
		at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
		at sun.nio.fs.WindowsFileCopy.move(Unknown Source)
		at sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
		at java.nio.file.Files.move(Unknown Source)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:806)
		... 16 more
[2019-01-26 19:39:22,392] ERROR Failed to clean up log for __consumer_offsets-2 in dir C:\tmp\logs3 due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex.cleaned: Impossibile accedere al file. Il file  utilizzato da un altro processo.

	at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(Unknown Source)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(Unknown Source)
	at java.nio.file.Files.deleteIfExists(Unknown Source)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2150)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:645)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:424)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:540)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:515)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:514)
	at scala.collection.immutable.List.foreach(List.scala:388)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:514)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:353)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-26 19:39:22,408] INFO Awaiting socket connections on localhost:9095. (kafka.network.Acceptor)
[2019-01-26 19:39:22,455] ERROR Failed to clean up log for __consumer_offsets-2 in dir C:\tmp\logs3 due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex.cleaned: Impossibile accedere al file. Il file  utilizzato da un altro processo.

	at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(Unknown Source)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(Unknown Source)
	at java.nio.file.Files.deleteIfExists(Unknown Source)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2150)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:645)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:424)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:540)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:515)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:514)
	at scala.collection.immutable.List.foreach(List.scala:388)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:514)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:353)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-26 19:39:22,502] INFO [SocketServer brokerId=3] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-26 19:39:22,502] ERROR Failed to clean up log for __consumer_offsets-2 in dir C:\tmp\logs3 due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex.cleaned: Impossibile accedere al file. Il file  utilizzato da un altro processo.

	at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(Unknown Source)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(Unknown Source)
	at java.nio.file.Files.deleteIfExists(Unknown Source)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2150)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:645)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:424)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:540)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:515)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:514)
	at scala.collection.immutable.List.foreach(List.scala:388)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:514)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:353)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-26 19:39:22,548] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:39:22,564] ERROR Failed to clean up log for __consumer_offsets-2 in dir C:\tmp\logs3 due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex.cleaned: Impossibile accedere al file. Il file  utilizzato da un altro processo.

	at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(Unknown Source)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(Unknown Source)
	at java.nio.file.Files.deleteIfExists(Unknown Source)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2150)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:645)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:424)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:540)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:515)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:514)
	at scala.collection.immutable.List.foreach(List.scala:388)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:514)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:353)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-26 19:39:22,564] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:39:22,564] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:39:22,627] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-26 19:39:22,627] INFO [ReplicaManager broker=3] Stopping serving replicas in dir C:\tmp\logs3 (kafka.server.ReplicaManager)
[2019-01-26 19:39:22,627] ERROR Failed to clean up log for __consumer_offsets-2 in dir C:\tmp\logs3 due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex.cleaned: Impossibile accedere al file. Il file  utilizzato da un altro processo.

	at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(Unknown Source)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(Unknown Source)
	at java.nio.file.Files.deleteIfExists(Unknown Source)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2150)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:645)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:424)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:540)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:515)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:514)
	at scala.collection.immutable.List.foreach(List.scala:388)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:514)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:353)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-26 19:39:22,642] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:39:22,642] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-26 19:39:22,658] INFO [ReplicaManager broker=3] Broker 3 stopped fetcher for partitions  and stopped moving logs for partitions  because they are in the failed log directory C:\tmp\logs3. (kafka.server.ReplicaManager)
[2019-01-26 19:39:22,658] INFO Stopping serving logs in dir C:\tmp\logs3 (kafka.log.LogManager)
[2019-01-26 19:39:22,658] ERROR Shutdown broker because all log dirs in C:\tmp\logs3 have failed (kafka.log.LogManager)
[2019-01-26 19:39:23,189] WARN Exception causing close of session 0x1000aa33c1e0002: Connessione in corso interrotta forzatamente dall'host remoto (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-26 19:39:23,189] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:62108 which had sessionid 0x1000aa33c1e0002 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-26 19:39:28,875] INFO Expiring session 0x1000aa33c1e0002, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:39:28,875] INFO Processed session termination for sessionid: 0x1000aa33c1e0002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:40:14,266] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-26 19:40:15,063] INFO starting (kafka.server.KafkaServer)
[2019-01-26 19:40:15,063] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-26 19:40:15,094] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-26 19:40:15,094] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:40:15,109] INFO Client environment:host.name=ITdif.mshome.net (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:40:15,109] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:40:15,109] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:40:15,125] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:40:15,125] INFO Client environment:java.class.path=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-connect-jdbc-5.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\mysql-connector-java-5.1.42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:40:15,125] INFO Client environment:java.library.path=C:\Program Files\Java\jre1.8.0_181\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Docker\Docker\Resources\bin;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\Scripts\;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\dotnet\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\NoteBook FanControl\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\extras\CUPTI\libx64;C:\tools\cuda\bin;C:\Program Files\PuTTY\;C:\Program Files\Calibre2\;C:\apache-maven-3.6.\bin;C:\Users\Stefano\Downloads\platform-tools_r28.0.1-windows\platform-tools;C:\Program Files\Java\jre1.8.0_181\bin;C:\Users\Stefano\AppData\Local\Programs\Python\Launcher\;C:\Users\Stefano\AppData\Local\Microsoft\WindowsApps;C:\Users\Stefano\AppData\Local\GitHubDesktop\bin;C:\apache-maven-3.6.0\bin;;. (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:40:15,125] INFO Client environment:java.io.tmpdir=C:\Users\Stefano\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:40:15,125] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:40:15,141] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:40:15,141] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:40:15,141] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:40:15,141] INFO Client environment:user.name=Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:40:15,141] INFO Client environment:user.home=C:\Users\Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:40:15,141] INFO Client environment:user.dir=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:40:15,156] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@1622f1b (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:40:15,188] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-26 19:40:15,188] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-26 19:40:15,203] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62128 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-26 19:40:15,203] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-26 19:40:15,203] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:62128 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:40:15,203] INFO Established session 0x1000aa33c1e0003 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:62128 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:40:15,203] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1000aa33c1e0003, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-26 19:40:15,203] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-26 19:40:15,281] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0003 type:create cxid:0x1 zxid:0xdc1 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:40:15,297] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0003 type:create cxid:0x2 zxid:0xdc2 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:40:15,297] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0003 type:create cxid:0x3 zxid:0xdc3 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:40:15,297] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0003 type:create cxid:0x4 zxid:0xdc4 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:40:15,297] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0003 type:create cxid:0x5 zxid:0xdc5 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:40:15,297] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0003 type:create cxid:0x6 zxid:0xdc6 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:40:15,313] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0003 type:create cxid:0x7 zxid:0xdc7 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:40:15,313] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0003 type:create cxid:0x8 zxid:0xdc8 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:40:15,313] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0003 type:create cxid:0x9 zxid:0xdc9 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:40:15,313] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0003 type:create cxid:0xa zxid:0xdca txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:40:15,313] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0003 type:create cxid:0xb zxid:0xdcb txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:40:15,313] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0003 type:create cxid:0xc zxid:0xdcc txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:40:15,328] INFO Got user-level KeeperException when processing sessionid:0x1000aa33c1e0003 type:create cxid:0xd zxid:0xdcd txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:40:15,516] INFO Cluster ID = RvEiz9fYQgKWcHR6fHb3dg (kafka.server.KafkaServer)
[2019-01-26 19:40:15,625] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-26 19:40:15,641] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-26 19:40:15,687] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-26 19:40:15,687] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-26 19:40:15,703] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-26 19:40:15,766] INFO Loading logs. (kafka.log.LogManager)
[2019-01-26 19:40:15,859] INFO [Log partition=aggregateddata-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:15,859] INFO [Log partition=aggregateddata-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:15,906] INFO [Log partition=aggregateddata-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:15,906] INFO [Log partition=aggregateddata-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 78 ms (kafka.log.Log)
[2019-01-26 19:40:15,922] WARN [Log partition=aggregateddata-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\aggregateddata-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\aggregateddata-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548412109187}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:40:15,922] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:15,953] INFO [ProducerStateManager partition=aggregateddata-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:15,953] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:15,953] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:15,969] INFO [ProducerStateManager partition=aggregateddata-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:15,984] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:15,984] INFO [ProducerStateManager partition=aggregateddata-1] Loading producer state from snapshot file 'C:\tmp\logs3\aggregateddata-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,016] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 94 ms (kafka.log.Log)
[2019-01-26 19:40:16,016] INFO [Log partition=aggregated_data-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:16,031] INFO [Log partition=aggregated_data-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,031] INFO [Log partition=aggregated_data-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,031] INFO [Log partition=aggregated_data-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:40:16,047] INFO [Log partition=aggregated_data-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:16,047] INFO [Log partition=aggregated_data-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,047] INFO [Log partition=aggregated_data-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,062] INFO [Log partition=aggregated_data-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:40:16,062] WARN [Log partition=alltools-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\alltools-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\alltools-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547979859855}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:40:16,062] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,078] INFO [ProducerStateManager partition=alltools-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,078] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:16,078] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,094] INFO [ProducerStateManager partition=alltools-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,094] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,109] INFO [ProducerStateManager partition=alltools-1] Loading producer state from snapshot file 'C:\tmp\logs3\alltools-1\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,109] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 47 ms (kafka.log.Log)
[2019-01-26 19:40:16,109] WARN [Log partition=alltools-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\alltools-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\alltools-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547977368170}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:40:16,109] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,125] INFO [ProducerStateManager partition=alltools-2] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,125] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:16,125] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,140] INFO [ProducerStateManager partition=alltools-2] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,140] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,140] INFO [ProducerStateManager partition=alltools-2] Loading producer state from snapshot file 'C:\tmp\logs3\alltools-2\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,140] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 31 ms (kafka.log.Log)
[2019-01-26 19:40:16,156] WARN [Log partition=edited-0, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\edited-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\edited-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996878625}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:40:16,156] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,172] INFO [ProducerStateManager partition=edited-0] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,172] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:16,172] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,187] INFO [ProducerStateManager partition=edited-0] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,187] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,203] INFO [ProducerStateManager partition=edited-0] Loading producer state from snapshot file 'C:\tmp\logs3\edited-0\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,203] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 47 ms (kafka.log.Log)
[2019-01-26 19:40:16,203] WARN [Log partition=edited-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\edited-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\edited-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996875547}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:40:16,203] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,219] INFO [ProducerStateManager partition=edited-2] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,219] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:16,219] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,234] INFO [ProducerStateManager partition=edited-2] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,234] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,234] INFO [ProducerStateManager partition=edited-2] Loading producer state from snapshot file 'C:\tmp\logs3\edited-2\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,250] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 47 ms (kafka.log.Log)
[2019-01-26 19:40:16,250] INFO [Log partition=edited10-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:16,250] INFO [Log partition=edited10-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,265] INFO [Log partition=edited10-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,265] INFO [Log partition=edited10-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:40:16,281] INFO [Log partition=edited10-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:16,281] INFO [Log partition=edited10-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,281] INFO [Log partition=edited10-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,297] INFO [Log partition=edited10-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-01-26 19:40:16,297] INFO [Log partition=edited11-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:16,297] INFO [Log partition=edited11-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,312] INFO [Log partition=edited11-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,312] INFO [Log partition=edited11-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:40:16,312] WARN [Log partition=edited12-0, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\edited12-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\edited12-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548410940127}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:40:16,312] INFO [Log partition=edited12-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,328] INFO [ProducerStateManager partition=edited12-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,328] INFO [Log partition=edited12-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:16,328] INFO [Log partition=edited12-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,344] INFO [ProducerStateManager partition=edited12-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,344] INFO [Log partition=edited12-0, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,344] INFO [ProducerStateManager partition=edited12-0] Loading producer state from snapshot file 'C:\tmp\logs3\edited12-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,344] INFO [Log partition=edited12-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 32 ms (kafka.log.Log)
[2019-01-26 19:40:16,359] INFO [Log partition=edited12-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:16,359] INFO [Log partition=edited12-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,359] INFO [Log partition=edited12-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,375] INFO [Log partition=edited12-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:40:16,375] INFO [Log partition=edited13-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:16,375] INFO [Log partition=edited13-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,390] INFO [Log partition=edited13-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,390] INFO [Log partition=edited13-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:40:16,406] WARN [Log partition=edited13-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\edited13-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\edited13-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548414680482}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:40:16,406] INFO [Log partition=edited13-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,422] INFO [ProducerStateManager partition=edited13-2] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,422] INFO [Log partition=edited13-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:16,422] INFO [Log partition=edited13-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,437] INFO [ProducerStateManager partition=edited13-2] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,437] INFO [Log partition=edited13-2, dir=C:\tmp\logs3] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,437] INFO [ProducerStateManager partition=edited13-2] Loading producer state from snapshot file 'C:\tmp\logs3\edited13-2\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,453] INFO [Log partition=edited13-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 47 ms (kafka.log.Log)
[2019-01-26 19:40:16,453] WARN [Log partition=edited6-0, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\edited6-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\edited6-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548158302054}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:40:16,453] INFO [Log partition=edited6-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,469] INFO [ProducerStateManager partition=edited6-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,469] INFO [Log partition=edited6-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:16,469] INFO [Log partition=edited6-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,484] INFO [ProducerStateManager partition=edited6-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,484] INFO [Log partition=edited6-0, dir=C:\tmp\logs3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,484] INFO [ProducerStateManager partition=edited6-0] Loading producer state from snapshot file 'C:\tmp\logs3\edited6-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,500] INFO [Log partition=edited6-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 47 ms (kafka.log.Log)
[2019-01-26 19:40:16,500] WARN [Log partition=edited6-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\edited6-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\edited6-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548176773646}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:40:16,500] INFO [Log partition=edited6-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,515] INFO [ProducerStateManager partition=edited6-2] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,515] INFO [Log partition=edited6-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:16,515] INFO [Log partition=edited6-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,531] INFO [ProducerStateManager partition=edited6-2] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,531] INFO [Log partition=edited6-2, dir=C:\tmp\logs3] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,547] INFO [ProducerStateManager partition=edited6-2] Loading producer state from snapshot file 'C:\tmp\logs3\edited6-2\00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,547] INFO [Log partition=edited6-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 47 ms (kafka.log.Log)
[2019-01-26 19:40:16,547] WARN [Log partition=edited8-0, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\edited8-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\edited8-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548341369651}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:40:16,547] INFO [Log partition=edited8-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,562] INFO [ProducerStateManager partition=edited8-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,562] INFO [Log partition=edited8-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:16,562] INFO [Log partition=edited8-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,578] INFO [ProducerStateManager partition=edited8-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,578] INFO [Log partition=edited8-0, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,578] INFO [ProducerStateManager partition=edited8-0] Loading producer state from snapshot file 'C:\tmp\logs3\edited8-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,578] INFO [Log partition=edited8-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 31 ms (kafka.log.Log)
[2019-01-26 19:40:16,594] INFO [Log partition=edited8-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:16,594] INFO [Log partition=edited8-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,594] INFO [Log partition=edited8-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,609] INFO [Log partition=edited8-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:40:16,609] INFO [Log partition=edited9-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:16,609] INFO [Log partition=edited9-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,625] INFO [Log partition=edited9-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,625] INFO [Log partition=edited9-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:40:16,640] INFO [Log partition=mytools-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:16,640] INFO [Log partition=mytools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,656] INFO [Log partition=mytools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,656] INFO [Log partition=mytools-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:40:16,656] INFO [Log partition=mytools-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:16,656] INFO [Log partition=mytools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,672] INFO [Log partition=mytools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,672] INFO [Log partition=mytools-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:40:16,687] WARN [Log partition=pairing-stream-app-pairs-store-changelog-0, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\pairing-stream-app-pairs-store-changelog-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\pairing-stream-app-pairs-store-changelog-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548429187726}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:40:16,687] INFO [Log partition=pairing-stream-app-pairs-store-changelog-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,703] INFO [ProducerStateManager partition=pairing-stream-app-pairs-store-changelog-0] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,703] INFO [Log partition=pairing-stream-app-pairs-store-changelog-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:16,703] INFO [Log partition=pairing-stream-app-pairs-store-changelog-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,719] INFO [ProducerStateManager partition=pairing-stream-app-pairs-store-changelog-0] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,719] INFO [Log partition=pairing-stream-app-pairs-store-changelog-0, dir=C:\tmp\logs3] Loading producer state till offset 11 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,734] INFO [ProducerStateManager partition=pairing-stream-app-pairs-store-changelog-0] Loading producer state from snapshot file 'C:\tmp\logs3\pairing-stream-app-pairs-store-changelog-0\00000000000000000011.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,734] INFO [Log partition=pairing-stream-app-pairs-store-changelog-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 11 in 47 ms (kafka.log.Log)
[2019-01-26 19:40:16,734] WARN [Log partition=pairs-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\pairs-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\pairs-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548429185722}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:40:16,734] INFO [Log partition=pairs-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,750] INFO [ProducerStateManager partition=pairs-1] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,750] INFO [Log partition=pairs-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:16,750] INFO [Log partition=pairs-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,765] INFO [ProducerStateManager partition=pairs-1] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,765] INFO [Log partition=pairs-1, dir=C:\tmp\logs3] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,765] INFO [ProducerStateManager partition=pairs-1] Loading producer state from snapshot file 'C:\tmp\logs3\pairs-1\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,781] INFO [Log partition=pairs-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 47 ms (kafka.log.Log)
[2019-01-26 19:40:16,781] WARN [Log partition=pairs-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\pairs-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\pairs-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548429184720}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:40:16,781] INFO [Log partition=pairs-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,797] INFO [ProducerStateManager partition=pairs-2] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,797] INFO [Log partition=pairs-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:16,797] INFO [Log partition=pairs-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,812] INFO [ProducerStateManager partition=pairs-2] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,828] INFO [Log partition=pairs-2, dir=C:\tmp\logs3] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,828] INFO [ProducerStateManager partition=pairs-2] Loading producer state from snapshot file 'C:\tmp\logs3\pairs-2\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,828] INFO [Log partition=pairs-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 47 ms (kafka.log.Log)
[2019-01-26 19:40:16,843] WARN [Log partition=randommessages-0, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\randommessages-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\randommessages-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548429187724}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:40:16,843] INFO [Log partition=randommessages-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,843] INFO [ProducerStateManager partition=randommessages-0] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,843] INFO [Log partition=randommessages-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:16,843] INFO [Log partition=randommessages-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,859] INFO [ProducerStateManager partition=randommessages-0] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,875] INFO [Log partition=randommessages-0, dir=C:\tmp\logs3] Loading producer state till offset 11 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,875] INFO [ProducerStateManager partition=randommessages-0] Loading producer state from snapshot file 'C:\tmp\logs3\randommessages-0\00000000000000000011.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,875] INFO [Log partition=randommessages-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 11 in 47 ms (kafka.log.Log)
[2019-01-26 19:40:16,890] WARN [Log partition=randommessages-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\randommessages-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\randommessages-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548429186722}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:40:16,890] INFO [Log partition=randommessages-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,906] INFO [ProducerStateManager partition=randommessages-1] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,906] INFO [Log partition=randommessages-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:16,906] INFO [Log partition=randommessages-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,922] INFO [ProducerStateManager partition=randommessages-1] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,922] INFO [Log partition=randommessages-1, dir=C:\tmp\logs3] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,937] INFO [ProducerStateManager partition=randommessages-1] Loading producer state from snapshot file 'C:\tmp\logs3\randommessages-1\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:16,937] INFO [Log partition=randommessages-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 47 ms (kafka.log.Log)
[2019-01-26 19:40:16,937] INFO [Log partition=stack-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:16,937] INFO [Log partition=stack-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,953] INFO [Log partition=stack-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,953] INFO [Log partition=stack-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:40:16,953] INFO [Log partition=stack-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:16,968] INFO [Log partition=stack-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,968] INFO [Log partition=stack-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,968] INFO [Log partition=stack-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:40:16,984] INFO [Log partition=tools-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:16,984] INFO [Log partition=tools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:16,984] INFO [Log partition=tools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,000] INFO [Log partition=tools-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:40:17,000] INFO [Log partition=tools-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:17,015] INFO [Log partition=tools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,015] INFO [Log partition=tools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,015] INFO [Log partition=tools-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:40:17,031] INFO [Log partition=tools1-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:17,031] INFO [Log partition=tools1-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,031] INFO [Log partition=tools1-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,047] INFO [Log partition=tools1-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:40:17,047] INFO [Log partition=tools1-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:17,047] INFO [Log partition=tools1-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,062] INFO [Log partition=tools1-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,062] INFO [Log partition=tools1-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:40:17,078] WARN [Log partition=tools10-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools10-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools10-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548410034606}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:40:17,078] INFO [Log partition=tools10-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,078] INFO [ProducerStateManager partition=tools10-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:17,093] INFO [Log partition=tools10-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:17,093] INFO [Log partition=tools10-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,093] INFO [ProducerStateManager partition=tools10-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:17,109] INFO [Log partition=tools10-1, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,109] INFO [ProducerStateManager partition=tools10-1] Loading producer state from snapshot file 'C:\tmp\logs3\tools10-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:17,109] INFO [Log partition=tools10-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 31 ms (kafka.log.Log)
[2019-01-26 19:40:17,125] INFO [Log partition=tools10-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:17,125] INFO [Log partition=tools10-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,140] INFO [Log partition=tools10-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,140] INFO [Log partition=tools10-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-26 19:40:17,156] INFO [Log partition=tools11-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:17,156] INFO [Log partition=tools11-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,172] INFO [Log partition=tools11-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,172] INFO [Log partition=tools11-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-01-26 19:40:17,172] INFO [Log partition=tools11-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:17,172] INFO [Log partition=tools11-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,187] INFO [Log partition=tools11-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,187] INFO [Log partition=tools11-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:40:17,187] INFO [Log partition=tools12-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:17,203] INFO [Log partition=tools12-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,203] INFO [Log partition=tools12-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,203] INFO [Log partition=tools12-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:40:17,218] INFO [Log partition=tools12-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:17,218] INFO [Log partition=tools12-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,218] INFO [Log partition=tools12-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,234] INFO [Log partition=tools12-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:40:17,234] WARN [Log partition=tools13-0, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools13-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools13-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548414842572}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:40:17,250] INFO [Log partition=tools13-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,250] INFO [ProducerStateManager partition=tools13-0] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:17,250] INFO [Log partition=tools13-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:17,250] INFO [Log partition=tools13-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,265] INFO [ProducerStateManager partition=tools13-0] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:17,265] INFO [Log partition=tools13-0, dir=C:\tmp\logs3] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,265] INFO [ProducerStateManager partition=tools13-0] Loading producer state from snapshot file 'C:\tmp\logs3\tools13-0\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:17,281] INFO [Log partition=tools13-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 47 ms (kafka.log.Log)
[2019-01-26 19:40:17,281] WARN [Log partition=tools13-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools13-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools13-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548414647242}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:40:17,281] INFO [Log partition=tools13-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,296] INFO [ProducerStateManager partition=tools13-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:17,296] INFO [Log partition=tools13-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:17,296] INFO [Log partition=tools13-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,312] INFO [ProducerStateManager partition=tools13-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:17,312] INFO [Log partition=tools13-2, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,312] INFO [ProducerStateManager partition=tools13-2] Loading producer state from snapshot file 'C:\tmp\logs3\tools13-2\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:17,312] INFO [Log partition=tools13-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 31 ms (kafka.log.Log)
[2019-01-26 19:40:17,328] INFO [Log partition=tools14-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:17,328] INFO [Log partition=tools14-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,328] INFO [Log partition=tools14-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,343] INFO [Log partition=tools14-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:40:17,343] INFO [Log partition=tools14-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:17,343] INFO [Log partition=tools14-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,359] INFO [Log partition=tools14-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,359] INFO [Log partition=tools14-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:40:17,359] WARN [Log partition=tools2-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools2-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools2-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547992951029}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:40:17,359] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,375] INFO [ProducerStateManager partition=tools2-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:17,375] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:17,375] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,390] INFO [ProducerStateManager partition=tools2-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:17,390] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,390] INFO [ProducerStateManager partition=tools2-1] Loading producer state from snapshot file 'C:\tmp\logs3\tools2-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:17,390] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 31 ms (kafka.log.Log)
[2019-01-26 19:40:17,406] INFO [Log partition=tools2-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:17,406] INFO [Log partition=tools2-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,421] INFO [Log partition=tools2-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,421] INFO [Log partition=tools2-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-26 19:40:17,421] WARN [Log partition=tools3-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools3-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools3-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547993388462}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:40:17,421] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,437] INFO [ProducerStateManager partition=tools3-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:17,437] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:17,437] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,453] INFO [ProducerStateManager partition=tools3-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:17,453] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,453] INFO [ProducerStateManager partition=tools3-1] Loading producer state from snapshot file 'C:\tmp\logs3\tools3-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:17,468] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 47 ms (kafka.log.Log)
[2019-01-26 19:40:17,468] INFO [Log partition=tools3-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:17,468] INFO [Log partition=tools3-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,484] INFO [Log partition=tools3-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,484] INFO [Log partition=tools3-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:40:17,500] INFO [Log partition=tools4-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:17,500] INFO [Log partition=tools4-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,500] INFO [Log partition=tools4-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,515] INFO [Log partition=tools4-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-26 19:40:17,515] WARN [Log partition=tools4-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools4-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools4-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547993897061}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:40:17,531] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,531] INFO [ProducerStateManager partition=tools4-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:17,531] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:17,531] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,546] INFO [ProducerStateManager partition=tools4-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:17,562] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,562] INFO [ProducerStateManager partition=tools4-2] Loading producer state from snapshot file 'C:\tmp\logs3\tools4-2\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:17,562] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 47 ms (kafka.log.Log)
[2019-01-26 19:40:17,578] WARN [Log partition=tools5-0, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools5-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools5-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996871342}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:40:17,578] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,593] INFO [ProducerStateManager partition=tools5-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:17,593] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:17,593] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,609] INFO [ProducerStateManager partition=tools5-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:17,609] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,625] INFO [ProducerStateManager partition=tools5-0] Loading producer state from snapshot file 'C:\tmp\logs3\tools5-0\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:17,625] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 47 ms (kafka.log.Log)
[2019-01-26 19:40:17,640] WARN [Log partition=tools5-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools5-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools5-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996876577}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:40:17,640] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,656] INFO [ProducerStateManager partition=tools5-1] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:17,656] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:17,656] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,671] INFO [ProducerStateManager partition=tools5-1] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:17,671] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,687] INFO [ProducerStateManager partition=tools5-1] Loading producer state from snapshot file 'C:\tmp\logs3\tools5-1\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:17,687] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 47 ms (kafka.log.Log)
[2019-01-26 19:40:17,687] WARN [Log partition=tools6-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools6-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools6-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548321919981}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:40:17,687] INFO [Log partition=tools6-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,703] INFO [ProducerStateManager partition=tools6-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:17,703] INFO [Log partition=tools6-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:17,703] INFO [Log partition=tools6-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,718] INFO [ProducerStateManager partition=tools6-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:17,718] INFO [Log partition=tools6-1, dir=C:\tmp\logs3] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,718] INFO [ProducerStateManager partition=tools6-1] Loading producer state from snapshot file 'C:\tmp\logs3\tools6-1\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:17,734] INFO [Log partition=tools6-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 47 ms (kafka.log.Log)
[2019-01-26 19:40:17,734] WARN [Log partition=tools6-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools6-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools6-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548158302054}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:40:17,734] INFO [Log partition=tools6-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,750] INFO [ProducerStateManager partition=tools6-2] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:17,750] INFO [Log partition=tools6-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:17,750] INFO [Log partition=tools6-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,765] INFO [ProducerStateManager partition=tools6-2] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:17,765] INFO [Log partition=tools6-2, dir=C:\tmp\logs3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,765] INFO [ProducerStateManager partition=tools6-2] Loading producer state from snapshot file 'C:\tmp\logs3\tools6-2\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:17,781] INFO [Log partition=tools6-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 47 ms (kafka.log.Log)
[2019-01-26 19:40:17,781] INFO [Log partition=tools7-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:17,781] INFO [Log partition=tools7-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,796] INFO [Log partition=tools7-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,796] INFO [Log partition=tools7-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:40:17,812] WARN [Log partition=tools7-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools7-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools7-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548156023437}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:40:17,812] INFO [Log partition=tools7-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,812] INFO [ProducerStateManager partition=tools7-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:17,828] INFO [Log partition=tools7-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:17,828] INFO [Log partition=tools7-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,828] INFO [ProducerStateManager partition=tools7-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:17,843] INFO [Log partition=tools7-2, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,843] INFO [ProducerStateManager partition=tools7-2] Loading producer state from snapshot file 'C:\tmp\logs3\tools7-2\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:17,843] INFO [Log partition=tools7-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 31 ms (kafka.log.Log)
[2019-01-26 19:40:17,859] INFO [Log partition=tools8-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:17,859] INFO [Log partition=tools8-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,859] INFO [Log partition=tools8-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,874] INFO [Log partition=tools8-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:40:17,874] INFO [Log partition=tools8-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:17,874] INFO [Log partition=tools8-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,890] INFO [Log partition=tools8-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,906] INFO [Log partition=tools8-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-01-26 19:40:17,906] WARN [Log partition=__consumer_offsets-11, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\__consumer_offsets-11\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\__consumer_offsets-11\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548451671096}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:40:17,906] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,921] INFO [ProducerStateManager partition=__consumer_offsets-11] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:17,921] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:17,921] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,937] INFO [ProducerStateManager partition=__consumer_offsets-11] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:17,937] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs3] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,953] INFO [ProducerStateManager partition=__consumer_offsets-11] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-11\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:17,953] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 9 in 47 ms (kafka.log.Log)
[2019-01-26 19:40:17,953] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:17,953] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,968] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,968] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:40:17,984] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:17,984] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,984] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:17,999] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:40:17,999] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Found file C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.index.swap from interrupted swap operation. (kafka.log.Log)
[2019-01-26 19:40:17,999] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Deleting index files with suffix  for baseFile C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.index (kafka.log.Log)
[2019-01-26 19:40:17,999] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Found file C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.log.swap from interrupted swap operation. (kafka.log.Log)
[2019-01-26 19:40:17,999] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Deleting index files with suffix  for baseFile C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.log (kafka.log.Log)
[2019-01-26 19:40:18,015] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Deleting index files with suffix .swap for baseFile C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.log (kafka.log.Log)
[2019-01-26 19:40:18,031] WARN [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\__consumer_offsets-2\00000000000000000162.log due to Corrupt time index found, time index file (C:\tmp\logs3\__consumer_offsets-2\00000000000000000162.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548451758096}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:40:18,031] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Loading producer state till offset 162 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:18,031] INFO [ProducerStateManager partition=__consumer_offsets-2] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-2\00000000000000000162.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:18,046] INFO [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 163 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:18,046] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:18,046] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:18,062] INFO [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 162 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:18,062] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Recovering unflushed segment 162 (kafka.log.Log)
[2019-01-26 19:40:18,062] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Loading producer state till offset 162 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:18,078] INFO [ProducerStateManager partition=__consumer_offsets-2] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-2\00000000000000000162.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:18,078] INFO [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 163 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:18,093] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Loading producer state till offset 163 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:18,093] INFO [ProducerStateManager partition=__consumer_offsets-2] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-2\00000000000000000163.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:18,093] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Completed load of log with 2 segments, log start offset 0 and log end offset 163 in 94 ms (kafka.log.Log)
[2019-01-26 19:40:18,109] WARN [Log partition=__consumer_offsets-20, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\__consumer_offsets-20\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\__consumer_offsets-20\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548412607771}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:40:18,109] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:18,124] INFO [ProducerStateManager partition=__consumer_offsets-20] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:18,124] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:18,124] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:18,124] INFO [ProducerStateManager partition=__consumer_offsets-20] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:18,140] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\logs3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:18,140] INFO [ProducerStateManager partition=__consumer_offsets-20] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-20\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:18,140] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 31 ms (kafka.log.Log)
[2019-01-26 19:40:18,156] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:18,156] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:18,156] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:18,156] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:40:18,171] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:18,171] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:18,187] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:18,187] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-26 19:40:18,187] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:18,187] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:18,203] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:18,203] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:40:18,218] WARN [Log partition=__consumer_offsets-32, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\__consumer_offsets-32\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\__consumer_offsets-32\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548408890599}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:40:18,218] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:18,234] INFO [ProducerStateManager partition=__consumer_offsets-32] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:18,234] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:18,249] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:18,249] INFO [ProducerStateManager partition=__consumer_offsets-32] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:18,249] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\logs3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:18,265] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-32\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:18,265] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 62 ms (kafka.log.Log)
[2019-01-26 19:40:18,265] WARN [Log partition=__consumer_offsets-35, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\__consumer_offsets-35\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\__consumer_offsets-35\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548327517176}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:40:18,265] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:18,281] INFO [ProducerStateManager partition=__consumer_offsets-35] Writing producer snapshot at offset 76 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:18,281] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:18,281] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:18,296] INFO [ProducerStateManager partition=__consumer_offsets-35] Writing producer snapshot at offset 76 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:18,296] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs3] Loading producer state till offset 76 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:18,312] INFO [ProducerStateManager partition=__consumer_offsets-35] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-35\00000000000000000076.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:18,312] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 76 in 47 ms (kafka.log.Log)
[2019-01-26 19:40:18,312] WARN [Log partition=__consumer_offsets-38, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\__consumer_offsets-38\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\__consumer_offsets-38\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548429189415}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:40:18,312] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:18,327] INFO [ProducerStateManager partition=__consumer_offsets-38] Writing producer snapshot at offset 20 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:18,327] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:18,327] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:18,343] INFO [ProducerStateManager partition=__consumer_offsets-38] Writing producer snapshot at offset 20 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:18,343] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\logs3] Loading producer state till offset 20 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:18,359] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-38\00000000000000000020.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:18,359] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 20 in 47 ms (kafka.log.Log)
[2019-01-26 19:40:18,359] WARN [Log partition=__consumer_offsets-41, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\__consumer_offsets-41\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\__consumer_offsets-41\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548427007773}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:40:18,359] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:18,374] INFO [ProducerStateManager partition=__consumer_offsets-41] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:18,374] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:18,374] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:18,390] INFO [ProducerStateManager partition=__consumer_offsets-41] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:18,390] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\logs3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:18,390] INFO [ProducerStateManager partition=__consumer_offsets-41] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-41\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:18,390] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 31 ms (kafka.log.Log)
[2019-01-26 19:40:18,390] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:18,390] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:18,406] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:18,406] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:40:18,421] WARN [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\__consumer_offsets-47\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\__consumer_offsets-47\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547992512270}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:40:18,421] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:18,421] INFO [ProducerStateManager partition=__consumer_offsets-47] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:18,421] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:18,421] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:18,437] INFO [ProducerStateManager partition=__consumer_offsets-47] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:18,452] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:18,452] INFO [ProducerStateManager partition=__consumer_offsets-47] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-47\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:18,452] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 31 ms (kafka.log.Log)
[2019-01-26 19:40:18,468] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:18,468] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:18,468] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:18,484] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:40:18,484] WARN [Log partition=__consumer_offsets-8, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\__consumer_offsets-8\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\__consumer_offsets-8\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548411290598}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:40:18,484] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:18,499] INFO [ProducerStateManager partition=__consumer_offsets-8] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:18,499] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:40:18,515] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:18,515] INFO [ProducerStateManager partition=__consumer_offsets-8] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:40:18,515] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\logs3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-26 19:40:18,531] INFO [ProducerStateManager partition=__consumer_offsets-8] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-8\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:40:18,531] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 47 ms (kafka.log.Log)
[2019-01-26 19:40:18,531] INFO Logs loading complete in 2750 ms. (kafka.log.LogManager)
[2019-01-26 19:40:18,546] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-26 19:40:18,546] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-26 19:40:18,796] ERROR Failed to clean up log for __consumer_offsets-2 in dir C:\tmp\logs3 due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex.cleaned -> C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex.swap: Impossibile accedere al file. Il file  utilizzato da un altro processo.

	at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsFileCopy.move(Unknown Source)
	at sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
	at java.nio.file.Files.move(Unknown Source)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:809)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:205)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:490)
	at kafka.log.Log.$anonfun$replaceSegments$4(Log.scala:1892)
	at kafka.log.Log.$anonfun$replaceSegments$4$adapted(Log.scala:1892)
	at scala.collection.immutable.List.foreach(List.scala:388)
	at kafka.log.Log.replaceSegments(Log.scala:1892)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:583)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:515)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:514)
	at scala.collection.immutable.List.foreach(List.scala:388)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:514)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:353)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
	Suppressed: java.nio.file.FileSystemException: C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex.cleaned -> C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex.swap: Impossibile accedere al file. Il file  utilizzato da un altro processo.

		at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
		at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
		at sun.nio.fs.WindowsFileCopy.move(Unknown Source)
		at sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
		at java.nio.file.Files.move(Unknown Source)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:806)
		... 16 more
[2019-01-26 19:40:18,890] ERROR Failed to clean up log for __consumer_offsets-2 in dir C:\tmp\logs3 due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex.cleaned: Impossibile accedere al file. Il file  utilizzato da un altro processo.

	at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(Unknown Source)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(Unknown Source)
	at java.nio.file.Files.deleteIfExists(Unknown Source)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2150)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:645)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:424)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:540)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:515)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:514)
	at scala.collection.immutable.List.foreach(List.scala:388)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:514)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:353)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-26 19:40:18,905] INFO Awaiting socket connections on localhost:9095. (kafka.network.Acceptor)
[2019-01-26 19:40:18,952] ERROR Failed to clean up log for __consumer_offsets-2 in dir C:\tmp\logs3 due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex.cleaned: Impossibile accedere al file. Il file  utilizzato da un altro processo.

	at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(Unknown Source)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(Unknown Source)
	at java.nio.file.Files.deleteIfExists(Unknown Source)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2150)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:645)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:424)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:540)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:515)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:514)
	at scala.collection.immutable.List.foreach(List.scala:388)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:514)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:353)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-26 19:40:18,999] INFO [SocketServer brokerId=3] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-26 19:40:18,999] ERROR Failed to clean up log for __consumer_offsets-2 in dir C:\tmp\logs3 due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex.cleaned: Impossibile accedere al file. Il file  utilizzato da un altro processo.

	at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(Unknown Source)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(Unknown Source)
	at java.nio.file.Files.deleteIfExists(Unknown Source)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2150)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:645)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:424)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:540)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:515)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:514)
	at scala.collection.immutable.List.foreach(List.scala:388)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:514)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:353)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-26 19:40:19,046] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:40:19,046] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:40:19,046] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:40:19,062] ERROR Failed to clean up log for __consumer_offsets-2 in dir C:\tmp\logs3 due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex.cleaned: Impossibile accedere al file. Il file  utilizzato da un altro processo.

	at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(Unknown Source)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(Unknown Source)
	at java.nio.file.Files.deleteIfExists(Unknown Source)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2150)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:645)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:424)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:540)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:515)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:514)
	at scala.collection.immutable.List.foreach(List.scala:388)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:514)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:353)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-26 19:40:19,124] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-26 19:40:19,124] ERROR Failed to clean up log for __consumer_offsets-2 in dir C:\tmp\logs3 due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex.cleaned: Impossibile accedere al file. Il file  utilizzato da un altro processo.

	at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(Unknown Source)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(Unknown Source)
	at java.nio.file.Files.deleteIfExists(Unknown Source)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2150)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:645)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:424)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:540)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:515)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:514)
	at scala.collection.immutable.List.foreach(List.scala:388)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:514)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:353)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-26 19:40:19,124] INFO [ReplicaManager broker=3] Stopping serving replicas in dir C:\tmp\logs3 (kafka.server.ReplicaManager)
[2019-01-26 19:40:19,187] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:40:19,187] ERROR Failed to clean up log for __consumer_offsets-2 in dir C:\tmp\logs3 due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex.cleaned: Impossibile accedere al file. Il file  utilizzato da un altro processo.

	at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(Unknown Source)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(Unknown Source)
	at java.nio.file.Files.deleteIfExists(Unknown Source)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2150)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:645)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:424)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:540)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:515)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:514)
	at scala.collection.immutable.List.foreach(List.scala:388)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:514)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:353)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-26 19:40:19,187] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-26 19:40:19,218] INFO [ReplicaManager broker=3] Broker 3 stopped fetcher for partitions  and stopped moving logs for partitions  because they are in the failed log directory C:\tmp\logs3. (kafka.server.ReplicaManager)
[2019-01-26 19:40:19,249] INFO Stopping serving logs in dir C:\tmp\logs3 (kafka.log.LogManager)
[2019-01-26 19:40:19,249] ERROR Shutdown broker because all log dirs in C:\tmp\logs3 have failed (kafka.log.LogManager)
[2019-01-26 19:40:19,749] WARN Exception causing close of session 0x1000aa33c1e0003: Connessione in corso interrotta forzatamente dall'host remoto (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-26 19:40:19,749] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:62128 which had sessionid 0x1000aa33c1e0003 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-26 19:40:25,873] INFO Expiring session 0x1000aa33c1e0003, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:40:25,873] INFO Processed session termination for sessionid: 0x1000aa33c1e0003 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:40:37,464] WARN Exception causing close of session 0x1000aa33c1e0001: Connessione in corso interrotta forzatamente dall'host remoto (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-26 19:40:37,479] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:62085 which had sessionid 0x1000aa33c1e0001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-26 19:40:40,853] WARN Exception causing close of session 0x1000aa33c1e0000: Connessione in corso interrotta forzatamente dall'host remoto (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-26 19:40:40,853] INFO Closed socket connection for client /127.0.0.1:62068 which had sessionid 0x1000aa33c1e0000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-26 19:40:43,869] INFO Expiring session 0x1000aa33c1e0001, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:40:43,869] INFO Processed session termination for sessionid: 0x1000aa33c1e0001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:41:27,677] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-26 19:41:28,334] INFO starting (kafka.server.KafkaServer)
[2019-01-26 19:41:28,334] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-26 19:41:28,349] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-26 19:41:28,365] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:41:28,365] INFO Client environment:host.name=ITdif.mshome.net (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:41:28,365] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:41:28,365] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:41:28,365] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:41:28,365] INFO Client environment:java.class.path=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-connect-jdbc-5.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\mysql-connector-java-5.1.42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:41:28,365] INFO Client environment:java.library.path=C:\Program Files\Java\jre1.8.0_181\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Docker\Docker\Resources\bin;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\Scripts\;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\dotnet\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\NoteBook FanControl\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\extras\CUPTI\libx64;C:\tools\cuda\bin;C:\Program Files\PuTTY\;C:\Program Files\Calibre2\;C:\apache-maven-3.6.\bin;C:\Users\Stefano\Downloads\platform-tools_r28.0.1-windows\platform-tools;C:\Program Files\Java\jre1.8.0_181\bin;C:\Users\Stefano\AppData\Local\Programs\Python\Launcher\;C:\Users\Stefano\AppData\Local\Microsoft\WindowsApps;C:\Users\Stefano\AppData\Local\GitHubDesktop\bin;C:\apache-maven-3.6.0\bin;;. (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:41:28,365] INFO Client environment:java.io.tmpdir=C:\Users\Stefano\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:41:28,365] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:41:28,365] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:41:28,365] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:41:28,365] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:41:28,365] INFO Client environment:user.name=Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:41:28,365] INFO Client environment:user.home=C:\Users\Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:41:28,365] INFO Client environment:user.dir=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:41:28,365] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@1622f1b (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:41:28,380] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-26 19:41:28,380] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-26 19:41:29,412] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2019-01-26 19:41:30,537] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-26 19:41:31,568] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2019-01-26 19:41:32,692] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-26 19:41:33,723] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2019-01-26 19:41:34,395] INFO [ZooKeeperClient] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-01-26 19:41:34,848] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-26 19:41:35,973] INFO Session: 0x0 closed (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:41:35,973] INFO EventThread shut down for session: 0x0 (org.apache.zookeeper.ClientCnxn)
[2019-01-26 19:41:35,973] INFO [ZooKeeperClient] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-01-26 19:41:35,988] ERROR Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
kafka.zookeeper.ZooKeeperClientTimeoutException: Timed out waiting for connection while in state: CONNECTING
	at kafka.zookeeper.ZooKeeperClient.$anonfun$waitUntilConnected$3(ZooKeeperClient.scala:268)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:251)
	at kafka.zookeeper.ZooKeeperClient.waitUntilConnected(ZooKeeperClient.scala:264)
	at kafka.zookeeper.ZooKeeperClient.<init>(ZooKeeperClient.scala:97)
	at kafka.zk.KafkaZkClient$.apply(KafkaZkClient.scala:1694)
	at kafka.server.KafkaServer.createZkClient$1(KafkaServer.scala:348)
	at kafka.server.KafkaServer.initZkClient(KafkaServer.scala:372)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:202)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:75)
	at kafka.Kafka.main(Kafka.scala)
[2019-01-26 19:41:36,004] INFO shutting down (kafka.server.KafkaServer)
[2019-01-26 19:41:36,019] INFO shut down completed (kafka.server.KafkaServer)
[2019-01-26 19:41:36,019] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2019-01-26 19:41:36,035] INFO shutting down (kafka.server.KafkaServer)
[2019-01-26 19:41:48,165] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-01-26 19:41:48,165] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-26 19:41:48,165] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-26 19:41:48,165] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-26 19:41:48,165] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-01-26 19:41:48,180] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-01-26 19:41:48,180] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-01-26 19:41:48,196] INFO Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:41:48,196] INFO Server environment:host.name=ITdif.mshome.net (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:41:48,196] INFO Server environment:java.version=1.8.0_181 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:41:48,196] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:41:48,196] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_181 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:41:48,196] INFO Server environment:java.class.path=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-connect-jdbc-5.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\mysql-connector-java-5.1.42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:41:48,196] INFO Server environment:java.library.path=C:\Program Files\Java\jre1.8.0_181\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Docker\Docker\Resources\bin;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\Scripts\;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\dotnet\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\NoteBook FanControl\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\extras\CUPTI\libx64;C:\tools\cuda\bin;C:\Program Files\PuTTY\;C:\Program Files\Calibre2\;C:\apache-maven-3.6.\bin;C:\Users\Stefano\Downloads\platform-tools_r28.0.1-windows\platform-tools;C:\Program Files\Java\jre1.8.0_181\bin;C:\Users\Stefano\AppData\Local\Programs\Python\Launcher\;C:\Users\Stefano\AppData\Local\Microsoft\WindowsApps;C:\Users\Stefano\AppData\Local\GitHubDesktop\bin;C:\apache-maven-3.6.0\bin;;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:41:48,196] INFO Server environment:java.io.tmpdir=C:\Users\Stefano\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:41:48,196] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:41:48,196] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:41:48,196] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:41:48,196] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:41:48,196] INFO Server environment:user.name=Stefano (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:41:48,196] INFO Server environment:user.home=C:\Users\Stefano (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:41:48,196] INFO Server environment:user.dir=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:41:48,212] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:41:48,212] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:41:48,212] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:41:48,243] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-01-26 19:41:48,243] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-26 19:41:55,866] INFO Expiring session 0x1000aa33c1e0000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:41:55,866] INFO Processed session termination for sessionid: 0x1000aa33c1e0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:41:55,866] INFO Creating new log file: log.dd0 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-01-26 19:42:08,847] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-26 19:42:09,505] INFO starting (kafka.server.KafkaServer)
[2019-01-26 19:42:09,505] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-26 19:42:09,521] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-26 19:42:09,521] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:42:09,521] INFO Client environment:host.name=ITdif.mshome.net (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:42:09,521] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:42:09,521] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:42:09,537] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:42:09,537] INFO Client environment:java.class.path=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-connect-jdbc-5.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\mysql-connector-java-5.1.42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:42:09,537] INFO Client environment:java.library.path=C:\Program Files\Java\jre1.8.0_181\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Docker\Docker\Resources\bin;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\Scripts\;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\dotnet\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\NoteBook FanControl\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\extras\CUPTI\libx64;C:\tools\cuda\bin;C:\Program Files\PuTTY\;C:\Program Files\Calibre2\;C:\apache-maven-3.6.\bin;C:\Users\Stefano\Downloads\platform-tools_r28.0.1-windows\platform-tools;C:\Program Files\Java\jre1.8.0_181\bin;C:\Users\Stefano\AppData\Local\Programs\Python\Launcher\;C:\Users\Stefano\AppData\Local\Microsoft\WindowsApps;C:\Users\Stefano\AppData\Local\GitHubDesktop\bin;C:\apache-maven-3.6.0\bin;;. (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:42:09,537] INFO Client environment:java.io.tmpdir=C:\Users\Stefano\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:42:09,537] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:42:09,537] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:42:09,537] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:42:09,537] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:42:09,537] INFO Client environment:user.name=Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:42:09,537] INFO Client environment:user.home=C:\Users\Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:42:09,537] INFO Client environment:user.dir=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:42:09,537] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@1622f1b (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:42:09,552] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-26 19:42:09,552] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-26 19:42:09,552] INFO Accepted socket connection from /127.0.0.1:62154 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-26 19:42:09,552] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-26 19:42:09,568] INFO Client attempting to establish new session at /127.0.0.1:62154 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:42:09,568] INFO Established session 0x1000aa69a040000 with negotiated timeout 6000 for client /127.0.0.1:62154 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:42:09,584] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000aa69a040000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-26 19:42:09,584] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-26 19:42:09,646] INFO Got user-level KeeperException when processing sessionid:0x1000aa69a040000 type:create cxid:0x1 zxid:0xdd2 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:42:09,662] INFO Got user-level KeeperException when processing sessionid:0x1000aa69a040000 type:create cxid:0x2 zxid:0xdd3 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:42:09,662] INFO Got user-level KeeperException when processing sessionid:0x1000aa69a040000 type:create cxid:0x3 zxid:0xdd4 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:42:09,662] INFO Got user-level KeeperException when processing sessionid:0x1000aa69a040000 type:create cxid:0x4 zxid:0xdd5 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:42:09,662] INFO Got user-level KeeperException when processing sessionid:0x1000aa69a040000 type:create cxid:0x5 zxid:0xdd6 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:42:09,677] INFO Got user-level KeeperException when processing sessionid:0x1000aa69a040000 type:create cxid:0x6 zxid:0xdd7 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:42:09,677] INFO Got user-level KeeperException when processing sessionid:0x1000aa69a040000 type:create cxid:0x7 zxid:0xdd8 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:42:09,677] INFO Got user-level KeeperException when processing sessionid:0x1000aa69a040000 type:create cxid:0x8 zxid:0xdd9 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:42:09,677] INFO Got user-level KeeperException when processing sessionid:0x1000aa69a040000 type:create cxid:0x9 zxid:0xdda txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:42:09,677] INFO Got user-level KeeperException when processing sessionid:0x1000aa69a040000 type:create cxid:0xa zxid:0xddb txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:42:09,677] INFO Got user-level KeeperException when processing sessionid:0x1000aa69a040000 type:create cxid:0xb zxid:0xddc txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:42:09,693] INFO Got user-level KeeperException when processing sessionid:0x1000aa69a040000 type:create cxid:0xc zxid:0xddd txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:42:09,693] INFO Got user-level KeeperException when processing sessionid:0x1000aa69a040000 type:create cxid:0xd zxid:0xdde txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:42:09,865] INFO Cluster ID = RvEiz9fYQgKWcHR6fHb3dg (kafka.server.KafkaServer)
[2019-01-26 19:42:09,958] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-26 19:42:09,974] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-26 19:42:10,021] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-26 19:42:10,021] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-26 19:42:10,021] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-26 19:42:10,099] INFO Loading logs. (kafka.log.LogManager)
[2019-01-26 19:42:10,177] INFO [Log partition=aggregateddata-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:10,177] INFO [Log partition=aggregateddata-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,224] INFO [Log partition=aggregateddata-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,224] INFO [Log partition=aggregateddata-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 78 ms (kafka.log.Log)
[2019-01-26 19:42:10,240] WARN [Log partition=aggregateddata-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\aggregateddata-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\aggregateddata-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548412109187}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:42:10,240] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,255] INFO [ProducerStateManager partition=aggregateddata-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:10,255] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:10,255] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,271] INFO [ProducerStateManager partition=aggregateddata-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:10,287] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,302] INFO [ProducerStateManager partition=aggregateddata-1] Loading producer state from snapshot file 'C:\tmp\logs3\aggregateddata-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:10,318] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 78 ms (kafka.log.Log)
[2019-01-26 19:42:10,318] INFO [Log partition=aggregated_data-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:10,318] INFO [Log partition=aggregated_data-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,333] INFO [Log partition=aggregated_data-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,333] INFO [Log partition=aggregated_data-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:42:10,333] INFO [Log partition=aggregated_data-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:10,349] INFO [Log partition=aggregated_data-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,349] INFO [Log partition=aggregated_data-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,349] INFO [Log partition=aggregated_data-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:42:10,365] WARN [Log partition=alltools-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\alltools-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\alltools-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547979859855}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:42:10,365] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,380] INFO [ProducerStateManager partition=alltools-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:10,380] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:10,380] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,396] INFO [ProducerStateManager partition=alltools-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:10,412] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,412] INFO [ProducerStateManager partition=alltools-1] Loading producer state from snapshot file 'C:\tmp\logs3\alltools-1\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:10,412] INFO [Log partition=alltools-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 47 ms (kafka.log.Log)
[2019-01-26 19:42:10,427] WARN [Log partition=alltools-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\alltools-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\alltools-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547977368170}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:42:10,427] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,427] INFO [ProducerStateManager partition=alltools-2] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:10,443] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:10,443] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,443] INFO [ProducerStateManager partition=alltools-2] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:10,458] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,458] INFO [ProducerStateManager partition=alltools-2] Loading producer state from snapshot file 'C:\tmp\logs3\alltools-2\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:10,458] INFO [Log partition=alltools-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 31 ms (kafka.log.Log)
[2019-01-26 19:42:10,474] WARN [Log partition=edited-0, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\edited-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\edited-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996878625}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:42:10,474] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,490] INFO [ProducerStateManager partition=edited-0] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:10,490] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:10,490] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,505] INFO [ProducerStateManager partition=edited-0] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:10,505] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,505] INFO [ProducerStateManager partition=edited-0] Loading producer state from snapshot file 'C:\tmp\logs3\edited-0\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:10,505] INFO [Log partition=edited-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 31 ms (kafka.log.Log)
[2019-01-26 19:42:10,521] WARN [Log partition=edited-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\edited-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\edited-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996875547}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:42:10,521] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,521] INFO [ProducerStateManager partition=edited-2] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:10,537] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:10,537] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,552] INFO [ProducerStateManager partition=edited-2] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:10,552] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,552] INFO [ProducerStateManager partition=edited-2] Loading producer state from snapshot file 'C:\tmp\logs3\edited-2\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:10,568] INFO [Log partition=edited-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 8 in 47 ms (kafka.log.Log)
[2019-01-26 19:42:10,568] INFO [Log partition=edited10-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:10,568] INFO [Log partition=edited10-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,583] INFO [Log partition=edited10-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,583] INFO [Log partition=edited10-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:42:10,599] INFO [Log partition=edited10-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:10,599] INFO [Log partition=edited10-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,615] INFO [Log partition=edited10-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,615] INFO [Log partition=edited10-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:42:10,615] INFO [Log partition=edited11-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:10,630] INFO [Log partition=edited11-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,630] INFO [Log partition=edited11-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,646] INFO [Log partition=edited11-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-26 19:42:10,646] WARN [Log partition=edited12-0, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\edited12-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\edited12-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548410940127}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:42:10,646] INFO [Log partition=edited12-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,661] INFO [ProducerStateManager partition=edited12-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:10,661] INFO [Log partition=edited12-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:10,677] INFO [Log partition=edited12-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,677] INFO [ProducerStateManager partition=edited12-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:10,693] INFO [Log partition=edited12-0, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,693] INFO [ProducerStateManager partition=edited12-0] Loading producer state from snapshot file 'C:\tmp\logs3\edited12-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:10,708] INFO [Log partition=edited12-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 62 ms (kafka.log.Log)
[2019-01-26 19:42:10,708] INFO [Log partition=edited12-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:10,708] INFO [Log partition=edited12-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,724] INFO [Log partition=edited12-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,724] INFO [Log partition=edited12-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:42:10,724] INFO [Log partition=edited13-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:10,724] INFO [Log partition=edited13-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,740] INFO [Log partition=edited13-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,740] INFO [Log partition=edited13-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:42:10,740] WARN [Log partition=edited13-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\edited13-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\edited13-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548414680482}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:42:10,740] INFO [Log partition=edited13-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,755] INFO [ProducerStateManager partition=edited13-2] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:10,755] INFO [Log partition=edited13-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:10,755] INFO [Log partition=edited13-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,771] INFO [ProducerStateManager partition=edited13-2] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:10,786] INFO [Log partition=edited13-2, dir=C:\tmp\logs3] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,786] INFO [ProducerStateManager partition=edited13-2] Loading producer state from snapshot file 'C:\tmp\logs3\edited13-2\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:10,786] INFO [Log partition=edited13-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 46 ms (kafka.log.Log)
[2019-01-26 19:42:10,802] WARN [Log partition=edited6-0, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\edited6-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\edited6-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548158302054}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:42:10,802] INFO [Log partition=edited6-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,818] INFO [ProducerStateManager partition=edited6-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:10,818] INFO [Log partition=edited6-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:10,818] INFO [Log partition=edited6-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,833] INFO [ProducerStateManager partition=edited6-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:10,833] INFO [Log partition=edited6-0, dir=C:\tmp\logs3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,833] INFO [ProducerStateManager partition=edited6-0] Loading producer state from snapshot file 'C:\tmp\logs3\edited6-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:10,849] INFO [Log partition=edited6-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 47 ms (kafka.log.Log)
[2019-01-26 19:42:10,849] WARN [Log partition=edited6-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\edited6-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\edited6-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548176773646}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:42:10,849] INFO [Log partition=edited6-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,865] INFO [ProducerStateManager partition=edited6-2] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:10,865] INFO [Log partition=edited6-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:10,865] INFO [Log partition=edited6-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,880] INFO [ProducerStateManager partition=edited6-2] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:10,880] INFO [Log partition=edited6-2, dir=C:\tmp\logs3] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,880] INFO [ProducerStateManager partition=edited6-2] Loading producer state from snapshot file 'C:\tmp\logs3\edited6-2\00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:10,896] INFO [Log partition=edited6-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 47 ms (kafka.log.Log)
[2019-01-26 19:42:10,896] WARN [Log partition=edited8-0, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\edited8-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\edited8-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548341369651}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:42:10,896] INFO [Log partition=edited8-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,911] INFO [ProducerStateManager partition=edited8-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:10,911] INFO [Log partition=edited8-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:10,911] INFO [Log partition=edited8-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,927] INFO [ProducerStateManager partition=edited8-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:10,927] INFO [Log partition=edited8-0, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,927] INFO [ProducerStateManager partition=edited8-0] Loading producer state from snapshot file 'C:\tmp\logs3\edited8-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:10,943] INFO [Log partition=edited8-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 47 ms (kafka.log.Log)
[2019-01-26 19:42:10,943] INFO [Log partition=edited8-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:10,943] INFO [Log partition=edited8-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,958] INFO [Log partition=edited8-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,958] INFO [Log partition=edited8-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:42:10,974] INFO [Log partition=edited9-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:10,974] INFO [Log partition=edited9-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,974] INFO [Log partition=edited9-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:10,990] INFO [Log partition=edited9-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:42:10,990] INFO [Log partition=mytools-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:10,990] INFO [Log partition=mytools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,005] INFO [Log partition=mytools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,005] INFO [Log partition=mytools-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:42:11,005] INFO [Log partition=mytools-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:11,005] INFO [Log partition=mytools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,021] INFO [Log partition=mytools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,021] INFO [Log partition=mytools-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:42:11,021] WARN [Log partition=pairing-stream-app-pairs-store-changelog-0, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\pairing-stream-app-pairs-store-changelog-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\pairing-stream-app-pairs-store-changelog-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548429187726}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:42:11,021] INFO [Log partition=pairing-stream-app-pairs-store-changelog-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,036] INFO [ProducerStateManager partition=pairing-stream-app-pairs-store-changelog-0] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,036] INFO [Log partition=pairing-stream-app-pairs-store-changelog-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:11,036] INFO [Log partition=pairing-stream-app-pairs-store-changelog-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,052] INFO [ProducerStateManager partition=pairing-stream-app-pairs-store-changelog-0] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,052] INFO [Log partition=pairing-stream-app-pairs-store-changelog-0, dir=C:\tmp\logs3] Loading producer state till offset 11 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,052] INFO [ProducerStateManager partition=pairing-stream-app-pairs-store-changelog-0] Loading producer state from snapshot file 'C:\tmp\logs3\pairing-stream-app-pairs-store-changelog-0\00000000000000000011.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,052] INFO [Log partition=pairing-stream-app-pairs-store-changelog-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 11 in 31 ms (kafka.log.Log)
[2019-01-26 19:42:11,068] WARN [Log partition=pairs-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\pairs-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\pairs-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548429185722}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:42:11,068] INFO [Log partition=pairs-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,083] INFO [ProducerStateManager partition=pairs-1] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,083] INFO [Log partition=pairs-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:11,083] INFO [Log partition=pairs-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,083] INFO [ProducerStateManager partition=pairs-1] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,083] INFO [Log partition=pairs-1, dir=C:\tmp\logs3] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,099] INFO [ProducerStateManager partition=pairs-1] Loading producer state from snapshot file 'C:\tmp\logs3\pairs-1\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,099] INFO [Log partition=pairs-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 31 ms (kafka.log.Log)
[2019-01-26 19:42:11,114] WARN [Log partition=pairs-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\pairs-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\pairs-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548429184720}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:42:11,114] INFO [Log partition=pairs-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,114] INFO [ProducerStateManager partition=pairs-2] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,130] INFO [Log partition=pairs-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:11,130] INFO [Log partition=pairs-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,130] INFO [ProducerStateManager partition=pairs-2] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,146] INFO [Log partition=pairs-2, dir=C:\tmp\logs3] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,146] INFO [ProducerStateManager partition=pairs-2] Loading producer state from snapshot file 'C:\tmp\logs3\pairs-2\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,146] INFO [Log partition=pairs-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 32 ms (kafka.log.Log)
[2019-01-26 19:42:11,161] WARN [Log partition=randommessages-0, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\randommessages-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\randommessages-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548429187724}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:42:11,161] INFO [Log partition=randommessages-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,161] INFO [ProducerStateManager partition=randommessages-0] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,177] INFO [Log partition=randommessages-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:11,177] INFO [Log partition=randommessages-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,177] INFO [ProducerStateManager partition=randommessages-0] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,193] INFO [Log partition=randommessages-0, dir=C:\tmp\logs3] Loading producer state till offset 11 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,193] INFO [ProducerStateManager partition=randommessages-0] Loading producer state from snapshot file 'C:\tmp\logs3\randommessages-0\00000000000000000011.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,193] INFO [Log partition=randommessages-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 11 in 32 ms (kafka.log.Log)
[2019-01-26 19:42:11,208] WARN [Log partition=randommessages-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\randommessages-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\randommessages-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548429186722}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:42:11,208] INFO [Log partition=randommessages-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,224] INFO [ProducerStateManager partition=randommessages-1] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,224] INFO [Log partition=randommessages-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:11,224] INFO [Log partition=randommessages-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,239] INFO [ProducerStateManager partition=randommessages-1] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,239] INFO [Log partition=randommessages-1, dir=C:\tmp\logs3] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,239] INFO [ProducerStateManager partition=randommessages-1] Loading producer state from snapshot file 'C:\tmp\logs3\randommessages-1\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,239] INFO [Log partition=randommessages-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 31 ms (kafka.log.Log)
[2019-01-26 19:42:11,255] INFO [Log partition=stack-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:11,255] INFO [Log partition=stack-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,255] INFO [Log partition=stack-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,271] INFO [Log partition=stack-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:42:11,271] INFO [Log partition=stack-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:11,271] INFO [Log partition=stack-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,286] INFO [Log partition=stack-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,286] INFO [Log partition=stack-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:42:11,302] INFO [Log partition=tools-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:11,302] INFO [Log partition=tools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,318] INFO [Log partition=tools-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,318] INFO [Log partition=tools-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-01-26 19:42:11,333] INFO [Log partition=tools-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:11,333] INFO [Log partition=tools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,349] INFO [Log partition=tools-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,349] INFO [Log partition=tools-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:42:11,349] INFO [Log partition=tools1-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:11,349] INFO [Log partition=tools1-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,364] INFO [Log partition=tools1-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,364] INFO [Log partition=tools1-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:42:11,380] INFO [Log partition=tools1-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:11,380] INFO [Log partition=tools1-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,380] INFO [Log partition=tools1-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,396] INFO [Log partition=tools1-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:42:11,396] WARN [Log partition=tools10-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools10-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools10-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548410034606}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:42:11,396] INFO [Log partition=tools10-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,411] INFO [ProducerStateManager partition=tools10-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,411] INFO [Log partition=tools10-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:11,411] INFO [Log partition=tools10-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,427] INFO [ProducerStateManager partition=tools10-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,427] INFO [Log partition=tools10-1, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,427] INFO [ProducerStateManager partition=tools10-1] Loading producer state from snapshot file 'C:\tmp\logs3\tools10-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,443] INFO [Log partition=tools10-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 47 ms (kafka.log.Log)
[2019-01-26 19:42:11,443] INFO [Log partition=tools10-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:11,443] INFO [Log partition=tools10-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,458] INFO [Log partition=tools10-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,458] INFO [Log partition=tools10-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:42:11,474] INFO [Log partition=tools11-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:11,474] INFO [Log partition=tools11-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,474] INFO [Log partition=tools11-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,474] INFO [Log partition=tools11-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:42:11,489] INFO [Log partition=tools11-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:11,489] INFO [Log partition=tools11-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,489] INFO [Log partition=tools11-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,505] INFO [Log partition=tools11-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:42:11,505] INFO [Log partition=tools12-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:11,505] INFO [Log partition=tools12-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,521] INFO [Log partition=tools12-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,521] INFO [Log partition=tools12-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:42:11,521] INFO [Log partition=tools12-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:11,521] INFO [Log partition=tools12-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,536] INFO [Log partition=tools12-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,536] INFO [Log partition=tools12-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:42:11,552] WARN [Log partition=tools13-0, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools13-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools13-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548414842572}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:42:11,552] INFO [Log partition=tools13-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,567] INFO [ProducerStateManager partition=tools13-0] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,567] INFO [Log partition=tools13-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:11,567] INFO [Log partition=tools13-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,583] INFO [ProducerStateManager partition=tools13-0] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,583] INFO [Log partition=tools13-0, dir=C:\tmp\logs3] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,583] INFO [ProducerStateManager partition=tools13-0] Loading producer state from snapshot file 'C:\tmp\logs3\tools13-0\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,599] INFO [Log partition=tools13-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 63 ms (kafka.log.Log)
[2019-01-26 19:42:11,599] WARN [Log partition=tools13-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools13-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools13-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548414647242}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:42:11,599] INFO [Log partition=tools13-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,614] INFO [ProducerStateManager partition=tools13-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,614] INFO [Log partition=tools13-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:11,614] INFO [Log partition=tools13-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,630] INFO [ProducerStateManager partition=tools13-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,630] INFO [Log partition=tools13-2, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,630] INFO [ProducerStateManager partition=tools13-2] Loading producer state from snapshot file 'C:\tmp\logs3\tools13-2\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,646] INFO [Log partition=tools13-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 47 ms (kafka.log.Log)
[2019-01-26 19:42:11,646] INFO [Log partition=tools14-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:11,646] INFO [Log partition=tools14-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,661] INFO [Log partition=tools14-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,661] INFO [Log partition=tools14-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:42:11,677] INFO [Log partition=tools14-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:11,677] INFO [Log partition=tools14-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,677] INFO [Log partition=tools14-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,692] INFO [Log partition=tools14-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:42:11,692] WARN [Log partition=tools2-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools2-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools2-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547992951029}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:42:11,692] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,708] INFO [ProducerStateManager partition=tools2-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,708] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:11,708] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,724] INFO [ProducerStateManager partition=tools2-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,724] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,724] INFO [ProducerStateManager partition=tools2-1] Loading producer state from snapshot file 'C:\tmp\logs3\tools2-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,724] INFO [Log partition=tools2-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 32 ms (kafka.log.Log)
[2019-01-26 19:42:11,739] INFO [Log partition=tools2-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:11,739] INFO [Log partition=tools2-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,739] INFO [Log partition=tools2-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,739] INFO [Log partition=tools2-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:42:11,755] WARN [Log partition=tools3-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools3-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools3-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547993388462}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:42:11,755] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,755] INFO [ProducerStateManager partition=tools3-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,771] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:11,771] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,771] INFO [ProducerStateManager partition=tools3-1] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,786] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,786] INFO [ProducerStateManager partition=tools3-1] Loading producer state from snapshot file 'C:\tmp\logs3\tools3-1\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,786] INFO [Log partition=tools3-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 31 ms (kafka.log.Log)
[2019-01-26 19:42:11,802] INFO [Log partition=tools3-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:11,802] INFO [Log partition=tools3-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,817] INFO [Log partition=tools3-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,817] INFO [Log partition=tools3-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:42:11,817] INFO [Log partition=tools4-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:11,817] INFO [Log partition=tools4-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,833] INFO [Log partition=tools4-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,833] INFO [Log partition=tools4-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:42:11,849] WARN [Log partition=tools4-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools4-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools4-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547993897061}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:42:11,849] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,864] INFO [ProducerStateManager partition=tools4-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,864] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:11,864] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,880] INFO [ProducerStateManager partition=tools4-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,880] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,896] INFO [ProducerStateManager partition=tools4-2] Loading producer state from snapshot file 'C:\tmp\logs3\tools4-2\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,896] INFO [Log partition=tools4-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 47 ms (kafka.log.Log)
[2019-01-26 19:42:11,896] WARN [Log partition=tools5-0, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools5-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools5-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996871342}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:42:11,896] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,911] INFO [ProducerStateManager partition=tools5-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,911] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:11,911] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,927] INFO [ProducerStateManager partition=tools5-0] Writing producer snapshot at offset 10 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,927] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Loading producer state till offset 10 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,927] INFO [ProducerStateManager partition=tools5-0] Loading producer state from snapshot file 'C:\tmp\logs3\tools5-0\00000000000000000010.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,942] INFO [Log partition=tools5-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 10 in 46 ms (kafka.log.Log)
[2019-01-26 19:42:11,942] WARN [Log partition=tools5-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools5-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools5-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547996876577}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:42:11,942] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,958] INFO [ProducerStateManager partition=tools5-1] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,958] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:11,958] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,974] INFO [ProducerStateManager partition=tools5-1] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,974] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,974] INFO [ProducerStateManager partition=tools5-1] Loading producer state from snapshot file 'C:\tmp\logs3\tools5-1\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:11,974] INFO [Log partition=tools5-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 32 ms (kafka.log.Log)
[2019-01-26 19:42:11,989] WARN [Log partition=tools6-1, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools6-1\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools6-1\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548321919981}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:42:11,989] INFO [Log partition=tools6-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:11,989] INFO [ProducerStateManager partition=tools6-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,005] INFO [Log partition=tools6-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:12,005] INFO [Log partition=tools6-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,021] INFO [ProducerStateManager partition=tools6-1] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,021] INFO [Log partition=tools6-1, dir=C:\tmp\logs3] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,021] INFO [ProducerStateManager partition=tools6-1] Loading producer state from snapshot file 'C:\tmp\logs3\tools6-1\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,036] INFO [Log partition=tools6-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 47 ms (kafka.log.Log)
[2019-01-26 19:42:12,052] WARN [Log partition=tools6-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools6-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools6-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548158302054}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:42:12,052] INFO [Log partition=tools6-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,067] INFO [ProducerStateManager partition=tools6-2] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,067] INFO [Log partition=tools6-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:12,067] INFO [Log partition=tools6-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,083] INFO [ProducerStateManager partition=tools6-2] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,083] INFO [Log partition=tools6-2, dir=C:\tmp\logs3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,099] INFO [ProducerStateManager partition=tools6-2] Loading producer state from snapshot file 'C:\tmp\logs3\tools6-2\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,099] INFO [Log partition=tools6-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 63 ms (kafka.log.Log)
[2019-01-26 19:42:12,099] INFO [Log partition=tools7-1, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:12,099] INFO [Log partition=tools7-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,114] INFO [Log partition=tools7-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,114] INFO [Log partition=tools7-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:42:12,114] WARN [Log partition=tools7-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\tools7-2\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\tools7-2\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548156023437}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:42:12,130] INFO [Log partition=tools7-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,130] INFO [ProducerStateManager partition=tools7-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,130] INFO [Log partition=tools7-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:12,130] INFO [Log partition=tools7-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,145] INFO [ProducerStateManager partition=tools7-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,145] INFO [Log partition=tools7-2, dir=C:\tmp\logs3] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,145] INFO [ProducerStateManager partition=tools7-2] Loading producer state from snapshot file 'C:\tmp\logs3\tools7-2\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,161] INFO [Log partition=tools7-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 47 ms (kafka.log.Log)
[2019-01-26 19:42:12,161] INFO [Log partition=tools8-0, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:12,161] INFO [Log partition=tools8-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,177] INFO [Log partition=tools8-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,177] INFO [Log partition=tools8-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:42:12,177] INFO [Log partition=tools8-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:12,192] INFO [Log partition=tools8-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,192] INFO [Log partition=tools8-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,192] INFO [Log partition=tools8-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:42:12,208] WARN [Log partition=__consumer_offsets-11, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\__consumer_offsets-11\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\__consumer_offsets-11\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548451671096}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:42:12,208] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,224] INFO [ProducerStateManager partition=__consumer_offsets-11] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,224] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:12,224] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,239] INFO [ProducerStateManager partition=__consumer_offsets-11] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,239] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs3] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,239] INFO [ProducerStateManager partition=__consumer_offsets-11] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-11\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,239] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 9 in 31 ms (kafka.log.Log)
[2019-01-26 19:42:12,255] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:12,255] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,270] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,270] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:42:12,270] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:12,270] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,286] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,286] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:42:12,302] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Found file C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.index.swap from interrupted swap operation. (kafka.log.Log)
[2019-01-26 19:42:12,302] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Deleting index files with suffix  for baseFile C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.index (kafka.log.Log)
[2019-01-26 19:42:12,302] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Found file C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.log.swap from interrupted swap operation. (kafka.log.Log)
[2019-01-26 19:42:12,302] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Deleting index files with suffix  for baseFile C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.log (kafka.log.Log)
[2019-01-26 19:42:12,317] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Deleting index files with suffix .swap for baseFile C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.log (kafka.log.Log)
[2019-01-26 19:42:12,317] WARN [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\__consumer_offsets-2\00000000000000000162.log due to Corrupt time index found, time index file (C:\tmp\logs3\__consumer_offsets-2\00000000000000000162.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548451758096}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:42:12,317] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Loading producer state till offset 162 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,333] INFO [ProducerStateManager partition=__consumer_offsets-2] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-2\00000000000000000162.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,333] INFO [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 163 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,333] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:12,333] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,349] INFO [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 162 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,349] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Recovering unflushed segment 162 (kafka.log.Log)
[2019-01-26 19:42:12,349] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Loading producer state till offset 162 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,364] INFO [ProducerStateManager partition=__consumer_offsets-2] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-2\00000000000000000162.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,364] INFO [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 163 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,364] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Loading producer state till offset 163 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,380] INFO [ProducerStateManager partition=__consumer_offsets-2] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-2\00000000000000000163.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,380] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs3] Completed load of log with 2 segments, log start offset 0 and log end offset 163 in 94 ms (kafka.log.Log)
[2019-01-26 19:42:12,380] WARN [Log partition=__consumer_offsets-20, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\__consumer_offsets-20\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\__consumer_offsets-20\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548412607771}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:42:12,380] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,395] INFO [ProducerStateManager partition=__consumer_offsets-20] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,395] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:12,395] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,411] INFO [ProducerStateManager partition=__consumer_offsets-20] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,411] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\logs3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,411] INFO [ProducerStateManager partition=__consumer_offsets-20] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-20\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,411] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 31 ms (kafka.log.Log)
[2019-01-26 19:42:12,427] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:12,427] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,442] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,442] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:42:12,442] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:12,442] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,458] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,458] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:42:12,458] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:12,458] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,474] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,474] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:42:12,489] WARN [Log partition=__consumer_offsets-32, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\__consumer_offsets-32\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\__consumer_offsets-32\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548408890599}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:42:12,489] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,489] INFO [ProducerStateManager partition=__consumer_offsets-32] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,505] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:12,505] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,505] INFO [ProducerStateManager partition=__consumer_offsets-32] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,520] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\logs3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,520] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-32\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,520] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 46 ms (kafka.log.Log)
[2019-01-26 19:42:12,536] WARN [Log partition=__consumer_offsets-35, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\__consumer_offsets-35\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\__consumer_offsets-35\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548327517176}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:42:12,536] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,552] INFO [ProducerStateManager partition=__consumer_offsets-35] Writing producer snapshot at offset 76 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,552] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:12,552] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,552] INFO [ProducerStateManager partition=__consumer_offsets-35] Writing producer snapshot at offset 76 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,567] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs3] Loading producer state till offset 76 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,567] INFO [ProducerStateManager partition=__consumer_offsets-35] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-35\00000000000000000076.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,567] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 76 in 47 ms (kafka.log.Log)
[2019-01-26 19:42:12,583] WARN [Log partition=__consumer_offsets-38, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\__consumer_offsets-38\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\__consumer_offsets-38\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548429189415}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:42:12,583] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,583] INFO [ProducerStateManager partition=__consumer_offsets-38] Writing producer snapshot at offset 20 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,599] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:12,599] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,599] INFO [ProducerStateManager partition=__consumer_offsets-38] Writing producer snapshot at offset 20 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,614] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\logs3] Loading producer state till offset 20 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,614] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-38\00000000000000000020.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,614] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 20 in 31 ms (kafka.log.Log)
[2019-01-26 19:42:12,630] WARN [Log partition=__consumer_offsets-41, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\__consumer_offsets-41\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\__consumer_offsets-41\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548427007773}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:42:12,630] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,645] INFO [ProducerStateManager partition=__consumer_offsets-41] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,645] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:12,645] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,661] INFO [ProducerStateManager partition=__consumer_offsets-41] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,677] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\logs3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,677] INFO [ProducerStateManager partition=__consumer_offsets-41] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-41\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,692] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 62 ms (kafka.log.Log)
[2019-01-26 19:42:12,708] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:12,708] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,723] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,723] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-26 19:42:12,723] WARN [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\__consumer_offsets-47\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\__consumer_offsets-47\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1547992512270}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:42:12,723] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,739] INFO [ProducerStateManager partition=__consumer_offsets-47] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,739] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:12,739] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,755] INFO [ProducerStateManager partition=__consumer_offsets-47] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,755] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,770] INFO [ProducerStateManager partition=__consumer_offsets-47] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-47\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,770] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 47 ms (kafka.log.Log)
[2019-01-26 19:42:12,770] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:12,770] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,786] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,786] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:42:12,802] WARN [Log partition=__consumer_offsets-8, dir=C:\tmp\logs3] Found a corrupted index file corresponding to log file C:\tmp\logs3\__consumer_offsets-8\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\logs3\__consumer_offsets-8\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1548411290598}, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-01-26 19:42:12,802] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,802] INFO [ProducerStateManager partition=__consumer_offsets-8] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,802] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\logs3] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-26 19:42:12,802] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,817] INFO [ProducerStateManager partition=__consumer_offsets-8] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,833] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\logs3] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-26 19:42:12,833] INFO [ProducerStateManager partition=__consumer_offsets-8] Loading producer state from snapshot file 'C:\tmp\logs3\__consumer_offsets-8\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-26 19:42:12,833] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 31 ms (kafka.log.Log)
[2019-01-26 19:42:12,833] INFO Logs loading complete in 2734 ms. (kafka.log.LogManager)
[2019-01-26 19:42:12,848] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-26 19:42:12,864] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-26 19:42:13,083] ERROR Failed to clean up log for __consumer_offsets-2 in dir C:\tmp\logs3 due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex.cleaned -> C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex.swap: Impossibile accedere al file. Il file  utilizzato da un altro processo.

	at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsFileCopy.move(Unknown Source)
	at sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
	at java.nio.file.Files.move(Unknown Source)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:809)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:205)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:490)
	at kafka.log.Log.$anonfun$replaceSegments$4(Log.scala:1892)
	at kafka.log.Log.$anonfun$replaceSegments$4$adapted(Log.scala:1892)
	at scala.collection.immutable.List.foreach(List.scala:388)
	at kafka.log.Log.replaceSegments(Log.scala:1892)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:583)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:515)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:514)
	at scala.collection.immutable.List.foreach(List.scala:388)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:514)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:353)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
	Suppressed: java.nio.file.FileSystemException: C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex.cleaned -> C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex.swap: Impossibile accedere al file. Il file  utilizzato da un altro processo.

		at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
		at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
		at sun.nio.fs.WindowsFileCopy.move(Unknown Source)
		at sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
		at java.nio.file.Files.move(Unknown Source)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:806)
		... 16 more
[2019-01-26 19:42:13,161] ERROR Failed to clean up log for __consumer_offsets-2 in dir C:\tmp\logs3 due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex.cleaned: Impossibile accedere al file. Il file  utilizzato da un altro processo.

	at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(Unknown Source)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(Unknown Source)
	at java.nio.file.Files.deleteIfExists(Unknown Source)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2150)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:645)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:424)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:540)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:515)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:514)
	at scala.collection.immutable.List.foreach(List.scala:388)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:514)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:353)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-26 19:42:13,192] INFO Awaiting socket connections on localhost:9095. (kafka.network.Acceptor)
[2019-01-26 19:42:13,208] ERROR Failed to clean up log for __consumer_offsets-2 in dir C:\tmp\logs3 due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex.cleaned: Impossibile accedere al file. Il file  utilizzato da un altro processo.

	at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(Unknown Source)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(Unknown Source)
	at java.nio.file.Files.deleteIfExists(Unknown Source)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2150)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:645)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:424)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:540)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:515)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:514)
	at scala.collection.immutable.List.foreach(List.scala:388)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:514)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:353)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-26 19:42:13,270] INFO [SocketServer brokerId=3] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-26 19:42:13,270] ERROR Failed to clean up log for __consumer_offsets-2 in dir C:\tmp\logs3 due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex.cleaned: Impossibile accedere al file. Il file  utilizzato da un altro processo.

	at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(Unknown Source)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(Unknown Source)
	at java.nio.file.Files.deleteIfExists(Unknown Source)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2150)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:645)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:424)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:540)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:515)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:514)
	at scala.collection.immutable.List.foreach(List.scala:388)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:514)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:353)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-26 19:42:13,317] ERROR Failed to clean up log for __consumer_offsets-2 in dir C:\tmp\logs3 due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex.cleaned: Impossibile accedere al file. Il file  utilizzato da un altro processo.

	at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(Unknown Source)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(Unknown Source)
	at java.nio.file.Files.deleteIfExists(Unknown Source)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2150)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:645)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:424)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:540)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:515)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:514)
	at scala.collection.immutable.List.foreach(List.scala:388)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:514)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:353)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-26 19:42:13,333] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:42:13,333] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:42:13,333] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:42:13,380] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-26 19:42:13,380] INFO [ReplicaManager broker=3] Stopping serving replicas in dir C:\tmp\logs3 (kafka.server.ReplicaManager)
[2019-01-26 19:42:13,380] ERROR Failed to clean up log for __consumer_offsets-2 in dir C:\tmp\logs3 due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\logs3\__consumer_offsets-2\00000000000000000000.timeindex.cleaned: Impossibile accedere al file. Il file  utilizzato da un altro processo.

	at sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(Unknown Source)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(Unknown Source)
	at java.nio.file.Files.deleteIfExists(Unknown Source)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2150)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:645)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:424)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:540)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:515)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:514)
	at scala.collection.immutable.List.foreach(List.scala:388)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:514)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:353)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-26 19:42:13,380] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:42:13,395] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-26 19:42:13,426] INFO [ReplicaManager broker=3] Broker 3 stopped fetcher for partitions  and stopped moving logs for partitions  because they are in the failed log directory C:\tmp\logs3. (kafka.server.ReplicaManager)
[2019-01-26 19:42:13,426] INFO Stopping serving logs in dir C:\tmp\logs3 (kafka.log.LogManager)
[2019-01-26 19:42:13,458] ERROR Shutdown broker because all log dirs in C:\tmp\logs3 have failed (kafka.log.LogManager)
[2019-01-26 19:42:13,942] WARN Exception causing close of session 0x1000aa69a040000: Connessione in corso interrotta forzatamente dall'host remoto (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-26 19:42:13,958] INFO Closed socket connection for client /127.0.0.1:62154 which had sessionid 0x1000aa69a040000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-26 19:42:19,865] INFO Expiring session 0x1000aa69a040000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:42:19,865] INFO Processed session termination for sessionid: 0x1000aa69a040000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:44:40,106] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-01-26 19:44:40,106] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-26 19:44:40,106] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-26 19:44:40,106] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-26 19:44:40,106] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-01-26 19:44:40,122] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-01-26 19:44:40,137] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-01-26 19:44:40,137] INFO Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:44:40,137] INFO Server environment:host.name=ITdif.mshome.net (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:44:40,137] INFO Server environment:java.version=1.8.0_181 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:44:40,137] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:44:40,137] INFO Server environment:java.home=C:\Program Files\Java\jre1.8.0_181 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:44:40,137] INFO Server environment:java.class.path=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-connect-jdbc-5.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\mysql-connector-java-5.1.42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:44:40,137] INFO Server environment:java.library.path=C:\Program Files\Java\jre1.8.0_181\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Docker\Docker\Resources\bin;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\Scripts\;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\dotnet\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\NoteBook FanControl\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\extras\CUPTI\libx64;C:\tools\cuda\bin;C:\Program Files\PuTTY\;C:\Program Files\Calibre2\;C:\apache-maven-3.6.\bin;C:\Users\Stefano\Downloads\platform-tools_r28.0.1-windows\platform-tools;C:\Program Files\Java\jre1.8.0_181\bin;C:\Users\Stefano\AppData\Local\Programs\Python\Launcher\;C:\Users\Stefano\AppData\Local\Microsoft\WindowsApps;C:\Users\Stefano\AppData\Local\GitHubDesktop\bin;C:\apache-maven-3.6.0\bin;;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:44:40,137] INFO Server environment:java.io.tmpdir=C:\Users\Stefano\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:44:40,137] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:44:40,137] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:44:40,137] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:44:40,137] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:44:40,137] INFO Server environment:user.name=Stefano (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:44:40,153] INFO Server environment:user.home=C:\Users\Stefano (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:44:40,153] INFO Server environment:user.dir=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:44:40,169] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:44:40,169] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:44:40,169] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:44:40,184] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-01-26 19:44:40,184] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-26 19:44:58,042] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-26 19:44:58,699] INFO starting (kafka.server.KafkaServer)
[2019-01-26 19:44:58,699] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-26 19:44:58,714] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-26 19:44:58,714] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:44:58,714] INFO Client environment:host.name=ITdif.mshome.net (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:44:58,714] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:44:58,730] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:44:58,730] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:44:58,730] INFO Client environment:java.class.path=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-connect-jdbc-5.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\mysql-connector-java-5.1.42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:44:58,730] INFO Client environment:java.library.path=C:\Program Files\Java\jre1.8.0_181\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Docker\Docker\Resources\bin;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\Scripts\;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\dotnet\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\NoteBook FanControl\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\extras\CUPTI\libx64;C:\tools\cuda\bin;C:\Program Files\PuTTY\;C:\Program Files\Calibre2\;C:\apache-maven-3.6.\bin;C:\Users\Stefano\Downloads\platform-tools_r28.0.1-windows\platform-tools;C:\Program Files\Java\jre1.8.0_181\bin;C:\Users\Stefano\AppData\Local\Programs\Python\Launcher\;C:\Users\Stefano\AppData\Local\Microsoft\WindowsApps;C:\Users\Stefano\AppData\Local\GitHubDesktop\bin;C:\apache-maven-3.6.0\bin;;. (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:44:58,730] INFO Client environment:java.io.tmpdir=C:\Users\Stefano\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:44:58,730] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:44:58,730] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:44:58,730] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:44:58,730] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:44:58,730] INFO Client environment:user.name=Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:44:58,730] INFO Client environment:user.home=C:\Users\Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:44:58,730] INFO Client environment:user.dir=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:44:58,730] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@1622f1b (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:44:58,745] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-26 19:44:58,745] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-26 19:44:58,745] INFO Accepted socket connection from /127.0.0.1:62177 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-26 19:44:58,745] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-26 19:44:58,761] INFO Client attempting to establish new session at /127.0.0.1:62177 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:44:58,761] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-01-26 19:44:58,777] INFO Established session 0x1000aa9390f0000 with negotiated timeout 6000 for client /127.0.0.1:62177 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:44:58,777] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000aa9390f0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-26 19:44:58,792] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-26 19:44:58,870] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0000 type:create cxid:0x2 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:44:58,886] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0000 type:create cxid:0x6 zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:44:58,902] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0000 type:create cxid:0x9 zxid:0xa txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:44:59,120] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0000 type:create cxid:0x15 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:44:59,136] INFO Cluster ID = 5GfY6w8PQ1yVBYvzG2VTdQ (kafka.server.KafkaServer)
[2019-01-26 19:44:59,152] WARN No meta.properties file under dir C:\tmp\logs1\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-01-26 19:44:59,230] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-26 19:44:59,245] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-26 19:44:59,277] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-26 19:44:59,277] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-26 19:44:59,292] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-26 19:44:59,323] INFO Loading logs. (kafka.log.LogManager)
[2019-01-26 19:44:59,339] INFO Logs loading complete in 16 ms. (kafka.log.LogManager)
[2019-01-26 19:44:59,355] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-26 19:44:59,355] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-26 19:44:59,714] INFO Awaiting socket connections on localhost:9093. (kafka.network.Acceptor)
[2019-01-26 19:44:59,745] INFO [SocketServer brokerId=1] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-26 19:44:59,776] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:44:59,776] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:44:59,776] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:44:59,792] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-26 19:44:59,823] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-26 19:44:59,823] INFO Result of znode creation at /brokers/ids/1 is: OK (kafka.zk.KafkaZkClient)
[2019-01-26 19:44:59,823] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(localhost,9093,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-26 19:44:59,839] WARN No meta.properties file under dir C:\tmp\logs1\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-01-26 19:44:59,901] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:44:59,901] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:44:59,917] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2019-01-26 19:44:59,917] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:44:59,948] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 19:44:59,948] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 19:44:59,979] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 15 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:44:59,995] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-26 19:45:00,026] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-26 19:45:00,026] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-26 19:45:00,042] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-26 19:45:00,104] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0000 type:multi cxid:0x30 zxid:0x1c txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:45:00,104] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-26 19:45:00,120] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0000 type:multi cxid:0x37 zxid:0x1d txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:45:00,120] INFO [SocketServer brokerId=1] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-26 19:45:00,136] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-26 19:45:00,136] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-26 19:45:00,136] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2019-01-26 19:45:14,883] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-26 19:45:15,523] INFO starting (kafka.server.KafkaServer)
[2019-01-26 19:45:15,523] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-26 19:45:15,555] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-26 19:45:15,555] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:45:15,555] INFO Client environment:host.name=ITdif.mshome.net (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:45:15,555] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:45:15,555] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:45:15,555] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:45:15,555] INFO Client environment:java.class.path=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-connect-jdbc-5.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\mysql-connector-java-5.1.42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:45:15,570] INFO Client environment:java.library.path=C:\Program Files\Java\jre1.8.0_181\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Docker\Docker\Resources\bin;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\Scripts\;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\dotnet\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\NoteBook FanControl\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\extras\CUPTI\libx64;C:\tools\cuda\bin;C:\Program Files\PuTTY\;C:\Program Files\Calibre2\;C:\apache-maven-3.6.\bin;C:\Users\Stefano\Downloads\platform-tools_r28.0.1-windows\platform-tools;C:\Program Files\Java\jre1.8.0_181\bin;C:\Users\Stefano\AppData\Local\Programs\Python\Launcher\;C:\Users\Stefano\AppData\Local\Microsoft\WindowsApps;C:\Users\Stefano\AppData\Local\GitHubDesktop\bin;C:\apache-maven-3.6.0\bin;;. (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:45:15,570] INFO Client environment:java.io.tmpdir=C:\Users\Stefano\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:45:15,570] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:45:15,570] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:45:15,570] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:45:15,570] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:45:15,570] INFO Client environment:user.name=Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:45:15,570] INFO Client environment:user.home=C:\Users\Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:45:15,570] INFO Client environment:user.dir=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:45:15,570] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@1622f1b (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:45:15,601] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-26 19:45:15,601] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-26 19:45:15,601] INFO Accepted socket connection from /127.0.0.1:62194 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-26 19:45:15,601] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-26 19:45:15,617] INFO Client attempting to establish new session at /127.0.0.1:62194 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:45:15,633] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000aa9390f0001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-26 19:45:15,633] INFO Established session 0x1000aa9390f0001 with negotiated timeout 6000 for client /127.0.0.1:62194 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:45:15,633] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-26 19:45:15,695] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0001 type:create cxid:0x1 zxid:0x1f txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:45:15,711] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0001 type:create cxid:0x2 zxid:0x20 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:45:15,711] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0001 type:create cxid:0x3 zxid:0x21 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:45:15,726] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0001 type:create cxid:0x4 zxid:0x22 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:45:15,726] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0001 type:create cxid:0x5 zxid:0x23 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:45:15,726] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0001 type:create cxid:0x6 zxid:0x24 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:45:15,742] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0001 type:create cxid:0x7 zxid:0x25 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:45:15,742] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0001 type:create cxid:0x8 zxid:0x26 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:45:15,742] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0001 type:create cxid:0x9 zxid:0x27 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:45:15,758] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0001 type:create cxid:0xa zxid:0x28 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:45:15,758] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0001 type:create cxid:0xb zxid:0x29 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:45:15,773] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0001 type:create cxid:0xc zxid:0x2a txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:45:15,773] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0001 type:create cxid:0xd zxid:0x2b txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:45:15,961] INFO Cluster ID = 5GfY6w8PQ1yVBYvzG2VTdQ (kafka.server.KafkaServer)
[2019-01-26 19:45:15,961] WARN No meta.properties file under dir C:\tmp\logs2\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-01-26 19:45:16,054] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-26 19:45:16,070] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-26 19:45:16,101] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-26 19:45:16,101] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-26 19:45:16,117] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-26 19:45:16,148] INFO Loading logs. (kafka.log.LogManager)
[2019-01-26 19:45:16,164] INFO Logs loading complete in 16 ms. (kafka.log.LogManager)
[2019-01-26 19:45:16,179] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-26 19:45:16,179] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-26 19:45:16,523] INFO Awaiting socket connections on localhost:9094. (kafka.network.Acceptor)
[2019-01-26 19:45:16,570] INFO [SocketServer brokerId=2] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-26 19:45:16,601] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:45:16,601] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:45:16,601] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:45:16,617] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-26 19:45:16,679] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-26 19:45:16,695] INFO Result of znode creation at /brokers/ids/2 is: OK (kafka.zk.KafkaZkClient)
[2019-01-26 19:45:16,695] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(localhost,9094,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-26 19:45:16,695] WARN No meta.properties file under dir C:\tmp\logs2\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-01-26 19:45:16,757] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:45:16,773] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:45:16,773] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:45:16,789] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 19:45:16,804] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 19:45:16,804] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:45:16,820] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-26 19:45:16,851] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-26 19:45:16,851] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-26 19:45:16,851] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-26 19:45:16,898] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-26 19:45:16,914] INFO [SocketServer brokerId=2] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-26 19:45:16,929] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-26 19:45:16,929] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-26 19:45:16,929] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2019-01-26 19:45:34,937] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-26 19:45:35,593] INFO starting (kafka.server.KafkaServer)
[2019-01-26 19:45:35,593] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-26 19:45:35,625] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-26 19:45:35,625] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:45:35,625] INFO Client environment:host.name=ITdif.mshome.net (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:45:35,625] INFO Client environment:java.version=1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:45:35,625] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:45:35,625] INFO Client environment:java.home=C:\Program Files\Java\jre1.8.0_181 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:45:35,625] INFO Client environment:java.class.path=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-connect-jdbc-5.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\mysql-connector-java-5.1.42.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\Stefano\Desktop\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:45:35,625] INFO Client environment:java.library.path=C:\Program Files\Java\jre1.8.0_181\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\Docker\Docker\Resources\bin;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\Scripts\;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\dotnet\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\NoteBook FanControl\;C:\Program Files\TortoiseSVN\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\extras\CUPTI\libx64;C:\tools\cuda\bin;C:\Program Files\PuTTY\;C:\Program Files\Calibre2\;C:\apache-maven-3.6.\bin;C:\Users\Stefano\Downloads\platform-tools_r28.0.1-windows\platform-tools;C:\Program Files\Java\jre1.8.0_181\bin;C:\Users\Stefano\AppData\Local\Programs\Python\Launcher\;C:\Users\Stefano\AppData\Local\Microsoft\WindowsApps;C:\Users\Stefano\AppData\Local\GitHubDesktop\bin;C:\apache-maven-3.6.0\bin;;. (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:45:35,625] INFO Client environment:java.io.tmpdir=C:\Users\Stefano\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:45:35,625] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:45:35,625] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:45:35,640] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:45:35,640] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:45:35,640] INFO Client environment:user.name=Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:45:35,640] INFO Client environment:user.home=C:\Users\Stefano (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:45:35,640] INFO Client environment:user.dir=C:\Users\Stefano\Desktop\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:45:35,640] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@1622f1b (org.apache.zookeeper.ZooKeeper)
[2019-01-26 19:45:35,671] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-26 19:45:35,671] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-26 19:45:35,671] INFO Accepted socket connection from /127.0.0.1:62212 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-26 19:45:35,671] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-26 19:45:35,671] INFO Client attempting to establish new session at /127.0.0.1:62212 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:45:35,687] INFO Established session 0x1000aa9390f0002 with negotiated timeout 6000 for client /127.0.0.1:62212 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:45:35,687] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000aa9390f0002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-26 19:45:35,687] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-26 19:45:35,765] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0002 type:create cxid:0x1 zxid:0x2f txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:45:35,781] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0002 type:create cxid:0x2 zxid:0x30 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:45:35,781] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0002 type:create cxid:0x3 zxid:0x31 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:45:35,781] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0002 type:create cxid:0x4 zxid:0x32 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:45:35,781] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0002 type:create cxid:0x5 zxid:0x33 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:45:35,796] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0002 type:create cxid:0x6 zxid:0x34 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:45:35,796] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0002 type:create cxid:0x7 zxid:0x35 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:45:35,796] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0002 type:create cxid:0x8 zxid:0x36 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:45:35,812] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0002 type:create cxid:0x9 zxid:0x37 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:45:35,812] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0002 type:create cxid:0xa zxid:0x38 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:45:35,812] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0002 type:create cxid:0xb zxid:0x39 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:45:35,828] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0002 type:create cxid:0xc zxid:0x3a txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:45:35,828] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0002 type:create cxid:0xd zxid:0x3b txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:45:36,015] INFO Cluster ID = 5GfY6w8PQ1yVBYvzG2VTdQ (kafka.server.KafkaServer)
[2019-01-26 19:45:36,015] WARN No meta.properties file under dir C:\tmp\logs3\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-01-26 19:45:36,109] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-26 19:45:36,124] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/logs3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-26 19:45:36,171] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-26 19:45:36,171] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-26 19:45:36,171] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-26 19:45:36,203] INFO Loading logs. (kafka.log.LogManager)
[2019-01-26 19:45:36,218] INFO Logs loading complete in 15 ms. (kafka.log.LogManager)
[2019-01-26 19:45:36,234] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-26 19:45:36,249] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-26 19:45:36,609] INFO Awaiting socket connections on localhost:9095. (kafka.network.Acceptor)
[2019-01-26 19:45:36,640] INFO [SocketServer brokerId=3] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-26 19:45:36,671] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:45:36,671] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:45:36,671] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:45:36,687] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-26 19:45:36,749] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-26 19:45:36,765] INFO Result of znode creation at /brokers/ids/3 is: OK (kafka.zk.KafkaZkClient)
[2019-01-26 19:45:36,765] INFO Registered broker 3 at path /brokers/ids/3 with addresses: ArrayBuffer(EndPoint(localhost,9095,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-26 19:45:36,765] WARN No meta.properties file under dir C:\tmp\logs3\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-01-26 19:45:36,843] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:45:36,843] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:45:36,843] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-26 19:45:36,874] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 19:45:36,874] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 19:45:36,874] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:45:36,890] INFO [ProducerId Manager 3]: Acquired new producerId block (brokerId:3,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-26 19:45:36,921] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-26 19:45:36,921] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-26 19:45:36,921] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-26 19:45:36,984] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-26 19:45:36,984] INFO [SocketServer brokerId=3] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-26 19:45:36,999] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-26 19:45:36,999] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-26 19:45:36,999] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2019-01-26 19:46:43,588] INFO Accepted socket connection from /127.0.0.1:62231 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-26 19:46:43,588] INFO Client attempting to establish new session at /127.0.0.1:62231 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:46:43,588] INFO Established session 0x1000aa9390f0003 with negotiated timeout 30000 for client /127.0.0.1:62231 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:46:43,933] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0003 type:setData cxid:0x6 zxid:0x3f txntype:-1 reqpath:n/a Error Path:/config/topics/toolsEvents Error:KeeperErrorCode = NoNode for /config/topics/toolsEvents (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:46:43,995] INFO Processed session termination for sessionid: 0x1000aa9390f0003 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:46:43,995] INFO Closed socket connection for client /127.0.0.1:62231 which had sessionid 0x1000aa9390f0003 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-26 19:46:44,062] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(toolsEvents-0) (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:46:44,078] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(toolsEvents-1) (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:46:44,078] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(toolsEvents-2) (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:46:44,171] INFO [Log partition=toolsEvents-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:46:44,187] INFO [Log partition=toolsEvents-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:46:44,187] INFO [Log partition=toolsEvents-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 78 ms (kafka.log.Log)
[2019-01-26 19:46:44,187] INFO Created log for partition toolsEvents-0 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:46:44,187] INFO [Log partition=toolsEvents-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:46:44,187] INFO [Partition toolsEvents-0 broker=1] No checkpointed highwatermark is found for partition toolsEvents-0 (kafka.cluster.Partition)
[2019-01-26 19:46:44,203] INFO Replica loaded for partition toolsEvents-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:46:44,203] INFO [Log partition=toolsEvents-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 78 ms (kafka.log.Log)
[2019-01-26 19:46:44,203] INFO Replica loaded for partition toolsEvents-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:46:44,203] INFO Created log for partition toolsEvents-2 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:46:44,203] INFO [Partition toolsEvents-0 broker=1] toolsEvents-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:46:44,203] INFO [Partition toolsEvents-2 broker=3] No checkpointed highwatermark is found for partition toolsEvents-2 (kafka.cluster.Partition)
[2019-01-26 19:46:44,203] INFO Replica loaded for partition toolsEvents-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:46:44,203] INFO Replica loaded for partition toolsEvents-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:46:44,203] INFO [Log partition=toolsEvents-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 63 ms (kafka.log.Log)
[2019-01-26 19:46:44,203] INFO [Partition toolsEvents-2 broker=3] toolsEvents-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:46:44,203] INFO Created log for partition toolsEvents-1 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:46:44,218] INFO [Partition toolsEvents-1 broker=2] No checkpointed highwatermark is found for partition toolsEvents-1 (kafka.cluster.Partition)
[2019-01-26 19:46:44,218] INFO Replica loaded for partition toolsEvents-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:46:44,218] INFO Replica loaded for partition toolsEvents-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:46:44,218] INFO [Partition toolsEvents-1 broker=2] toolsEvents-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:46:44,234] INFO Replica loaded for partition toolsEvents-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:46:44,234] INFO [Log partition=toolsEvents-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:46:44,234] INFO Replica loaded for partition toolsEvents-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:46:44,234] INFO [Log partition=toolsEvents-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-26 19:46:44,250] INFO Created log for partition toolsEvents-2 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:46:44,250] INFO [Partition toolsEvents-2 broker=1] No checkpointed highwatermark is found for partition toolsEvents-2 (kafka.cluster.Partition)
[2019-01-26 19:46:44,250] INFO Replica loaded for partition toolsEvents-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:46:44,250] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(toolsEvents-2) (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:46:44,250] INFO [Log partition=toolsEvents-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:46:44,250] INFO [Log partition=toolsEvents-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-26 19:46:44,250] INFO Created log for partition toolsEvents-1 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:46:44,250] INFO [Partition toolsEvents-1 broker=3] No checkpointed highwatermark is found for partition toolsEvents-1 (kafka.cluster.Partition)
[2019-01-26 19:46:44,250] INFO Replica loaded for partition toolsEvents-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:46:44,250] INFO Replica loaded for partition toolsEvents-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:46:44,265] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(toolsEvents-1) (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:46:44,265] INFO [Log partition=toolsEvents-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:46:44,265] INFO [Log partition=toolsEvents-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-26 19:46:44,265] INFO Created log for partition toolsEvents-0 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:46:44,265] INFO [Partition toolsEvents-0 broker=2] No checkpointed highwatermark is found for partition toolsEvents-0 (kafka.cluster.Partition)
[2019-01-26 19:46:44,265] INFO Replica loaded for partition toolsEvents-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:46:44,281] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(toolsEvents-0) (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:46:44,296] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-26 19:46:44,296] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(toolsEvents-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:46:44,296] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-26 19:46:44,296] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in toolsEvents-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-26 19:46:44,296] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(toolsEvents-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:46:44,312] INFO [Log partition=toolsEvents-2, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-26 19:46:44,312] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in toolsEvents-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-26 19:46:44,312] INFO [Log partition=toolsEvents-1, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-26 19:46:44,328] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-26 19:46:44,343] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(toolsEvents-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:46:44,343] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in toolsEvents-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-26 19:46:44,359] INFO [Log partition=toolsEvents-0, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-26 19:46:44,406] ERROR [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error for partition toolsEvents-1 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-01-26 19:47:16,409] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62244 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-26 19:47:16,409] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:62244 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:47:16,409] INFO Established session 0x1000aa9390f0004 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:62244 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:47:16,752] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0004 type:setData cxid:0x6 zxid:0x4b txntype:-1 reqpath:n/a Error Path:/config/topics/aggregateddata Error:KeeperErrorCode = NoNode for /config/topics/aggregateddata (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:47:16,815] INFO Processed session termination for sessionid: 0x1000aa9390f0004 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:47:16,815] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:62244 which had sessionid 0x1000aa9390f0004 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-26 19:47:16,830] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(aggregateddata-2) (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:47:16,830] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(aggregateddata-0) (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:47:16,830] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(aggregateddata-1) (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:47:16,846] INFO [Log partition=aggregateddata-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:47:16,846] INFO [Log partition=aggregateddata-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:47:16,846] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:47:16,846] INFO [Log partition=aggregateddata-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:47:16,846] INFO [Log partition=aggregateddata-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:47:16,846] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:47:16,846] INFO Created log for partition aggregateddata-0 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:47:16,846] INFO Created log for partition aggregateddata-2 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:47:16,846] INFO Created log for partition aggregateddata-1 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:47:16,846] INFO [Partition aggregateddata-0 broker=2] No checkpointed highwatermark is found for partition aggregateddata-0 (kafka.cluster.Partition)
[2019-01-26 19:47:16,846] INFO [Partition aggregateddata-2 broker=1] No checkpointed highwatermark is found for partition aggregateddata-2 (kafka.cluster.Partition)
[2019-01-26 19:47:16,846] INFO [Partition aggregateddata-1 broker=3] No checkpointed highwatermark is found for partition aggregateddata-1 (kafka.cluster.Partition)
[2019-01-26 19:47:16,846] INFO Replica loaded for partition aggregateddata-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:47:16,846] INFO Replica loaded for partition aggregateddata-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:47:16,846] INFO Replica loaded for partition aggregateddata-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:47:16,846] INFO Replica loaded for partition aggregateddata-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:47:16,846] INFO Replica loaded for partition aggregateddata-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:47:16,846] INFO Replica loaded for partition aggregateddata-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:47:16,846] INFO [Partition aggregateddata-0 broker=2] aggregateddata-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:47:16,846] INFO [Partition aggregateddata-2 broker=1] aggregateddata-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:47:16,846] INFO [Partition aggregateddata-1 broker=3] aggregateddata-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:47:16,862] INFO Replica loaded for partition aggregateddata-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:47:16,862] INFO Replica loaded for partition aggregateddata-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:47:16,862] INFO Replica loaded for partition aggregateddata-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:47:16,862] INFO [Log partition=aggregateddata-2, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:47:16,862] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:47:16,862] INFO [Log partition=aggregateddata-0, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:47:16,862] INFO [Log partition=aggregateddata-2, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-26 19:47:16,862] INFO [Log partition=aggregateddata-0, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-26 19:47:16,862] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-26 19:47:16,862] INFO Created log for partition aggregateddata-2 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:47:16,862] INFO Created log for partition aggregateddata-0 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:47:16,862] INFO Created log for partition aggregateddata-1 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:47:16,862] INFO [Partition aggregateddata-2 broker=2] No checkpointed highwatermark is found for partition aggregateddata-2 (kafka.cluster.Partition)
[2019-01-26 19:47:16,877] INFO Replica loaded for partition aggregateddata-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:47:16,877] INFO [Partition aggregateddata-0 broker=3] No checkpointed highwatermark is found for partition aggregateddata-0 (kafka.cluster.Partition)
[2019-01-26 19:47:16,877] INFO [Partition aggregateddata-1 broker=1] No checkpointed highwatermark is found for partition aggregateddata-1 (kafka.cluster.Partition)
[2019-01-26 19:47:16,877] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(aggregateddata-2) (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:47:16,877] INFO Replica loaded for partition aggregateddata-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:47:16,877] INFO Replica loaded for partition aggregateddata-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:47:16,877] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(aggregateddata-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:47:16,877] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(aggregateddata-0) (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:47:16,877] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(aggregateddata-1) (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:47:16,877] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(aggregateddata-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:47:16,877] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(aggregateddata-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:47:16,893] WARN [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in aggregateddata-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-26 19:47:16,893] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in aggregateddata-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-26 19:47:16,893] INFO [Log partition=aggregateddata-0, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-26 19:47:16,893] INFO [Log partition=aggregateddata-1, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-26 19:47:16,924] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in aggregateddata-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-26 19:47:16,924] INFO [Log partition=aggregateddata-2, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-26 19:48:38,917] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62249 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-26 19:48:38,932] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:62249 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:48:38,932] INFO Established session 0x1000aa9390f0005 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:62249 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 19:48:39,291] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0005 type:setData cxid:0x6 zxid:0x57 txntype:-1 reqpath:n/a Error Path:/config/topics/globalTableHoldON Error:KeeperErrorCode = NoNode for /config/topics/globalTableHoldON (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:48:39,338] INFO Processed session termination for sessionid: 0x1000aa9390f0005 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:48:39,338] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:62249 which had sessionid 0x1000aa9390f0005 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-26 19:48:39,354] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(globalTableHoldON-2) (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:48:39,354] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(globalTableHoldON-1) (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:48:39,354] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(globalTableHoldON-0) (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:48:39,370] INFO [Log partition=globalTableHoldON-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:48:39,370] INFO [Log partition=globalTableHoldON-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:48:39,370] INFO [Log partition=globalTableHoldON-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:48:39,370] INFO [Log partition=globalTableHoldON-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-26 19:48:39,370] INFO Created log for partition globalTableHoldON-2 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:48:39,370] INFO [Log partition=globalTableHoldON-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-26 19:48:39,370] INFO [Log partition=globalTableHoldON-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-26 19:48:39,370] INFO [Partition globalTableHoldON-2 broker=1] No checkpointed highwatermark is found for partition globalTableHoldON-2 (kafka.cluster.Partition)
[2019-01-26 19:48:39,370] INFO Created log for partition globalTableHoldON-1 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:48:39,370] INFO Replica loaded for partition globalTableHoldON-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:48:39,370] INFO Created log for partition globalTableHoldON-0 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:48:39,370] INFO [Partition globalTableHoldON-1 broker=3] No checkpointed highwatermark is found for partition globalTableHoldON-1 (kafka.cluster.Partition)
[2019-01-26 19:48:39,370] INFO Replica loaded for partition globalTableHoldON-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:48:39,370] INFO [Partition globalTableHoldON-0 broker=2] No checkpointed highwatermark is found for partition globalTableHoldON-0 (kafka.cluster.Partition)
[2019-01-26 19:48:39,370] INFO [Partition globalTableHoldON-2 broker=1] globalTableHoldON-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:48:39,370] INFO Replica loaded for partition globalTableHoldON-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:48:39,370] INFO Replica loaded for partition globalTableHoldON-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:48:39,385] INFO Replica loaded for partition globalTableHoldON-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:48:39,370] INFO Replica loaded for partition globalTableHoldON-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:48:39,385] INFO [Partition globalTableHoldON-0 broker=2] globalTableHoldON-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:48:39,385] INFO [Partition globalTableHoldON-1 broker=3] globalTableHoldON-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:48:39,385] INFO Replica loaded for partition globalTableHoldON-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:48:39,385] INFO Replica loaded for partition globalTableHoldON-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:48:39,385] INFO Replica loaded for partition globalTableHoldON-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:48:39,385] INFO [Log partition=globalTableHoldON-0, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:48:39,385] INFO [Log partition=globalTableHoldON-1, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:48:39,401] INFO [Log partition=globalTableHoldON-0, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:48:39,401] INFO [Log partition=globalTableHoldON-2, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:48:39,401] INFO [Log partition=globalTableHoldON-1, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:48:39,401] INFO Created log for partition globalTableHoldON-0 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:48:39,401] INFO [Partition globalTableHoldON-0 broker=1] No checkpointed highwatermark is found for partition globalTableHoldON-0 (kafka.cluster.Partition)
[2019-01-26 19:48:39,401] INFO Created log for partition globalTableHoldON-1 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:48:39,401] INFO [Log partition=globalTableHoldON-2, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:48:39,401] INFO Replica loaded for partition globalTableHoldON-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:48:39,401] INFO [Partition globalTableHoldON-1 broker=2] No checkpointed highwatermark is found for partition globalTableHoldON-1 (kafka.cluster.Partition)
[2019-01-26 19:48:39,401] INFO Created log for partition globalTableHoldON-2 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:48:39,401] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(globalTableHoldON-0) (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:48:39,401] INFO Replica loaded for partition globalTableHoldON-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:48:39,401] INFO [Partition globalTableHoldON-2 broker=3] No checkpointed highwatermark is found for partition globalTableHoldON-2 (kafka.cluster.Partition)
[2019-01-26 19:48:39,401] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(globalTableHoldON-1) (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:48:39,401] INFO Replica loaded for partition globalTableHoldON-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:48:39,401] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(globalTableHoldON-2) (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:48:39,401] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=localhost:9094) for partitions Map(globalTableHoldON-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:48:39,416] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=3, host=localhost:9095) for partitions Map(globalTableHoldON-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:48:39,401] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-26 19:48:39,416] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in globalTableHoldON-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-26 19:48:39,416] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-26 19:48:39,416] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9093) for partitions Map(globalTableHoldON-2 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:48:39,416] INFO [Log partition=globalTableHoldON-0, dir=C:\tmp\logs1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-26 19:48:39,416] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in globalTableHoldON-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-26 19:48:39,416] INFO [Log partition=globalTableHoldON-1, dir=C:\tmp\logs2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-26 19:48:39,416] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-26 19:48:39,416] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in globalTableHoldON-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-26 19:48:39,416] INFO [Log partition=globalTableHoldON-2, dir=C:\tmp\logs3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-26 19:49:05,539] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0000 type:setData cxid:0x6d zxid:0x62 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 19:49:05,554] INFO Topic creation Map(__consumer_offsets-22 -> ArrayBuffer(3), __consumer_offsets-30 -> ArrayBuffer(2), __consumer_offsets-8 -> ArrayBuffer(1), __consumer_offsets-21 -> ArrayBuffer(2), __consumer_offsets-4 -> ArrayBuffer(3), __consumer_offsets-27 -> ArrayBuffer(2), __consumer_offsets-7 -> ArrayBuffer(3), __consumer_offsets-9 -> ArrayBuffer(2), __consumer_offsets-46 -> ArrayBuffer(3), __consumer_offsets-25 -> ArrayBuffer(3), __consumer_offsets-35 -> ArrayBuffer(1), __consumer_offsets-41 -> ArrayBuffer(1), __consumer_offsets-33 -> ArrayBuffer(2), __consumer_offsets-23 -> ArrayBuffer(1), __consumer_offsets-49 -> ArrayBuffer(3), __consumer_offsets-47 -> ArrayBuffer(1), __consumer_offsets-16 -> ArrayBuffer(3), __consumer_offsets-28 -> ArrayBuffer(3), __consumer_offsets-31 -> ArrayBuffer(3), __consumer_offsets-36 -> ArrayBuffer(2), __consumer_offsets-42 -> ArrayBuffer(2), __consumer_offsets-3 -> ArrayBuffer(2), __consumer_offsets-18 -> ArrayBuffer(2), __consumer_offsets-37 -> ArrayBuffer(3), __consumer_offsets-15 -> ArrayBuffer(2), __consumer_offsets-24 -> ArrayBuffer(2), __consumer_offsets-38 -> ArrayBuffer(1), __consumer_offsets-17 -> ArrayBuffer(1), __consumer_offsets-48 -> ArrayBuffer(2), __consumer_offsets-19 -> ArrayBuffer(3), __consumer_offsets-11 -> ArrayBuffer(1), __consumer_offsets-13 -> ArrayBuffer(3), __consumer_offsets-2 -> ArrayBuffer(1), __consumer_offsets-43 -> ArrayBuffer(3), __consumer_offsets-6 -> ArrayBuffer(2), __consumer_offsets-14 -> ArrayBuffer(1), __consumer_offsets-20 -> ArrayBuffer(1), __consumer_offsets-0 -> ArrayBuffer(2), __consumer_offsets-44 -> ArrayBuffer(1), __consumer_offsets-39 -> ArrayBuffer(2), __consumer_offsets-12 -> ArrayBuffer(2), __consumer_offsets-45 -> ArrayBuffer(2), __consumer_offsets-1 -> ArrayBuffer(3), __consumer_offsets-5 -> ArrayBuffer(1), __consumer_offsets-26 -> ArrayBuffer(1), __consumer_offsets-29 -> ArrayBuffer(1), __consumer_offsets-34 -> ArrayBuffer(3), __consumer_offsets-10 -> ArrayBuffer(3), __consumer_offsets-32 -> ArrayBuffer(1), __consumer_offsets-40 -> ArrayBuffer(3)) (kafka.zk.AdminZkClient)
[2019-01-26 19:49:05,554] INFO [KafkaApi-1] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2019-01-26 19:49:05,695] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-8, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-47, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-32) (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:49:05,710] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45) (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:49:05,710] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:05,726] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:49:05,726] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-01-26 19:49:05,726] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:05,726] INFO Created log for partition __consumer_offsets-29 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:05,726] INFO [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2019-01-26 19:49:05,726] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:05,726] INFO [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:05,726] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:49:05,726] INFO Created log for partition __consumer_offsets-0 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:05,726] INFO [Partition __consumer_offsets-0 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2019-01-26 19:49:05,726] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:05,742] INFO [Partition __consumer_offsets-0 broker=2] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:05,742] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:05,742] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:49:05,757] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:05,742] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:05,757] INFO Created log for partition __consumer_offsets-10 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:05,757] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:49:05,757] INFO [Partition __consumer_offsets-10 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2019-01-26 19:49:05,757] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:05,757] INFO Created log for partition __consumer_offsets-48 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:05,757] INFO [Partition __consumer_offsets-10 broker=3] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:05,757] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:49:05,757] INFO [Partition __consumer_offsets-48 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2019-01-26 19:49:05,757] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:05,757] INFO [Partition __consumer_offsets-48 broker=2] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:05,757] INFO Created log for partition __consumer_offsets-26 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:05,773] INFO [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2019-01-26 19:49:05,773] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:05,773] INFO [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:05,789] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:05,789] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:05,789] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:05,789] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:49:05,789] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:49:05,804] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:49:05,804] INFO Created log for partition __consumer_offsets-7 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:05,804] INFO Created log for partition __consumer_offsets-45 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:05,804] INFO [Partition __consumer_offsets-7 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2019-01-26 19:49:05,804] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:05,804] INFO Created log for partition __consumer_offsets-23 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:05,804] INFO [Partition __consumer_offsets-45 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2019-01-26 19:49:05,804] INFO [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2019-01-26 19:49:05,804] INFO [Partition __consumer_offsets-7 broker=3] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:05,804] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:05,804] INFO [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:05,804] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:05,804] INFO [Partition __consumer_offsets-45 broker=2] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:05,835] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:05,835] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:05,851] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-26 19:49:05,835] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:49:05,851] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:05,851] INFO Created log for partition __consumer_offsets-42 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:05,851] INFO Created log for partition __consumer_offsets-20 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:05,851] INFO [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2019-01-26 19:49:05,851] INFO [Partition __consumer_offsets-42 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2019-01-26 19:49:05,851] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:05,851] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:05,867] INFO [Partition __consumer_offsets-42 broker=2] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:05,867] INFO [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:05,867] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-01-26 19:49:05,867] INFO Created log for partition __consumer_offsets-4 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:05,867] INFO [Partition __consumer_offsets-4 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2019-01-26 19:49:05,867] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:05,882] INFO [Partition __consumer_offsets-4 broker=3] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:05,882] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:05,882] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:05,882] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:49:05,882] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-26 19:49:05,882] INFO Created log for partition __consumer_offsets-39 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:05,882] INFO Created log for partition __consumer_offsets-17 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:05,898] INFO [Partition __consumer_offsets-39 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2019-01-26 19:49:05,882] INFO [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2019-01-26 19:49:05,898] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:05,898] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:05,898] INFO [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:05,898] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:05,898] INFO [Partition __consumer_offsets-39 broker=2] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:05,898] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:49:05,898] INFO Created log for partition __consumer_offsets-1 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:05,898] INFO [Partition __consumer_offsets-1 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2019-01-26 19:49:05,914] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:05,914] INFO [Partition __consumer_offsets-1 broker=3] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:05,914] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:05,929] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:05,929] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:49:05,929] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:05,929] INFO Created log for partition __consumer_offsets-36 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:05,929] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:49:05,929] INFO [Partition __consumer_offsets-36 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2019-01-26 19:49:05,929] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:05,929] INFO [Partition __consumer_offsets-36 broker=2] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:05,929] INFO Created log for partition __consumer_offsets-14 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:05,929] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-26 19:49:05,929] INFO [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2019-01-26 19:49:05,929] INFO Created log for partition __consumer_offsets-49 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:05,929] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:05,929] INFO [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:05,929] INFO [Partition __consumer_offsets-49 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2019-01-26 19:49:05,929] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:05,945] INFO [Partition __consumer_offsets-49 broker=3] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:05,945] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:05,960] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:49:05,960] INFO Created log for partition __consumer_offsets-33 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:05,960] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:05,960] INFO [Partition __consumer_offsets-33 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2019-01-26 19:49:05,960] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:05,960] INFO [Partition __consumer_offsets-33 broker=2] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:05,960] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-26 19:49:05,960] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:05,960] INFO Created log for partition __consumer_offsets-11 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:05,960] INFO [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2019-01-26 19:49:05,960] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:05,976] INFO [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:05,976] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:49:05,976] INFO Created log for partition __consumer_offsets-46 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:05,976] INFO [Partition __consumer_offsets-46 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2019-01-26 19:49:05,976] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:05,976] INFO [Partition __consumer_offsets-46 broker=3] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:05,976] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:05,976] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-26 19:49:05,992] INFO Created log for partition __consumer_offsets-30 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:05,992] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:05,992] INFO [Partition __consumer_offsets-30 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2019-01-26 19:49:05,992] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:05,992] INFO [Partition __consumer_offsets-30 broker=2] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:05,992] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:49:05,992] INFO Created log for partition __consumer_offsets-8 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:05,992] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:05,992] INFO [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2019-01-26 19:49:05,992] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:05,992] INFO [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:05,992] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-26 19:49:05,992] INFO Created log for partition __consumer_offsets-43 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:05,992] INFO [Partition __consumer_offsets-43 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2019-01-26 19:49:05,992] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:06,007] INFO [Partition __consumer_offsets-43 broker=3] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:06,007] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:06,007] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:49:06,007] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:06,007] INFO Created log for partition __consumer_offsets-27 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:06,007] INFO [Partition __consumer_offsets-27 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2019-01-26 19:49:06,007] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:06,007] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-26 19:49:06,007] INFO [Partition __consumer_offsets-27 broker=2] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:06,007] INFO Created log for partition __consumer_offsets-5 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:06,023] INFO [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2019-01-26 19:49:06,023] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:06,023] INFO [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:06,023] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:06,023] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:49:06,023] INFO Created log for partition __consumer_offsets-40 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:06,023] INFO [Partition __consumer_offsets-40 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2019-01-26 19:49:06,023] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:06,023] INFO [Partition __consumer_offsets-40 broker=3] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:06,023] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:06,039] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:49:06,039] INFO Created log for partition __consumer_offsets-24 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:06,039] INFO [Partition __consumer_offsets-24 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2019-01-26 19:49:06,039] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:06,039] INFO [Partition __consumer_offsets-24 broker=2] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:06,039] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:06,039] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:49:06,039] INFO Created log for partition __consumer_offsets-2 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:06,039] INFO [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2019-01-26 19:49:06,039] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:06,039] INFO [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:06,039] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:06,054] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:49:06,054] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:06,054] INFO Created log for partition __consumer_offsets-37 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:06,054] INFO [Partition __consumer_offsets-37 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2019-01-26 19:49:06,054] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:06,054] INFO [Partition __consumer_offsets-37 broker=3] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:06,054] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:49:06,054] INFO Created log for partition __consumer_offsets-21 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:06,054] INFO [Partition __consumer_offsets-21 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2019-01-26 19:49:06,054] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:06,054] INFO [Partition __consumer_offsets-21 broker=2] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:06,054] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:06,070] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:06,070] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:49:06,070] INFO Created log for partition __consumer_offsets-47 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:06,070] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:49:06,070] INFO [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2019-01-26 19:49:06,070] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:06,070] INFO [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:06,070] INFO Created log for partition __consumer_offsets-34 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:06,070] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:06,070] INFO [Partition __consumer_offsets-34 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2019-01-26 19:49:06,070] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:06,070] INFO [Partition __consumer_offsets-34 broker=3] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:06,070] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-26 19:49:06,070] INFO Created log for partition __consumer_offsets-18 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:06,070] INFO [Partition __consumer_offsets-18 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2019-01-26 19:49:06,070] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:06,070] INFO [Partition __consumer_offsets-18 broker=2] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:06,085] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:06,085] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:06,085] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:49:06,085] INFO Created log for partition __consumer_offsets-38 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:06,085] INFO [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2019-01-26 19:49:06,085] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:49:06,085] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:06,085] INFO [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:06,085] INFO Created log for partition __consumer_offsets-31 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:06,085] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:06,085] INFO [Partition __consumer_offsets-31 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2019-01-26 19:49:06,085] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:06,085] INFO [Partition __consumer_offsets-31 broker=3] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:06,085] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-26 19:49:06,085] INFO Created log for partition __consumer_offsets-15 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:06,101] INFO [Partition __consumer_offsets-15 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2019-01-26 19:49:06,101] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:06,101] INFO [Partition __consumer_offsets-15 broker=2] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:06,101] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:06,101] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:06,101] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-26 19:49:06,101] INFO Created log for partition __consumer_offsets-35 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:06,101] INFO [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2019-01-26 19:49:06,101] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:06,101] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-26 19:49:06,101] INFO [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:06,101] INFO Created log for partition __consumer_offsets-19 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:06,101] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:06,117] INFO [Partition __consumer_offsets-19 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2019-01-26 19:49:06,117] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:06,117] INFO [Partition __consumer_offsets-19 broker=3] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:06,117] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:49:06,117] INFO Created log for partition __consumer_offsets-12 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:06,117] INFO [Partition __consumer_offsets-12 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2019-01-26 19:49:06,117] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:06,117] INFO [Partition __consumer_offsets-12 broker=2] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:06,117] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:06,117] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:06,117] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-26 19:49:06,117] INFO Created log for partition __consumer_offsets-44 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:06,117] INFO [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2019-01-26 19:49:06,132] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:49:06,132] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:06,132] INFO [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:06,132] INFO Created log for partition __consumer_offsets-28 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:06,132] INFO [Partition __consumer_offsets-28 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2019-01-26 19:49:06,132] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:06,132] INFO [Partition __consumer_offsets-28 broker=3] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:06,132] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:06,132] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:49:06,132] INFO Created log for partition __consumer_offsets-9 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:06,132] INFO [Partition __consumer_offsets-9 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2019-01-26 19:49:06,132] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:06,132] INFO [Partition __consumer_offsets-9 broker=2] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:06,132] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:06,148] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:06,148] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:49:06,148] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:49:06,148] INFO Created log for partition __consumer_offsets-32 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:06,148] INFO Created log for partition __consumer_offsets-25 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:06,148] INFO [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2019-01-26 19:49:06,148] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:06,148] INFO [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:06,148] INFO [Partition __consumer_offsets-25 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2019-01-26 19:49:06,148] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:06,148] INFO [Partition __consumer_offsets-25 broker=3] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:06,148] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:06,163] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-01-26 19:49:06,163] INFO Created log for partition __consumer_offsets-6 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:06,163] INFO [Partition __consumer_offsets-6 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2019-01-26 19:49:06,163] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:06,163] INFO [Partition __consumer_offsets-6 broker=2] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:06,163] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\logs1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:06,163] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:06,163] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\logs1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-26 19:49:06,163] INFO Created log for partition __consumer_offsets-41 in C:\tmp\logs1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:06,179] INFO [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2019-01-26 19:49:06,179] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:06,179] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:49:06,179] INFO [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:06,179] INFO Created log for partition __consumer_offsets-16 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:06,179] INFO [Partition __consumer_offsets-16 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2019-01-26 19:49:06,179] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:06,179] INFO [Partition __consumer_offsets-16 broker=3] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:06,179] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:06,179] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 0 ms (kafka.log.Log)
[2019-01-26 19:49:06,179] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,179] INFO Created log for partition __consumer_offsets-3 in C:\tmp\logs2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:06,179] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,179] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,179] INFO [Partition __consumer_offsets-3 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2019-01-26 19:49:06,179] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,179] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,179] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:06,179] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,179] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,179] INFO [Partition __consumer_offsets-3 broker=2] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:06,179] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,179] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,195] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,195] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,195] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,195] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,195] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,195] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,195] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,195] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:06,195] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,195] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,195] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,195] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:49:06,195] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,195] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,195] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,195] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,195] INFO Created log for partition __consumer_offsets-22 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:06,195] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,195] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,195] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,195] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,210] INFO [Partition __consumer_offsets-22 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2019-01-26 19:49:06,210] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,210] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:06,210] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,210] INFO [Partition __consumer_offsets-22 broker=3] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:06,210] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,210] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,210] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,210] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,210] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,210] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-0 in 15 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,210] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,210] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,210] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,210] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,210] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,210] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,210] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,210] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,210] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,210] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,210] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,210] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,210] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,210] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,210] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,210] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,226] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,226] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,226] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,226] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,226] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,226] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,226] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\logs3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-26 19:49:06,226] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,226] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,226] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,226] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,226] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,226] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\logs3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-26 19:49:06,226] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,226] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,226] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,226] INFO Created log for partition __consumer_offsets-13 in C:\tmp\logs3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-26 19:49:06,226] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,226] INFO [Partition __consumer_offsets-13 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2019-01-26 19:49:06,226] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-26 19:49:06,226] INFO [Partition __consumer_offsets-13 broker=3] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-26 19:49:06,242] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,257] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,257] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,257] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,257] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,257] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,257] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,257] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,257] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,257] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,257] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,257] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,257] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,257] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,257] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,257] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,257] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,257] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-22 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,273] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,288] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,288] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,288] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,288] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,288] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,288] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,288] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,288] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,288] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,288] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,288] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,288] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,288] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,288] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,288] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:49:06,304] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-7542 in state PreparingRebalance with old generation 0 (__consumer_offsets-17) (reason: Adding new member consumer-1-dc5b06d2-7b13-42f3-a199-15395fb6fb3f) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 19:49:06,320] INFO [GroupCoordinator 1]: Stabilized group console-consumer-7542 generation 1 (__consumer_offsets-17) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 19:49:06,320] INFO [GroupCoordinator 1]: Assignment received from leader for group console-consumer-7542 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 19:49:26,076] INFO [GroupCoordinator 3]: Preparing to rebalance group console-consumer-39884 in state PreparingRebalance with old generation 0 (__consumer_offsets-13) (reason: Adding new member consumer-1-f6eb6e1e-0f50-48ab-b064-450d79ee359a) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 19:49:26,076] INFO [GroupCoordinator 3]: Stabilized group console-consumer-39884 generation 1 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 19:49:26,092] INFO [GroupCoordinator 3]: Assignment received from leader for group console-consumer-39884 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 19:49:47,580] INFO [GroupCoordinator 3]: Preparing to rebalance group console-consumer-28537 in state PreparingRebalance with old generation 0 (__consumer_offsets-16) (reason: Adding new member consumer-1-ff58ba51-4a78-4213-b4ee-4884bd4f5a88) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 19:49:47,580] INFO [GroupCoordinator 3]: Stabilized group console-consumer-28537 generation 1 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 19:49:47,580] INFO [GroupCoordinator 3]: Assignment received from leader for group console-consumer-28537 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 19:50:30,916] INFO [GroupCoordinator 1]: Preparing to rebalance group connect-test-sink in state PreparingRebalance with old generation 0 (__consumer_offsets-35) (reason: Adding new member consumer-1-4bf605d2-0ded-438d-832f-8c0f22489baa) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 19:50:30,916] INFO [GroupCoordinator 1]: Stabilized group connect-test-sink generation 1 (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 19:50:30,916] INFO [GroupCoordinator 1]: Assignment received from leader for group connect-test-sink for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 19:50:51,578] INFO [GroupCoordinator 1]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-f3d555ff-ef44-4814-accc-6de11d18a036-StreamThread-1-consumer-a27b838c-a0b6-4678-bd88-333910cadbba) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 19:50:51,578] INFO [GroupCoordinator 1]: Stabilized group alltoolsStream generation 1 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 19:50:51,578] INFO [GroupCoordinator 1]: Assignment received from leader for group alltoolsStream for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 19:51:19,694] INFO [GroupCoordinator 1]: Member alltoolsStream-f3d555ff-ef44-4814-accc-6de11d18a036-StreamThread-1-consumer-a27b838c-a0b6-4678-bd88-333910cadbba in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 19:51:19,694] INFO [GroupCoordinator 1]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: removing member alltoolsStream-f3d555ff-ef44-4814-accc-6de11d18a036-StreamThread-1-consumer-a27b838c-a0b6-4678-bd88-333910cadbba on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 19:51:19,694] INFO [GroupCoordinator 1]: Group alltoolsStream with generation 2 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 19:54:59,959] INFO [GroupMetadataManager brokerId=1] Group alltoolsStream transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:54:59,974] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 15 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:55:16,820] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 19:55:36,896] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 14 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 20:04:59,954] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 20:05:16,806] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 20:05:36,896] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 20:06:34,146] INFO [GroupCoordinator 1]: Member consumer-1-dc5b06d2-7b13-42f3-a199-15395fb6fb3f in group console-consumer-7542 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:06:34,148] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-7542 in state PreparingRebalance with old generation 1 (__consumer_offsets-17) (reason: removing member consumer-1-dc5b06d2-7b13-42f3-a199-15395fb6fb3f on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:06:34,150] INFO [GroupCoordinator 1]: Group console-consumer-7542 with generation 2 is now empty (__consumer_offsets-17) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:06:38,795] INFO [GroupCoordinator 3]: Member consumer-1-f6eb6e1e-0f50-48ab-b064-450d79ee359a in group console-consumer-39884 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:06:38,797] INFO [GroupCoordinator 3]: Preparing to rebalance group console-consumer-39884 in state PreparingRebalance with old generation 1 (__consumer_offsets-13) (reason: removing member consumer-1-f6eb6e1e-0f50-48ab-b064-450d79ee359a on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:06:38,800] INFO [GroupCoordinator 3]: Group console-consumer-39884 with generation 2 is now empty (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:06:42,201] INFO [GroupCoordinator 3]: Member consumer-1-ff58ba51-4a78-4213-b4ee-4884bd4f5a88 in group console-consumer-28537 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:06:42,201] INFO [GroupCoordinator 3]: Preparing to rebalance group console-consumer-28537 in state PreparingRebalance with old generation 1 (__consumer_offsets-16) (reason: removing member consumer-1-ff58ba51-4a78-4213-b4ee-4884bd4f5a88 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:06:42,202] INFO [GroupCoordinator 3]: Group console-consumer-28537 with generation 2 is now empty (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:08:00,650] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62539 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-26 20:08:00,653] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:62539 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 20:08:00,655] INFO Established session 0x1000aa9390f0006 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:62539 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 20:08:01,001] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0006 type:create cxid:0x5 zxid:0xcc txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 20:08:01,014] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2019-01-26 20:08:01,016] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2019-01-26 20:08:01,016] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2019-01-26 20:08:01,019] INFO Processed session termination for sessionid: 0x1000aa9390f0006 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 20:08:01,022] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:62539 which had sessionid 0x1000aa9390f0006 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-26 20:08:01,028] INFO Processing override for entityPath: topics/aggregateddata with config: Map(retention.ms -> 1000) (kafka.server.DynamicConfigManager)
[2019-01-26 20:08:01,029] INFO Processing override for entityPath: topics/aggregateddata with config: Map(retention.ms -> 1000) (kafka.server.DynamicConfigManager)
[2019-01-26 20:08:01,030] INFO Processing override for entityPath: topics/aggregateddata with config: Map(retention.ms -> 1000) (kafka.server.DynamicConfigManager)
[2019-01-26 20:08:01,034] WARN [Log partition=aggregateddata-0, dir=C:\tmp\logs3] retention.ms for topic aggregateddata is set to 1000. It is smaller than message.timestamp.difference.max.ms's value 9223372036854775807. This may result in frequent log rolling. (kafka.log.Log)
[2019-01-26 20:08:01,035] WARN [Log partition=aggregateddata-0, dir=C:\tmp\logs2] retention.ms for topic aggregateddata is set to 1000. It is smaller than message.timestamp.difference.max.ms's value 9223372036854775807. This may result in frequent log rolling. (kafka.log.Log)
[2019-01-26 20:09:01,129] INFO Accepted socket connection from /127.0.0.1:62556 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-26 20:09:01,145] INFO Client attempting to establish new session at /127.0.0.1:62556 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 20:09:01,145] INFO Established session 0x1000aa9390f0007 with negotiated timeout 30000 for client /127.0.0.1:62556 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 20:09:01,379] INFO Processed session termination for sessionid: 0x1000aa9390f0007 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 20:09:01,379] INFO Closed socket connection for client /127.0.0.1:62556 which had sessionid 0x1000aa9390f0007 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-26 20:12:03,977] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62694 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-26 20:12:03,993] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:62694 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 20:12:03,993] INFO Established session 0x1000aa9390f0008 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:62694 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 20:12:04,336] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0008 type:create cxid:0x5 zxid:0xd3 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 20:12:04,336] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2019-01-26 20:12:04,336] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2019-01-26 20:12:04,336] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2019-01-26 20:12:04,352] INFO Processing override for entityPath: topics/aggregateddata with config: Map(retention.ms -> 604800000) (kafka.server.DynamicConfigManager)
[2019-01-26 20:12:04,352] INFO Processing override for entityPath: topics/aggregateddata with config: Map(retention.ms -> 604800000) (kafka.server.DynamicConfigManager)
[2019-01-26 20:12:04,352] INFO Processing override for entityPath: topics/aggregateddata with config: Map(retention.ms -> 604800000) (kafka.server.DynamicConfigManager)
[2019-01-26 20:12:04,352] WARN [Log partition=aggregateddata-0, dir=C:\tmp\logs2] retention.ms for topic aggregateddata is set to 604800000. It is smaller than message.timestamp.difference.max.ms's value 9223372036854775807. This may result in frequent log rolling. (kafka.log.Log)
[2019-01-26 20:12:04,352] WARN [Log partition=aggregateddata-0, dir=C:\tmp\logs3] retention.ms for topic aggregateddata is set to 604800000. It is smaller than message.timestamp.difference.max.ms's value 9223372036854775807. This may result in frequent log rolling. (kafka.log.Log)
[2019-01-26 20:12:04,352] INFO Processed session termination for sessionid: 0x1000aa9390f0008 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 20:12:04,352] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:62694 which had sessionid 0x1000aa9390f0008 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-26 20:12:29,417] INFO Accepted socket connection from /127.0.0.1:62698 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-26 20:12:29,417] INFO Client attempting to establish new session at /127.0.0.1:62698 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 20:12:29,433] INFO Established session 0x1000aa9390f0009 with negotiated timeout 30000 for client /127.0.0.1:62698 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 20:12:29,761] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f0009 type:create cxid:0x5 zxid:0xd8 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 20:12:29,777] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2019-01-26 20:12:29,777] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2019-01-26 20:12:29,777] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2019-01-26 20:12:29,777] INFO Processing override for entityPath: topics/toolsEvents with config: Map(retention.ms -> 1000) (kafka.server.DynamicConfigManager)
[2019-01-26 20:12:29,777] INFO Processing override for entityPath: topics/toolsEvents with config: Map(retention.ms -> 1000) (kafka.server.DynamicConfigManager)
[2019-01-26 20:12:29,777] INFO Processing override for entityPath: topics/toolsEvents with config: Map(retention.ms -> 1000) (kafka.server.DynamicConfigManager)
[2019-01-26 20:12:29,777] WARN [Log partition=toolsEvents-0, dir=C:\tmp\logs1] retention.ms for topic toolsEvents is set to 1000. It is smaller than message.timestamp.difference.max.ms's value 9223372036854775807. This may result in frequent log rolling. (kafka.log.Log)
[2019-01-26 20:12:29,777] WARN [Log partition=toolsEvents-0, dir=C:\tmp\logs2] retention.ms for topic toolsEvents is set to 1000. It is smaller than message.timestamp.difference.max.ms's value 9223372036854775807. This may result in frequent log rolling. (kafka.log.Log)
[2019-01-26 20:12:29,777] INFO Processed session termination for sessionid: 0x1000aa9390f0009 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 20:12:29,777] INFO Closed socket connection for client /127.0.0.1:62698 which had sessionid 0x1000aa9390f0009 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-26 20:12:41,930] INFO Accepted socket connection from /127.0.0.1:62702 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-26 20:12:41,946] INFO Client attempting to establish new session at /127.0.0.1:62702 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 20:12:41,946] INFO Established session 0x1000aa9390f000a with negotiated timeout 30000 for client /127.0.0.1:62702 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 20:12:42,290] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f000a type:create cxid:0x5 zxid:0xdd txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 20:12:42,290] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2019-01-26 20:12:42,290] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2019-01-26 20:12:42,290] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2019-01-26 20:12:42,290] INFO Processing override for entityPath: topics/toolsEvents with config: Map(retention.ms -> 604800000) (kafka.server.DynamicConfigManager)
[2019-01-26 20:12:42,290] INFO Processing override for entityPath: topics/toolsEvents with config: Map(retention.ms -> 604800000) (kafka.server.DynamicConfigManager)
[2019-01-26 20:12:42,290] INFO Processing override for entityPath: topics/toolsEvents with config: Map(retention.ms -> 604800000) (kafka.server.DynamicConfigManager)
[2019-01-26 20:12:42,305] WARN [Log partition=toolsEvents-0, dir=C:\tmp\logs2] retention.ms for topic toolsEvents is set to 604800000. It is smaller than message.timestamp.difference.max.ms's value 9223372036854775807. This may result in frequent log rolling. (kafka.log.Log)
[2019-01-26 20:12:42,305] WARN [Log partition=toolsEvents-0, dir=C:\tmp\logs1] retention.ms for topic toolsEvents is set to 604800000. It is smaller than message.timestamp.difference.max.ms's value 9223372036854775807. This may result in frequent log rolling. (kafka.log.Log)
[2019-01-26 20:12:42,305] INFO Processed session termination for sessionid: 0x1000aa9390f000a (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 20:12:42,305] INFO Closed socket connection for client /127.0.0.1:62702 which had sessionid 0x1000aa9390f000a (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-26 20:12:58,857] INFO Accepted socket connection from /127.0.0.1:62706 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-26 20:12:58,857] INFO Client attempting to establish new session at /127.0.0.1:62706 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 20:12:58,873] INFO Established session 0x1000aa9390f000b with negotiated timeout 30000 for client /127.0.0.1:62706 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 20:12:59,201] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f000b type:create cxid:0x5 zxid:0xe2 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 20:12:59,216] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2019-01-26 20:12:59,216] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2019-01-26 20:12:59,216] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2019-01-26 20:12:59,216] INFO Processing override for entityPath: topics/globalTableHoldON with config: Map(retention.ms -> 1000) (kafka.server.DynamicConfigManager)
[2019-01-26 20:12:59,216] INFO Processing override for entityPath: topics/globalTableHoldON with config: Map(retention.ms -> 1000) (kafka.server.DynamicConfigManager)
[2019-01-26 20:12:59,216] INFO Processing override for entityPath: topics/globalTableHoldON with config: Map(retention.ms -> 1000) (kafka.server.DynamicConfigManager)
[2019-01-26 20:12:59,232] WARN [Log partition=globalTableHoldON-0, dir=C:\tmp\logs2] retention.ms for topic globalTableHoldON is set to 1000. It is smaller than message.timestamp.difference.max.ms's value 9223372036854775807. This may result in frequent log rolling. (kafka.log.Log)
[2019-01-26 20:12:59,232] WARN [Log partition=globalTableHoldON-0, dir=C:\tmp\logs1] retention.ms for topic globalTableHoldON is set to 1000. It is smaller than message.timestamp.difference.max.ms's value 9223372036854775807. This may result in frequent log rolling. (kafka.log.Log)
[2019-01-26 20:12:59,232] INFO Processed session termination for sessionid: 0x1000aa9390f000b (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 20:12:59,232] INFO Closed socket connection for client /127.0.0.1:62706 which had sessionid 0x1000aa9390f000b (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-26 20:13:12,613] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62710 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-26 20:13:12,613] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:62710 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 20:13:12,613] INFO Established session 0x1000aa9390f000c with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:62710 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-26 20:13:12,957] INFO Got user-level KeeperException when processing sessionid:0x1000aa9390f000c type:create cxid:0x5 zxid:0xe7 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 20:13:12,973] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2019-01-26 20:13:12,973] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2019-01-26 20:13:12,973] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2019-01-26 20:13:12,973] INFO Processing override for entityPath: topics/globalTableHoldON with config: Map(retention.ms -> 604800000) (kafka.server.DynamicConfigManager)
[2019-01-26 20:13:12,973] INFO Processing override for entityPath: topics/globalTableHoldON with config: Map(retention.ms -> 604800000) (kafka.server.DynamicConfigManager)
[2019-01-26 20:13:12,973] INFO Processing override for entityPath: topics/globalTableHoldON with config: Map(retention.ms -> 604800000) (kafka.server.DynamicConfigManager)
[2019-01-26 20:13:12,973] WARN [Log partition=globalTableHoldON-0, dir=C:\tmp\logs2] retention.ms for topic globalTableHoldON is set to 604800000. It is smaller than message.timestamp.difference.max.ms's value 9223372036854775807. This may result in frequent log rolling. (kafka.log.Log)
[2019-01-26 20:13:12,973] WARN [Log partition=globalTableHoldON-0, dir=C:\tmp\logs1] retention.ms for topic globalTableHoldON is set to 604800000. It is smaller than message.timestamp.difference.max.ms's value 9223372036854775807. This may result in frequent log rolling. (kafka.log.Log)
[2019-01-26 20:13:12,973] INFO Processed session termination for sessionid: 0x1000aa9390f000c (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-26 20:13:12,973] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:62710 which had sessionid 0x1000aa9390f000c (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-26 20:13:21,740] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-51021 in state PreparingRebalance with old generation 0 (__consumer_offsets-0) (reason: Adding new member consumer-1-e2f5476f-c6e9-40fd-af7d-30619a916afc) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:13:21,740] INFO [GroupCoordinator 2]: Stabilized group console-consumer-51021 generation 1 (__consumer_offsets-0) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:13:21,756] INFO [GroupCoordinator 2]: Assignment received from leader for group console-consumer-51021 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:13:37,790] INFO [GroupCoordinator 2]: Member consumer-1-e2f5476f-c6e9-40fd-af7d-30619a916afc in group console-consumer-51021 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:13:37,790] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-51021 in state PreparingRebalance with old generation 1 (__consumer_offsets-0) (reason: removing member consumer-1-e2f5476f-c6e9-40fd-af7d-30619a916afc on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:13:37,790] INFO [GroupCoordinator 2]: Group console-consumer-51021 with generation 2 is now empty (__consumer_offsets-0) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:13:40,593] INFO [GroupCoordinator 1]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-46d5c3fe-6883-42bf-b2ef-9fed812fb925-StreamThread-1-consumer-a078d570-eefc-4253-8698-938ebbf40a43) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:13:40,593] INFO [GroupCoordinator 1]: Stabilized group alltoolsStream generation 1 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:13:40,608] INFO [GroupCoordinator 1]: Assignment received from leader for group alltoolsStream for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:13:59,651] INFO [GroupCoordinator 1]: Member alltoolsStream-46d5c3fe-6883-42bf-b2ef-9fed812fb925-StreamThread-1-consumer-a078d570-eefc-4253-8698-938ebbf40a43 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:13:59,651] INFO [GroupCoordinator 1]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: removing member alltoolsStream-46d5c3fe-6883-42bf-b2ef-9fed812fb925-StreamThread-1-consumer-a078d570-eefc-4253-8698-938ebbf40a43 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:13:59,651] INFO [GroupCoordinator 1]: Group alltoolsStream with generation 2 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:14:59,966] INFO [GroupMetadataManager brokerId=1] Group console-consumer-7542 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 20:14:59,966] INFO [GroupMetadataManager brokerId=1] Group alltoolsStream transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 20:14:59,966] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 20:15:16,808] INFO [GroupMetadataManager brokerId=2] Group console-consumer-51021 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 20:15:16,824] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 20:15:36,882] INFO [GroupMetadataManager brokerId=3] Group console-consumer-28537 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 20:15:36,882] INFO [GroupMetadataManager brokerId=3] Group console-consumer-39884 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 20:15:36,882] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 20:24:59,966] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 20:25:16,808] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 20:25:36,895] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 20:29:21,439] INFO [GroupCoordinator 1]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-c4916116-78e0-4d9e-8a92-ac4e7a75b710-StreamThread-1-consumer-c1369573-a8db-4ddf-9c86-ec908b835608) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:29:21,439] INFO [GroupCoordinator 1]: Stabilized group alltoolsStream generation 1 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:29:21,455] INFO [GroupCoordinator 1]: Assignment received from leader for group alltoolsStream for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:29:31,474] INFO [GroupCoordinator 1]: Member alltoolsStream-c4916116-78e0-4d9e-8a92-ac4e7a75b710-StreamThread-1-consumer-c1369573-a8db-4ddf-9c86-ec908b835608 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:29:31,474] INFO [GroupCoordinator 1]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: removing member alltoolsStream-c4916116-78e0-4d9e-8a92-ac4e7a75b710-StreamThread-1-consumer-c1369573-a8db-4ddf-9c86-ec908b835608 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:29:31,474] INFO [GroupCoordinator 1]: Group alltoolsStream with generation 2 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:30:35,120] INFO [GroupCoordinator 1]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 2 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-28c9fb09-72e7-4653-b854-b2f7155ab51a-StreamThread-1-consumer-e840a297-cbfd-4483-9210-7aa90744935d) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:30:35,120] INFO [GroupCoordinator 1]: Stabilized group alltoolsStream generation 3 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:30:35,120] INFO [GroupCoordinator 1]: Assignment received from leader for group alltoolsStream for generation 3 (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:30:45,129] INFO [GroupCoordinator 1]: Member alltoolsStream-28c9fb09-72e7-4653-b854-b2f7155ab51a-StreamThread-1-consumer-e840a297-cbfd-4483-9210-7aa90744935d in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:30:45,129] INFO [GroupCoordinator 1]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 3 (__consumer_offsets-2) (reason: removing member alltoolsStream-28c9fb09-72e7-4653-b854-b2f7155ab51a-StreamThread-1-consumer-e840a297-cbfd-4483-9210-7aa90744935d on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:30:45,129] INFO [GroupCoordinator 1]: Group alltoolsStream with generation 4 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:30:45,145] INFO [GroupCoordinator 1]: Member alltoolsStream-28c9fb09-72e7-4653-b854-b2f7155ab51a-StreamThread-1-consumer-e840a297-cbfd-4483-9210-7aa90744935d in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:33:15,808] INFO [GroupCoordinator 1]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 4 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-97e87805-fefd-4024-82e1-a27761524de6-StreamThread-1-consumer-455548a6-b04e-4833-8b0f-413333a85e21) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:33:15,808] INFO [GroupCoordinator 1]: Stabilized group alltoolsStream generation 5 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:33:15,824] INFO [GroupCoordinator 1]: Assignment received from leader for group alltoolsStream for generation 5 (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:33:25,843] INFO [GroupCoordinator 1]: Member alltoolsStream-97e87805-fefd-4024-82e1-a27761524de6-StreamThread-1-consumer-455548a6-b04e-4833-8b0f-413333a85e21 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:33:25,843] INFO [GroupCoordinator 1]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 5 (__consumer_offsets-2) (reason: removing member alltoolsStream-97e87805-fefd-4024-82e1-a27761524de6-StreamThread-1-consumer-455548a6-b04e-4833-8b0f-413333a85e21 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:33:25,843] INFO [GroupCoordinator 1]: Group alltoolsStream with generation 6 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 20:34:59,963] INFO [GroupMetadataManager brokerId=1] Group alltoolsStream transitioned to Dead in generation 6 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 20:34:59,963] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 20:35:16,819] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 20:35:36,880] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 20:44:59,958] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 20:45:16,813] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 20:45:36,886] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 20:54:59,966] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 20:55:16,806] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 20:55:36,895] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 21:04:59,952] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 21:05:16,807] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 21:05:36,881] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 21:14:59,959] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 21:15:16,817] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 21:15:36,893] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 21:19:30,873] INFO [GroupCoordinator 1]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member alltoolsStream-15cc960e-5e24-4fad-9abb-6ae3909844ee-StreamThread-1-consumer-a7c2a3e2-8355-45a1-8845-eb2591257468) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 21:19:30,873] INFO [GroupCoordinator 1]: Stabilized group alltoolsStream generation 1 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 21:19:30,873] INFO [GroupCoordinator 1]: Assignment received from leader for group alltoolsStream for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 21:24:59,954] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 21:25:16,805] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 21:25:36,893] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 21:32:15,996] INFO [GroupCoordinator 1]: Member alltoolsStream-15cc960e-5e24-4fad-9abb-6ae3909844ee-StreamThread-1-consumer-a7c2a3e2-8355-45a1-8845-eb2591257468 in group alltoolsStream has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 21:32:15,996] INFO [GroupCoordinator 1]: Preparing to rebalance group alltoolsStream in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: removing member alltoolsStream-15cc960e-5e24-4fad-9abb-6ae3909844ee-StreamThread-1-consumer-a7c2a3e2-8355-45a1-8845-eb2591257468 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 21:32:15,996] INFO [GroupCoordinator 1]: Group alltoolsStream with generation 2 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-01-26 21:34:59,965] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 21:35:16,807] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 21:35:36,880] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 21:44:59,957] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 21:45:16,812] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 21:45:36,890] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 21:54:59,953] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 21:55:16,808] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 21:55:36,886] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 22:04:59,955] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 22:05:16,809] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 22:05:36,885] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 22:14:59,963] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 22:15:16,817] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 22:15:36,883] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 22:24:59,968] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 22:25:16,805] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 22:25:36,880] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 22:34:59,964] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 22:35:16,805] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 22:35:36,881] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 22:44:59,952] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 22:45:16,805] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 22:45:36,880] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 22:54:59,953] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 22:55:16,806] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 22:55:36,891] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 23:04:59,965] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 23:05:16,804] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-26 23:05:36,887] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
